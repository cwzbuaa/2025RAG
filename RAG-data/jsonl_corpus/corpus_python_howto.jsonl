{"doc_id": "e6bf796d", "content": "asyncio 的概念概述\n这篇 指南 旨在帮助您充分理解 asyncio 的基本运作原理，并使您理解推荐模式背后的原理和原\n因。\n你可能会对某些关键的 asyncio 概念感到好奇。 读完本文后，你将能够轻松地回答这些问题：\n当一个对象被等待时，幕后发生了什么？\nasyncio 如何区分不需要 CPU 时间的任务（如网络请求或文件读取）和与之相反的任务（如计算\nn 的阶乘）？\n如何编写一个操作的异步变体，例如异步的休眠或数据库请求。\n参见:\n启发这篇指南文章的 指南 ，作者是 Alexander Nordin。\n这套深入讲解 asyncio 的 YouTube 教程系列，由 Python 核心团队成员 Łukasz Langa 制作。\n500 Lines or Less: A Web Crawler With asyncio Coroutines，作者是 A. Jesse Jiryu Davis 和\nGuido van Rossum。\n概念概述第 1 部分：高层次\n在第 1 部分中，我们将介绍主要的、高层级的 asyncio 构成部分：事件循环、协程函数、协程对\n象、任务和 await。\n事件循环\nasyncio 中的一切都与事件循环相关。它是演出的主角。它就像一名乐队指挥一样在幕后管理资\n源。它掌握着一些权力，但它完成工作的能力很大程度上来自于它的工蜂们的尊重与合作。\n用更专业的术语来说，事件循环包含一组待运行的作业。 有些作业是由你直接添加的，有些则是由\nasyncio 间接添加的。 事件循环会从其待处理事项中取出一个作业并唤起它（或称“给予其控制\n权”），类似于调用一个函数，然后该作业就会运行。 一旦它暂停或完成，它会将控制权返回给事件\n循环。 然后事件循环会从作业池中选择另一个作业并唤起它。 你可以 粗略地 将这组作业视为一个\n队列：作业被添加然后被逐个处理，通常（但不总是）按顺序进行。 此过程将无限地重复，事件循\n环也不停地循环下去。 如果没有待执行的作业，事件循环会足够智能地转入休息状态以避免浪费\nCPU 周期，并在有更多工作需完成时恢复运行。\n有效的执行依赖于作业的良好共享和合作；一个贪婪的作业可能会霸占控制权，让其他作业陷入饥\n饿，从而使整个事件循环机制变得毫无用处。\nimport asyncio\n# 这会创建一个事件循环并无限循环地执行其作业集合。\n\n| asyncio 的概念概述\n这篇 指南 旨在帮助您充分理解 asyncio 的基本运作原理，并使您理解推荐模式背后的原理和原\n因。\n你可能会对某些关键的 asyncio 概念感到好奇。 读完本文后，你将能够轻松地回答这些问题：\n当一个对象被等待时，幕后发生了什么？\nasyncio 如何区分不需要 CPU 时间的任务（如网络请求或文件读取）和与之相反的任务（如计算\nn 的阶乘）？\n如何编写一个操作的异步变体，例如异步的休眠或数据库请求。 |\n| --- |\n| 参见:\n启发这篇指南文章的 指南 ，作者是 Alexander Nordin。\n这套深入讲解 asyncio 的 YouTube 教程系列，由 Python 核心团队成员 Łukasz Langa 制作。\n500 Lines or Less: A Web Crawler With asyncio Coroutines，作者是 A. Jesse Jiryu Davis 和\nGuido van Rossum。 |\n| 概念概述第 1 部分：高层次\n在第 1 部分中，我们将介绍主要的、高层级的 asyncio 构成部分：事件循环、协程函数、协程对\n象、任务和 await。\n事件循环\nasyncio 中的一切都与事件循环相关。它是演出的主角。它就像一名乐队指挥一样在幕后管理资\n源。它掌握着一些权力，但它完成工作的能力很大程度上来自于它的工蜂们的尊重与合作。\n用更专业的术语来说，事件循环包含一组待运行的作业。 有些作业是由你直接添加的，有些则是由\nasyncio 间接添加的。 事件循环会从其待处理事项中取出一个作业并唤起它（或称“给予其控制\n权”），类似于调用一个函数，然后该作业就会运行。 一旦它暂停或完成，它会将控制权返回给事件\n循环。 然后事件循环会从作业池中选择另一个作业并唤起它。 你可以 粗略地 将这组作业视为一个\n队列：作业被添加然后被逐个处理，通常（但不总是）按顺序进行。 此过程将无限地重复，事件循\n环也不停地循环下去。 如果没有待执行的作业，事件循环会足够智能地转入休息状态以避免浪费\nCPU 周期，并在有更多工作需完成时恢复运行。\n有效的执行依赖于作业的良好共享和合作；一个贪婪的作业可能会霸占控制权，让其他作业陷入饥\n饿，从而使整个事件循环机制变得毫无用处。 |\n| import asyncio\n# 这会创建一个事件循环并无限循环地执行其作业集合。 |\n\nevent_loop = asyncio.new_event_loop()\nevent_loop.run_forever()\n异步函数和协程\n这是一个基本的、无趣的Python 函数：\ndef hello_printer():\nprint(\n\"Hi, I am a lowly, simple printer, though I have all I \"\n\"need in life -- \\nfresh paper and my dearly beloved octopus \"\n\"partner in crime.\"\n)\n调用一个普通函数会执行它的逻辑或函数体：\n>>> hello_printer()\nHi, I am a lowly, simple printer, though I have all I need in life --\nfresh paper and my dearly beloved octopus partner in crime.\n与普通的 def 不同，async def 使它成为一个异步函数（或“协程函数”）。调用它会创建并返回一个\n协程 对象。\nasync def loudmouth_penguin(magic_number: int):\nprint(\n\"I am a super special talking penguin. Far cooler than that printer. \"\nf\"By the way, my lucky number is: {magic_number}.\"\n)\n调用异步函数 loudmouth_penguin 不会执行打印语句 ；相反，它会创建一个协程对象：\n>>> loudmouth_penguin(magic_number=3)\n<coroutine object loudmouth_penguin at 0x104ed2740>\n“协程函数”和“协程对象”这两个术语经常被统称为协程。这可能会引起混淆！在本文中，协程特指协\n程 对象，或者更准确地说，是 types.CoroutineType 的实例 （原生协程 ）。请注意，协程也可以\n作为 collections.abc.Coroutine 的实例存在——这一点对于类型检查来说很重要。\n协程代表函数体或逻辑。协程必须显式启动；再次强调，仅仅创建协程并不能启动它。值得注意的\n是，协程可以在函数体的不同位置暂停和恢复。这种暂停和恢复能力使得异步行为成为可能！\n协程和协程函数是利用 生成器 和 生成器函数 构建的。回想一下，生成器函数是一个会 yield 的函\n数，就像这样：\ndef get_random_number():\n# 这是一个糟糕的随机数生成器！\nprint(\"Hi\")\nyield 1\nprint(\"Hello\")\nyield 7\nprint(\"Howdy\")\nyield 4\n...\n\n|  | event_loop = asyncio.new_event_loop()\nevent_loop.run_forever() |  |\n| --- | --- | --- |\n|  | 异步函数和协程\n这是一个基本的、无趣的Python 函数： |  |\n|  | def hello_printer():\nprint(\n\"Hi, I am a lowly, simple printer, though I have all I \"\n\"need in life -- \\nfresh paper and my dearly beloved octopus \"\n\"partner in crime.\"\n) |  |\n|  | 调用一个普通函数会执行它的逻辑或函数体： |  |\n|  | >>> hello_printer()\nHi, I am a lowly, simple printer, though I have all I need in life --\nfresh paper and my dearly beloved octopus partner in crime. |  |\n|  | 与普通的 def 不同，async def 使它成为一个异步函数（或“协程函数”）。调用它会创建并返回一个\n协程 对象。 |  |\n|  | async def loudmouth_penguin(magic_number: int):\nprint(\n\"I am a super special talking penguin. Far cooler than that printer. \"\nf\"By the way, my lucky number is: {magic_number}.\"\n) |  |\n|  | 调用异步函数 loudmouth_penguin 不会执行打印语句 ；相反，它会创建一个协程对象： |  |\n|  | >>> loudmouth_penguin(magic_number=3)\n<coroutine object loudmouth_penguin at 0x104ed2740> |  |\n|  | “协程函数”和“协程对象”这两个术语经常被统称为协程。这可能会引起混淆！在本文中，协程特指协\n程 对象，或者更准确地说，是 types.CoroutineType 的实例 （原生协程 ）。请注意，协程也可以\n作为 collections.abc.Coroutine 的实例存在——这一点对于类型检查来说很重要。\n协程代表函数体或逻辑。协程必须显式启动；再次强调，仅仅创建协程并不能启动它。值得注意的\n是，协程可以在函数体的不同位置暂停和恢复。这种暂停和恢复能力使得异步行为成为可能！\n协程和协程函数是利用 生成器 和 生成器函数 构建的。回想一下，生成器函数是一个会 yield 的函\n数，就像这样： |  |\n|  | def get_random_number():\n# 这是一个糟糕的随机数生成器！\nprint(\"Hi\")\nyield 1\nprint(\"Hello\")\nyield 7\nprint(\"Howdy\")\nyield 4\n... |  |\n\n与协程函数类似，调用生成器函数并不会运行该函数，而是创建一个生成器对象：\n>>> get_random_number()\n<generator object get_random_number at 0x1048671c0>\n你可以通过内置函数 next() 执行生成器到下一个 yield。换句话说，生成器运行，然后暂停。例\n如：\n>>> generator = get_random_number()\n>>> next(generator)\nHi\n1\n>>> next(generator)\nHello\n7\n任务\n粗略地说，任务 是绑定到事件循环的协程（而非协程函数）。任务还维护一个回调函数列表，这些\n回调函数的重要性在稍后讨论 await 时会更加清晰。推荐使用 asyncio.create_task() 创建任\n务。\n创建任务会自动安排它的执行（通过在事件循环的待办事项列表（即作业集合）中添加回调函数来\n运行它）。\n由于（每个线程中）只有一个事件循环，asyncio 会帮你把任务与事件循环关联起来。因此，你无\n需指定事件循环。\ncoroutine = loudmouth_penguin(magic_number=5)\n# 这将创建一个 Task 对象并通过事件循环安排其执行。\ntask = asyncio.create_task(coroutine)\n之前，我们手动创建了事件循环并将其设置为永久运行。实际上，推荐（且常见）的做法是使用\nasyncio.run()，它负责管理事件循环并确保提供的协程在继续执行之前结束。例如，许多异步程\n序都遵循以下设置：\nimport asyncio\nasync def main():\n# 执行各种稀奇古怪、天马行空的异步操作……\n...\nif __name__ == \"__main__\":\nasyncio.run(main())\n# 直到协程 main() 结束，程序才会到达下面的打印语句。\nprint(\"coroutine main() is done!\")\n需要注意的是，任务本身不会被添加到事件循环中，只有任务的回调函数才会被添加到事件循环\n中。如果你创建的任务对象在被事件循环调用之前就被垃圾回收了，这就会产生问题。例如，考虑\n这个程序：\n\n|  | 与协程函数类似，调用生成器函数并不会运行该函数，而是创建一个生成器对象： |  |\n| --- | --- | --- |\n|  | >>> get_random_number()\n<generator object get_random_number at 0x1048671c0> |  |\n|  | 你可以通过内置函数 next() 执行生成器到下一个 yield。换句话说，生成器运行，然后暂停。例\n如： |  |\n|  | >>> generator = get_random_number()\n>>> next(generator)\nHi\n1\n>>> next(generator)\nHello\n7 |  |\n|  | 任务\n粗略地说，任务 是绑定到事件循环的协程（而非协程函数）。任务还维护一个回调函数列表，这些\n回调函数的重要性在稍后讨论 await 时会更加清晰。推荐使用 asyncio.create_task() 创建任\n务。\n创建任务会自动安排它的执行（通过在事件循环的待办事项列表（即作业集合）中添加回调函数来\n运行它）。\n由于（每个线程中）只有一个事件循环，asyncio 会帮你把任务与事件循环关联起来。因此，你无\n需指定事件循环。 |  |\n|  | coroutine = loudmouth_penguin(magic_number=5)\n# 这将创建一个 Task 对象并通过事件循环安排其执行。\ntask = asyncio.create_task(coroutine) |  |\n|  | 之前，我们手动创建了事件循环并将其设置为永久运行。实际上，推荐（且常见）的做法是使用\nasyncio.run()，它负责管理事件循环并确保提供的协程在继续执行之前结束。例如，许多异步程\n序都遵循以下设置： |  |\n|  | import asyncio\nasync def main():\n# 执行各种稀奇古怪、天马行空的异步操作……\n...\nif __name__ == \"__main__\":\nasyncio.run(main())\n# 直到协程 main() 结束，程序才会到达下面的打印语句。\nprint(\"coroutine main() is done!\") |  |\n|  | 需要注意的是，任务本身不会被添加到事件循环中，只有任务的回调函数才会被添加到事件循环\n中。如果你创建的任务对象在被事件循环调用之前就被垃圾回收了，这就会产生问题。例如，考虑\n这个程序： |  |\n\n1 async def hello():\n2 print(\"hello!\")\n3\n4 async def main():\n5 asyncio.create_task(hello())\n6 # 其他异步指令运行一段时间并将控制权交还给事件循环......\n7 ...\n8\n9 asyncio.run(main())\n由于没有对第 5 行创建的任务对象的引用，它 可能 在事件循环调用它之前就被垃圾回收了。协程\nmain() 中的后续指令将控制权交还给事件循环，以便它可以调用其他作业。当事件循环最终尝试运\n行该任务时，它可能会失败并发现任务对象不存在！即使协程持有对某个任务的引用，但如果协程\n在该任务结束之前就完成了，也可能发生这种情况。当协程退出时，局部变量超出范围，可能被垃\n圾回收。实际上，asyncio 和 Python 的垃圾回收器会非常努力地确保此类事情不会发生。但这并不\n是鲁莽行事的理由！\nawait\nawait 是一个 Python 关键字，通常以两种不同的方式使用：\nawait task\nawait coroutine\n从关键方面来说，await 的行为取决于所等待对象的类型。\n等待任务会将控制权从当前任务或协程交还给事件循环。在交还控制权的过程中，会发生一些重要\n的事情。我们将使用以下代码示例来说明：\nasync def plant_a_tree():\ndig_the_hole_task = asyncio.create_task(dig_the_hole())\nawait dig_the_hole_task\n# 与植树相关的其他指令。\n...\n在这个例子中，假设事件循环已经将控制权交给了协程 plant_a_tree() 的开始部分。如上所示，\n协程创建了一个任务，然后对其执行了 await。await dig_the_hole_task 这条指令会将一个回调\n函数（用于恢复 plant_a_tree() 的执行）添加到 dig_the_hole_task 对象的回调函数列表中。随\n后，这条指令将控制权交还给事件循环。过一段时间后，事件循环会将控制权传递给\ndig_the_hole_task，该任务会完成它需要做的工作。一旦任务结束，它会将它的各种回调函数添\n加到事件循环中，在这里是恢复 plant_a_tree() 的执行。\n一般来说，当等待的任务完成时 (dig_the_hole_task)，原先的任务或协程 (plant_a_tree()) 将被\n添加回事件循环的待办列表以便恢复运行。\n这是一个基础但可靠的思维模型。实际操作中，控制权交接会稍微复杂一些，但不会复杂太多。在\n第 2 部分中，我们将逐步讲解实现这一目标的细节。\n\n|  | 1 async def hello():\n2 print(\"hello!\")\n3\n4 async def main():\n5 asyncio.create_task(hello())\n6 # 其他异步指令运行一段时间并将控制权交还给事件循环......\n7 ...\n8\n9 asyncio.run(main()) |  |\n| --- | --- | --- |\n|  | 由于没有对第 5 行创建的任务对象的引用，它 可能 在事件循环调用它之前就被垃圾回收了。协程\nmain() 中的后续指令将控制权交还给事件循环，以便它可以调用其他作业。当事件循环最终尝试运\n行该任务时，它可能会失败并发现任务对象不存在！即使协程持有对某个任务的引用，但如果协程\n在该任务结束之前就完成了，也可能发生这种情况。当协程退出时，局部变量超出范围，可能被垃\n圾回收。实际上，asyncio 和 Python 的垃圾回收器会非常努力地确保此类事情不会发生。但这并不\n是鲁莽行事的理由！\nawait\nawait 是一个 Python 关键字，通常以两种不同的方式使用： |  |\n|  | await task\nawait coroutine |  |\n|  | 从关键方面来说，await 的行为取决于所等待对象的类型。\n等待任务会将控制权从当前任务或协程交还给事件循环。在交还控制权的过程中，会发生一些重要\n的事情。我们将使用以下代码示例来说明： |  |\n|  | async def plant_a_tree():\ndig_the_hole_task = asyncio.create_task(dig_the_hole())\nawait dig_the_hole_task\n# 与植树相关的其他指令。\n... |  |\n|  | 在这个例子中，假设事件循环已经将控制权交给了协程 plant_a_tree() 的开始部分。如上所示，\n协程创建了一个任务，然后对其执行了 await。await dig_the_hole_task 这条指令会将一个回调\n函数（用于恢复 plant_a_tree() 的执行）添加到 dig_the_hole_task 对象的回调函数列表中。随\n后，这条指令将控制权交还给事件循环。过一段时间后，事件循环会将控制权传递给\ndig_the_hole_task，该任务会完成它需要做的工作。一旦任务结束，它会将它的各种回调函数添\n加到事件循环中，在这里是恢复 plant_a_tree() 的执行。\n一般来说，当等待的任务完成时 (dig_the_hole_task)，原先的任务或协程 (plant_a_tree()) 将被\n添加回事件循环的待办列表以便恢复运行。\n这是一个基础但可靠的思维模型。实际操作中，控制权交接会稍微复杂一些，但不会复杂太多。在\n第 2 部分中，我们将逐步讲解实现这一目标的细节。 |  |\n\n与任务不同，等待协程并不会将控制权交还给事件循环！ 先将协程包装到任务中，然后再等待，会\n导致控制权交还。await coroutine 的行为实际上与调用常规的同步 Python 函数相同。考虑以下\n程序：\nimport asyncio\nasync def coro_a():\nprint(\"I am coro_a(). Hi!\")\nasync def coro_b():\nprint(\"I am coro_b(). I sure hope no one hogs the event loop...\")\nasync def main():\ntask_b = asyncio.create_task(coro_b())\nnum_repeats = 3\nfor _ in range(num_repeats):\nawait coro_a()\nawait task_b\nasyncio.run(main())\n协程 main() 中的第一条语句创建了 task_b 并调度它通过事件循环运行。 然后，将重复地等待\ncoro_a()。 控制权从未被交还给事件循环，这就是为什么在 coro_b() 的输出之前我们会看到所有\n三次唤起 coro_a() 的输出。invocations before\nI am coro_a(). Hi!\nI am coro_a(). Hi!\nI am coro_a(). Hi!\nI am coro_b(). I sure hope no one hogs the event loop...\n如果我们将 await coro_a() 改为 await asyncio.create_task(coro_a())，行为就会发生变\n化。协程 main() 会通过该语句将控制权交还给事件循环。然后，事件循环会继续处理其积压的工\n作，先调用 task_b，然后调用包装 coro_a() 的任务，最后恢复协程 main()。\nI am coro_b(). I sure hope no one hogs the event loop...\nI am coro_a(). Hi!\nI am coro_a(). Hi!\nI am coro_a(). Hi!\n这种 await coroutine 的行为可能会困扰很多人！ 这个例子强调了仅使用 await coroutine 可能\n会无意中霸占其他任务的控制权并在实际上阻滞事件循环。 asyncio.run() 可以通过 debug=True\n旗标来检测这种情况，它将会启用 调试模式。 此外，它还会记录任何独占执行时间 100 毫秒以上的\n协程。\n该设计有意牺牲了 await 用法的某些概念明晰度以提升性能。 每当有任务被等待时，控制权都需要\n沿着调用栈一路向上传递到事件循环。 这听起来可能微不足道，但在一个具有大量 await 语句和深\n度调用栈的大型程序中，这种开销可能会累积到明显拖累性能。\n概念概述第 2 部分：核心细节与运作机制\n\n|  | 与任务不同，等待协程并不会将控制权交还给事件循环！ 先将协程包装到任务中，然后再等待，会\n导致控制权交还。await coroutine 的行为实际上与调用常规的同步 Python 函数相同。考虑以下\n程序： |  |\n| --- | --- | --- |\n|  | import asyncio\nasync def coro_a():\nprint(\"I am coro_a(). Hi!\")\nasync def coro_b():\nprint(\"I am coro_b(). I sure hope no one hogs the event loop...\")\nasync def main():\ntask_b = asyncio.create_task(coro_b())\nnum_repeats = 3\nfor _ in range(num_repeats):\nawait coro_a()\nawait task_b\nasyncio.run(main()) |  |\n|  | 协程 main() 中的第一条语句创建了 task_b 并调度它通过事件循环运行。 然后，将重复地等待\ncoro_a()。 控制权从未被交还给事件循环，这就是为什么在 coro_b() 的输出之前我们会看到所有\n三次唤起 coro_a() 的输出。invocations before |  |\n|  | I am coro_a(). Hi!\nI am coro_a(). Hi!\nI am coro_a(). Hi!\nI am coro_b(). I sure hope no one hogs the event loop... |  |\n|  | 如果我们将 await coro_a() 改为 await asyncio.create_task(coro_a())，行为就会发生变\n化。协程 main() 会通过该语句将控制权交还给事件循环。然后，事件循环会继续处理其积压的工\n作，先调用 task_b，然后调用包装 coro_a() 的任务，最后恢复协程 main()。 |  |\n|  | I am coro_b(). I sure hope no one hogs the event loop...\nI am coro_a(). Hi!\nI am coro_a(). Hi!\nI am coro_a(). Hi! |  |\n|  | 这种 await coroutine 的行为可能会困扰很多人！ 这个例子强调了仅使用 await coroutine 可能\n会无意中霸占其他任务的控制权并在实际上阻滞事件循环。 asyncio.run() 可以通过 debug=True\n旗标来检测这种情况，它将会启用 调试模式。 此外，它还会记录任何独占执行时间 100 毫秒以上的\n协程。\n该设计有意牺牲了 await 用法的某些概念明晰度以提升性能。 每当有任务被等待时，控制权都需要\n沿着调用栈一路向上传递到事件循环。 这听起来可能微不足道，但在一个具有大量 await 语句和深\n度调用栈的大型程序中，这种开销可能会累积到明显拖累性能。\n概念概述第 2 部分：核心细节与运作机制 |  |\n\n第 2 部分将详细介绍 asyncio 用于管理控制流的机制。这正是魔法发生的地方。读完本节后，您将\n了解 await 在幕后做了什么，以及如何创建您自己的异步运算符。\n协程的内部工作原理\nasyncio 利用四个组件来传递控制权。\ncoroutine.send(arg) 是用于启动或恢复协程的方法。 如果协程已暂停并正在被恢复，则参数 arg\n将作为原先暂停它的 yield 语句的返回值被发送。 如果协程是首次被使用（而不是被恢复），则\narg 必须为 None。\n1 class Rock:\n2 def __await__(self):\n3 value_sent_in = yield 7\n4 print(f\"Rock.__await__ resuming with value: {value_sent_in}.\")\n5 return value_sent_in\n6\n7 async def main():\n8 print(\"Beginning coroutine main().\")\n9 rock = Rock()\n10 print(\"Awaiting rock...\")\n11 value_from_rock = await rock\n12 print(f\"Coroutine received value: {value_from_rock} from rock.\")\n13 return 23\n14\n15 coroutine = main()\n16 intermediate_result = coroutine.send(None)\n17 print(f\"Coroutine paused and returned intermediate value: {intermediate_result}\n18\n19 print(f\"Resuming coroutine and sending in value: 42.\")\n20 try:\n21 coroutine.send(42)\n22 except StopIteration as e:\n23 returned_value = e.value\n24 print(f\"Coroutine main() finished and provided value: {returned_value}.\")\nyield 像往常一样暂停执行并将控制权返回给调用者。 在上面的例子中，第 3 行的 yield 被第 11 行\n的 ... = await rock 调用。 更宽泛地说，await 会调用给定对象的 __await__() 方法。 await\n还会做一件非常特别的事情：它会将接收到的任何 yield 沿着调用链向上传播（或称“传递”）。 在\n本例中，这将回到第 16 行的 ... = coroutine.send(None)。\n协程通过第 21 行的 coroutine.send(42) 调用恢复。协程从第 3 行 yield (或暂停) 的位置继续执\n行，并执行其主体中的剩余语句。协程完成后，它会引发一个 StopIteration 异常，并将返回值附\n加在 value 属性中。\n该代码片段产生以下输出：\nBeginning coroutine main().\nAwaiting rock...\nCoroutine paused and returned intermediate value: 7.\nResuming coroutine and sending in value: 42.\nRock.__await__ resuming with value: 42.\n\n|  | 第 2 部分将详细介绍 asyncio 用于管理控制流的机制。这正是魔法发生的地方。读完本节后，您将\n了解 await 在幕后做了什么，以及如何创建您自己的异步运算符。\n协程的内部工作原理\nasyncio 利用四个组件来传递控制权。\ncoroutine.send(arg) 是用于启动或恢复协程的方法。 如果协程已暂停并正在被恢复，则参数 arg\n将作为原先暂停它的 yield 语句的返回值被发送。 如果协程是首次被使用（而不是被恢复），则\narg 必须为 None。 |  |  |\n| --- | --- | --- | --- |\n|  | 1 class Rock:\n2 def __await__(self):\n3 value_sent_in = yield 7\n4 print(f\"Rock.__await__ resuming with value: {value_sent_in}.\")\n5 return value_sent_in\n6\n7 async def main():\n8 print(\"Beginning coroutine main().\")\n9 rock = Rock()\n10 print(\"Awaiting rock...\")\n11 value_from_rock = await rock\n12 print(f\"Coroutine received value: {value_from_rock} from rock.\")\n13 return 23\n14\n15 coroutine = main()\n16 intermediate_result = coroutine.send(None)\n17 print(f\"Coroutine paused and returned intermediate value: {intermediate_result\n18\n19 print(f\"Resuming coroutine and sending in value: 42.\")\n20 try:\n21 coroutine.send(42)\n22 except StopIteration as e:\n23 returned_value = e.value\n24 print(f\"Coroutine main() finished and provided value: {returned_value}.\") | } |  |\n|  | yield 像往常一样暂停执行并将控制权返回给调用者。 在上面的例子中，第 3 行的 yield 被第 11 行\n的 ... = await rock 调用。 更宽泛地说，await 会调用给定对象的 __await__() 方法。 await\n还会做一件非常特别的事情：它会将接收到的任何 yield 沿着调用链向上传播（或称“传递”）。 在\n本例中，这将回到第 16 行的 ... = coroutine.send(None)。\n协程通过第 21 行的 coroutine.send(42) 调用恢复。协程从第 3 行 yield (或暂停) 的位置继续执\n行，并执行其主体中的剩余语句。协程完成后，它会引发一个 StopIteration 异常，并将返回值附\n加在 value 属性中。\n该代码片段产生以下输出： |  |  |\n|  | Beginning coroutine main().\nAwaiting rock...\nCoroutine paused and returned intermediate value: 7.\nResuming coroutine and sending in value: 42.\nRock.__await__ resuming with value: 42. |  |  |\n\nCoroutine received value: 42 from rock.\nCoroutine main() finished and provided value: 23.\n这里值得暂停一下，确保您已经理解了控制流和值传递的各种方式。我们涵盖了很多重要的概念，\n确保您理解得足够牢固。\n从协程中“yield”（或有效地放弃控制权）的唯一方法是 await 一个在其 __await__ 方法中 yield\n的对象。这听起来可能有点奇怪。你可能会想：\n1. What about a yield directly within the coroutine function? The coroutine function becomes\nan async generator function, a different beast entirely.\n2. What about a yield from within the coroutine function to a (plain) generator? That causes the\nerror: SyntaxError: yield from not allowed in a coroutine. This was intentionally\ndesigned for the sake of simplicity -- mandating only one way of using coroutines. Initially\nyield was barred as well, but was re-accepted to allow for async generators. Despite that, yield\nfrom and await effectively do the same thing.\nFuture\nFuture 是一个用来表示计算状态和结果的对象。该术语指的是尚未发生的事情，而 Future 对象则是\n一种用来关注这些事情的方式。\nFuture 对象有几个重要的属性。 其一是它的状态，可以是“待处理”、“已取消”或“已完成”。 其二是\n它的结果，当状态转换为已完成时它就会被设定。 与协程不同，Future 并不代表要执行的实际计\n算；相反，它代表该计算的状态和结果，有点像一个状态灯（红色、黄色或绿色）或指示器。\n为了获得这些功能，asyncio.Task 继承了 asyncio.Future 类。上一节提到任务存储了一个回调\n函数列表，这并不完全准确。实际上，实现这些逻辑的是 Future 类，而 Task 继承了它。\nFuture 也可以被直接使用（无需通过任务）。任务会在协程完成后将自身标记为已完成。而 Future\n的功能更加多样，由你来指定它何时标记为已完成。因此，Future 是一个灵活的接口，您可以自定\n义等待和恢复的条件。\n自制 asyncio.sleep\n我们将通过一个例子来说明如何利用 Future 来创建自己的异步睡眠变体（async_sleep），模仿了\nasyncio.sleep()。\n这个代码段在为事件循环注册了一些任务然后等待由 asyncio.create_task 创建的任务，它包装在\nasync_sleep(3) 协程中。 我们希望该任务在三秒之后才结束，但不会阻止其他任务的运行。\nasync def other_work():\nprint(\"I like work. Work work.\")\nasync def main():\n# 向事件循环添加一些其他任务，这样在异步休眠时就可以做一些事情。\nwork_tasks = [\nasyncio.create_task(other_work()),\nasyncio.create_task(other_work()),\n\n|  |  | Coroutine received value: 42 from rock.\nCoroutine main() finished and provided value: 23. |  |  |  |\n| --- | --- | --- | --- | --- | --- |\n|  |  | 这里值得暂停一下，确保您已经理解了控制流和值传递的各种方式。我们涵盖了很多重要的概念，\n确保您理解得足够牢固。\n从协程中“yield”（或有效地放弃控制权）的唯一方法是 await 一个在其 __await__ 方法中 yield\n的对象。这听起来可能有点奇怪。你可能会想：\n1. What about a yield directly within the coroutine function? The coroutine function becomes\nan async generator function, a different beast entirely.\n2. What about a yield from within the coroutine function to a (plain) generator? That causes the\nerror: SyntaxError: yield from not allowed in a coroutine. This was intentionally\ndesigned for the sake of simplicity -- mandating only one way of using coroutines. Initially\nyield was barred as well, but was re-accepted to allow for async generators. Despite that, yield\nfrom and await effectively do the same thing.\nFuture\nFuture 是一个用来表示计算状态和结果的对象。该术语指的是尚未发生的事情，而 Future 对象则是\n一种用来关注这些事情的方式。\nFuture 对象有几个重要的属性。 其一是它的状态，可以是“待处理”、“已取消”或“已完成”。 其二是\n它的结果，当状态转换为已完成时它就会被设定。 与协程不同，Future 并不代表要执行的实际计\n算；相反，它代表该计算的状态和结果，有点像一个状态灯（红色、黄色或绿色）或指示器。\n为了获得这些功能，asyncio.Task 继承了 asyncio.Future 类。上一节提到任务存储了一个回调\n函数列表，这并不完全准确。实际上，实现这些逻辑的是 Future 类，而 Task 继承了它。\nFuture 也可以被直接使用（无需通过任务）。任务会在协程完成后将自身标记为已完成。而 Future\n的功能更加多样，由你来指定它何时标记为已完成。因此，Future 是一个灵活的接口，您可以自定\n义等待和恢复的条件。\n自制 asyncio.sleep\n我们将通过一个例子来说明如何利用 Future 来创建自己的异步睡眠变体（async_sleep），模仿了\nasyncio.sleep()。\n这个代码段在为事件循环注册了一些任务然后等待由 asyncio.create_task 创建的任务，它包装在\nasync_sleep(3) 协程中。 我们希望该任务在三秒之后才结束，但不会阻止其他任务的运行。 |  |  |  |\n|  |  |  | yield |  |  |\n|  |  |  |  |  |  |\n|  |  | from |  |  |  |\n|  |  |  |  |  |  |\n|  |  | async def other_work():\nprint(\"I like work. Work work.\")\nasync def main():\n# 向事件循环添加一些其他任务，这样在异步休眠时就可以做一些事情。\nwork_tasks = [\nasyncio.create_task(other_work()),\nasyncio.create_task(other_work()), |  |  |  |\n\nasyncio.create_task(other_work())\n]\nprint(\n\"Beginning asynchronous sleep at time: \"\nf\"{datetime.datetime.now().strftime(\"%H:%M:%S\")}.\"\n)\nawait asyncio.create_task(async_sleep(3))\nprint(\n\"Done asynchronous sleep at time: \"\nf\"{datetime.datetime.now().strftime(\"%H:%M:%S\")}.\"\n)\n# asyncio.gather 有效地等待集合中的每个任务。\nawait asyncio.gather(*work_tasks)\n下面，我们使用 Future 来自定义控制何时将任务标记为已完成。如果 future.set_result()\n<asyncio.Future.set_result>`（负责将该 Future 标记为已完成的方法）从未被调用，那么该\n任务将永远不会结束。我们还借助了另一个任务（稍后会看到），它将监视已过去的时间，并相应\n地调用 ``future.set_result()`()。\nasync def async_sleep(seconds: float):\nfuture = asyncio.Future()\ntime_to_wake = time.time() + seconds\n# 将监视任务添加到事件循环。\nwatcher_task = asyncio.create_task(_sleep_watcher(future, time_to_wake))\n# 阻塞直到 future 被标记为已完成。\nawait future\n下面，我们将使用一个相当简单的 YieldToEventLoop() 对象从其 __await__ 方法中 yield，将控\n制权交还给事件循环。 这实际上与调用 asyncio.sleep(0) 相同，但这种方式更为明晰，更不用说\n在展示如何实现 asyncio.sleep 时直接使用它有点作弊！\n与往常一样，事件循环会轮番处理其任务，给予它们控制权并在它们暂停或完成时收回控制权。 运\n行 _sleep_watcher(...) 协程的 watcher_task 将在事件循环的每个完整周期中被唤起一次。 在\n每次恢复时，它将检查时间，如果经过的时间不够，则会再次暂停并将控制权交还给事件循环。 一\n旦经过了足够的时间，_sleep_watcher(...) 会将该 Future 标记为已完成并通过退出无限的\nwhile 循环来结束执行。 鉴于这个辅助任务在事件循环的每个周期中只会被唤起一次，因此你应该\n注意到这个异步休眠将 至少 休眠三秒，而不是恰好三秒。 请注意 asyncio.sleep 也同样如此。\nclass YieldToEventLoop:\ndef __await__(self):\nyield\nasync def _sleep_watcher(future, time_to_wake):\nwhile True:\nif time.time() >= time_to_wake:\n# 这标记 future 为已完成。\nfuture.set_result(None)\nbreak\nelse:\nawait YieldToEventLoop()\n以下是程序的完整输出：\n\n|  | asyncio.create_task(other_work())\n]\nprint(\n\"Beginning asynchronous sleep at time: \"\nf\"{datetime.datetime.now().strftime(\"%H:%M:%S\")}.\"\n)\nawait asyncio.create_task(async_sleep(3))\nprint(\n\"Done asynchronous sleep at time: \"\nf\"{datetime.datetime.now().strftime(\"%H:%M:%S\")}.\"\n)\n# asyncio.gather 有效地等待集合中的每个任务。\nawait asyncio.gather(*work_tasks) |  |\n| --- | --- | --- |\n|  | 下面，我们使用 Future 来自定义控制何时将任务标记为已完成。如果 future.set_result()\n<asyncio.Future.set_result>`（负责将该 Future 标记为已完成的方法）从未被调用，那么该\n任务将永远不会结束。我们还借助了另一个任务（稍后会看到），它将监视已过去的时间，并相应\n地调用 ``future.set_result()`()。 |  |\n|  | async def async_sleep(seconds: float):\nfuture = asyncio.Future()\ntime_to_wake = time.time() + seconds\n# 将监视任务添加到事件循环。\nwatcher_task = asyncio.create_task(_sleep_watcher(future, time_to_wake))\n# 阻塞直到 future 被标记为已完成。\nawait future |  |\n|  | 下面，我们将使用一个相当简单的 YieldToEventLoop() 对象从其 __await__ 方法中 yield，将控\n制权交还给事件循环。 这实际上与调用 asyncio.sleep(0) 相同，但这种方式更为明晰，更不用说\n在展示如何实现 asyncio.sleep 时直接使用它有点作弊！\n与往常一样，事件循环会轮番处理其任务，给予它们控制权并在它们暂停或完成时收回控制权。 运\n行 _sleep_watcher(...) 协程的 watcher_task 将在事件循环的每个完整周期中被唤起一次。 在\n每次恢复时，它将检查时间，如果经过的时间不够，则会再次暂停并将控制权交还给事件循环。 一\n旦经过了足够的时间，_sleep_watcher(...) 会将该 Future 标记为已完成并通过退出无限的\nwhile 循环来结束执行。 鉴于这个辅助任务在事件循环的每个周期中只会被唤起一次，因此你应该\n注意到这个异步休眠将 至少 休眠三秒，而不是恰好三秒。 请注意 asyncio.sleep 也同样如此。 |  |\n|  | class YieldToEventLoop:\ndef __await__(self):\nyield\nasync def _sleep_watcher(future, time_to_wake):\nwhile True:\nif time.time() >= time_to_wake:\n# 这标记 future 为已完成。\nfuture.set_result(None)\nbreak\nelse:\nawait YieldToEventLoop() |  |\n|  | 以下是程序的完整输出： |  |\n\n$ python custom-async-sleep.py\nBeginning asynchronous sleep at time: 14:52:22.\nI like work. Work work.\nI like work. Work work.\nI like work. Work work.\nDone asynchronous sleep at time: 14:52:25.\n你可能会觉得这种异步睡眠的实现过于复杂。确实如此。这个例子旨在通过一个简单的示例来展示\nFuture 的多功能性，以便可以模仿更复杂的需求。作为参考，你可以不使用 Future 来实现它，如下\n所示：\nasync def simpler_async_sleep(seconds):\ntime_to_wake = time.time() + seconds\nwhile True:\nif time.time() >= time_to_wake:\nreturn\nelse:\nawait YieldToEventLoop()\n目前就说这些了。 希望你已准备好更自信地深入探索异步编程或是查看 文档其余部分 中的进阶主\n题。\n\n| $ python custom-async-sleep.py\nBeginning asynchronous sleep at time: 14:52:22.\nI like work. Work work.\nI like work. Work work.\nI like work. Work work.\nDone asynchronous sleep at time: 14:52:25. |\n| --- |\n| 你可能会觉得这种异步睡眠的实现过于复杂。确实如此。这个例子旨在通过一个简单的示例来展示\nFuture 的多功能性，以便可以模仿更复杂的需求。作为参考，你可以不使用 Future 来实现它，如下\n所示： |\n| async def simpler_async_sleep(seconds):\ntime_to_wake = time.time() + seconds\nwhile True:\nif time.time() >= time_to_wake:\nreturn\nelse:\nawait YieldToEventLoop() |\n| 目前就说这些了。 希望你已准备好更自信地深入探索异步编程或是查看 文档其余部分 中的进阶主\n题。 |", "metadata": {"title": "01_asyncio_的概念概述", "source": "md_docs\\python_howto_md\\01_asyncio_的概念概述.md", "doc_type": "指南", "language": "中文", "doc_id": "e6bf796d"}}
{"doc_id": "558405fb", "content": "注解最佳实践\n作者: Larry Hastings\n摘要\n本文档旨在概括与注解字典打交道的最佳实践。查看 Python 对象的 __annotations__ 的代码应\n遵循下面的准则。\n本文档按四部分组织：在 3.10 及更高版本的 Python 中查看对象注解的最佳实践、在 3.9 及更低\n版本的 Python 中查看对象注解的最佳实践、其它一些适于任何版本的 Python 的\n__annotations__ 的最佳实践、__annotations__ 的一些“坑”。\n本文是 __annotations__ 的文档，不是注解的用法。如果在寻找如何使用“类型提示”，请参阅\ntyping 模块。\n在 3.10 及更高版本的 Python 中访问对象的注解字典\nPython 3.10 在标准库中加入了一个新函数: inspect.get_annotations()。 在 Python 3.10 至 3.13\n版中，调用该函数是访问任何支持标注的对象的标注字典的最佳实践。 该函数还能为你“反字符串\n化”已被字符串化的标注。\n在 Python 3.14 中，有一个新的 annotationlib 模块，具有处理注解的功能。 这包括\nannotationlib.get_annotations() 函数，它取代了 inspect.get_annotations()。\n不用 inspect.get_annotations() 也可以手动访问 __annotations__ 这一数据成员。该方法的最\n佳实践在 Python 3.10 中也发生了变化：从 Python 3.10 开始，对于 Python 函数、类和模块，\no.__annotations__ 保证 会正常工作。只要你确信所检查的对象是这三种之一，你便可以用\no.__annotations__ 获取该对象的注解字典。\n不过，其它类型的可调用对象可不一定定义了 __annotations__ 属性，就比如说，\nfunctools.partial() 创建的可调用对象。当访问某个未知对象的 __annotations__ 时，3.10 及\n更高版本的 Python 中的最佳实践是用三个参数去调用 getattr()，像 getattr(o,\n'__annotations__', None) 这样。\nPython 3.10 之前，在一个没定义注解而其父类定义了注解的类上访问 __annotations__ 将返回父\n类的 __annotations__。在 3.10 及更高版本的 Python 中，这样的子类的注解是个空字典。\n在 3.9 及更低版本的 Python 中访问对象的注解字典\n在 3.9 及更低版本的 Python 中访问对象的注解字典要比新版复杂。这是低版本 Python 的设计缺\n陷，特别是类的注解。\n\n|  | 注解最佳实践\n作者: Larry Hastings\n摘要\n本文档旨在概括与注解字典打交道的最佳实践。查看 Python 对象的 __annotations__ 的代码应\n遵循下面的准则。\n本文档按四部分组织：在 3.10 及更高版本的 Python 中查看对象注解的最佳实践、在 3.9 及更低\n版本的 Python 中查看对象注解的最佳实践、其它一些适于任何版本的 Python 的\n__annotations__ 的最佳实践、__annotations__ 的一些“坑”。\n本文是 __annotations__ 的文档，不是注解的用法。如果在寻找如何使用“类型提示”，请参阅\ntyping 模块。\n在 3.10 及更高版本的 Python 中访问对象的注解字典\nPython 3.10 在标准库中加入了一个新函数: inspect.get_annotations()。 在 Python 3.10 至 3.13\n版中，调用该函数是访问任何支持标注的对象的标注字典的最佳实践。 该函数还能为你“反字符串\n化”已被字符串化的标注。\n在 Python 3.14 中，有一个新的 annotationlib 模块，具有处理注解的功能。 这包括\nannotationlib.get_annotations() 函数，它取代了 inspect.get_annotations()。\n不用 inspect.get_annotations() 也可以手动访问 __annotations__ 这一数据成员。该方法的最\n佳实践在 Python 3.10 中也发生了变化：从 Python 3.10 开始，对于 Python 函数、类和模块，\no.__annotations__ 保证 会正常工作。只要你确信所检查的对象是这三种之一，你便可以用\no.__annotations__ 获取该对象的注解字典。\n不过，其它类型的可调用对象可不一定定义了 __annotations__ 属性，就比如说，\nfunctools.partial() 创建的可调用对象。当访问某个未知对象的 __annotations__ 时，3.10 及\n更高版本的 Python 中的最佳实践是用三个参数去调用 getattr()，像 getattr(o,\n'__annotations__', None) 这样。\nPython 3.10 之前，在一个没定义注解而其父类定义了注解的类上访问 __annotations__ 将返回父\n类的 __annotations__。在 3.10 及更高版本的 Python 中，这样的子类的注解是个空字典。\n在 3.9 及更低版本的 Python 中访问对象的注解字典\n在 3.9 及更低版本的 Python 中访问对象的注解字典要比新版复杂。这是低版本 Python 的设计缺\n陷，特别是类的注解。 |  |  |  |  |\n| --- | --- | --- | --- | --- | --- |\n|  |  | 注解最佳实践\n作者: Larry Hastings |  |  |  |\n|  |  | 摘要\n本文档旨在概括与注解字典打交道的最佳实践。查看 Python 对象的 __annotations__ 的代码应\n遵循下面的准则。\n本文档按四部分组织：在 3.10 及更高版本的 Python 中查看对象注解的最佳实践、在 3.9 及更低\n版本的 Python 中查看对象注解的最佳实践、其它一些适于任何版本的 Python 的\n__annotations__ 的最佳实践、__annotations__ 的一些“坑”。\n本文是 __annotations__ 的文档，不是注解的用法。如果在寻找如何使用“类型提示”，请参阅\ntyping 模块。 |  |  |  |\n|  |  | 在 3.10 及更高版本的 Python 中访问对象的注解字典\nPython 3.10 在标准库中加入了一个新函数: inspect.get_annotations()。 在 Python 3.10 至 3.13\n版中，调用该函数是访问任何支持标注的对象的标注字典的最佳实践。 该函数还能为你“反字符串\n化”已被字符串化的标注。\n在 Python 3.14 中，有一个新的 annotationlib 模块，具有处理注解的功能。 这包括\nannotationlib.get_annotations() 函数，它取代了 inspect.get_annotations()。\n不用 inspect.get_annotations() 也可以手动访问 __annotations__ 这一数据成员。该方法的最\n佳实践在 Python 3.10 中也发生了变化：从 Python 3.10 开始，对于 Python 函数、类和模块，\no.__annotations__ 保证 会正常工作。只要你确信所检查的对象是这三种之一，你便可以用\no.__annotations__ 获取该对象的注解字典。\n不过，其它类型的可调用对象可不一定定义了 __annotations__ 属性，就比如说，\nfunctools.partial() 创建的可调用对象。当访问某个未知对象的 __annotations__ 时，3.10 及\n更高版本的 Python 中的最佳实践是用三个参数去调用 getattr()，像 getattr(o,\n'__annotations__', None) 这样。\nPython 3.10 之前，在一个没定义注解而其父类定义了注解的类上访问 __annotations__ 将返回父\n类的 __annotations__。在 3.10 及更高版本的 Python 中，这样的子类的注解是个空字典。\n在 3.9 及更低版本的 Python 中访问对象的注解字典\n在 3.9 及更低版本的 Python 中访问对象的注解字典要比新版复杂。这是低版本 Python 的设计缺\n陷，特别是类的注解。 |  |  |  |\n|  |  |  | getattr(o, |  |  |\n|  |  |  |  |  |  |\n|  |  | '__annotations__', None) |  |  |  |\n|  |  |  |  |  |  |\n\n访问其它对象——函数、其它可调用对象和模块——的注解字典的最佳实践与 3.10 版本相同，如果\n不用 inspect.get_annotations()，就用三个参数去调用 getattr() 以访问对象的\n__annotations__ 属性。\n不幸的是，对类而言，这并不是最佳实践。问题在于，由于 __annotations__ 在某个类上是可有可\n无的，而类又可以从基类继承属性，所以访问某个类的 __annotations__ 属性可能会无意间返回\n基类 的注解字典。如：\nclass Base:\na: int = 3\nb: str = 'abc'\nclass Derived(Base):\npass\nprint(Derived.__annotations__)\n会打印出 Base 的注解字典，而非 Derived 的。\n如果你所检查的对象是一个类 (isinstance(o, type)) 则你的代码将不得不使用单独的代码路径。\n在此情况下，最佳实践依赖于 Python 3.9 及之前版本的一个实现细节：如果一个类定义了标注，它\n们将存储在类的 __dict__ 字典中。 由于类可能有也可能没有定义标注，因此最佳实践是在类的\ndict 字典上调用 get() 方法。\n综上所述，下面给出一些示例代码，可以在 Python 3.9 及之前版本安全地访问任意对象的\n__annotations__ 属性：\nif isinstance(o, type):\nann = o.__dict__.get('__annotations__', None)\nelse:\nann = getattr(o, '__annotations__', None)\n运行之后，ann 应为一个字典对象或 None。建议在继续之前，先用 isinstance() 再次检查 ann\n的类型。\n请注意某些特别的或错误的类型对象可能没有 __dict__ 属性，因此为确保绝对安全你可能会需要\n使用 getattr() 来访问 __dict__。\n解析字符串形式的注解\n有时注释可能会被“字符串化”，解析这些字符串可以求得其所代表的 Python 值，最好是调用\ninspect.get_annotations() 来完成这项工作。\n如果是 Python 3.9 及之前的版本，或者由于某种原因无法使用 inspect.get_annotations() ，那\n就需要重现其代码逻辑。建议查看一下当前 Python 版本中 inspect.get_annotations() 的实现代\n码，并遵照实现。\n简而言之，假设要对任一对象解析其字符串化的注释 o ：\n如果 o 是个模块，在调用 eval() 时，o.__dict__ 可视为 globals 。\n\n|  | 访问其它对象——函数、其它可调用对象和模块——的注解字典的最佳实践与 3.10 版本相同，如果\n不用 inspect.get_annotations()，就用三个参数去调用 getattr() 以访问对象的\n__annotations__ 属性。\n不幸的是，对类而言，这并不是最佳实践。问题在于，由于 __annotations__ 在某个类上是可有可\n无的，而类又可以从基类继承属性，所以访问某个类的 __annotations__ 属性可能会无意间返回\n基类 的注解字典。如： |  |\n| --- | --- | --- |\n|  | class Base:\na: int = 3\nb: str = 'abc'\nclass Derived(Base):\npass\nprint(Derived.__annotations__) |  |\n|  | 会打印出 Base 的注解字典，而非 Derived 的。\n如果你所检查的对象是一个类 (isinstance(o, type)) 则你的代码将不得不使用单独的代码路径。\n在此情况下，最佳实践依赖于 Python 3.9 及之前版本的一个实现细节：如果一个类定义了标注，它\n们将存储在类的 __dict__ 字典中。 由于类可能有也可能没有定义标注，因此最佳实践是在类的\ndict 字典上调用 get() 方法。\n综上所述，下面给出一些示例代码，可以在 Python 3.9 及之前版本安全地访问任意对象的\n__annotations__ 属性： |  |\n|  | if isinstance(o, type):\nann = o.__dict__.get('__annotations__', None)\nelse:\nann = getattr(o, '__annotations__', None) |  |\n|  | 运行之后，ann 应为一个字典对象或 None。建议在继续之前，先用 isinstance() 再次检查 ann\n的类型。\n请注意某些特别的或错误的类型对象可能没有 __dict__ 属性，因此为确保绝对安全你可能会需要\n使用 getattr() 来访问 __dict__。\n解析字符串形式的注解\n有时注释可能会被“字符串化”，解析这些字符串可以求得其所代表的 Python 值，最好是调用\ninspect.get_annotations() 来完成这项工作。\n如果是 Python 3.9 及之前的版本，或者由于某种原因无法使用 inspect.get_annotations() ，那\n就需要重现其代码逻辑。建议查看一下当前 Python 版本中 inspect.get_annotations() 的实现代\n码，并遵照实现。\n简而言之，假设要对任一对象解析其字符串化的注释 o ：\n如果 o 是个模块，在调用 eval() 时，o.__dict__ 可视为 globals 。 |  |\n\n如果 o 是一个类，在调用 eval() 时，sys.modules[o.__module__].__dict__ 视作 globals，\ndict(vars(o)) 视作 locals 。\n如果 o 是一个用 functools.update_wrapper() 、 functools.wraps() 或\nfunctools.partial() 封装的可调用对象，可酌情访问 o.__wrapped__ 或 o.func 进行反复解\n包，直到你找到未经封装的根函数。\n如果 o 为可调用对象（但不是类），则在调用 eval() 时可以使用 o.__globals__ 作为\nglobals。\n但并不是所有注解字符串都可以通过 eval() 成功地转化为 Python 值。理论上，注解字符串中可以\n包含任何合法字符串，确实有一些类型提示的场合，需要用到特殊的 无法 被解析的字符串来作注\n解。比如：\n在 Python 支持 PEP 604 的联合类型 | (Python 3.10) 之前使用它。\n运行时用不到的定义，只在 typing.TYPE_CHECKING 为 True 时才会导入。\n如果 eval() 试图求值，将会失败并触发异常。因此，当要设计一个可采用注解的库 API ，建议只\n在调用方显式请求的时才对字符串求值。\n任何版本 Python 中使用 __annotations__ 的最佳实践\n应避免直接给对象的 __annotations__ 成员赋值。请让 Python 来管理 __annotations__。\n如果直接给某对象的 __annotations__ 成员赋值，应该确保设成一个 dict 对象。\n你应该避免在任何对象上直接访问 __annotations__。 相反，使用\nannotationlib.get_annotations() (Python 3.14+) 或 inspect.get_annotations() (Python\n3.10+)。\n如果你直接访问一个对象的``__annotations__``成员，在尝试检查其内容之前，你应该确保它是一\n个字典。\n应避免修改 __annotations__ 字典。\n应避免删除对象的 __annotations__ 属性。\n__annotations__ 的一些“坑”\n在 Python 3 的所有版本中，如果对象没有定义注解，函数对象就会直接创建一个注解字典对象。用\ndel fn.__annotations__ 可删除 __annotations__ 属性，但如果后续再访问\nfn.__annotations__，该对象将新建一个空的字典对象，用于存放并返回注解。在函数直接创建注\n解字典前，删除注解操作会抛出 AttributeError 异常；连续两次调用 del fn.__annotations__\n一定会抛出一次 AttributeError 异常。\n以上同样适用于 Python 3.10 以上版本中的类和模块对象。\n所有版本的 Python 3 中，均可将函数对象的 __annotations__ 设为 None。但后续用\nfn.__annotations__ 访问该对象的注解时，会像本节第一段所述那样，直接创建一个空字典。但\n在任何 Python 版本中，模块和类均非如此，他们允许将 __annotations__ 设为任意 Python 值，\n并且会留存所设值。\n\n|  | 如果 o 是一个类，在调用 eval() 时，sys.modules[o.__module__].__dict__ 视作 globals，\ndict(vars(o)) 视作 locals 。\n如果 o 是一个用 functools.update_wrapper() 、 functools.wraps() 或\nfunctools.partial() 封装的可调用对象，可酌情访问 o.__wrapped__ 或 o.func 进行反复解\n包，直到你找到未经封装的根函数。\n如果 o 为可调用对象（但不是类），则在调用 eval() 时可以使用 o.__globals__ 作为\nglobals。\n但并不是所有注解字符串都可以通过 eval() 成功地转化为 Python 值。理论上，注解字符串中可以\n包含任何合法字符串，确实有一些类型提示的场合，需要用到特殊的 无法 被解析的字符串来作注\n解。比如：\n在 Python 支持 PEP 604 的联合类型 | (Python 3.10) 之前使用它。\n运行时用不到的定义，只在 typing.TYPE_CHECKING 为 True 时才会导入。\n如果 eval() 试图求值，将会失败并触发异常。因此，当要设计一个可采用注解的库 API ，建议只\n在调用方显式请求的时才对字符串求值。\n任何版本 Python 中使用 __annotations__ 的最佳实践\n应避免直接给对象的 __annotations__ 成员赋值。请让 Python 来管理 __annotations__。\n如果直接给某对象的 __annotations__ 成员赋值，应该确保设成一个 dict 对象。\n你应该避免在任何对象上直接访问 __annotations__。 相反，使用\nannotationlib.get_annotations() (Python 3.14+) 或 inspect.get_annotations() (Python\n3.10+)。\n如果你直接访问一个对象的``__annotations__``成员，在尝试检查其内容之前，你应该确保它是一\n个字典。\n应避免修改 __annotations__ 字典。\n应避免删除对象的 __annotations__ 属性。\n__annotations__ 的一些“坑”\n在 Python 3 的所有版本中，如果对象没有定义注解，函数对象就会直接创建一个注解字典对象。用\ndel fn.__annotations__ 可删除 __annotations__ 属性，但如果后续再访问\nfn.__annotations__，该对象将新建一个空的字典对象，用于存放并返回注解。在函数直接创建注\n解字典前，删除注解操作会抛出 AttributeError 异常；连续两次调用 del fn.__annotations__\n一定会抛出一次 AttributeError 异常。\n以上同样适用于 Python 3.10 以上版本中的类和模块对象。\n所有版本的 Python 3 中，均可将函数对象的 __annotations__ 设为 None。但后续用\nfn.__annotations__ 访问该对象的注解时，会像本节第一段所述那样，直接创建一个空字典。但\n在任何 Python 版本中，模块和类均非如此，他们允许将 __annotations__ 设为任意 Python 值，\n并且会留存所设值。 |  |\n| --- | --- | --- |\n\n如果 Python 会对注解作字符串化处理（用 from __future__ import annotations ），并且注解\n本身就是一个字符串，那么将会为其加上引号。实际效果就是，注解加了 两次 引号。例如：\nfrom __future__ import annotations\ndef foo(a: \"str\"): pass\nprint(foo.__annotations__)\n这会打印出 {'a': \"'str'\"}。这不应算是个“坑”；只是因为可能会让人吃惊，所以才提一下。\n如果你使用一个带有自定义元类的类，并在该类上访问 __annotations__，你可能会观察到意外的\n行为；请参阅 749 以获取一些示例。 你可以通过在 Python 3.14+ 上使用\nannotationlib.get_annotations() 或在 Python 3.10+ 上使用 inspect.get_annotations() 来\n避免这些问题。 在 Python 的早期版本中，你可以通过访问类的 __dict__ 中的注解来避免这些\nbug (例如 cls.__dict__.get('__annotations__', None)）。\n在某些版本的 Python 中，类的实例可能具有 __annotations__ 属性。 但是，这不是支持的功能。\n如果你需要一个实例的注解，你可以使用 type() 来访问它的类 (例如，Python 3.14+ 上的\nannotationlib.get_annotations(type(myinstance)))。\n\n| 如果 Python 会对注解作字符串化处理（用 from __future__ import annotations ），并且注解\n本身就是一个字符串，那么将会为其加上引号。实际效果就是，注解加了 两次 引号。例如： |\n| --- |\n| from __future__ import annotations\ndef foo(a: \"str\"): pass\nprint(foo.__annotations__) |\n| 这会打印出 {'a': \"'str'\"}。这不应算是个“坑”；只是因为可能会让人吃惊，所以才提一下。\n如果你使用一个带有自定义元类的类，并在该类上访问 __annotations__，你可能会观察到意外的\n行为；请参阅 749 以获取一些示例。 你可以通过在 Python 3.14+ 上使用\nannotationlib.get_annotations() 或在 Python 3.10+ 上使用 inspect.get_annotations() 来\n避免这些问题。 在 Python 的早期版本中，你可以通过访问类的 __dict__ 中的注解来避免这些\nbug (例如 cls.__dict__.get('__annotations__', None)）。\n在某些版本的 Python 中，类的实例可能具有 __annotations__ 属性。 但是，这不是支持的功能。\n如果你需要一个实例的注解，你可以使用 type() 来访问它的类 (例如，Python 3.14+ 上的\nannotationlib.get_annotations(type(myinstance)))。 |", "metadata": {"title": "02_注解最佳实践", "source": "md_docs\\python_howto_md\\02_注解最佳实践.md", "doc_type": "指南", "language": "中文", "doc_id": "558405fb"}}
{"doc_id": "93e5bf48", "content": "argparse 教程\n作者: Tshepang Mbambo\n这篇教程旨在作为 argparse 的入门介绍，此模块是 Python 标准库中推荐的命令行解析模块。\n备注: 标准库还包括另两个与命令行形参处理直接相关的库：低层级的 optparse 模块 (对于特\n定应用程序它可能需要更多的代码来配置，但也允许应用程序请求 argparse 所不支持的行为)，\n以及更低层级的 getopt (它被作为供 C 程序员使用的 getopt() 函数族的等价物)。 这些模块并\n未在本指南中直接介绍，argparse 中的许多核心概念最初都是来自 optparse，因此本教程的某\n些部分对 optparse 用户来说也是有用的。\n概念\n让我们利用 ls 命令来展示我们将要在这篇入门教程中探索的功能：\n$ ls\ncpython devguide prog.py pypy rm-unused-function.patch\n$ ls pypy\nctypes_configure demo dotviewer include lib_pypy lib-python ...\n$ ls -l\ntotal 20\ndrwxr-xr-x 19 wena wena 4096 Feb 18 18:51 cpython\ndrwxr-xr-x 4 wena wena 4096 Feb 8 12:04 devguide\n-rwxr-xr-x 1 wena wena 535 Feb 19 00:05 prog.py\ndrwxr-xr-x 14 wena wena 4096 Feb 7 00:59 pypy\n-rw-r--r-- 1 wena wena 741 Feb 18 01:01 rm-unused-function.patch\n$ ls --help\nUsage: ls [OPTION]... [FILE]...\nList information about the FILEs (the current directory by default).\nSort entries alphabetically if none of -cftuvSUX nor --sort is specified.\n...\n我们可以从这四个命令中学到几个概念：\nls 是一个即使在运行的时候没有提供任何选项，也非常有用的命令。在默认情况下他会输出当前\n文件夹包含的文件和文件夹。\n如果我们想要使用比它默认提供的更多功能，我们需要告诉该命令更多信息。在这个例子里，我\n们想要查看一个不同的目录，pypy。我们所做的是指定所谓的位置参数。之所以这样命名，是因\n为程序应该如何处理该参数值，完全取决于它在命令行出现的位置。更能体现这个概念的命令如\ncp，它最基本的用法是 cp SRC DEST。第一个位置参数指的是*你想要复制的*，第二个位置参数\n指的是*你想要复制到的位置*。\n现在假设我们想要改变这个程序的行为。在我们的例子中，我们不仅仅只是输出每个文件的文件\n名，还输出了更多信息。在这个例子中，-l 被称为可选参数。\n\n| argparse 教程\n作者: Tshepang Mbambo\n这篇教程旨在作为 argparse 的入门介绍，此模块是 Python 标准库中推荐的命令行解析模块。 |\n| --- |\n| 备注: 标准库还包括另两个与命令行形参处理直接相关的库：低层级的 optparse 模块 (对于特\n定应用程序它可能需要更多的代码来配置，但也允许应用程序请求 argparse 所不支持的行为)，\n以及更低层级的 getopt (它被作为供 C 程序员使用的 getopt() 函数族的等价物)。 这些模块并\n未在本指南中直接介绍，argparse 中的许多核心概念最初都是来自 optparse，因此本教程的某\n些部分对 optparse 用户来说也是有用的。 |\n| 概念\n让我们利用 ls 命令来展示我们将要在这篇入门教程中探索的功能： |\n| $ ls\ncpython devguide prog.py pypy rm-unused-function.patch\n$ ls pypy\nctypes_configure demo dotviewer include lib_pypy lib-python ...\n$ ls -l\ntotal 20\ndrwxr-xr-x 19 wena wena 4096 Feb 18 18:51 cpython\ndrwxr-xr-x 4 wena wena 4096 Feb 8 12:04 devguide\n-rwxr-xr-x 1 wena wena 535 Feb 19 00:05 prog.py\ndrwxr-xr-x 14 wena wena 4096 Feb 7 00:59 pypy\n-rw-r--r-- 1 wena wena 741 Feb 18 01:01 rm-unused-function.patch\n$ ls --help\nUsage: ls [OPTION]... [FILE]...\nList information about the FILEs (the current directory by default).\nSort entries alphabetically if none of -cftuvSUX nor --sort is specified.\n... |\n| 我们可以从这四个命令中学到几个概念：\nls 是一个即使在运行的时候没有提供任何选项，也非常有用的命令。在默认情况下他会输出当前\n文件夹包含的文件和文件夹。\n如果我们想要使用比它默认提供的更多功能，我们需要告诉该命令更多信息。在这个例子里，我\n们想要查看一个不同的目录，pypy。我们所做的是指定所谓的位置参数。之所以这样命名，是因\n为程序应该如何处理该参数值，完全取决于它在命令行出现的位置。更能体现这个概念的命令如\ncp，它最基本的用法是 cp SRC DEST。第一个位置参数指的是*你想要复制的*，第二个位置参数\n指的是*你想要复制到的位置*。\n现在假设我们想要改变这个程序的行为。在我们的例子中，我们不仅仅只是输出每个文件的文件\n名，还输出了更多信息。在这个例子中，-l 被称为可选参数。 |\n\n这是一段帮助文档的文字。它是非常有用的，因为当你遇到一个你从未使用过的程序时，你可以\n通过阅读它的帮助文档来弄清楚它是如何运行的。\n基础\n让我们从一个简单到（几乎）什么也做不了的例子开始：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.parse_args()\n以下是该代码的运行结果：\n$ python prog.py\n$ python prog.py --help\nusage: prog.py [-h]\noptions:\n-h, --help show this help message and exit\n$ python prog.py --verbose\nusage: prog.py [-h]\nprog.py: error: unrecognized arguments: --verbose\n$ python prog.py foo\nusage: prog.py [-h]\nprog.py: error: unrecognized arguments: foo\n程序运行情况如下：\n在没有任何选项的情况下运行脚本不会在标准输出显示任何内容。这没有什么用处。\n第二行代码开始展现出 argparse 模块的作用。我们几乎什么也没有做，但已经得到一条很好的\n帮助信息。\n--help 选项，也可缩写为 -h，是唯一一个可以直接使用的选项（即不需要指定该选项的内\n容）。指定任何内容都会导致错误。即便如此，我们也能直接得到一条有用的用法信息。\n位置参数介绍\n举个例子：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"echo\")\nargs = parser.parse_args()\nprint(args.echo)\n运行此程序：\n$ python prog.py\nusage: prog.py [-h] echo\nprog.py: error: the following arguments are required: echo\n$ python prog.py --help\nusage: prog.py [-h] echo\n\n|  | 这是一段帮助文档的文字。它是非常有用的，因为当你遇到一个你从未使用过的程序时，你可以\n通过阅读它的帮助文档来弄清楚它是如何运行的。\n基础\n让我们从一个简单到（几乎）什么也做不了的例子开始： |  |\n| --- | --- | --- |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.parse_args() |  |\n|  | 以下是该代码的运行结果： |  |\n|  | $ python prog.py\n$ python prog.py --help\nusage: prog.py [-h]\noptions:\n-h, --help show this help message and exit\n$ python prog.py --verbose\nusage: prog.py [-h]\nprog.py: error: unrecognized arguments: --verbose\n$ python prog.py foo\nusage: prog.py [-h]\nprog.py: error: unrecognized arguments: foo |  |\n|  | 程序运行情况如下：\n在没有任何选项的情况下运行脚本不会在标准输出显示任何内容。这没有什么用处。\n第二行代码开始展现出 argparse 模块的作用。我们几乎什么也没有做，但已经得到一条很好的\n帮助信息。\n--help 选项，也可缩写为 -h，是唯一一个可以直接使用的选项（即不需要指定该选项的内\n容）。指定任何内容都会导致错误。即便如此，我们也能直接得到一条有用的用法信息。\n位置参数介绍\n举个例子： |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"echo\")\nargs = parser.parse_args()\nprint(args.echo) |  |\n|  | 运行此程序： |  |\n|  | $ python prog.py\nusage: prog.py [-h] echo\nprog.py: error: the following arguments are required: echo\n$ python prog.py --help\nusage: prog.py [-h] echo |  |\n\npositional arguments:\necho\noptions:\n-h, --help show this help message and exit\n$ python prog.py foo\nfoo\n程序运行情况如下：\n我们增加了 add_argument() 方法，该方法用于指定程序将能接受哪些命令行选项。 在这个例子\n中，我将它命名为 echo 以与其对应的函数保持一致。\n现在调用我们的程序必须要指定一个选项。\nparse_args() 方法实际将返回来自指定选项的某些数据，在这个例子中是 echo。\n这一变量是 argparse 免费施放的某种 “魔法”（即是说，不需要指定哪个变量是存储哪个值\n的）。你也可以注意到，这一名称与传递给方法的字符串参数一致，都是 echo。\n然而请注意，尽管显示的帮助看起来清楚完整，但它可以比现在更有帮助。比如我们可以知道 echo\n是一个位置参数，但我们除了靠猜或者看源代码，没法知道它是用来干什么的。所以，我们可以把\n它改造得更有用：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"echo\", help=\"echo the string you use here\")\nargs = parser.parse_args()\nprint(args.echo)\n然后我们得到：\n$ python prog.py -h\nusage: prog.py [-h] echo\npositional arguments:\necho echo the string you use here\noptions:\n-h, --help show this help message and exit\n现在，来做一些更有用的事情：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", help=\"display a square of a given number\")\nargs = parser.parse_args()\nprint(args.square**2)\n以下是该代码的运行结果：\n$ python prog.py 4\nTraceback (most recent call last):\nFile \"prog.py\", line 5, in <module>\nprint(args.square**2)\nTypeError: unsupported operand type(s) for ** or pow(): 'str' and 'int'\n\n|  | positional arguments:\necho\noptions:\n-h, --help show this help message and exit\n$ python prog.py foo\nfoo |  |\n| --- | --- | --- |\n|  | 程序运行情况如下：\n我们增加了 add_argument() 方法，该方法用于指定程序将能接受哪些命令行选项。 在这个例子\n中，我将它命名为 echo 以与其对应的函数保持一致。\n现在调用我们的程序必须要指定一个选项。\nparse_args() 方法实际将返回来自指定选项的某些数据，在这个例子中是 echo。\n这一变量是 argparse 免费施放的某种 “魔法”（即是说，不需要指定哪个变量是存储哪个值\n的）。你也可以注意到，这一名称与传递给方法的字符串参数一致，都是 echo。\n然而请注意，尽管显示的帮助看起来清楚完整，但它可以比现在更有帮助。比如我们可以知道 echo\n是一个位置参数，但我们除了靠猜或者看源代码，没法知道它是用来干什么的。所以，我们可以把\n它改造得更有用： |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"echo\", help=\"echo the string you use here\")\nargs = parser.parse_args()\nprint(args.echo) |  |\n|  | 然后我们得到： |  |\n|  | $ python prog.py -h\nusage: prog.py [-h] echo\npositional arguments:\necho echo the string you use here\noptions:\n-h, --help show this help message and exit |  |\n|  | 现在，来做一些更有用的事情： |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", help=\"display a square of a given number\")\nargs = parser.parse_args()\nprint(args.square**2) |  |\n|  | 以下是该代码的运行结果： |  |\n|  | $ python prog.py 4\nTraceback (most recent call last):\nFile \"prog.py\", line 5, in <module>\nprint(args.square**2)\nTypeError: unsupported operand type(s) for ** or pow(): 'str' and 'int' |  |\n\n进展不太顺利。那是因为 argparse 会把我们传递给它的选项视作为字符串，除非我们告诉它别这\n样。所以，让我们来告诉 argparse 来把这一输入视为整数：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", help=\"display a square of a given number\",\ntype=int)\nargs = parser.parse_args()\nprint(args.square**2)\n以下是该代码的运行结果：\n$ python prog.py 4\n16\n$ python prog.py four\nusage: prog.py [-h] square\nprog.py: error: argument square: invalid int value: 'four'\n做得不错。当这个程序在收到错误的无效的输入时，它甚至能在执行计算之前先退出，还能显示很\n有帮助的错误信息。\n可选参数介绍\n到目前为止，我们一直在研究位置参数。让我们看看如何添加可选的：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--verbosity\", help=\"increase output verbosity\")\nargs = parser.parse_args()\nif args.verbosity:\nprint(\"verbosity turned on\")\n和输出：\n$ python prog.py --verbosity 1\nverbosity turned on\n$ python prog.py\n$ python prog.py --help\nusage: prog.py [-h] [--verbosity VERBOSITY]\noptions:\n-h, --help show this help message and exit\n--verbosity VERBOSITY\nincrease output verbosity\n$ python prog.py --verbosity\nusage: prog.py [-h] [--verbosity VERBOSITY]\nprog.py: error: argument --verbosity: expected one argument\n程序运行情况如下：\n这一程序被设计为当指定 --verbosity 选项时显示某些东西，否则不显示。\n为表明此选项确实是可选的，当不附带该选项运行程序时将不会提示任何错误。 请注意在默认情\n况下，如果一个可选参数未被使用，则关联的变量，在这个例子中是 args.verbosity，将被赋\n\n|  | 进展不太顺利。那是因为 argparse 会把我们传递给它的选项视作为字符串，除非我们告诉它别这\n样。所以，让我们来告诉 argparse 来把这一输入视为整数： |  |\n| --- | --- | --- |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", help=\"display a square of a given number\",\ntype=int)\nargs = parser.parse_args()\nprint(args.square**2) |  |\n|  | 以下是该代码的运行结果： |  |\n|  | $ python prog.py 4\n16\n$ python prog.py four\nusage: prog.py [-h] square\nprog.py: error: argument square: invalid int value: 'four' |  |\n|  | 做得不错。当这个程序在收到错误的无效的输入时，它甚至能在执行计算之前先退出，还能显示很\n有帮助的错误信息。\n可选参数介绍\n到目前为止，我们一直在研究位置参数。让我们看看如何添加可选的： |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--verbosity\", help=\"increase output verbosity\")\nargs = parser.parse_args()\nif args.verbosity:\nprint(\"verbosity turned on\") |  |\n|  | 和输出： |  |\n|  | $ python prog.py --verbosity 1\nverbosity turned on\n$ python prog.py\n$ python prog.py --help\nusage: prog.py [-h] [--verbosity VERBOSITY]\noptions:\n-h, --help show this help message and exit\n--verbosity VERBOSITY\nincrease output verbosity\n$ python prog.py --verbosity\nusage: prog.py [-h] [--verbosity VERBOSITY]\nprog.py: error: argument --verbosity: expected one argument |  |\n|  | 程序运行情况如下：\n这一程序被设计为当指定 --verbosity 选项时显示某些东西，否则不显示。\n为表明此选项确实是可选的，当不附带该选项运行程序时将不会提示任何错误。 请注意在默认情\n况下，如果一个可选参数未被使用，则关联的变量，在这个例子中是 args.verbosity，将被赋 |  |\n\n值为 None，这也就是它在 if 语句中无法通过真值检测的原因。\n帮助信息有点不同。\n使用 --verbosity 选项时，必须指定一个值，但可以是任何值。\n上述例子接受任何整数值作为 --verbosity 的参数，但对于我们的简单程序而言，只有两个值有实\n际意义：True 或者 False。让我们据此修改代码：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--verbose\", help=\"increase output verbosity\",\naction=\"store_true\")\nargs = parser.parse_args()\nif args.verbose:\nprint(\"verbosity turned on\")\n和输出：\n$ python prog.py --verbose\nverbosity turned on\n$ python prog.py --verbose 1\nusage: prog.py [-h] [--verbose]\nprog.py: error: unrecognized arguments: 1\n$ python prog.py --help\nusage: prog.py [-h] [--verbose]\noptions:\n-h, --help show this help message and exit\n--verbose increase output verbosity\n程序运行情况如下：\n现在此选项更像是一个旗标而不需要接受特定的值。 我们甚至改变了此选项的名字来匹配这一\n点。 请注意我们现在指定了一个新的关键词 action，并将其赋值为 \"store_true\"。 这意味\n着，如果指定了该选项，则将值 True 赋给 args.verbose。 如未指定则表示其值为 False。\n当你为其指定一个值时，它会报错，符合作为标志的真正的精神。\n留意不同的帮助文字。\n短选项\n如果你熟悉命令行的用法，你会发现我还没讲到这一选项的短版本。这也很简单：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-v\", \"--verbose\", help=\"increase output verbosity\",\naction=\"store_true\")\nargs = parser.parse_args()\nif args.verbose:\nprint(\"verbosity turned on\")\n效果就像这样：\n\n|  | 值为 None，这也就是它在 if 语句中无法通过真值检测的原因。\n帮助信息有点不同。\n使用 --verbosity 选项时，必须指定一个值，但可以是任何值。\n上述例子接受任何整数值作为 --verbosity 的参数，但对于我们的简单程序而言，只有两个值有实\n际意义：True 或者 False。让我们据此修改代码： |  |\n| --- | --- | --- |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--verbose\", help=\"increase output verbosity\",\naction=\"store_true\")\nargs = parser.parse_args()\nif args.verbose:\nprint(\"verbosity turned on\") |  |\n|  | 和输出： |  |\n|  | $ python prog.py --verbose\nverbosity turned on\n$ python prog.py --verbose 1\nusage: prog.py [-h] [--verbose]\nprog.py: error: unrecognized arguments: 1\n$ python prog.py --help\nusage: prog.py [-h] [--verbose]\noptions:\n-h, --help show this help message and exit\n--verbose increase output verbosity |  |\n|  | 程序运行情况如下：\n现在此选项更像是一个旗标而不需要接受特定的值。 我们甚至改变了此选项的名字来匹配这一\n点。 请注意我们现在指定了一个新的关键词 action，并将其赋值为 \"store_true\"。 这意味\n着，如果指定了该选项，则将值 True 赋给 args.verbose。 如未指定则表示其值为 False。\n当你为其指定一个值时，它会报错，符合作为标志的真正的精神。\n留意不同的帮助文字。\n短选项\n如果你熟悉命令行的用法，你会发现我还没讲到这一选项的短版本。这也很简单： |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-v\", \"--verbose\", help=\"increase output verbosity\",\naction=\"store_true\")\nargs = parser.parse_args()\nif args.verbose:\nprint(\"verbosity turned on\") |  |\n|  | 效果就像这样： |  |\n\n$ python prog.py -v\nverbosity turned on\n$ python prog.py --help\nusage: prog.py [-h] [-v]\noptions:\n-h, --help show this help message and exit\n-v, --verbose increase output verbosity\n可以注意到，这一新的能力也反映在帮助文本里。\n结合位置参数和可选参数\n我们的程序变得越来越复杂了：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbose:\nprint(f\"the square of {args.square} equals {answer}\")\nelse:\nprint(answer)\n接着是输出：\n$ python prog.py\nusage: prog.py [-h] [-v] square\nprog.py: error: the following arguments are required: square\n$ python prog.py 4\n16\n$ python prog.py 4 --verbose\nthe square of 4 equals 16\n$ python prog.py --verbose 4\nthe square of 4 equals 16\n我们带回了一个位置参数，结果发生了报错。\n注意顺序无关紧要。\n给我们的程序加上接受多个冗长度的值，然后实际来用用：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbosity\", type=int,\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbosity == 2:\nprint(f\"the square of {args.square} equals {answer}\")\n\n|  | $ python prog.py -v\nverbosity turned on\n$ python prog.py --help\nusage: prog.py [-h] [-v]\noptions:\n-h, --help show this help message and exit\n-v, --verbose increase output verbosity |  |\n| --- | --- | --- |\n|  | 可以注意到，这一新的能力也反映在帮助文本里。\n结合位置参数和可选参数\n我们的程序变得越来越复杂了： |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbose:\nprint(f\"the square of {args.square} equals {answer}\")\nelse:\nprint(answer) |  |\n|  | 接着是输出： |  |\n|  | $ python prog.py\nusage: prog.py [-h] [-v] square\nprog.py: error: the following arguments are required: square\n$ python prog.py 4\n16\n$ python prog.py 4 --verbose\nthe square of 4 equals 16\n$ python prog.py --verbose 4\nthe square of 4 equals 16 |  |\n|  | 我们带回了一个位置参数，结果发生了报错。\n注意顺序无关紧要。\n给我们的程序加上接受多个冗长度的值，然后实际来用用： |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbosity\", type=int,\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbosity == 2:\nprint(f\"the square of {args.square} equals {answer}\") |  |\n\nelif args.verbosity == 1:\nprint(f\"{args.square}^2 == {answer}\")\nelse:\nprint(answer)\n和输出：\n$ python prog.py 4\n16\n$ python prog.py 4 -v\nusage: prog.py [-h] [-v VERBOSITY] square\nprog.py: error: argument -v/--verbosity: expected one argument\n$ python prog.py 4 -v 1\n4^2 == 16\n$ python prog.py 4 -v 2\nthe square of 4 equals 16\n$ python prog.py 4 -v 3\n16\n除了最后一个，看上去都不错。最后一个暴露了我们的程序中有一个 bug。我们可以通过限制 --\nverbosity 选项可以接受的值来修复它：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbosity\", type=int, choices=[0, 1, 2],\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbosity == 2:\nprint(f\"the square of {args.square} equals {answer}\")\nelif args.verbosity == 1:\nprint(f\"{args.square}^2 == {answer}\")\nelse:\nprint(answer)\n和输出：\n$ python prog.py 4 -v 3\nusage: prog.py [-h] [-v {0,1,2}] square\nprog.py: error: argument -v/--verbosity: invalid choice: 3 (choose from 0, 1, 2)\n$ python prog.py 4 -h\nusage: prog.py [-h] [-v {0,1,2}] square\npositional arguments:\nsquare display a square of a given number\noptions:\n-h, --help show this help message and exit\n-v, --verbosity {0,1,2}\nincrease output verbosity\n注意这一改变同时反应在错误信息和帮助信息里。\n\n|  | elif args.verbosity == 1:\nprint(f\"{args.square}^2 == {answer}\")\nelse:\nprint(answer) |  |  |  |\n| --- | --- | --- | --- | --- |\n|  | 和输出： |  |  |  |\n|  | $ python prog.py 4\n16\n$ python prog.py 4 -v\nusage: prog.py [-h] [-v VERBOSITY] square\nprog.py: error: argument -v/--verbosity: expected one argument\n$ python prog.py 4 -v 1\n4^2 == 16\n$ python prog.py 4 -v 2\nthe square of 4 equals 16\n$ python prog.py 4 -v 3\n16 |  |  |  |\n|  | 除了最后一个，看上去都不错。最后一个暴露了我们的程序中有一个 bug。我们可以通过限制 --\nverbosity 选项可以接受的值来修复它： |  |  |  |\n|  |  | -- |  |  |\n|  |  |  |  |  |\n|  | verbosity |  |  |  |\n|  |  |  |  |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbosity\", type=int, choices=[0, 1, 2],\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbosity == 2:\nprint(f\"the square of {args.square} equals {answer}\")\nelif args.verbosity == 1:\nprint(f\"{args.square}^2 == {answer}\")\nelse:\nprint(answer) |  |  |  |\n|  | 和输出： |  |  |  |\n|  | $ python prog.py 4 -v 3\nusage: prog.py [-h] [-v {0,1,2}] square\nprog.py: error: argument -v/--verbosity: invalid choice: 3 (choose from 0, 1, 2)\n$ python prog.py 4 -h\nusage: prog.py [-h] [-v {0,1,2}] square\npositional arguments:\nsquare display a square of a given number\noptions:\n-h, --help show this help message and exit\n-v, --verbosity {0,1,2}\nincrease output verbosity |  |  |  |\n|  | 注意这一改变同时反应在错误信息和帮助信息里。 |  |  |  |\n\n现在，让我们使用另一种的方式来改变冗长度。这种方式更常见，也和 CPython 的可执行文件处理\n它自己的冗长度参数的方式一致（参考 python --help 的输出）：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display the square of a given number\")\nparser.add_argument(\"-v\", \"--verbosity\", action=\"count\",\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbosity == 2:\nprint(f\"the square of {args.square} equals {answer}\")\nelif args.verbosity == 1:\nprint(f\"{args.square}^2 == {answer}\")\nelse:\nprint(answer)\n我们引入了另一种动作 \"count\"，来统计特定选项出现的次数。\n$ python prog.py 4\n16\n$ python prog.py 4 -v\n4^2 == 16\n$ python prog.py 4 -vv\nthe square of 4 equals 16\n$ python prog.py 4 --verbosity --verbosity\nthe square of 4 equals 16\n$ python prog.py 4 -v 1\nusage: prog.py [-h] [-v] square\nprog.py: error: unrecognized arguments: 1\n$ python prog.py 4 -h\nusage: prog.py [-h] [-v] square\npositional arguments:\nsquare display a square of a given number\noptions:\n-h, --help show this help message and exit\n-v, --verbosity increase output verbosity\n$ python prog.py 4 -vvv\n16\n是的，它现在比前一版本更像是一个标志（和 action=\"store_true\" 相似）。这能解释它为什\n么报错。\n它也表现得与 “store_true” 的行为相似。\n这给出了一个关于 count 动作的效果的演示。你之前很可能应该已经看过这种用法。\n如果你不添加 -v 标志，这一标志的值会是 None。\n如期望的那样，添加该标志的长形态能够获得相同的输出。\n可惜的是，对于我们的脚本获得的新能力，我们的帮助输出并没有提供很多信息，但我们总是可\n以通过改善文档来修复这一问题（比如通过 help 关键字参数）。\n最后一个输出暴露了我们程序中的一个 bug。\n让我们修复一下：\n\n|  | 现在，让我们使用另一种的方式来改变冗长度。这种方式更常见，也和 CPython 的可执行文件处理\n它自己的冗长度参数的方式一致（参考 python --help 的输出）： |  |\n| --- | --- | --- |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display the square of a given number\")\nparser.add_argument(\"-v\", \"--verbosity\", action=\"count\",\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbosity == 2:\nprint(f\"the square of {args.square} equals {answer}\")\nelif args.verbosity == 1:\nprint(f\"{args.square}^2 == {answer}\")\nelse:\nprint(answer) |  |\n|  | 我们引入了另一种动作 \"count\"，来统计特定选项出现的次数。 |  |\n|  | $ python prog.py 4\n16\n$ python prog.py 4 -v\n4^2 == 16\n$ python prog.py 4 -vv\nthe square of 4 equals 16\n$ python prog.py 4 --verbosity --verbosity\nthe square of 4 equals 16\n$ python prog.py 4 -v 1\nusage: prog.py [-h] [-v] square\nprog.py: error: unrecognized arguments: 1\n$ python prog.py 4 -h\nusage: prog.py [-h] [-v] square\npositional arguments:\nsquare display a square of a given number\noptions:\n-h, --help show this help message and exit\n-v, --verbosity increase output verbosity\n$ python prog.py 4 -vvv\n16 |  |\n|  | 是的，它现在比前一版本更像是一个标志（和 action=\"store_true\" 相似）。这能解释它为什\n么报错。\n它也表现得与 “store_true” 的行为相似。\n这给出了一个关于 count 动作的效果的演示。你之前很可能应该已经看过这种用法。\n如果你不添加 -v 标志，这一标志的值会是 None。\n如期望的那样，添加该标志的长形态能够获得相同的输出。\n可惜的是，对于我们的脚本获得的新能力，我们的帮助输出并没有提供很多信息，但我们总是可\n以通过改善文档来修复这一问题（比如通过 help 关键字参数）。\n最后一个输出暴露了我们程序中的一个 bug。\n让我们修复一下： |  |\n\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbosity\", action=\"count\",\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\n# bugfix: replace == with >=\nif args.verbosity >= 2:\nprint(f\"the square of {args.square} equals {answer}\")\nelif args.verbosity >= 1:\nprint(f\"{args.square}^2 == {answer}\")\nelse:\nprint(answer)\n这是它给我们的输出：\n$ python prog.py 4 -vvv\nthe square of 4 equals 16\n$ python prog.py 4 -vvvv\nthe square of 4 equals 16\n$ python prog.py 4\nTraceback (most recent call last):\nFile \"prog.py\", line 11, in <module>\nif args.verbosity >= 2:\nTypeError: '>=' not supported between instances of 'NoneType' and 'int'\n第一组输出很好，修复了之前的 bug。也就是说，我们希望任何 >= 2 的值尽可能详尽。\n第三组输出并不理想。\n让我们修复那个 bug：\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbosity\", action=\"count\", default=0,\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbosity >= 2:\nprint(f\"the square of {args.square} equals {answer}\")\nelif args.verbosity >= 1:\nprint(f\"{args.square}^2 == {answer}\")\nelse:\nprint(answer)\n我们刚刚引入了又一个新的关键字 default。我们把它设置为 0 来让它可以与其他整数值相互比\n较。记住，默认情况下如果一个可选参数没有被指定，它的值会是 None，并且它不能和整数值相比\n较（所以产生了 TypeError 异常）。\n然后：\n\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbosity\", action=\"count\",\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\n# bugfix: replace == with >=\nif args.verbosity >= 2:\nprint(f\"the square of {args.square} equals {answer}\")\nelif args.verbosity >= 1:\nprint(f\"{args.square}^2 == {answer}\")\nelse:\nprint(answer) |  |\n| --- | --- | --- |\n|  | 这是它给我们的输出： |  |\n|  | $ python prog.py 4 -vvv\nthe square of 4 equals 16\n$ python prog.py 4 -vvvv\nthe square of 4 equals 16\n$ python prog.py 4\nTraceback (most recent call last):\nFile \"prog.py\", line 11, in <module>\nif args.verbosity >= 2:\nTypeError: '>=' not supported between instances of 'NoneType' and 'int' |  |\n|  | 第一组输出很好，修复了之前的 bug。也就是说，我们希望任何 >= 2 的值尽可能详尽。\n第三组输出并不理想。\n让我们修复那个 bug： |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\nhelp=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbosity\", action=\"count\", default=0,\nhelp=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbosity >= 2:\nprint(f\"the square of {args.square} equals {answer}\")\nelif args.verbosity >= 1:\nprint(f\"{args.square}^2 == {answer}\")\nelse:\nprint(answer) |  |\n|  | 我们刚刚引入了又一个新的关键字 default。我们把它设置为 0 来让它可以与其他整数值相互比\n较。记住，默认情况下如果一个可选参数没有被指定，它的值会是 None，并且它不能和整数值相比\n较（所以产生了 TypeError 异常）。\n然后： |  |\n\n$ python prog.py 4\n16\n凭借我们目前已学的东西你就可以做到许多事情，而我们还仅仅学了一些皮毛而已。 argparse 模\n块是非常强大的，在结束本篇教程之前我们将再探索更多一些内容。\n进行一些小小的改进\n如果我们想扩展我们的简短程序来执行其他幂次的运算，而不仅是乘方:\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"x\", type=int, help=\"the base\")\nparser.add_argument(\"y\", type=int, help=\"the exponent\")\nparser.add_argument(\"-v\", \"--verbosity\", action=\"count\", default=0)\nargs = parser.parse_args()\nanswer = args.x**args.y\nif args.verbosity >= 2:\nprint(f\"{args.x} to the power {args.y} equals {answer}\")\nelif args.verbosity >= 1:\nprint(f\"{args.x}^{args.y} == {answer}\")\nelse:\nprint(answer)\n输出：\n$ python prog.py\nusage: prog.py [-h] [-v] x y\nprog.py: error: the following arguments are required: x, y\n$ python prog.py -h\nusage: prog.py [-h] [-v] x y\npositional arguments:\nx the base\ny the exponent\noptions:\n-h, --help show this help message and exit\n-v, --verbosity\n$ python prog.py 4 2 -v\n4^2 == 16\n请注意到目前为止我们一直在使用详细级别来 更改 所显示的文本。 以下示例则使用详细级别来显示\n更多的 文本:\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"x\", type=int, help=\"the base\")\nparser.add_argument(\"y\", type=int, help=\"the exponent\")\nparser.add_argument(\"-v\", \"--verbosity\", action=\"count\", default=0)\nargs = parser.parse_args()\nanswer = args.x**args.y\nif args.verbosity >= 2:\nprint(f\"Running '{__file__}'\")\nif args.verbosity >= 1:\n\n|  | $ python prog.py 4\n16 |  |\n| --- | --- | --- |\n|  | 凭借我们目前已学的东西你就可以做到许多事情，而我们还仅仅学了一些皮毛而已。 argparse 模\n块是非常强大的，在结束本篇教程之前我们将再探索更多一些内容。\n进行一些小小的改进\n如果我们想扩展我们的简短程序来执行其他幂次的运算，而不仅是乘方: |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"x\", type=int, help=\"the base\")\nparser.add_argument(\"y\", type=int, help=\"the exponent\")\nparser.add_argument(\"-v\", \"--verbosity\", action=\"count\", default=0)\nargs = parser.parse_args()\nanswer = args.x**args.y\nif args.verbosity >= 2:\nprint(f\"{args.x} to the power {args.y} equals {answer}\")\nelif args.verbosity >= 1:\nprint(f\"{args.x}^{args.y} == {answer}\")\nelse:\nprint(answer) |  |\n|  | 输出： |  |\n|  | $ python prog.py\nusage: prog.py [-h] [-v] x y\nprog.py: error: the following arguments are required: x, y\n$ python prog.py -h\nusage: prog.py [-h] [-v] x y\npositional arguments:\nx the base\ny the exponent\noptions:\n-h, --help show this help message and exit\n-v, --verbosity\n$ python prog.py 4 2 -v\n4^2 == 16 |  |\n|  | 请注意到目前为止我们一直在使用详细级别来 更改 所显示的文本。 以下示例则使用详细级别来显示\n更多的 文本: |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"x\", type=int, help=\"the base\")\nparser.add_argument(\"y\", type=int, help=\"the exponent\")\nparser.add_argument(\"-v\", \"--verbosity\", action=\"count\", default=0)\nargs = parser.parse_args()\nanswer = args.x**args.y\nif args.verbosity >= 2:\nprint(f\"Running '{__file__}'\")\nif args.verbosity >= 1: |  |\n\nprint(f\"{args.x}^{args.y} == \", end=\"\")\nprint(answer)\n输出：\n$ python prog.py 4 2\n16\n$ python prog.py 4 2 -v\n4^2 == 16\n$ python prog.py 4 2 -vv\nRunning 'prog.py'\n4^2 == 16\n指定有歧义的参数\n当在确定一个参数是位置参数还是从属于另一个参数存在歧义时，可以使用 -- 来告诉\nparse_args() 在它之后的参数是位置参数:\n>>> parser = argparse.ArgumentParser(prog='PROG')\n>>> parser.add_argument('-n', nargs='+')\n>>> parser.add_argument('args', nargs='*')\n>>> # ambiguous, so parse_args assumes it's an option\n>>> parser.parse_args(['-f'])\nusage: PROG [-h] [-n N [N ...]] [args ...]\nPROG: error: unrecognized arguments: -f\n>>> parser.parse_args(['--', '-f'])\nNamespace(args=['-f'], n=None)\n>>> # ambiguous, so the -n option greedily accepts arguments\n>>> parser.parse_args(['-n', '1', '2', '3'])\nNamespace(args=[], n=['1', '2', '3'])\n>>> parser.parse_args(['-n', '1', '--', '2', '3'])\nNamespace(args=['2', '3'], n=['1'])\n矛盾的选项\n到目前为止，我们一直在使用 argparse.ArgumentParser 实例的两个方法。 让我们再介绍第三个\n方法 add_mutually_exclusive_group()。 它允许我们指定彼此相冲突的选项。 让我们再修改程\n序的其余部分以便使新功能更有意义：我们将引入 --quiet 选项，它将与 --verbose 的作用相反:\nimport argparse\nparser = argparse.ArgumentParser()\ngroup = parser.add_mutually_exclusive_group()\ngroup.add_argument(\"-v\", \"--verbose\", action=\"store_true\")\ngroup.add_argument(\"-q\", \"--quiet\", action=\"store_true\")\nparser.add_argument(\"x\", type=int, help=\"the base\")\nparser.add_argument(\"y\", type=int, help=\"the exponent\")\nargs = parser.parse_args()\nanswer = args.x**args.y\n\n|  | print(f\"{args.x}^{args.y} == \", end=\"\")\nprint(answer) |  |\n| --- | --- | --- |\n|  | 输出： |  |\n|  | $ python prog.py 4 2\n16\n$ python prog.py 4 2 -v\n4^2 == 16\n$ python prog.py 4 2 -vv\nRunning 'prog.py'\n4^2 == 16 |  |\n|  | 指定有歧义的参数\n当在确定一个参数是位置参数还是从属于另一个参数存在歧义时，可以使用 -- 来告诉\nparse_args() 在它之后的参数是位置参数: |  |\n|  | >>> parser = argparse.ArgumentParser(prog='PROG')\n>>> parser.add_argument('-n', nargs='+')\n>>> parser.add_argument('args', nargs='*')\n>>> # ambiguous, so parse_args assumes it's an option\n>>> parser.parse_args(['-f'])\nusage: PROG [-h] [-n N [N ...]] [args ...]\nPROG: error: unrecognized arguments: -f\n>>> parser.parse_args(['--', '-f'])\nNamespace(args=['-f'], n=None)\n>>> # ambiguous, so the -n option greedily accepts arguments\n>>> parser.parse_args(['-n', '1', '2', '3'])\nNamespace(args=[], n=['1', '2', '3'])\n>>> parser.parse_args(['-n', '1', '--', '2', '3'])\nNamespace(args=['2', '3'], n=['1']) |  |\n|  | 矛盾的选项\n到目前为止，我们一直在使用 argparse.ArgumentParser 实例的两个方法。 让我们再介绍第三个\n方法 add_mutually_exclusive_group()。 它允许我们指定彼此相冲突的选项。 让我们再修改程\n序的其余部分以便使新功能更有意义：我们将引入 --quiet 选项，它将与 --verbose 的作用相反: |  |\n|  | import argparse\nparser = argparse.ArgumentParser()\ngroup = parser.add_mutually_exclusive_group()\ngroup.add_argument(\"-v\", \"--verbose\", action=\"store_true\")\ngroup.add_argument(\"-q\", \"--quiet\", action=\"store_true\")\nparser.add_argument(\"x\", type=int, help=\"the base\")\nparser.add_argument(\"y\", type=int, help=\"the exponent\")\nargs = parser.parse_args()\nanswer = args.x**args.y |  |\n\nif args.quiet:\nprint(answer)\nelif args.verbose:\nprint(f\"{args.x} to the power {args.y} equals {answer}\")\nelse:\nprint(f\"{args.x}^{args.y} == {answer}\")\n我们的程序现在变得更简洁了，我们出于演示需要略去了一些功能。 无论如何，输出是这样的:\n$ python prog.py 4 2\n4^2 == 16\n$ python prog.py 4 2 -q\n16\n$ python prog.py 4 2 -v\n4 to the power 2 equals 16\n$ python prog.py 4 2 -vq\nusage: prog.py [-h] [-v | -q] x y\nprog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose\n$ python prog.py 4 2 -v --quiet\nusage: prog.py [-h] [-v | -q] x y\nprog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose\n这应该很容易理解。 我添加了末尾的输出这样你就可以看到其所达到的灵活性，即混合使用长和短\n两种形式的选项。\n在我们收尾之前，你也许希望告诉你的用户这个程序的主要目标，以免他们还不清楚:\nimport argparse\nparser = argparse.ArgumentParser(description=\"calculate X to the power of Y\")\ngroup = parser.add_mutually_exclusive_group()\ngroup.add_argument(\"-v\", \"--verbose\", action=\"store_true\")\ngroup.add_argument(\"-q\", \"--quiet\", action=\"store_true\")\nparser.add_argument(\"x\", type=int, help=\"the base\")\nparser.add_argument(\"y\", type=int, help=\"the exponent\")\nargs = parser.parse_args()\nanswer = args.x**args.y\nif args.quiet:\nprint(answer)\nelif args.verbose:\nprint(f\"{args.x} to the power {args.y} equals {answer}\")\nelse:\nprint(f\"{args.x}^{args.y} == {answer}\")\n请注意用法文本中有细微的差异。 注意 [-v | -q]，它的意思是说我们可以使用 -v 或 -q，但不能\n同时使用两者：\n$ python prog.py --help\nusage: prog.py [-h] [-v | -q] x y\ncalculate X to the power of Y\npositional arguments:\nx the base\ny the exponent\n\n|  | if args.quiet:\nprint(answer)\nelif args.verbose:\nprint(f\"{args.x} to the power {args.y} equals {answer}\")\nelse:\nprint(f\"{args.x}^{args.y} == {answer}\") |  |\n| --- | --- | --- |\n|  | 我们的程序现在变得更简洁了，我们出于演示需要略去了一些功能。 无论如何，输出是这样的: |  |\n|  | $ python prog.py 4 2\n4^2 == 16\n$ python prog.py 4 2 -q\n16\n$ python prog.py 4 2 -v\n4 to the power 2 equals 16\n$ python prog.py 4 2 -vq\nusage: prog.py [-h] [-v | -q] x y\nprog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose\n$ python prog.py 4 2 -v --quiet\nusage: prog.py [-h] [-v | -q] x y\nprog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose |  |\n|  | 这应该很容易理解。 我添加了末尾的输出这样你就可以看到其所达到的灵活性，即混合使用长和短\n两种形式的选项。\n在我们收尾之前，你也许希望告诉你的用户这个程序的主要目标，以免他们还不清楚: |  |\n|  | import argparse\nparser = argparse.ArgumentParser(description=\"calculate X to the power of Y\")\ngroup = parser.add_mutually_exclusive_group()\ngroup.add_argument(\"-v\", \"--verbose\", action=\"store_true\")\ngroup.add_argument(\"-q\", \"--quiet\", action=\"store_true\")\nparser.add_argument(\"x\", type=int, help=\"the base\")\nparser.add_argument(\"y\", type=int, help=\"the exponent\")\nargs = parser.parse_args()\nanswer = args.x**args.y\nif args.quiet:\nprint(answer)\nelif args.verbose:\nprint(f\"{args.x} to the power {args.y} equals {answer}\")\nelse:\nprint(f\"{args.x}^{args.y} == {answer}\") |  |\n|  | 请注意用法文本中有细微的差异。 注意 [-v | -q]，它的意思是说我们可以使用 -v 或 -q，但不能\n同时使用两者： |  |\n|  | $ python prog.py --help\nusage: prog.py [-h] [-v | -q] x y\ncalculate X to the power of Y\npositional arguments:\nx the base\ny the exponent |  |\n\noptions:\n-h, --help show this help message and exit\n-v, --verbose\n-q, --quiet\n如何翻译 argparse 的输出\nargparse 模块的输出例如它的帮助文本和错误消息都可以通过 gettext 模块实现翻译。 这允许应\n用程序轻松本地化 argparse 所产生的消息。 另请参见 国际化 (I18N) 你的程序和模块。\n例如，在这个 argparse 输出中:\n$ python prog.py --help\nusage: prog.py [-h] [-v | -q] x y\ncalculate X to the power of Y\npositional arguments:\nx the base\ny the exponent\noptions:\n-h, --help show this help message and exit\n-v, --verbose\n-q, --quiet\n字符串 usage:, positional arguments:, options: 和 show this help message and exit 都是\n可翻译的。\n要翻译这些字符串，必须先将它们提取到一个 .po 文件中。 例如，使用 Babel，运行这条命令:\n$ pybabel extract -o messages.po /usr/lib/python3.12/argparse.py\n此命令将从 argparse 模块提取所有可翻译的字符串，并将其输出到名为 messages.po 的文件中。\n此命令假定你的 Python 安装位置为 /usr/lib。\n你可以使用以下脚本查找 argparse 模块在系统中的位置：\nimport argparse\nprint(argparse.__file__)\n一旦 .po 文件中的文本信息翻译完毕并使用 gettext 安装了译文，argparse 将能显示翻译后的信\n息。\n要翻译在 argparse 输出中的字符串，请使用 gettext。\n自定义类型转换器\nargparse 模块允许您为命令行参数指定自定义类型转换器。 这使您能够在用户输入存储在\nargparse.Namespace 中之前对其进行修改。 当您需要在程序中使用输入之前对其进行预处理时，\n\n|  | options:\n-h, --help show this help message and exit\n-v, --verbose\n-q, --quiet |  |\n| --- | --- | --- |\n|  | 如何翻译 argparse 的输出\nargparse 模块的输出例如它的帮助文本和错误消息都可以通过 gettext 模块实现翻译。 这允许应\n用程序轻松本地化 argparse 所产生的消息。 另请参见 国际化 (I18N) 你的程序和模块。\n例如，在这个 argparse 输出中: |  |\n|  | $ python prog.py --help\nusage: prog.py [-h] [-v | -q] x y\ncalculate X to the power of Y\npositional arguments:\nx the base\ny the exponent\noptions:\n-h, --help show this help message and exit\n-v, --verbose\n-q, --quiet |  |\n|  | 字符串 usage:, positional arguments:, options: 和 show this help message and exit 都是\n可翻译的。\n要翻译这些字符串，必须先将它们提取到一个 .po 文件中。 例如，使用 Babel，运行这条命令: |  |\n|  | $ pybabel extract -o messages.po /usr/lib/python3.12/argparse.py |  |\n|  | 此命令将从 argparse 模块提取所有可翻译的字符串，并将其输出到名为 messages.po 的文件中。\n此命令假定你的 Python 安装位置为 /usr/lib。\n你可以使用以下脚本查找 argparse 模块在系统中的位置： |  |\n|  | import argparse\nprint(argparse.__file__) |  |\n|  | 一旦 .po 文件中的文本信息翻译完毕并使用 gettext 安装了译文，argparse 将能显示翻译后的信\n息。\n要翻译在 argparse 输出中的字符串，请使用 gettext。\n自定义类型转换器\nargparse 模块允许您为命令行参数指定自定义类型转换器。 这使您能够在用户输入存储在\nargparse.Namespace 中之前对其进行修改。 当您需要在程序中使用输入之前对其进行预处理时， |  |\n\n这会很有用。\n使用自定义类型转换器时，您可以使用任何可调用对象，该对象接受单个字符串参数（参数值）并\n返回转换后的值。但是，如果需要处理更复杂的情况，可以使用带有 action 形参的自定义动作类。\n例如，假设您希望处理带有不同前缀的参数并相应地进行处理:\nimport argparse\nparser = argparse.ArgumentParser(prefix_chars='-+')\nparser.add_argument('-a', metavar='<value>', action='append',\ntype=lambda x: ('-', x))\nparser.add_argument('+a', metavar='<value>', action='append',\ntype=lambda x: ('+', x))\nargs = parser.parse_args()\nprint(args)\n输出：\n$ python prog.py -a value1 +a value2\nNamespace(a=[('-', 'value1'), ('+', 'value2')])\n在这个例子中，我们：\n使用 prefix_chars 形参创建了带有自定义前缀字符的解析器 。\n定义了两个参数 -a 和 +a, 它们使用 type 形参创建自定义类型转换器，以便将值存储在带有前缀\n的元组中。\n如果没有自定义类型转换器，参数会将 -a 和 +a 视为同一个参数，这是不可取的。 通过使用自定义\n类型转换器，我们能够区分这两个参数。\n后记\n除了这里显示的内容，argparse 模块还提供了更多功能。 它的文档相当详细和完整，包含大量示\n例。 完成这个教程之后，你应该能毫不困难地阅读该文档。\n\n| 这会很有用。\n使用自定义类型转换器时，您可以使用任何可调用对象，该对象接受单个字符串参数（参数值）并\n返回转换后的值。但是，如果需要处理更复杂的情况，可以使用带有 action 形参的自定义动作类。\n例如，假设您希望处理带有不同前缀的参数并相应地进行处理: |\n| --- |\n| import argparse\nparser = argparse.ArgumentParser(prefix_chars='-+')\nparser.add_argument('-a', metavar='<value>', action='append',\ntype=lambda x: ('-', x))\nparser.add_argument('+a', metavar='<value>', action='append',\ntype=lambda x: ('+', x))\nargs = parser.parse_args()\nprint(args) |\n| 输出： |\n| $ python prog.py -a value1 +a value2\nNamespace(a=[('-', 'value1'), ('+', 'value2')]) |\n| 在这个例子中，我们：\n使用 prefix_chars 形参创建了带有自定义前缀字符的解析器 。\n定义了两个参数 -a 和 +a, 它们使用 type 形参创建自定义类型转换器，以便将值存储在带有前缀\n的元组中。\n如果没有自定义类型转换器，参数会将 -a 和 +a 视为同一个参数，这是不可取的。 通过使用自定义\n类型转换器，我们能够区分这两个参数。\n后记\n除了这里显示的内容，argparse 模块还提供了更多功能。 它的文档相当详细和完整，包含大量示\n例。 完成这个教程之后，你应该能毫不困难地阅读该文档。 |", "metadata": {"title": "03_argparse_教程", "source": "md_docs\\python_howto_md\\03_argparse_教程.md", "doc_type": "指南", "language": "中文", "doc_id": "93e5bf48"}}
{"doc_id": "a8b66780", "content": "描述器指南\n作者: Raymond Hettinger（译者：wh2099 at outlook dot com）\n联系方式: <python at rcn dot com>\n目录\n描述器指南\n入门\n简单示例：返回常量的描述器\n动态查找\n托管属性\n定制名称\n结束语\n完整的实际例子\n验证器类\n自定义验证器\n实际应用\n技术教程\n摘要\n定义与介绍\n描述器协议\n描述器调用概述\n通过实例调用\n通过类调用\n通过 super 调用\n调用逻辑总结\n自动名称通知\nORM （对象关系映射）示例\n纯 Python 等价实现\n属性\n函数和方法\n方法的种类\n静态方法\n类方法\n成员对象和 __slots__\n描述器 让对象能够自定义属性查找、存储和删除的操作。\n本指南主要分为四个部分：\n\n| 描述器指南\n作者: Raymond Hettinger（译者：wh2099 at outlook dot com）\n联系方式: <python at rcn dot com> |\n| --- |\n| 目录\n描述器指南\n入门\n简单示例：返回常量的描述器\n动态查找\n托管属性\n定制名称\n结束语\n完整的实际例子\n验证器类\n自定义验证器\n实际应用\n技术教程\n摘要\n定义与介绍\n描述器协议\n描述器调用概述\n通过实例调用\n通过类调用\n通过 super 调用\n调用逻辑总结\n自动名称通知\nORM （对象关系映射）示例\n纯 Python 等价实现\n属性\n函数和方法\n方法的种类\n静态方法\n类方法\n成员对象和 __slots__ |\n| 描述器 让对象能够自定义属性查找、存储和删除的操作。\n本指南主要分为四个部分： |\n\n| 作者: |\n| --- |\n| 联系方式: |\n\n1. “入门” 部分从简单的示例着手，逐步添加特性，从而给出基本的概述。如果你是刚接触到描\n述器，请从这里开始。\n2. 第二部分展示了完整的、实用的描述器示例。如果您已经掌握了基础知识，请从此处开始。\n3. 第三部分提供了更多技术教程，详细介绍了描述器如何工作。大多数人并不需要深入到这种程\n度。\n4. 最后一部分有对内置描述器（用 C 编写）的纯 Python 等价实现。如果您想了解函数如何变成\n绑定方法或对 classmethod()， staticmethod()，property() 和 __slots__ 这类常见工具\n的实现感兴趣，请阅读此部分。\n入门\n现在，让我们从最基本的示例开始，然后逐步添加新功能。\n简单示例：返回常量的描述器\nTen 类是一个描述器，其 __get__() 方法始终返回常量 10:\nclass Ten:\ndef __get__(self, obj, objtype=None):\nreturn 10\n要使用描述器，它必须作为一个类变量存储在另一个类中：\nclass A:\nx = 5 # 常规类属性\ny = Ten() # 描述器实例\n用交互式会话查看普通属性查找和描述器查找之间的区别：\n>>> a = A() # 创建一个类 A 的实例\n>>> a.x # 正常属性查找\n5\n>>> a.y # 描述器查找\n10\n在 a.x 属性查找中，点运算符会找到存储在类字典中的 'x': 5。 在 a.y 查找中，点运算符会根据\n描述器实例的 __get__ 方法将其识别出来，调用该方法并返回 10 。\n请注意，值 10 既不存储在类字典中也不存储在实例字典中。相反，值 10 是在调用时才取到的。\n这个简单的例子展示了一个描述器是如何工作的，但它不是很有用。在查找常量时，用常规属性查\n找会更好。\n在下一节中，我们将创建更有用的东西，即动态查找。\n动态查找\n有趣的描述器通常运行计算而不是返回常量：\n\n|  | 1. “入门” 部分从简单的示例着手，逐步添加特性，从而给出基本的概述。如果你是刚接触到描\n述器，请从这里开始。\n2. 第二部分展示了完整的、实用的描述器示例。如果您已经掌握了基础知识，请从此处开始。\n3. 第三部分提供了更多技术教程，详细介绍了描述器如何工作。大多数人并不需要深入到这种程\n度。\n4. 最后一部分有对内置描述器（用 C 编写）的纯 Python 等价实现。如果您想了解函数如何变成\n绑定方法或对 classmethod()， staticmethod()，property() 和 __slots__ 这类常见工具\n的实现感兴趣，请阅读此部分。\n入门\n现在，让我们从最基本的示例开始，然后逐步添加新功能。\n简单示例：返回常量的描述器\nTen 类是一个描述器，其 __get__() 方法始终返回常量 10: |  |\n| --- | --- | --- |\n|  | class Ten:\ndef __get__(self, obj, objtype=None):\nreturn 10 |  |\n|  | 要使用描述器，它必须作为一个类变量存储在另一个类中： |  |\n|  | class A:\nx = 5 # 常规类属性\ny = Ten() # 描述器实例 |  |\n|  | 用交互式会话查看普通属性查找和描述器查找之间的区别： |  |\n|  | >>> a = A() # 创建一个类 A 的实例\n>>> a.x # 正常属性查找\n5\n>>> a.y # 描述器查找\n10 |  |\n|  | 在 a.x 属性查找中，点运算符会找到存储在类字典中的 'x': 5。 在 a.y 查找中，点运算符会根据\n描述器实例的 __get__ 方法将其识别出来，调用该方法并返回 10 。\n请注意，值 10 既不存储在类字典中也不存储在实例字典中。相反，值 10 是在调用时才取到的。\n这个简单的例子展示了一个描述器是如何工作的，但它不是很有用。在查找常量时，用常规属性查\n找会更好。\n在下一节中，我们将创建更有用的东西，即动态查找。\n动态查找\n有趣的描述器通常运行计算而不是返回常量： |  |\n\nimport os\nclass DirectorySize:\ndef __get__(self, obj, objtype=None):\nreturn len(os.listdir(obj.dirname))\nclass Directory:\nsize = DirectorySize() # 描述器实例\ndef __init__(self, dirname):\nself.dirname = dirname # 常规实例属性\n交互式会话显示查找是动态的，每次都会计算不同的，经过更新的返回值:\n>>> s = Directory('songs')\n>>> g = Directory('games')\n>>> s.size # songs 目录有二十个文件\n20\n>>> g.size # games 目录有三个文件\n3\n>>> os.remove('games/chess') # 删除一个 game\n>>> g.size # 文件计数将自动更新\n2\n除了说明描述器如何运行计算，这个例子也揭示了传给 __get__() 的形参的目的。 self 形参为\nsize，即一个 DirectorySize 的实例。 obj 形参为 g 或 s，即一个 Directory 的实例。 obj 形参让\n__get__() 方法获知目标目录。 objtype 形参为 Directory 类。\n托管属性\n描述器的一种流行用法是管理对实例数据的访问。 描述器被分配给类字典中的公有属性，而实际数\n据则作为私有属性存储在实例字典中。 描述器的 __get__() 和 __set__() 方法会在公有属性被访\n问时被触发。\n在下面的例子中，age 是公开属性，_age 是私有属性。当访问公开属性时，描述器会记录下查找或\n更新的日志：\nimport logging\nlogging.basicConfig(level=logging.INFO)\nclass LoggedAgeAccess:\ndef __get__(self, obj, objtype=None):\nvalue = obj._age\nlogging.info('Accessing %r giving %r', 'age', value)\nreturn value\ndef __set__(self, obj, value):\nlogging.info('Updating %r to %r', 'age', value)\nobj._age = value\nclass Person:\n\n|  | import os\nclass DirectorySize:\ndef __get__(self, obj, objtype=None):\nreturn len(os.listdir(obj.dirname))\nclass Directory:\nsize = DirectorySize() # 描述器实例\ndef __init__(self, dirname):\nself.dirname = dirname # 常规实例属性 |  |\n| --- | --- | --- |\n|  | 交互式会话显示查找是动态的，每次都会计算不同的，经过更新的返回值: |  |\n|  | >>> s = Directory('songs')\n>>> g = Directory('games')\n>>> s.size # songs 目录有二十个文件\n20\n>>> g.size # games 目录有三个文件\n3\n>>> os.remove('games/chess') # 删除一个 game\n>>> g.size # 文件计数将自动更新\n2 |  |\n|  | 除了说明描述器如何运行计算，这个例子也揭示了传给 __get__() 的形参的目的。 self 形参为\nsize，即一个 DirectorySize 的实例。 obj 形参为 g 或 s，即一个 Directory 的实例。 obj 形参让\n__get__() 方法获知目标目录。 objtype 形参为 Directory 类。\n托管属性\n描述器的一种流行用法是管理对实例数据的访问。 描述器被分配给类字典中的公有属性，而实际数\n据则作为私有属性存储在实例字典中。 描述器的 __get__() 和 __set__() 方法会在公有属性被访\n问时被触发。\n在下面的例子中，age 是公开属性，_age 是私有属性。当访问公开属性时，描述器会记录下查找或\n更新的日志： |  |\n|  | import logging\nlogging.basicConfig(level=logging.INFO)\nclass LoggedAgeAccess:\ndef __get__(self, obj, objtype=None):\nvalue = obj._age\nlogging.info('Accessing %r giving %r', 'age', value)\nreturn value\ndef __set__(self, obj, value):\nlogging.info('Updating %r to %r', 'age', value)\nobj._age = value\nclass Person: |  |\n\nage = LoggedAgeAccess() # 描述器实例\ndef __init__(self, name, age):\nself.name = name # 常规实例属性\nself.age = age # 调用 __set__()\ndef birthday(self):\nself.age += 1 # 调用 __get__() 和 __set__()\n交互式会话展示中，对托管属性 age 的所有访问都被记录了下来，但常规属性 name 则未被记录：\n>>> mary = Person('Mary M', 30) # 初始年龄更新会被记录\nINFO:root:Updating 'age' to 30\n>>> dave = Person('David D', 40)\nINFO:root:Updating 'age' to 40\n>>> vars(mary) # 私有属性中的实际数据\n{'name': 'Mary M', '_age': 30}\n>>> vars(dave)\n{'name': 'David D', '_age': 40}\n>>> mary.age # 访问数据并记录查找操作\nINFO:root:Accessing 'age' giving 30\n30\n>>> mary.birthday() # 更新也会被记录\nINFO:root:Accessing 'age' giving 30\nINFO:root:Updating 'age' to 31\n>>> dave.name # 常规属性查找不会被记录\n'David D'\n>>> dave.age # 只有被管理的属性会被记录\nINFO:root:Accessing 'age' giving 40\n40\n此示例的一个主要问题是私有名称 _age 在类 LoggedAgeAccess 中是硬耦合的。这意味着每个实例只\n能有一个用于记录的属性，并且其名称不可更改。\n定制名称\n当一个类使用描述器时，它可以告知每个描述器使用了什么变量名。\n在此示例中，Person 类具有两个描述器实例 name 和 age。 当 Person 类被定义时，它将在\nLoggedAccess 中执行对 __set_name__() 的回调以便记录字段名称，给予每个描述器自己的\npublic_name 和 private_name:\nimport logging\nlogging.basicConfig(level=logging.INFO)\nclass LoggedAccess:\ndef __set_name__(self, owner, name):\nself.public_name = name\nself.private_name = '_' + name\n\n|  | age = LoggedAgeAccess() # 描述器实例\ndef __init__(self, name, age):\nself.name = name # 常规实例属性\nself.age = age # 调用 __set__()\ndef birthday(self):\nself.age += 1 # 调用 __get__() 和 __set__() |  |\n| --- | --- | --- |\n|  | 交互式会话展示中，对托管属性 age 的所有访问都被记录了下来，但常规属性 name 则未被记录： |  |\n|  | >>> mary = Person('Mary M', 30) # 初始年龄更新会被记录\nINFO:root:Updating 'age' to 30\n>>> dave = Person('David D', 40)\nINFO:root:Updating 'age' to 40\n>>> vars(mary) # 私有属性中的实际数据\n{'name': 'Mary M', '_age': 30}\n>>> vars(dave)\n{'name': 'David D', '_age': 40}\n>>> mary.age # 访问数据并记录查找操作\nINFO:root:Accessing 'age' giving 30\n30\n>>> mary.birthday() # 更新也会被记录\nINFO:root:Accessing 'age' giving 30\nINFO:root:Updating 'age' to 31\n>>> dave.name # 常规属性查找不会被记录\n'David D'\n>>> dave.age # 只有被管理的属性会被记录\nINFO:root:Accessing 'age' giving 40\n40 |  |\n|  | 此示例的一个主要问题是私有名称 _age 在类 LoggedAgeAccess 中是硬耦合的。这意味着每个实例只\n能有一个用于记录的属性，并且其名称不可更改。\n定制名称\n当一个类使用描述器时，它可以告知每个描述器使用了什么变量名。\n在此示例中，Person 类具有两个描述器实例 name 和 age。 当 Person 类被定义时，它将在\nLoggedAccess 中执行对 __set_name__() 的回调以便记录字段名称，给予每个描述器自己的\npublic_name 和 private_name: |  |\n|  | import logging\nlogging.basicConfig(level=logging.INFO)\nclass LoggedAccess:\ndef __set_name__(self, owner, name):\nself.public_name = name\nself.private_name = '_' + name |  |\n\ndef __get__(self, obj, objtype=None):\nvalue = getattr(obj, self.private_name)\nlogging.info('Accessing %r giving %r', self.public_name, value)\nreturn value\ndef __set__(self, obj, value):\nlogging.info('Updating %r to %r', self.public_name, value)\nsetattr(obj, self.private_name, value)\nclass Person:\nname = LoggedAccess() # 第一个描述器实例\nage = LoggedAccess() # 第二个描述器实例\ndef __init__(self, name, age):\nself.name = name # 调用第一个描述器\nself.age = age # 调用第二个描述器\ndef birthday(self):\nself.age += 1\n交互式会话显示 Person 类调用了 __set_name__() 以使字段名称可被记录。 在这里我们调用\nvars() 来查找描述器而不触发它：\n>>> vars(vars(Person)['name'])\n{'public_name': 'name', 'private_name': '_name'}\n>>> vars(vars(Person)['age'])\n{'public_name': 'age', 'private_name': '_age'}\n现在，新类会记录对 name 和 age 二者的访问：\n>>> pete = Person('Peter P', 10)\nINFO:root:Updating 'name' to 'Peter P'\nINFO:root:Updating 'age' to 10\n>>> kate = Person('Catherine C', 20)\nINFO:root:Updating 'name' to 'Catherine C'\nINFO:root:Updating 'age' to 20\n这两个 Person 实例仅包含私有名称:\n>>> vars(pete)\n{'_name': 'Peter P', '_age': 10}\n>>> vars(kate)\n{'_name': 'Catherine C', '_age': 20}\n结束语\ndescriptor 是指任何定义了 __get__(), __set__() 或 __delete__() 的对象。\n作为可选项，描述器可以有 __set_name__() 方法。 这仅会被用于当描述器需要知道创建它的类或\n它被分配的类变量名称等场合。 （此方法如果存在，那么即使所在类并不是一个描述器仍会被调\n用。）\n\n|  | def __get__(self, obj, objtype=None):\nvalue = getattr(obj, self.private_name)\nlogging.info('Accessing %r giving %r', self.public_name, value)\nreturn value\ndef __set__(self, obj, value):\nlogging.info('Updating %r to %r', self.public_name, value)\nsetattr(obj, self.private_name, value)\nclass Person:\nname = LoggedAccess() # 第一个描述器实例\nage = LoggedAccess() # 第二个描述器实例\ndef __init__(self, name, age):\nself.name = name # 调用第一个描述器\nself.age = age # 调用第二个描述器\ndef birthday(self):\nself.age += 1 |  |\n| --- | --- | --- |\n|  | 交互式会话显示 Person 类调用了 __set_name__() 以使字段名称可被记录。 在这里我们调用\nvars() 来查找描述器而不触发它： |  |\n|  | >>> vars(vars(Person)['name'])\n{'public_name': 'name', 'private_name': '_name'}\n>>> vars(vars(Person)['age'])\n{'public_name': 'age', 'private_name': '_age'} |  |\n|  | 现在，新类会记录对 name 和 age 二者的访问： |  |\n|  | >>> pete = Person('Peter P', 10)\nINFO:root:Updating 'name' to 'Peter P'\nINFO:root:Updating 'age' to 10\n>>> kate = Person('Catherine C', 20)\nINFO:root:Updating 'name' to 'Catherine C'\nINFO:root:Updating 'age' to 20 |  |\n|  | 这两个 Person 实例仅包含私有名称: |  |\n|  | >>> vars(pete)\n{'_name': 'Peter P', '_age': 10}\n>>> vars(kate)\n{'_name': 'Catherine C', '_age': 20} |  |\n|  | 结束语\ndescriptor 是指任何定义了 __get__(), __set__() 或 __delete__() 的对象。\n作为可选项，描述器可以有 __set_name__() 方法。 这仅会被用于当描述器需要知道创建它的类或\n它被分配的类变量名称等场合。 （此方法如果存在，那么即使所在类并不是一个描述器仍会被调\n用。） |  |\n\n在属性查找期间，描述器由点运算符调用。如果使用 vars(some_class)[descriptor_name] 间接\n访问描述器，则返回描述器实例而不调用它。\n描述器仅在用作类变量时起作用。放入实例时，它们将失效。\n描述器的主要目的是提供一个挂钩，允许存储在类变量中的对象控制在属性查找期间发生的情况。\n传统上，调用类控制查找过程中发生的事情。描述器反转了这种关系，并允许正在被查询的数据对\n此进行干涉。\n描述器的使用贯穿了整个语言。就是它让函数变成绑定方法。常见工具诸如 classmethod()，\nstaticmethod()，property() 和 functools.cached_property() 都作为描述器实现。\n完整的实际例子\n在此示例中，我们创建了一个实用而强大的工具来查找难以发现的数据损坏错误。\n验证器类\n验证器是一个用于托管属性访问的描述器。在存储任何数据之前，它会验证新值是否满足各种类型\n和范围限制。如果不满足这些限制，它将引发异常，从源头上防止数据损坏。\n这个 Validator 类既是一个 abstract base class 也是一个被管理的属性描述器：\nfrom abc import ABC, abstractmethod\nclass Validator(ABC):\ndef __set_name__(self, owner, name):\nself.private_name = '_' + name\ndef __get__(self, obj, objtype=None):\nreturn getattr(obj, self.private_name)\ndef __set__(self, obj, value):\nself.validate(value)\nsetattr(obj, self.private_name, value)\n@abstractmethod\ndef validate(self, value):\npass\n自定义验证器必须继承自 Validator 并且必须提供 validate() 方法以根据需要测试各种约束。\n自定义验证器\n这是三个实用的数据验证工具：\n1. OneOf 验证值是指定的受约束选项集合中的一项。\n2. Number 验证值是否为 int 或 float。 作为可选项，它还能验证值在给定的最小值和最大值\n之间。\n\n|  | 在属性查找期间，描述器由点运算符调用。如果使用 vars(some_class)[descriptor_name] 间接\n访问描述器，则返回描述器实例而不调用它。\n描述器仅在用作类变量时起作用。放入实例时，它们将失效。\n描述器的主要目的是提供一个挂钩，允许存储在类变量中的对象控制在属性查找期间发生的情况。\n传统上，调用类控制查找过程中发生的事情。描述器反转了这种关系，并允许正在被查询的数据对\n此进行干涉。\n描述器的使用贯穿了整个语言。就是它让函数变成绑定方法。常见工具诸如 classmethod()，\nstaticmethod()，property() 和 functools.cached_property() 都作为描述器实现。\n完整的实际例子\n在此示例中，我们创建了一个实用而强大的工具来查找难以发现的数据损坏错误。\n验证器类\n验证器是一个用于托管属性访问的描述器。在存储任何数据之前，它会验证新值是否满足各种类型\n和范围限制。如果不满足这些限制，它将引发异常，从源头上防止数据损坏。\n这个 Validator 类既是一个 abstract base class 也是一个被管理的属性描述器： |  |\n| --- | --- | --- |\n|  | from abc import ABC, abstractmethod\nclass Validator(ABC):\ndef __set_name__(self, owner, name):\nself.private_name = '_' + name\ndef __get__(self, obj, objtype=None):\nreturn getattr(obj, self.private_name)\ndef __set__(self, obj, value):\nself.validate(value)\nsetattr(obj, self.private_name, value)\n@abstractmethod\ndef validate(self, value):\npass |  |\n|  | 自定义验证器必须继承自 Validator 并且必须提供 validate() 方法以根据需要测试各种约束。\n自定义验证器\n这是三个实用的数据验证工具：\n1. OneOf 验证值是指定的受约束选项集合中的一项。\n2. Number 验证值是否为 int 或 float。 作为可选项，它还能验证值在给定的最小值和最大值\n之间。 |  |\n\n3. String 验证值是否为 str。 作为可选项，它还能验证给定的最小或最大长度。 它还能验证\n用户定义的 predicate。\nclass OneOf(Validator):\ndef __init__(self, *options):\nself.options = set(options)\ndef validate(self, value):\nif value not in self.options:\nraise ValueError(\nf'Expected {value!r} to be one of {self.options!r}'\n)\nclass Number(Validator):\ndef __init__(self, minvalue=None, maxvalue=None):\nself.minvalue = minvalue\nself.maxvalue = maxvalue\ndef validate(self, value):\nif not isinstance(value, (int, float)):\nraise TypeError(f'Expected {value!r} to be an int or float')\nif self.minvalue is not None and value < self.minvalue:\nraise ValueError(\nf'Expected {value!r} to be at least {self.minvalue!r}'\n)\nif self.maxvalue is not None and value > self.maxvalue:\nraise ValueError(\nf'Expected {value!r} to be no more than {self.maxvalue!r}'\n)\nclass String(Validator):\ndef __init__(self, minsize=None, maxsize=None, predicate=None):\nself.minsize = minsize\nself.maxsize = maxsize\nself.predicate = predicate\ndef validate(self, value):\nif not isinstance(value, str):\nraise TypeError(f'Expected {value!r} to be a str')\nif self.minsize is not None and len(value) < self.minsize:\nraise ValueError(\nf'Expected {value!r} to be no smaller than {self.minsize!r}'\n)\nif self.maxsize is not None and len(value) > self.maxsize:\nraise ValueError(\nf'Expected {value!r} to be no bigger than {self.maxsize!r}'\n)\nif self.predicate is not None and not self.predicate(value):\nraise ValueError(\nf'Expected {self.predicate} to be true for {value!r}'\n)\n实际应用\n这是在真实类中使用数据验证器的方法：\n\n|  | 3. String 验证值是否为 str。 作为可选项，它还能验证给定的最小或最大长度。 它还能验证\n用户定义的 predicate。 |  |\n| --- | --- | --- |\n|  | class OneOf(Validator):\ndef __init__(self, *options):\nself.options = set(options)\ndef validate(self, value):\nif value not in self.options:\nraise ValueError(\nf'Expected {value!r} to be one of {self.options!r}'\n)\nclass Number(Validator):\ndef __init__(self, minvalue=None, maxvalue=None):\nself.minvalue = minvalue\nself.maxvalue = maxvalue\ndef validate(self, value):\nif not isinstance(value, (int, float)):\nraise TypeError(f'Expected {value!r} to be an int or float')\nif self.minvalue is not None and value < self.minvalue:\nraise ValueError(\nf'Expected {value!r} to be at least {self.minvalue!r}'\n)\nif self.maxvalue is not None and value > self.maxvalue:\nraise ValueError(\nf'Expected {value!r} to be no more than {self.maxvalue!r}'\n)\nclass String(Validator):\ndef __init__(self, minsize=None, maxsize=None, predicate=None):\nself.minsize = minsize\nself.maxsize = maxsize\nself.predicate = predicate\ndef validate(self, value):\nif not isinstance(value, str):\nraise TypeError(f'Expected {value!r} to be a str')\nif self.minsize is not None and len(value) < self.minsize:\nraise ValueError(\nf'Expected {value!r} to be no smaller than {self.minsize!r}'\n)\nif self.maxsize is not None and len(value) > self.maxsize:\nraise ValueError(\nf'Expected {value!r} to be no bigger than {self.maxsize!r}'\n)\nif self.predicate is not None and not self.predicate(value):\nraise ValueError(\nf'Expected {self.predicate} to be true for {value!r}'\n) |  |\n|  | 实际应用\n这是在真实类中使用数据验证器的方法： |  |\n\nclass Component:\nname = String(minsize=3, maxsize=10, predicate=str.isupper)\nkind = OneOf('wood', 'metal', 'plastic')\nquantity = Number(minvalue=0)\ndef __init__(self, name, kind, quantity):\nself.name = name\nself.kind = kind\nself.quantity = quantity\n描述器阻止无效实例的创建：\n>>> Component('Widget', 'metal', 5) # 阻止: 'Widget' 不是全大写\nTraceback (most recent call last):\n...\nValueError: Expected <method 'isupper' of 'str' objects> to be true for 'Widget'\n>>> Component('WIDGET', 'metle', 5) # 阻止: 'metle' 拼写错误\nTraceback (most recent call last):\n...\nValueError: Expected 'metle' to be one of {'metal', 'plastic', 'wood'}\n>>> Component('WIDGET', 'metal', -5) # 阻止: -5 为负数\nTraceback (most recent call last):\n...\nValueError: Expected -5 to be at least 0\n>>> Component('WIDGET', 'metal', 'V') # 阻止: 'V' 不是数字\nTraceback (most recent call last):\n...\nTypeError: Expected 'V' to be an int or float\n>>> c = Component('WIDGET', 'metal', 5) # 允许: 输入有效\n技术教程\n接下来是专业性更强的技术教程，以及描述器工作原理的详细信息。\n摘要\n定义描述器，总结协议，并说明如何调用描述器。提供一个展示对象关系映射如何工作的示例。\n学习描述器不仅能提供接触到更多工具集的途径，还能更深地理解 Python 工作的原理。\n定义与介绍\n一般而言，描述器是具有描述器协议中的方法之一的属性值。 这些方法是 __get__(), __set__()\n和 __delete__()。 如果为某个属性定义了这些方法中的任何一个，它就被称为 descriptor。\n属性访问的默认行为是从一个对象的字典中获取、设置或删除属性。对于实例来说，a.x 的查找顺\n序会从 a.__dict__['x'] 开始，然后是 type(a).__dict__['x']，接下来依次查找 type(a) 的方\n法解析顺序（MRO）。 如果找到的值是定义了某个描述器方法的对象，则 Python 可能会重写默认\n\n|  | class Component:\nname = String(minsize=3, maxsize=10, predicate=str.isupper)\nkind = OneOf('wood', 'metal', 'plastic')\nquantity = Number(minvalue=0)\ndef __init__(self, name, kind, quantity):\nself.name = name\nself.kind = kind\nself.quantity = quantity |  |\n| --- | --- | --- |\n|  | 描述器阻止无效实例的创建： |  |\n|  | >>> Component('Widget', 'metal', 5) # 阻止: 'Widget' 不是全大写\nTraceback (most recent call last):\n...\nValueError: Expected <method 'isupper' of 'str' objects> to be true for 'Widget'\n>>> Component('WIDGET', 'metle', 5) # 阻止: 'metle' 拼写错误\nTraceback (most recent call last):\n...\nValueError: Expected 'metle' to be one of {'metal', 'plastic', 'wood'}\n>>> Component('WIDGET', 'metal', -5) # 阻止: -5 为负数\nTraceback (most recent call last):\n...\nValueError: Expected -5 to be at least 0\n>>> Component('WIDGET', 'metal', 'V') # 阻止: 'V' 不是数字\nTraceback (most recent call last):\n...\nTypeError: Expected 'V' to be an int or float\n>>> c = Component('WIDGET', 'metal', 5) # 允许: 输入有效 |  |\n|  | 技术教程\n接下来是专业性更强的技术教程，以及描述器工作原理的详细信息。\n摘要\n定义描述器，总结协议，并说明如何调用描述器。提供一个展示对象关系映射如何工作的示例。\n学习描述器不仅能提供接触到更多工具集的途径，还能更深地理解 Python 工作的原理。\n定义与介绍\n一般而言，描述器是具有描述器协议中的方法之一的属性值。 这些方法是 __get__(), __set__()\n和 __delete__()。 如果为某个属性定义了这些方法中的任何一个，它就被称为 descriptor。\n属性访问的默认行为是从一个对象的字典中获取、设置或删除属性。对于实例来说，a.x 的查找顺\n序会从 a.__dict__['x'] 开始，然后是 type(a).__dict__['x']，接下来依次查找 type(a) 的方\n法解析顺序（MRO）。 如果找到的值是定义了某个描述器方法的对象，则 Python 可能会重写默认 |  |\n\n行为并转而唤起描述器方法。这具体发生在优先级链的哪个环节则要根据所定义的描述器方法及其\n被调用的方式来决定。\n描述器是一种强大的，通用的协议。 它们是属性、方法、静态方法、类方法和 super() 背后的机\n制。 它们在整个 Python 中都有使用。 描述器简化了底层的 C 代码并为日常的 Python 程序提供了\n一套灵活的新工具。\n描述器协议\ndescr.__get__(self, obj, type=None)\ndescr.__set__(self, obj, value)\ndescr.__delete__(self, obj)\n描述器的方法就这些。一个对象只要定义了以上方法中的任何一个，就被视为描述器，并在被作为\n属性时覆盖其默认行为。\n如果一个对象定义了 __set__() 或 __delete__()，它将被视为数据描述器。 仅定义了 __get__()\n的描述器称为非数据描述器（它们经常被用于方法但也可以有其他用途。\n数据和非数据描述器的不同之处在于，如何计算实例字典中条目的替代值。如果实例的字典具有与\n数据描述器同名的条目，则数据描述器优先。如果实例的字典具有与非数据描述器同名的条目，则\n该字典条目优先。\n为了使一个数据描述器只读，应同时定义 __get__() 和 __set__() 并在调用 __set__() 时引发\nAttributeError。 用引发异常的占位符定义 __set__() 方法就足以使其成为一个数据描述器。\n描述器调用概述\n描述器可以通过 d.__get__(obj) 或 desc.__get__(None, cls) 直接调用。\n但更常见的是通过属性访问自动调用描述器。\n表达式 obj.x 在 obj 的命名空间链中查找属性 x。 如果搜索发现了一个实例 __dict__ 以外的描述\n器，将根据下面列出的优先级规则调用其 __get__() 方法。\n调用的细节取决于 obj 是对象、类还是超类的实例。\n通过实例调用\n实例查找会扫描命名空间链并给予数据描述器最高的优先级，然后是实例变量，然后是非数据描述\n器，最后是 __getattr__()，如果有提供的话。\n如果 a.x 找到了一个描述器，那么将通过 desc.__get__(a, type(a)) 调用它。\n点运算符的查找逻辑在 object.__getattribute__() 中。这里是一个等价的纯 Python 实现：\ndef find_name_in_mro(cls, name, default):\n\"Emulate _PyType_Lookup() in Objects/typeobject.c\"\n\n|  | 行为并转而唤起描述器方法。这具体发生在优先级链的哪个环节则要根据所定义的描述器方法及其\n被调用的方式来决定。\n描述器是一种强大的，通用的协议。 它们是属性、方法、静态方法、类方法和 super() 背后的机\n制。 它们在整个 Python 中都有使用。 描述器简化了底层的 C 代码并为日常的 Python 程序提供了\n一套灵活的新工具。\n描述器协议\ndescr.__get__(self, obj, type=None)\ndescr.__set__(self, obj, value)\ndescr.__delete__(self, obj)\n描述器的方法就这些。一个对象只要定义了以上方法中的任何一个，就被视为描述器，并在被作为\n属性时覆盖其默认行为。\n如果一个对象定义了 __set__() 或 __delete__()，它将被视为数据描述器。 仅定义了 __get__()\n的描述器称为非数据描述器（它们经常被用于方法但也可以有其他用途。\n数据和非数据描述器的不同之处在于，如何计算实例字典中条目的替代值。如果实例的字典具有与\n数据描述器同名的条目，则数据描述器优先。如果实例的字典具有与非数据描述器同名的条目，则\n该字典条目优先。\n为了使一个数据描述器只读，应同时定义 __get__() 和 __set__() 并在调用 __set__() 时引发\nAttributeError。 用引发异常的占位符定义 __set__() 方法就足以使其成为一个数据描述器。\n描述器调用概述\n描述器可以通过 d.__get__(obj) 或 desc.__get__(None, cls) 直接调用。\n但更常见的是通过属性访问自动调用描述器。\n表达式 obj.x 在 obj 的命名空间链中查找属性 x。 如果搜索发现了一个实例 __dict__ 以外的描述\n器，将根据下面列出的优先级规则调用其 __get__() 方法。\n调用的细节取决于 obj 是对象、类还是超类的实例。\n通过实例调用\n实例查找会扫描命名空间链并给予数据描述器最高的优先级，然后是实例变量，然后是非数据描述\n器，最后是 __getattr__()，如果有提供的话。\n如果 a.x 找到了一个描述器，那么将通过 desc.__get__(a, type(a)) 调用它。\n点运算符的查找逻辑在 object.__getattribute__() 中。这里是一个等价的纯 Python 实现： |  |\n| --- | --- | --- |\n|  | def find_name_in_mro(cls, name, default):\n\"Emulate _PyType_Lookup() in Objects/typeobject.c\" |  |\n\nfor base in cls.__mro__:\nif name in vars(base):\nreturn vars(base)[name]\nreturn default\ndef object_getattribute(obj, name):\n\"Emulate PyObject_GenericGetAttr() in Objects/object.c\"\nnull = object()\nobjtype = type(obj)\ncls_var = find_name_in_mro(objtype, name, null)\ndescr_get = getattr(type(cls_var), '__get__', null)\nif descr_get is not null:\nif (hasattr(type(cls_var), '__set__')\nor hasattr(type(cls_var), '__delete__')):\nreturn descr_get(cls_var, obj, objtype) # 数据描述器\nif hasattr(obj, '__dict__') and name in vars(obj):\nreturn vars(obj)[name] # 实例变量\nif descr_get is not null:\nreturn descr_get(cls_var, obj, objtype) # 非数据描述器\nif cls_var is not null:\nreturn cls_var # 类变量\nraise AttributeError(name)\n注意，在 __getattribute__() 代码中没有 __getattr__() 钩子。 这就是为什么直接调用\n__getattribute__() 或用 super().__getattribute__ 会彻底绕过 __getattr__()。\n相反，一旦 __getattribute__() 引发 AttributeError 则将由点运算符和 getattr() 函数来负责\n唤起 __getattr__()。 它们的逻辑封装在一个辅助函数中：\ndef getattr_hook(obj, name):\n\"Emulate slot_tp_getattr_hook() in Objects/typeobject.c\"\ntry:\nreturn obj.__getattribute__(name)\nexcept AttributeError:\nif not hasattr(type(obj), '__getattr__'):\nraise\nreturn type(obj).__getattr__(obj, name) # __getattr__\n通过类调用\n像 A.x 这样的点操作符查找的逻辑在 type.__getattribute__() 中。 其步骤与\nobject.__getattribute__() 相似，但是实例字典查找被替换为搜索类的 method resolution\norder。\n如果找到了一个描述器，那么将通过 desc.__get__(None, A) 调用它。\n完整的 C 实现可在 Objects/typeobject.c 里的 type_getattro() 和 _PyType_Lookup() 中找到。\n通过 super 调用\nsuper 的点操作符查找的逻辑在 super() 所返回对象的 __getattribute__() 方法中。\n类似 super(A, obj).m 形式的点分查找将在 obj.__class__.__mro__ 中搜索紧接在 A 之后的基类\nB，然后返回 B.__dict__['m'].__get__(obj, A)。如果 m 不是描述器，则直接返回其值。\n\n|  | for base in cls.__mro__:\nif name in vars(base):\nreturn vars(base)[name]\nreturn default\ndef object_getattribute(obj, name):\n\"Emulate PyObject_GenericGetAttr() in Objects/object.c\"\nnull = object()\nobjtype = type(obj)\ncls_var = find_name_in_mro(objtype, name, null)\ndescr_get = getattr(type(cls_var), '__get__', null)\nif descr_get is not null:\nif (hasattr(type(cls_var), '__set__')\nor hasattr(type(cls_var), '__delete__')):\nreturn descr_get(cls_var, obj, objtype) # 数据描述器\nif hasattr(obj, '__dict__') and name in vars(obj):\nreturn vars(obj)[name] # 实例变量\nif descr_get is not null:\nreturn descr_get(cls_var, obj, objtype) # 非数据描述器\nif cls_var is not null:\nreturn cls_var # 类变量\nraise AttributeError(name) |  |\n| --- | --- | --- |\n|  | 注意，在 __getattribute__() 代码中没有 __getattr__() 钩子。 这就是为什么直接调用\n__getattribute__() 或用 super().__getattribute__ 会彻底绕过 __getattr__()。\n相反，一旦 __getattribute__() 引发 AttributeError 则将由点运算符和 getattr() 函数来负责\n唤起 __getattr__()。 它们的逻辑封装在一个辅助函数中： |  |\n|  | def getattr_hook(obj, name):\n\"Emulate slot_tp_getattr_hook() in Objects/typeobject.c\"\ntry:\nreturn obj.__getattribute__(name)\nexcept AttributeError:\nif not hasattr(type(obj), '__getattr__'):\nraise\nreturn type(obj).__getattr__(obj, name) # __getattr__ |  |\n|  | 通过类调用\n像 A.x 这样的点操作符查找的逻辑在 type.__getattribute__() 中。 其步骤与\nobject.__getattribute__() 相似，但是实例字典查找被替换为搜索类的 method resolution\norder。\n如果找到了一个描述器，那么将通过 desc.__get__(None, A) 调用它。\n完整的 C 实现可在 Objects/typeobject.c 里的 type_getattro() 和 _PyType_Lookup() 中找到。\n通过 super 调用\nsuper 的点操作符查找的逻辑在 super() 所返回对象的 __getattribute__() 方法中。\n类似 super(A, obj).m 形式的点分查找将在 obj.__class__.__mro__ 中搜索紧接在 A 之后的基类\nB，然后返回 B.__dict__['m'].__get__(obj, A)。如果 m 不是描述器，则直接返回其值。 |  |\n\n完整的 C 实现可在 Objects/typeobject.c 里的 super_getattro() 中找到。 纯 Python 的等价实现\n可在 Guido 的教程 中找到。\n调用逻辑总结\n描述器的机制嵌入在 object, type 和 super() 的 __getattribute__() 方法中。\n要记住的重要点是：\n描述器将由 __getattribute__() 方法唤起。\n类从 object，type 或 super() 继承此机制。\n重写 __getattribute__() 将阻止自动的描述器调用因为所有描述器逻辑都在该方法中。\nobject.__getattribute__() 和 type.__getattribute__() 会用不同方式调用 __get__()。\n第一个会包括实例并可能包括类 。第二个会将 None 作为实例并且总是包括类。\n数据描述器始终会覆盖实例字典。\n非数据描述器会被实例字典覆盖。\n自动名称通知\n有时描述器需要知道它被赋值到哪个变量名。 当一个新类被创建时，type 元类将扫描新类的字典。\n如果其中有任何条目是描述器并且它们定义了 __set_name__()，则该方法被调用时将附带两个参\n数。 owner 是使用该描述器的类，而 name 是该描述器被赋值到的变量。\n实现的细节在 Objects/typeobject.c 里的 type_new() 和 set_names() 中。\n由于更新逻辑是在 type.__new__() 中，因此通知仅在类创建时发出。 之后如果将描述器添加到类\n中，则需要手动调用 __set_name__()。\nORM （对象关系映射）示例\n以下代码展示了如何使用数据描述器来实现简单的 对象关系映射 框架。\n其核心思路是将数据存储在外部数据库中，Python 实例仅持有数据库表中对应的的键。描述器负责\n对值进行查找或更新：\nclass Field:\ndef __set_name__(self, owner, name):\nself.fetch = f'SELECT {name} FROM {owner.table} WHERE {owner.key}=?;'\nself.store = f'UPDATE {owner.table} SET {name}=? WHERE {owner.key}=?;'\ndef __get__(self, obj, objtype=None):\nreturn conn.execute(self.fetch, [obj.key]).fetchone()[0]\ndef __set__(self, obj, value):\nconn.execute(self.store, [value, obj.key])\nconn.commit()\n我们可以使用 Field 类来定义描述了数据库中每张表的结构的 模型:\n\n|  | 完整的 C 实现可在 Objects/typeobject.c 里的 super_getattro() 中找到。 纯 Python 的等价实现\n可在 Guido 的教程 中找到。\n调用逻辑总结\n描述器的机制嵌入在 object, type 和 super() 的 __getattribute__() 方法中。\n要记住的重要点是：\n描述器将由 __getattribute__() 方法唤起。\n类从 object，type 或 super() 继承此机制。\n重写 __getattribute__() 将阻止自动的描述器调用因为所有描述器逻辑都在该方法中。\nobject.__getattribute__() 和 type.__getattribute__() 会用不同方式调用 __get__()。\n第一个会包括实例并可能包括类 。第二个会将 None 作为实例并且总是包括类。\n数据描述器始终会覆盖实例字典。\n非数据描述器会被实例字典覆盖。\n自动名称通知\n有时描述器需要知道它被赋值到哪个变量名。 当一个新类被创建时，type 元类将扫描新类的字典。\n如果其中有任何条目是描述器并且它们定义了 __set_name__()，则该方法被调用时将附带两个参\n数。 owner 是使用该描述器的类，而 name 是该描述器被赋值到的变量。\n实现的细节在 Objects/typeobject.c 里的 type_new() 和 set_names() 中。\n由于更新逻辑是在 type.__new__() 中，因此通知仅在类创建时发出。 之后如果将描述器添加到类\n中，则需要手动调用 __set_name__()。\nORM （对象关系映射）示例\n以下代码展示了如何使用数据描述器来实现简单的 对象关系映射 框架。\n其核心思路是将数据存储在外部数据库中，Python 实例仅持有数据库表中对应的的键。描述器负责\n对值进行查找或更新： |  |\n| --- | --- | --- |\n|  | class Field:\ndef __set_name__(self, owner, name):\nself.fetch = f'SELECT {name} FROM {owner.table} WHERE {owner.key}=?;'\nself.store = f'UPDATE {owner.table} SET {name}=? WHERE {owner.key}=?;'\ndef __get__(self, obj, objtype=None):\nreturn conn.execute(self.fetch, [obj.key]).fetchone()[0]\ndef __set__(self, obj, value):\nconn.execute(self.store, [value, obj.key])\nconn.commit() |  |\n|  | 我们可以使用 Field 类来定义描述了数据库中每张表的结构的 模型: |  |\n\nclass Movie:\ntable = 'Movies' # 表名\nkey = 'title' # 主键\ndirector = Field()\nyear = Field()\ndef __init__(self, key):\nself.key = key\nclass Song:\ntable = 'Music'\nkey = 'title'\nartist = Field()\nyear = Field()\ngenre = Field()\ndef __init__(self, key):\nself.key = key\n要使用模型，首先要连接到数据库：\n>>> import sqlite3\n>>> conn = sqlite3.connect('entertainment.db')\n交互式会话显示了如何从数据库中检索数据及如何对其进行更新：\n>>> Movie('Star Wars').director\n'George Lucas'\n>>> jaws = Movie('Jaws')\n>>> f'Released in {jaws.year} by {jaws.director}'\n'Released in 1975 by Steven Spielberg'\n>>> Song('Country Roads').artist\n'John Denver'\n>>> Movie('Star Wars').director = 'J.J. Abrams'\n>>> Movie('Star Wars').director\n'J.J. Abrams'\n纯 Python 等价实现\n描述器协议很简单，但它提供了令人兴奋的可能性。有几个用例非常通用，以至于它们已预先打包\n到内置工具中。属性、绑定方法、静态方法、类方法和 __slots__ 均基于描述器协议。\n属性\n调用 property() 是构建数据描述器的简洁方式，该数据描述器在访问属性时触发函数调用。它的\n签名是：\nproperty(fget=None, fset=None, fdel=None, doc=None) -> property\n该文档显示了定义托管属性 x 的典型用法：\n\n|  | class Movie:\ntable = 'Movies' # 表名\nkey = 'title' # 主键\ndirector = Field()\nyear = Field()\ndef __init__(self, key):\nself.key = key\nclass Song:\ntable = 'Music'\nkey = 'title'\nartist = Field()\nyear = Field()\ngenre = Field()\ndef __init__(self, key):\nself.key = key |  |\n| --- | --- | --- |\n|  | 要使用模型，首先要连接到数据库： |  |\n|  | >>> import sqlite3\n>>> conn = sqlite3.connect('entertainment.db') |  |\n|  | 交互式会话显示了如何从数据库中检索数据及如何对其进行更新： |  |\n|  | >>> Movie('Star Wars').director\n'George Lucas'\n>>> jaws = Movie('Jaws')\n>>> f'Released in {jaws.year} by {jaws.director}'\n'Released in 1975 by Steven Spielberg'\n>>> Song('Country Roads').artist\n'John Denver'\n>>> Movie('Star Wars').director = 'J.J. Abrams'\n>>> Movie('Star Wars').director\n'J.J. Abrams' |  |\n|  | 纯 Python 等价实现\n描述器协议很简单，但它提供了令人兴奋的可能性。有几个用例非常通用，以至于它们已预先打包\n到内置工具中。属性、绑定方法、静态方法、类方法和 __slots__ 均基于描述器协议。\n属性\n调用 property() 是构建数据描述器的简洁方式，该数据描述器在访问属性时触发函数调用。它的\n签名是： |  |\n|  | property(fget=None, fset=None, fdel=None, doc=None) -> property |  |\n|  | 该文档显示了定义托管属性 x 的典型用法： |  |\n\nclass C:\ndef getx(self): return self.__x\ndef setx(self, value): self.__x = value\ndef delx(self): del self.__x\nx = property(getx, setx, delx, \"I'm the 'x' property.\")\n要了解 property() 是如何按描述器协议的方式来实现的，以下是一个实现了大部分核心功能的纯\nPython 等价实现：\nclass Property:\n\"Emulate PyProperty_Type() in Objects/descrobject.c\"\ndef __init__(self, fget=None, fset=None, fdel=None, doc=None):\nself.fget = fget\nself.fset = fset\nself.fdel = fdel\nif doc is None and fget is not None:\ndoc = fget.__doc__\nself.__doc__ = doc\ndef __set_name__(self, owner, name):\nself.__name__ = name\ndef __get__(self, obj, objtype=None):\nif obj is None:\nreturn self\nif self.fget is None:\nraise AttributeError\nreturn self.fget(obj)\ndef __set__(self, obj, value):\nif self.fset is None:\nraise AttributeError\nself.fset(obj, value)\ndef __delete__(self, obj):\nif self.fdel is None:\nraise AttributeError\nself.fdel(obj)\ndef getter(self, fget):\nreturn type(self)(fget, self.fset, self.fdel, self.__doc__)\ndef setter(self, fset):\nreturn type(self)(self.fget, fset, self.fdel, self.__doc__)\ndef deleter(self, fdel):\nreturn type(self)(self.fget, self.fset, fdel, self.__doc__)\n这个内置的 property() 每当用户访问属性时生效，随后的变化需要一个方法的参与。\n例如，一个电子表格类可以通过 Cell('b10').value 授予对单元格值的访问权限。对程序的后续改\n进要求每次访问都要重新计算单元格；但是，程序员不希望影响直接访问该属性的现有客户端代\n码。解决方案是将对 value 属性的访问包装在属性数据描述器中:\n\n|  | class C:\ndef getx(self): return self.__x\ndef setx(self, value): self.__x = value\ndef delx(self): del self.__x\nx = property(getx, setx, delx, \"I'm the 'x' property.\") |  |\n| --- | --- | --- |\n|  | 要了解 property() 是如何按描述器协议的方式来实现的，以下是一个实现了大部分核心功能的纯\nPython 等价实现： |  |\n|  | class Property:\n\"Emulate PyProperty_Type() in Objects/descrobject.c\"\ndef __init__(self, fget=None, fset=None, fdel=None, doc=None):\nself.fget = fget\nself.fset = fset\nself.fdel = fdel\nif doc is None and fget is not None:\ndoc = fget.__doc__\nself.__doc__ = doc\ndef __set_name__(self, owner, name):\nself.__name__ = name\ndef __get__(self, obj, objtype=None):\nif obj is None:\nreturn self\nif self.fget is None:\nraise AttributeError\nreturn self.fget(obj)\ndef __set__(self, obj, value):\nif self.fset is None:\nraise AttributeError\nself.fset(obj, value)\ndef __delete__(self, obj):\nif self.fdel is None:\nraise AttributeError\nself.fdel(obj)\ndef getter(self, fget):\nreturn type(self)(fget, self.fset, self.fdel, self.__doc__)\ndef setter(self, fset):\nreturn type(self)(self.fget, fset, self.fdel, self.__doc__)\ndef deleter(self, fdel):\nreturn type(self)(self.fget, self.fset, fdel, self.__doc__) |  |\n|  | 这个内置的 property() 每当用户访问属性时生效，随后的变化需要一个方法的参与。\n例如，一个电子表格类可以通过 Cell('b10').value 授予对单元格值的访问权限。对程序的后续改\n进要求每次访问都要重新计算单元格；但是，程序员不希望影响直接访问该属性的现有客户端代\n码。解决方案是将对 value 属性的访问包装在属性数据描述器中: |  |\n\nclass Cell:\n...\n@property\ndef value(self):\n\"Recalculate the cell before returning value\"\nself.recalc()\nreturn self._value\n在这个例子中内置的 property() 或我们的 Property() 等价实现都是可以的。\n函数和方法\nPython 的面向对象功能是在基于函数的环境构建的。通过使用非数据描述器，这两方面完成了无缝\n融合。\n在调用时，存储在类词典中的函数将被转换为方法。方法与常规函数的不同之处仅在于对象实例被\n置于其他参数之前。方法与常规函数的不同之处仅在于第一个参数是为对象实例保留的。按照惯\n例，实例引用称为 self ，但也可以称为 this 或任何其他变量名称。\n可以使用 types.MethodType 手动创建方法，其行为基本等价于：\nclass MethodType:\n\"Emulate PyMethod_Type in Objects/classobject.c\"\ndef __init__(self, func, obj):\nself.__func__ = func\nself.__self__ = obj\ndef __call__(self, *args, **kwargs):\nfunc = self.__func__\nobj = self.__self__\nreturn func(obj, *args, **kwargs)\ndef __getattribute__(self, name):\n\"Emulate method_getset() in Objects/classobject.c\"\nif name == '__doc__':\nreturn self.__func__.__doc__\nreturn object.__getattribute__(self, name)\ndef __getattr__(self, name):\n\"Emulate method_getattro() in Objects/classobject.c\"\nreturn getattr(self.__func__, name)\ndef __get__(self, obj, objtype=None):\n\"Emulate method_descr_get() in Objects/classobject.c\"\nreturn self\n为支持方法的自动创建，函数会包括 __get__() 方法以便在属性访问期间绑定方法。 这意味着函数\n就是在通过实例进行点号查找期间返回所绑定方法的非数据描述器。 其运作方式是这样的：\nclass Function:\n...\ndef __get__(self, obj, objtype=None):\n\n|  | class Cell:\n...\n@property\ndef value(self):\n\"Recalculate the cell before returning value\"\nself.recalc()\nreturn self._value |  |\n| --- | --- | --- |\n|  | 在这个例子中内置的 property() 或我们的 Property() 等价实现都是可以的。\n函数和方法\nPython 的面向对象功能是在基于函数的环境构建的。通过使用非数据描述器，这两方面完成了无缝\n融合。\n在调用时，存储在类词典中的函数将被转换为方法。方法与常规函数的不同之处仅在于对象实例被\n置于其他参数之前。方法与常规函数的不同之处仅在于第一个参数是为对象实例保留的。按照惯\n例，实例引用称为 self ，但也可以称为 this 或任何其他变量名称。\n可以使用 types.MethodType 手动创建方法，其行为基本等价于： |  |\n|  | class MethodType:\n\"Emulate PyMethod_Type in Objects/classobject.c\"\ndef __init__(self, func, obj):\nself.__func__ = func\nself.__self__ = obj\ndef __call__(self, *args, **kwargs):\nfunc = self.__func__\nobj = self.__self__\nreturn func(obj, *args, **kwargs)\ndef __getattribute__(self, name):\n\"Emulate method_getset() in Objects/classobject.c\"\nif name == '__doc__':\nreturn self.__func__.__doc__\nreturn object.__getattribute__(self, name)\ndef __getattr__(self, name):\n\"Emulate method_getattro() in Objects/classobject.c\"\nreturn getattr(self.__func__, name)\ndef __get__(self, obj, objtype=None):\n\"Emulate method_descr_get() in Objects/classobject.c\"\nreturn self |  |\n|  | 为支持方法的自动创建，函数会包括 __get__() 方法以便在属性访问期间绑定方法。 这意味着函数\n就是在通过实例进行点号查找期间返回所绑定方法的非数据描述器。 其运作方式是这样的： |  |\n|  | class Function:\n...\ndef __get__(self, obj, objtype=None): |  |\n\n\"Simulate func_descr_get() in Objects/funcobject.c\"\nif obj is None:\nreturn self\nreturn MethodType(self, obj)\n在解释器中运行以下类，这显示了函数描述器的实际工作方式：\nclass D:\ndef f(self):\nreturn self\nclass D2:\npass\n该函数具有 qualified name 属性以支持自省：\n>>> D.f.__qualname__\n'D.f'\n通过类字典访问函数不会唤起 __get__()。 相反，它只是返回下层的函数对象:\n>>> D.__dict__['f']\n<function D.f at 0x00C45070>\n通过类进行点号访问调用 __get__()，它将只原样返回下层的函数:\n>>> D.f\n<function D.f at 0x00C45070>\n有趣的行为发生在通过实例进行点号访问期间。 点号查找调用 __get__()，它将返回绑定的方法对\n象:\n>>> d = D()\n>>> d.f\n<bound method D.f of <__main__.D object at 0x00B18C90>>\n绑定方法在内部存储了底层函数和绑定的实例：\n>>> d.f.__func__\n<function D.f at 0x00C45070>\n>>> d.f.__self__\n<__main__.D object at 0x00B18C90>\n如果你曾好奇常规方法中的 self 或类方法中的 cls 是从什么地方来的，就是这里了！\n方法的种类\n非数据描述器为把函数绑定为方法的通常模式提供了一种简单的机制。\n总结一下，函数具有 __get__() 方法以便在其作为属性被访问时可被转换为方法。 非数据描述器会\n将 obj.f(*args) 调用转化为 f(obj, *args)。 调用 cls.f(*args) 将变成 f(*args)。\n\n|  | \"Simulate func_descr_get() in Objects/funcobject.c\"\nif obj is None:\nreturn self\nreturn MethodType(self, obj) |  |\n| --- | --- | --- |\n|  | 在解释器中运行以下类，这显示了函数描述器的实际工作方式： |  |\n|  | class D:\ndef f(self):\nreturn self\nclass D2:\npass |  |\n|  | 该函数具有 qualified name 属性以支持自省： |  |\n|  | >>> D.f.__qualname__\n'D.f' |  |\n|  | 通过类字典访问函数不会唤起 __get__()。 相反，它只是返回下层的函数对象: |  |\n|  | >>> D.__dict__['f']\n<function D.f at 0x00C45070> |  |\n|  | 通过类进行点号访问调用 __get__()，它将只原样返回下层的函数: |  |\n|  | >>> D.f\n<function D.f at 0x00C45070> |  |\n|  | 有趣的行为发生在通过实例进行点号访问期间。 点号查找调用 __get__()，它将返回绑定的方法对\n象: |  |\n|  | >>> d = D()\n>>> d.f\n<bound method D.f of <__main__.D object at 0x00B18C90>> |  |\n|  | 绑定方法在内部存储了底层函数和绑定的实例： |  |\n|  | >>> d.f.__func__\n<function D.f at 0x00C45070>\n>>> d.f.__self__\n<__main__.D object at 0x00B18C90> |  |\n|  | 如果你曾好奇常规方法中的 self 或类方法中的 cls 是从什么地方来的，就是这里了！\n方法的种类\n非数据描述器为把函数绑定为方法的通常模式提供了一种简单的机制。\n总结一下，函数具有 __get__() 方法以便在其作为属性被访问时可被转换为方法。 非数据描述器会\n将 obj.f(*args) 调用转化为 f(obj, *args)。 调用 cls.f(*args) 将变成 f(*args)。 |  |\n\n下表总结了绑定及其两个最有用的变体：\n转换形式 通过对象调用 通过类调用\nfunction -- 函数 f(obj, *args) f(*args)\n静态方法 f(*args) f(*args)\n类方法 f(type(obj), *args) f(cls, *args)\n静态方法\n静态方法返回底层函数，不做任何更改。调用 c.f 或 C.f 等效于通过\nobject.__getattribute__(c, \"f\") 或 object.__getattribute__(C, \"f\") 查找。这样该函数\n就可以从对象或类中进行相同的访问。\n适合作为静态方法的是那些不引用 self 变量的方法。\n举例来说，一个统计软件包可能包括存放实验性数据的容器类。 该类提供了用于计算平均数、均\n值、中位数以及其他描述性的统计数据的方法。 不过，还可能存在在概念上相关但不依赖于这些数\n据的有用函数。 例如，erf(x) 是在统计工作中的便捷转换例程但并不直接依赖于特定的数据集。\n它可以通过对象或者类来调用: s.erf(1.5) --> 0.9332 或者 Sample.erf(1.5) --> 0.9332。\n由于静态方法返回的底层函数没有任何变化，因此示例调用也是意料之中：\nclass E:\n@staticmethod\ndef f(x):\nreturn x * 10\n>>> E.f(3)\n30\n>>> E().f(3)\n30\n使用非数据描述器，纯 Python 版本的 staticmethod() 如下所示：\nimport functools\nclass StaticMethod:\n\"Emulate PyStaticMethod_Type() in Objects/funcobject.c\"\ndef __init__(self, f):\nself.f = f\nfunctools.update_wrapper(self, f)\ndef __get__(self, obj, objtype=None):\nreturn self.f\ndef __call__(self, *args, **kwds):\nreturn self.f(*args, **kwds)\n@property\n\n|  | 下表总结了绑定及其两个最有用的变体：\n转换形式 通过对象调用 通过类调用\nfunction -- 函数 f(obj, *args) f(*args)\n静态方法 f(*args) f(*args)\n类方法 f(type(obj), *args) f(cls, *args)\n静态方法\n静态方法返回底层函数，不做任何更改。调用 c.f 或 C.f 等效于通过\nobject.__getattribute__(c, \"f\") 或 object.__getattribute__(C, \"f\") 查找。这样该函数\n就可以从对象或类中进行相同的访问。\n适合作为静态方法的是那些不引用 self 变量的方法。\n举例来说，一个统计软件包可能包括存放实验性数据的容器类。 该类提供了用于计算平均数、均\n值、中位数以及其他描述性的统计数据的方法。 不过，还可能存在在概念上相关但不依赖于这些数\n据的有用函数。 例如，erf(x) 是在统计工作中的便捷转换例程但并不直接依赖于特定的数据集。\n它可以通过对象或者类来调用: s.erf(1.5) --> 0.9332 或者 Sample.erf(1.5) --> 0.9332。\n由于静态方法返回的底层函数没有任何变化，因此示例调用也是意料之中： |  |\n| --- | --- | --- |\n|  | class E:\n@staticmethod\ndef f(x):\nreturn x * 10 |  |\n|  |  |  |\n|  | >>> E.f(3)\n30\n>>> E().f(3)\n30 |  |\n|  | 使用非数据描述器，纯 Python 版本的 staticmethod() 如下所示： |  |\n|  | import functools\nclass StaticMethod:\n\"Emulate PyStaticMethod_Type() in Objects/funcobject.c\"\ndef __init__(self, f):\nself.f = f\nfunctools.update_wrapper(self, f)\ndef __get__(self, obj, objtype=None):\nreturn self.f\ndef __call__(self, *args, **kwds):\nreturn self.f(*args, **kwds)\n@property |  |\n\n| 转换形式 | 通过对象调用 | 通过类调用 |\n| --- | --- | --- |\n| function -- 函数 | f(obj, *args) | f(*args) |\n| 静态方法 | f(*args) | f(*args) |\n| 类方法 | f(type(obj), *args) | f(cls, *args) |\n\ndef __annotations__(self):\nreturn self.f.__annotations__\nfunctools.update_wrapper() 调用增加了一个指向下层函数的 __wrapped__ 属性。 它还会向前\n传递必要的属性以使此包装器看起来像是被包装的函数，包括 __name__, __qualname__ 和\n__doc__。\n类方法\n与静态方法不同，类方法在调用函数之前将类引用放在参数列表的最前。无论调用方是对象还是\n类，此格式相同：\nclass F:\n@classmethod\ndef f(cls, x):\nreturn cls.__name__, x\n>>> F.f(3)\n('F', 3)\n>>> F().f(3)\n('F', 3)\n当方法仅需要具有类引用并且确实依赖于存储在特定实例中的数据时，此行为就很有用。类方法的\n一种用途是创建备用类构造函数。例如，类方法 dict.fromkeys() 从键列表创建一个新字典。纯\nPython 的等价实现是：\nclass Dict(dict):\n@classmethod\ndef fromkeys(cls, iterable, value=None):\n\"Emulate dict_fromkeys() in Objects/dictobject.c\"\nd = cls()\nfor key in iterable:\nd[key] = value\nreturn d\n现在可以这样构造一个新的唯一键字典：\n>>> d = Dict.fromkeys('abracadabra')\n>>> type(d) is Dict\nTrue\n>>> d\n{'a': None, 'b': None, 'r': None, 'c': None, 'd': None}\n使用非数据描述器协议，纯 Python 版本的 classmethod() 如下：\nimport functools\nclass ClassMethod:\n\"Emulate PyClassMethod_Type() in Objects/funcobject.c\"\ndef __init__(self, f):\nself.f = f\nfunctools.update_wrapper(self, f)\n\n|  | def __annotations__(self):\nreturn self.f.__annotations__ |  |\n| --- | --- | --- |\n|  | functools.update_wrapper() 调用增加了一个指向下层函数的 __wrapped__ 属性。 它还会向前\n传递必要的属性以使此包装器看起来像是被包装的函数，包括 __name__, __qualname__ 和\n__doc__。\n类方法\n与静态方法不同，类方法在调用函数之前将类引用放在参数列表的最前。无论调用方是对象还是\n类，此格式相同： |  |\n|  | class F:\n@classmethod\ndef f(cls, x):\nreturn cls.__name__, x |  |\n|  |  |  |\n|  | >>> F.f(3)\n('F', 3)\n>>> F().f(3)\n('F', 3) |  |\n|  | 当方法仅需要具有类引用并且确实依赖于存储在特定实例中的数据时，此行为就很有用。类方法的\n一种用途是创建备用类构造函数。例如，类方法 dict.fromkeys() 从键列表创建一个新字典。纯\nPython 的等价实现是： |  |\n|  | class Dict(dict):\n@classmethod\ndef fromkeys(cls, iterable, value=None):\n\"Emulate dict_fromkeys() in Objects/dictobject.c\"\nd = cls()\nfor key in iterable:\nd[key] = value\nreturn d |  |\n|  | 现在可以这样构造一个新的唯一键字典： |  |\n|  | >>> d = Dict.fromkeys('abracadabra')\n>>> type(d) is Dict\nTrue\n>>> d\n{'a': None, 'b': None, 'r': None, 'c': None, 'd': None} |  |\n|  | 使用非数据描述器协议，纯 Python 版本的 classmethod() 如下： |  |\n|  | import functools\nclass ClassMethod:\n\"Emulate PyClassMethod_Type() in Objects/funcobject.c\"\ndef __init__(self, f):\nself.f = f\nfunctools.update_wrapper(self, f) |  |\n\ndef __get__(self, obj, cls=None):\nif cls is None:\ncls = type(obj)\nreturn MethodType(self.f, cls)\nClassMethod 中的 functools.update_wrapper() 调用增加了一个指向下层函数的 __wrapped__\n属性。 它还会向前传递必要的属性以使此包装器看起来像是被包装的函数: __name__,\n__qualname__, __doc__ 以及 __annotations__。\n成员对象和 __slots__\n当一个类定义了 __slots__，它会用一个固定长度的 slot 值数组来替换实例字典。 从用户的视角\n看，效果是这样的：\n1. Provides immediate detection of bugs due to misspelled attribute assignments. Only attribute\nnames specified in __slots__ are allowed:\nclass Vehicle:\n__slots__ = ('id_number', 'make', 'model')\n>>> auto = Vehicle()\n>>> auto.id_nubmer = 'VYE483814LQEX'\nTraceback (most recent call last):\n...\nAttributeError: 'Vehicle' object has no attribute 'id_nubmer'\n2. Helps create immutable objects where descriptors manage access to private attributes stored in\n__slots__:\nclass Immutable:\n__slots__ = ('_dept', '_name') # 替代实例字典\ndef __init__(self, dept, name):\nself._dept = dept # 保存到私有属性\nself._name = name # 保存到私有属性\n@property # 只读描述器\ndef dept(self):\nreturn self._dept\n@property\ndef name(self): # 只读描述器\nreturn self._name\n>>> mark = Immutable('Botany', 'Mark Watney')\n>>> mark.dept\n'Botany'\n>>> mark.dept = 'Space Pirate'\nTraceback (most recent call last):\n...\nAttributeError: property 'dept' of 'Immutable' object has no setter\n>>> mark.location = 'Mars'\nTraceback (most recent call last):\n\n|  | def __get__(self, obj, cls=None):\nif cls is None:\ncls = type(obj)\nreturn MethodType(self.f, cls) |  |\n| --- | --- | --- |\n|  | ClassMethod 中的 functools.update_wrapper() 调用增加了一个指向下层函数的 __wrapped__\n属性。 它还会向前传递必要的属性以使此包装器看起来像是被包装的函数: __name__,\n__qualname__, __doc__ 以及 __annotations__。\n成员对象和 __slots__\n当一个类定义了 __slots__，它会用一个固定长度的 slot 值数组来替换实例字典。 从用户的视角\n看，效果是这样的：\n1. Provides immediate detection of bugs due to misspelled attribute assignments. Only attribute\nnames specified in __slots__ are allowed: |  |\n|  | class Vehicle:\n__slots__ = ('id_number', 'make', 'model') |  |\n|  |  |  |\n|  | >>> auto = Vehicle()\n>>> auto.id_nubmer = 'VYE483814LQEX'\nTraceback (most recent call last):\n...\nAttributeError: 'Vehicle' object has no attribute 'id_nubmer' |  |\n|  | 2. Helps create immutable objects where descriptors manage access to private attributes stored in\n__slots__: |  |\n|  | class Immutable:\n__slots__ = ('_dept', '_name') # 替代实例字典\ndef __init__(self, dept, name):\nself._dept = dept # 保存到私有属性\nself._name = name # 保存到私有属性\n@property # 只读描述器\ndef dept(self):\nreturn self._dept\n@property\ndef name(self): # 只读描述器\nreturn self._name |  |\n|  |  |  |\n|  | >>> mark = Immutable('Botany', 'Mark Watney')\n>>> mark.dept\n'Botany'\n>>> mark.dept = 'Space Pirate'\nTraceback (most recent call last):\n...\nAttributeError: property 'dept' of 'Immutable' object has no setter\n>>> mark.location = 'Mars'\nTraceback (most recent call last): |  |\n\n...\nAttributeError: 'Immutable' object has no attribute 'location'\n3. Saves memory. On a 64-bit Linux build, an instance with two attributes takes 48 bytes with\n__slots__ and 152 bytes without. This flyweight design pattern likely only matters when a large\nnumber of instances are going to be created.\n4. Improves speed. Reading instance variables is 35% faster with __slots__ (as measured with\nPython 3.10 on an Apple M1 processor).\n5. Blocks tools like functools.cached_property() which require an instance dictionary to\nfunction correctly:\nfrom functools import cached_property\nclass CP:\n__slots__ = () # 去除实例字典\n@cached_property # 需要一个实例字典\ndef pi(self):\nreturn 4 * sum((-1.0)**n / (2.0*n + 1.0)\nfor n in reversed(range(100_000)))\n>>> CP().pi\nTraceback (most recent call last):\n...\nTypeError: No '__dict__' attribute on 'CP' instance to cache 'pi' property.\n要创建一个一模一样的纯 Python 版的 __slots__ 是不可能的，因为它需要直接访问 C 结构体并控\n制对象内存分配。 但是，我们可以构建一个非常相似的模拟版，其中作为 slot 的实际 C 结构体由一\n个私有的 _slotvalues 列表来模拟。 对该私有结构体的读写操作将由成员描述器来管理：\nnull = object()\nclass Member:\ndef __init__(self, name, clsname, offset):\n'Emulate PyMemberDef in Include/structmember.h'\n# 另请参阅 Objects/descrobject.c 中的 descr_new()\nself.name = name\nself.clsname = clsname\nself.offset = offset\ndef __get__(self, obj, objtype=None):\n'Emulate member_get() in Objects/descrobject.c'\n# 另请参阅 Python/structmember.c 中的 PyMember_GetOne()\nif obj is None:\nreturn self\nvalue = obj._slotvalues[self.offset]\nif value is null:\nraise AttributeError(self.name)\nreturn value\ndef __set__(self, obj, value):\n\n|  | ...\nAttributeError: 'Immutable' object has no attribute 'location' |  |\n| --- | --- | --- |\n|  | 3. Saves memory. On a 64-bit Linux build, an instance with two attributes takes 48 bytes with\n__slots__ and 152 bytes without. This flyweight design pattern likely only matters when a large\nnumber of instances are going to be created.\n4. Improves speed. Reading instance variables is 35% faster with __slots__ (as measured with\nPython 3.10 on an Apple M1 processor).\n5. Blocks tools like functools.cached_property() which require an instance dictionary to\nfunction correctly: |  |\n|  | from functools import cached_property\nclass CP:\n__slots__ = () # 去除实例字典\n@cached_property # 需要一个实例字典\ndef pi(self):\nreturn 4 * sum((-1.0)**n / (2.0*n + 1.0)\nfor n in reversed(range(100_000))) |  |\n|  |  |  |\n|  | >>> CP().pi\nTraceback (most recent call last):\n...\nTypeError: No '__dict__' attribute on 'CP' instance to cache 'pi' property. |  |\n|  | 要创建一个一模一样的纯 Python 版的 __slots__ 是不可能的，因为它需要直接访问 C 结构体并控\n制对象内存分配。 但是，我们可以构建一个非常相似的模拟版，其中作为 slot 的实际 C 结构体由一\n个私有的 _slotvalues 列表来模拟。 对该私有结构体的读写操作将由成员描述器来管理： |  |\n|  | null = object()\nclass Member:\ndef __init__(self, name, clsname, offset):\n'Emulate PyMemberDef in Include/structmember.h'\n# 另请参阅 Objects/descrobject.c 中的 descr_new()\nself.name = name\nself.clsname = clsname\nself.offset = offset\ndef __get__(self, obj, objtype=None):\n'Emulate member_get() in Objects/descrobject.c'\n# 另请参阅 Python/structmember.c 中的 PyMember_GetOne()\nif obj is None:\nreturn self\nvalue = obj._slotvalues[self.offset]\nif value is null:\nraise AttributeError(self.name)\nreturn value\ndef __set__(self, obj, value): |  |\n\n'Emulate member_set() in Objects/descrobject.c'\nobj._slotvalues[self.offset] = value\ndef __delete__(self, obj):\n'Emulate member_delete() in Objects/descrobject.c'\nvalue = obj._slotvalues[self.offset]\nif value is null:\nraise AttributeError(self.name)\nobj._slotvalues[self.offset] = null\ndef __repr__(self):\n'Emulate member_repr() in Objects/descrobject.c'\nreturn f'<Member {self.name!r} of {self.clsname!r}>'\ntype.__new__() 方法负责将成员对象添加到类变量：\nclass Type(type):\n'Simulate how the type metaclass adds member objects for slots'\ndef __new__(mcls, clsname, bases, mapping, **kwargs):\n'Emulate type_new() in Objects/typeobject.c'\n# type_new() 将调用 PyTypeReady()，后者将调用 add_methods()\nslot_names = mapping.get('slot_names', [])\nfor offset, name in enumerate(slot_names):\nmapping[name] = Member(name, clsname, offset)\nreturn type.__new__(mcls, clsname, bases, mapping, **kwargs)\nobject.__new__() 方法负责创建具有 slot 而非实例字典的实例。 以下是一个纯 Python 的粗略模\n拟版：\nclass Object:\n'Simulate how object.__new__() allocates memory for __slots__'\ndef __new__(cls, *args, **kwargs):\n'Emulate object_new() in Objects/typeobject.c'\ninst = super().__new__(cls)\nif hasattr(cls, 'slot_names'):\nempty_slots = [null] * len(cls.slot_names)\nobject.__setattr__(inst, '_slotvalues', empty_slots)\nreturn inst\ndef __setattr__(self, name, value):\n'Emulate _PyObject_GenericSetAttrWithDict() Objects/object.c'\ncls = type(self)\nif hasattr(cls, 'slot_names') and name not in cls.slot_names:\nraise AttributeError(\nf'{cls.__name__!r} object has no attribute {name!r}'\n)\nsuper().__setattr__(name, value)\ndef __delattr__(self, name):\n'Emulate _PyObject_GenericSetAttrWithDict() Objects/object.c'\ncls = type(self)\nif hasattr(cls, 'slot_names') and name not in cls.slot_names:\nraise AttributeError(\nf'{cls.__name__!r} object has no attribute {name!r}'\n\n|  | 'Emulate member_set() in Objects/descrobject.c'\nobj._slotvalues[self.offset] = value\ndef __delete__(self, obj):\n'Emulate member_delete() in Objects/descrobject.c'\nvalue = obj._slotvalues[self.offset]\nif value is null:\nraise AttributeError(self.name)\nobj._slotvalues[self.offset] = null\ndef __repr__(self):\n'Emulate member_repr() in Objects/descrobject.c'\nreturn f'<Member {self.name!r} of {self.clsname!r}>' |  |\n| --- | --- | --- |\n|  | type.__new__() 方法负责将成员对象添加到类变量： |  |\n|  | class Type(type):\n'Simulate how the type metaclass adds member objects for slots'\ndef __new__(mcls, clsname, bases, mapping, **kwargs):\n'Emulate type_new() in Objects/typeobject.c'\n# type_new() 将调用 PyTypeReady()，后者将调用 add_methods()\nslot_names = mapping.get('slot_names', [])\nfor offset, name in enumerate(slot_names):\nmapping[name] = Member(name, clsname, offset)\nreturn type.__new__(mcls, clsname, bases, mapping, **kwargs) |  |\n|  | object.__new__() 方法负责创建具有 slot 而非实例字典的实例。 以下是一个纯 Python 的粗略模\n拟版： |  |\n|  | class Object:\n'Simulate how object.__new__() allocates memory for __slots__'\ndef __new__(cls, *args, **kwargs):\n'Emulate object_new() in Objects/typeobject.c'\ninst = super().__new__(cls)\nif hasattr(cls, 'slot_names'):\nempty_slots = [null] * len(cls.slot_names)\nobject.__setattr__(inst, '_slotvalues', empty_slots)\nreturn inst\ndef __setattr__(self, name, value):\n'Emulate _PyObject_GenericSetAttrWithDict() Objects/object.c'\ncls = type(self)\nif hasattr(cls, 'slot_names') and name not in cls.slot_names:\nraise AttributeError(\nf'{cls.__name__!r} object has no attribute {name!r}'\n)\nsuper().__setattr__(name, value)\ndef __delattr__(self, name):\n'Emulate _PyObject_GenericSetAttrWithDict() Objects/object.c'\ncls = type(self)\nif hasattr(cls, 'slot_names') and name not in cls.slot_names:\nraise AttributeError(\nf'{cls.__name__!r} object has no attribute {name!r}' |  |\n\n)\nsuper().__delattr__(name)\n要在真实的类中使用此模拟，只需从 Object 继承并将 metaclass 设为 Type:\nclass H(Object, metaclass=Type):\n'Instance variables stored in slots'\nslot_names = ['x', 'y']\ndef __init__(self, x, y):\nself.x = x\nself.y = y\n这时，metaclass 已经为 x 和 y 加载了成员对象：\n>>> from pprint import pp\n>>> pp(dict(vars(H)))\n{'__module__': '__main__',\n'__doc__': 'Instance variables stored in slots',\n'slot_names': ['x', 'y'],\n'__init__': <function H.__init__ at 0x7fb5d302f9d0>,\n'x': <Member 'x' of 'H'>,\n'y': <Member 'y' of 'H'>}\n当实例被创建时，它们将拥有一个用于存放属性的 slot_values 列表：\n>>> h = H(10, 20)\n>>> vars(h)\n{'_slotvalues': [10, 20]}\n>>> h.x = 55\n>>> vars(h)\n{'_slotvalues': [55, 20]}\n错误拼写或未赋值的属性将引发一个异常：\n>>> h.xz\nTraceback (most recent call last):\n...\nAttributeError: 'H' object has no attribute 'xz'\n\n| )\nsuper().__delattr__(name) |\n| --- |\n| 要在真实的类中使用此模拟，只需从 Object 继承并将 metaclass 设为 Type: |\n| class H(Object, metaclass=Type):\n'Instance variables stored in slots'\nslot_names = ['x', 'y']\ndef __init__(self, x, y):\nself.x = x\nself.y = y |\n| 这时，metaclass 已经为 x 和 y 加载了成员对象： |\n| >>> from pprint import pp\n>>> pp(dict(vars(H)))\n{'__module__': '__main__',\n'__doc__': 'Instance variables stored in slots',\n'slot_names': ['x', 'y'],\n'__init__': <function H.__init__ at 0x7fb5d302f9d0>,\n'x': <Member 'x' of 'H'>,\n'y': <Member 'y' of 'H'>} |\n| 当实例被创建时，它们将拥有一个用于存放属性的 slot_values 列表： |\n| >>> h = H(10, 20)\n>>> vars(h)\n{'_slotvalues': [10, 20]}\n>>> h.x = 55\n>>> vars(h)\n{'_slotvalues': [55, 20]} |\n| 错误拼写或未赋值的属性将引发一个异常： |\n| >>> h.xz\nTraceback (most recent call last):\n...\nAttributeError: 'H' object has no attribute 'xz' |", "metadata": {"title": "04_描述器指南", "source": "md_docs\\python_howto_md\\04_描述器指南.md", "doc_type": "指南", "language": "中文", "doc_id": "a8b66780"}}
{"doc_id": "26cf0d0c", "content": "Enum 指南\nEnum 是一组绑定到唯一值的符号名称。 它们类似于全局变量，但提供了更好用的 repr()、分组、\n类型安全和一些其他特性。\n它们最适用于当某个变量可选的值有限时。例如，从一周中选取一天：\n>>> from enum import Enum\n>>> class Weekday(Enum):\n... MONDAY = 1\n... TUESDAY = 2\n... WEDNESDAY = 3\n... THURSDAY = 4\n... FRIDAY = 5\n... SATURDAY = 6\n... SUNDAY = 7\n或是 RGB 三原色：\n>>> from enum import Enum\n>>> class Color(Enum):\n... RED = 1\n... GREEN = 2\n... BLUE = 3\n正如你所见，创建一个 Enum 就是简单地写一个继承 Enum 的类。\n备注: 枚举成员名的大小写\n由于枚举被用来代表常量，并有助于避免混入类方法/属性和枚举名之间发生名称冲突，我们强烈\n建议用大写形式的名称表示成员，我们将在我们的示例中使用此风格。\n根据枚举的性质，某个成员的值可能不一定用得上，但无论如何都能用那个值构造对应的成员：\n>>> Weekday(3)\n<Weekday.WEDNESDAY: 3>\n如你所见，成员的 repr() 会显示枚举名称、成员名称和值。 成员的 str() 只会显示枚举名称和成\n员名称:\n>>> print(Weekday.THURSDAY)\nWeekday.THURSDAY\n枚举成员的 类型 就是其所属的枚举:\n>>> type(Weekday.MONDAY)\n<enum 'Weekday'>\n\n| Enum 指南\nEnum 是一组绑定到唯一值的符号名称。 它们类似于全局变量，但提供了更好用的 repr()、分组、\n类型安全和一些其他特性。\n它们最适用于当某个变量可选的值有限时。例如，从一周中选取一天： |\n| --- |\n| >>> from enum import Enum\n>>> class Weekday(Enum):\n... MONDAY = 1\n... TUESDAY = 2\n... WEDNESDAY = 3\n... THURSDAY = 4\n... FRIDAY = 5\n... SATURDAY = 6\n... SUNDAY = 7 |\n| 或是 RGB 三原色： |\n| >>> from enum import Enum\n>>> class Color(Enum):\n... RED = 1\n... GREEN = 2\n... BLUE = 3 |\n| 正如你所见，创建一个 Enum 就是简单地写一个继承 Enum 的类。 |\n| 备注: 枚举成员名的大小写\n由于枚举被用来代表常量，并有助于避免混入类方法/属性和枚举名之间发生名称冲突，我们强烈\n建议用大写形式的名称表示成员，我们将在我们的示例中使用此风格。 |\n| 根据枚举的性质，某个成员的值可能不一定用得上，但无论如何都能用那个值构造对应的成员： |\n| >>> Weekday(3)\n<Weekday.WEDNESDAY: 3> |\n| 如你所见，成员的 repr() 会显示枚举名称、成员名称和值。 成员的 str() 只会显示枚举名称和成\n员名称: |\n| >>> print(Weekday.THURSDAY)\nWeekday.THURSDAY |\n| 枚举成员的 类型 就是其所属的枚举: |\n| >>> type(Weekday.MONDAY)\n<enum 'Weekday'> |\n\n>>> isinstance(Weekday.FRIDAY, Weekday)\nTrue\n枚举成员带有一个只包含了它们的 name 的属性:\n>>> print(Weekday.TUESDAY.name)\nTUESDAY\n类似地，它们还有一个包含其 value 的属性:\n>>> Weekday.WEDNESDAY.value\n3\n不同于许多只把枚举当作名称/值对的的语言，Python 枚举还可以添加行为。 例如，\ndatetime.date 有两个方法用来返回星期序号: weekday() 和 isoweekday()。 两者的区别在于一\n个是以 0-6 计数而另一个是以 1-7。 这一点无须我们自己来记住而是可以向 Weekday 枚举添加一个\n方法用来从 date 实例提取日期并返回匹配的枚举成员:\n@classmethod\ndef from_date(cls, date):\nreturn cls(date.isoweekday())\n完整的 Weekday 枚举现在看起来是这样的:\n>>> class Weekday(Enum):\n... MONDAY = 1\n... TUESDAY = 2\n... WEDNESDAY = 3\n... THURSDAY = 4\n... FRIDAY = 5\n... SATURDAY = 6\n... SUNDAY = 7\n... #\n... @classmethod\n... def from_date(cls, date):\n... return cls(date.isoweekday())\n现在可以知道今天是星期几了:\n>>> from datetime import date\n>>> Weekday.from_date(date.today())\n<Weekday.TUESDAY: 2>\n当然，如果换个日子读到这篇文章，应该看到当天是周几。\n如果我们的变量只需记录一天那么这个 Weekday 枚举很好用，但是如果我们需要记录好几天呢？ 可\n能我们要写一个函数来描述一星期内的家务，并且不想使用 list —— 我们可以使用另一种类型的\nEnum:\n>>> from enum import Flag\n>>> class Weekday(Flag):\n... MONDAY = 1\n\n|  | >>> isinstance(Weekday.FRIDAY, Weekday)\nTrue |  |\n| --- | --- | --- |\n|  | 枚举成员带有一个只包含了它们的 name 的属性: |  |\n|  | >>> print(Weekday.TUESDAY.name)\nTUESDAY |  |\n|  | 类似地，它们还有一个包含其 value 的属性: |  |\n|  | >>> Weekday.WEDNESDAY.value\n3 |  |\n|  | 不同于许多只把枚举当作名称/值对的的语言，Python 枚举还可以添加行为。 例如，\ndatetime.date 有两个方法用来返回星期序号: weekday() 和 isoweekday()。 两者的区别在于一\n个是以 0-6 计数而另一个是以 1-7。 这一点无须我们自己来记住而是可以向 Weekday 枚举添加一个\n方法用来从 date 实例提取日期并返回匹配的枚举成员: |  |\n|  | @classmethod\ndef from_date(cls, date):\nreturn cls(date.isoweekday()) |  |\n|  | 完整的 Weekday 枚举现在看起来是这样的: |  |\n|  | >>> class Weekday(Enum):\n... MONDAY = 1\n... TUESDAY = 2\n... WEDNESDAY = 3\n... THURSDAY = 4\n... FRIDAY = 5\n... SATURDAY = 6\n... SUNDAY = 7\n... #\n... @classmethod\n... def from_date(cls, date):\n... return cls(date.isoweekday()) |  |\n|  | 现在可以知道今天是星期几了: |  |\n|  | >>> from datetime import date\n>>> Weekday.from_date(date.today())\n<Weekday.TUESDAY: 2> |  |\n|  | 当然，如果换个日子读到这篇文章，应该看到当天是周几。\n如果我们的变量只需记录一天那么这个 Weekday 枚举很好用，但是如果我们需要记录好几天呢？ 可\n能我们要写一个函数来描述一星期内的家务，并且不想使用 list —— 我们可以使用另一种类型的\nEnum: |  |\n|  | >>> from enum import Flag\n>>> class Weekday(Flag):\n... MONDAY = 1 |  |\n\n... TUESDAY = 2\n... WEDNESDAY = 4\n... THURSDAY = 8\n... FRIDAY = 16\n... SATURDAY = 32\n... SUNDAY = 64\n这里做了两处改动：继承了 Flag，而且值都是2的幂。\n就像上面的原始 Weekday 枚举一样，我们可以有单个选择:\n>>> first_week_day = Weekday.MONDAY\n>>> first_week_day\n<Weekday.MONDAY: 1>\n但 Flag 也允许将几个成员并入一个变量:\n>>> weekend = Weekday.SATURDAY | Weekday.SUNDAY\n>>> weekend\n<Weekday.SATURDAY|SUNDAY: 96>\n甚至可以在一个 Flag 变量上进行迭代:\n>>> for day in weekend:\n... print(day)\nWeekday.SATURDAY\nWeekday.SUNDAY\n好吧，让我们来安排家务吧:\n>>> chores_for_ethan = {\n... 'feed the cat': Weekday.MONDAY | Weekday.WEDNESDAY | Weekday.FRIDAY,\n... 'do the dishes': Weekday.TUESDAY | Weekday.THURSDAY,\n... 'answer SO questions': Weekday.SATURDAY,\n... }\n一个显示某天家务的函数:\n>>> def show_chores(chores, day):\n... for chore, days in chores.items():\n... if day in days:\n... print(chore)\n...\n>>> show_chores(chores_for_ethan, Weekday.SATURDAY)\nanswer SO questions\n对于成员的实际取值无关紧要的情况，你可以省事地使用 auto() 来设置值:\n>>> from enum import auto\n>>> class Weekday(Flag):\n... MONDAY = auto()\n... TUESDAY = auto()\n... WEDNESDAY = auto()\n... THURSDAY = auto()\n\n|  | ... TUESDAY = 2\n... WEDNESDAY = 4\n... THURSDAY = 8\n... FRIDAY = 16\n... SATURDAY = 32\n... SUNDAY = 64 |  |\n| --- | --- | --- |\n|  | 这里做了两处改动：继承了 Flag，而且值都是2的幂。\n就像上面的原始 Weekday 枚举一样，我们可以有单个选择: |  |\n|  | >>> first_week_day = Weekday.MONDAY\n>>> first_week_day\n<Weekday.MONDAY: 1> |  |\n|  | 但 Flag 也允许将几个成员并入一个变量: |  |\n|  | >>> weekend = Weekday.SATURDAY | Weekday.SUNDAY\n>>> weekend\n<Weekday.SATURDAY|SUNDAY: 96> |  |\n|  | 甚至可以在一个 Flag 变量上进行迭代: |  |\n|  | >>> for day in weekend:\n... print(day)\nWeekday.SATURDAY\nWeekday.SUNDAY |  |\n|  | 好吧，让我们来安排家务吧: |  |\n|  | >>> chores_for_ethan = {\n... 'feed the cat': Weekday.MONDAY | Weekday.WEDNESDAY | Weekday.FRIDAY,\n... 'do the dishes': Weekday.TUESDAY | Weekday.THURSDAY,\n... 'answer SO questions': Weekday.SATURDAY,\n... } |  |\n|  | 一个显示某天家务的函数: |  |\n|  | >>> def show_chores(chores, day):\n... for chore, days in chores.items():\n... if day in days:\n... print(chore)\n...\n>>> show_chores(chores_for_ethan, Weekday.SATURDAY)\nanswer SO questions |  |\n|  | 对于成员的实际取值无关紧要的情况，你可以省事地使用 auto() 来设置值: |  |\n|  | >>> from enum import auto\n>>> class Weekday(Flag):\n... MONDAY = auto()\n... TUESDAY = auto()\n... WEDNESDAY = auto()\n... THURSDAY = auto() |  |\n\n... FRIDAY = auto()\n... SATURDAY = auto()\n... SUNDAY = auto()\n... WEEKEND = SATURDAY | SUNDAY\n枚举成员及其属性的编程访问\n有时，要在程序中访问枚举成员（如，开发时不知道颜色的确切值，Color.RED 不适用的情况）。\nEnum 支持如下访问方式:\n>>> Color(1)\n<Color.RED: 1>\n>>> Color(3)\n<Color.BLUE: 3>\n若要用 名称 访问枚举成员时，可使用枚举项:\n>>> Color['RED']\n<Color.RED: 1>\n>>> Color['GREEN']\n<Color.GREEN: 2>\n如果你有一个枚举成员并需要它的 name 或 value:\n>>> member = Color.RED\n>>> member.name\n'RED'\n>>> member.value\n1\n重复的枚举成员和值\n两个枚举成员的名称不能相同:\n>>> class Shape(Enum):\n... SQUARE = 2\n... SQUARE = 3\n...\nTraceback (most recent call last):\n...\nTypeError: 'SQUARE' already defined as 2\n然而，一个枚举成员可以关联多个其他名称。如果两个枚举项 A 和 B 具有相同值（并且首先定义的\n是 A ），则 B 是成员 A 的别名。对 A 按值检索将会返回成员 A。按名称检索 B 也会返回成员 A:\n>>> class Shape(Enum):\n... SQUARE = 2\n... DIAMOND = 1\n... CIRCLE = 3\n... ALIAS_FOR_SQUARE = 2\n...\n>>> Shape.SQUARE\n\n|  | ... FRIDAY = auto()\n... SATURDAY = auto()\n... SUNDAY = auto()\n... WEEKEND = SATURDAY | SUNDAY |  |\n| --- | --- | --- |\n|  | 枚举成员及其属性的编程访问\n有时，要在程序中访问枚举成员（如，开发时不知道颜色的确切值，Color.RED 不适用的情况）。\nEnum 支持如下访问方式: |  |\n|  | >>> Color(1)\n<Color.RED: 1>\n>>> Color(3)\n<Color.BLUE: 3> |  |\n|  | 若要用 名称 访问枚举成员时，可使用枚举项: |  |\n|  | >>> Color['RED']\n<Color.RED: 1>\n>>> Color['GREEN']\n<Color.GREEN: 2> |  |\n|  | 如果你有一个枚举成员并需要它的 name 或 value: |  |\n|  | >>> member = Color.RED\n>>> member.name\n'RED'\n>>> member.value\n1 |  |\n|  | 重复的枚举成员和值\n两个枚举成员的名称不能相同: |  |\n|  | >>> class Shape(Enum):\n... SQUARE = 2\n... SQUARE = 3\n...\nTraceback (most recent call last):\n...\nTypeError: 'SQUARE' already defined as 2 |  |\n|  | 然而，一个枚举成员可以关联多个其他名称。如果两个枚举项 A 和 B 具有相同值（并且首先定义的\n是 A ），则 B 是成员 A 的别名。对 A 按值检索将会返回成员 A。按名称检索 B 也会返回成员 A: |  |\n|  | >>> class Shape(Enum):\n... SQUARE = 2\n... DIAMOND = 1\n... CIRCLE = 3\n... ALIAS_FOR_SQUARE = 2\n...\n>>> Shape.SQUARE |  |\n\n<Shape.SQUARE: 2>\n>>> Shape.ALIAS_FOR_SQUARE\n<Shape.SQUARE: 2>\n>>> Shape(2)\n<Shape.SQUARE: 2>\n备注: 不允许创建与已定义属性（其他成员、方法等）同名的成员，也不支持创建与现有成员同\n名的属性。\n确保枚举值唯一\n默认情况下，枚举允许多个名称作为同一个值的别名。若不想如此，可以使用 unique() 装饰器:\n>>> from enum import Enum, unique\n>>> @unique\n... class Mistake(Enum):\n... ONE = 1\n... TWO = 2\n... THREE = 3\n... FOUR = 3\n...\nTraceback (most recent call last):\n...\nValueError: duplicate values found in <enum 'Mistake'>: FOUR -> THREE\n使用自动设定的值\n如果具体的枚举值无所谓是什么，可以使用 auto:\n>>> from enum import Enum, auto\n>>> class Color(Enum):\n... RED = auto()\n... BLUE = auto()\n... GREEN = auto()\n...\n>>> [member.value for member in Color]\n[1, 2, 3]\n枚举值由 _generate_next_value_() 来选取，它可以被重写:\n>>> class AutoName(Enum):\n... @staticmethod\n... def _generate_next_value_(name, start, count, last_values):\n... return name\n...\n>>> class Ordinal(AutoName):\n... NORTH = auto()\n... SOUTH = auto()\n... EAST = auto()\n... WEST = auto()\n...\n>>> [member.value for member in Ordinal]\n['NORTH', 'SOUTH', 'EAST', 'WEST']\n\n|  | <Shape.SQUARE: 2>\n>>> Shape.ALIAS_FOR_SQUARE\n<Shape.SQUARE: 2>\n>>> Shape(2)\n<Shape.SQUARE: 2> |  |\n| --- | --- | --- |\n|  |  |  |\n|  | 备注: 不允许创建与已定义属性（其他成员、方法等）同名的成员，也不支持创建与现有成员同\n名的属性。 |  |\n|  | 确保枚举值唯一\n默认情况下，枚举允许多个名称作为同一个值的别名。若不想如此，可以使用 unique() 装饰器: |  |\n|  | >>> from enum import Enum, unique\n>>> @unique\n... class Mistake(Enum):\n... ONE = 1\n... TWO = 2\n... THREE = 3\n... FOUR = 3\n...\nTraceback (most recent call last):\n...\nValueError: duplicate values found in <enum 'Mistake'>: FOUR -> THREE |  |\n|  | 使用自动设定的值\n如果具体的枚举值无所谓是什么，可以使用 auto: |  |\n|  | >>> from enum import Enum, auto\n>>> class Color(Enum):\n... RED = auto()\n... BLUE = auto()\n... GREEN = auto()\n...\n>>> [member.value for member in Color]\n[1, 2, 3] |  |\n|  | 枚举值由 _generate_next_value_() 来选取，它可以被重写: |  |\n|  | >>> class AutoName(Enum):\n... @staticmethod\n... def _generate_next_value_(name, start, count, last_values):\n... return name\n...\n>>> class Ordinal(AutoName):\n... NORTH = auto()\n... SOUTH = auto()\n... EAST = auto()\n... WEST = auto()\n...\n>>> [member.value for member in Ordinal]\n['NORTH', 'SOUTH', 'EAST', 'WEST'] |  |\n|  |  |  |\n\n备注: _generate_next_value_() 方法必须在任何成员之前定义。\n迭代遍历\n对枚举成员的迭代遍历不会列出别名:\n>>> list(Shape)\n[<Shape.SQUARE: 2>, <Shape.DIAMOND: 1>, <Shape.CIRCLE: 3>]\n>>> list(Weekday)\n[<Weekday.MONDAY: 1>, <Weekday.TUESDAY: 2>, <Weekday.WEDNESDAY: 4>, <Weekday.THURS\n请注意 Shape.ALIAS_FOR_SQUARE 和 Weekday.WEEKEND 等别名不会被显示。\n特殊属性 __members__ 是一个名称与成员间的只读有序映射。包含了枚举中定义的所有名称，包括\n别名:\n>>> for name, member in Shape.__members__.items():\n... name, member\n...\n('SQUARE', <Shape.SQUARE: 2>)\n('DIAMOND', <Shape.DIAMOND: 1>)\n('CIRCLE', <Shape.CIRCLE: 3>)\n('ALIAS_FOR_SQUARE', <Shape.SQUARE: 2>)\n__members__ 属性可用于获取枚举成员的详细信息。比如查找所有别名:\n>>> [name for name, member in Shape.__members__.items() if member.name != name]\n['ALIAS_FOR_SQUARE']\n备注: 旗标的别名包括带有多个旗标设置的值，如 3，以及不设置任何旗标，即 0。\n比较运算\n枚举成员是按 ID 进行比较的:\n>>> Color.RED is Color.RED\nTrue\n>>> Color.RED is Color.BLUE\nFalse\n>>> Color.RED is not Color.BLUE\nTrue\n枚举值之间无法进行有序的比较。枚举的成员不是整数（另请参阅下文 IntEnum）:\n>>> Color.RED < Color.BLUE\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nTypeError: '<' not supported between instances of 'Color' and 'Color'\n相等性比较的定义如下:\n\n|  | 备注: _generate_next_value_() 方法必须在任何成员之前定义。 |  |  |\n| --- | --- | --- | --- |\n|  | 迭代遍历\n对枚举成员的迭代遍历不会列出别名: |  |  |\n|  | >>> list(Shape)\n[<Shape.SQUARE: 2>, <Shape.DIAMOND: 1>, <Shape.CIRCLE: 3>]\n>>> list(Weekday)\n[<Weekday.MONDAY: 1>, <Weekday.TUESDAY: 2>, <Weekday.WEDNESDAY: 4>, <Weekday.THURS |  |  |\n|  | 请注意 Shape.ALIAS_FOR_SQUARE 和 Weekday.WEEKEND 等别名不会被显示。\n特殊属性 __members__ 是一个名称与成员间的只读有序映射。包含了枚举中定义的所有名称，包括\n别名: |  |  |\n|  | >>> for name, member in Shape.__members__.items():\n... name, member\n...\n('SQUARE', <Shape.SQUARE: 2>)\n('DIAMOND', <Shape.DIAMOND: 1>)\n('CIRCLE', <Shape.CIRCLE: 3>)\n('ALIAS_FOR_SQUARE', <Shape.SQUARE: 2>) |  |  |\n|  | __members__ 属性可用于获取枚举成员的详细信息。比如查找所有别名: |  |  |\n|  | >>> [name for name, member in Shape.__members__.items() if member.name != name]\n['ALIAS_FOR_SQUARE'] |  |  |\n|  |  |  |  |\n|  | 备注: 旗标的别名包括带有多个旗标设置的值，如 3，以及不设置任何旗标，即 0。 |  |  |\n|  | 比较运算\n枚举成员是按 ID 进行比较的: |  |  |\n|  | >>> Color.RED is Color.RED\nTrue\n>>> Color.RED is Color.BLUE\nFalse\n>>> Color.RED is not Color.BLUE\nTrue |  |  |\n|  | 枚举值之间无法进行有序的比较。枚举的成员不是整数（另请参阅下文 IntEnum）: |  |  |\n|  | >>> Color.RED < Color.BLUE\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nTypeError: '<' not supported between instances of 'Color' and 'Color' |  |  |\n|  | 相等性比较的定义如下: |  |  |\n\n>>> Color.BLUE == Color.RED\nFalse\n>>> Color.BLUE != Color.RED\nTrue\n>>> Color.BLUE == Color.BLUE\nTrue\n与非枚举值的比较将总是不等的（同样 IntEnum 有意设计为其他的做法，参见下文）:\n>>> Color.BLUE == 2\nFalse\n警告: 重载模块是可能的 -- 如果载入的模块包含枚举，它们将被重新创建，而新成员的标识号/\n相等性比较不一定会通过。\n合法的枚举成员和属性\n以上大多数示例都用了整数作为枚举值。使用整数确实简短方便（并且是 Functional API 默认提供\n的值），但并非强制要求。绝大多数情况下，人们并不关心枚举的实际值是什么。但如果值确实重\n要，可以使用任何值。\n枚举是 Python 的类，可带有普通方法和特殊方法。假设有如下枚举:\n>>> class Mood(Enum):\n... FUNKY = 1\n... HAPPY = 3\n...\n... def describe(self):\n... # 在这里 self 是成员\n... return self.name, self.value\n...\n... def __str__(self):\n... return 'my custom str! {0}'.format(self.value)\n...\n... @classmethod\n... def favorite_mood(cls):\n... # 在这里 cls 是枚举\n... return cls.HAPPY\n...\n那么:\n>>> Mood.favorite_mood()\n<Mood.HAPPY: 3>\n>>> Mood.HAPPY.describe()\n('HAPPY', 3)\n>>> str(Mood.FUNKY)\n'my custom str! 1'\n对于允许内容的规则如下：以单下划线开始和结尾的名称是由枚举保留而不可使用的；在枚举中定\n义的其他属性将成为该枚举的成员，例外项则包括特殊方法 (__str__(), __add__(), etc.)、描述器\n(方法也属于描述器) 以及在 _ignore_ 中列出的变量名。\n\n|  | >>> Color.BLUE == Color.RED\nFalse\n>>> Color.BLUE != Color.RED\nTrue\n>>> Color.BLUE == Color.BLUE\nTrue |  |\n| --- | --- | --- |\n|  | 与非枚举值的比较将总是不等的（同样 IntEnum 有意设计为其他的做法，参见下文）: |  |\n|  | >>> Color.BLUE == 2\nFalse |  |\n|  |  |  |\n|  | 警告: 重载模块是可能的 -- 如果载入的模块包含枚举，它们将被重新创建，而新成员的标识号/\n相等性比较不一定会通过。 |  |\n|  | 合法的枚举成员和属性\n以上大多数示例都用了整数作为枚举值。使用整数确实简短方便（并且是 Functional API 默认提供\n的值），但并非强制要求。绝大多数情况下，人们并不关心枚举的实际值是什么。但如果值确实重\n要，可以使用任何值。\n枚举是 Python 的类，可带有普通方法和特殊方法。假设有如下枚举: |  |\n|  | >>> class Mood(Enum):\n... FUNKY = 1\n... HAPPY = 3\n...\n... def describe(self):\n... # 在这里 self 是成员\n... return self.name, self.value\n...\n... def __str__(self):\n... return 'my custom str! {0}'.format(self.value)\n...\n... @classmethod\n... def favorite_mood(cls):\n... # 在这里 cls 是枚举\n... return cls.HAPPY\n... |  |\n|  | 那么: |  |\n|  | >>> Mood.favorite_mood()\n<Mood.HAPPY: 3>\n>>> Mood.HAPPY.describe()\n('HAPPY', 3)\n>>> str(Mood.FUNKY)\n'my custom str! 1' |  |\n|  | 对于允许内容的规则如下：以单下划线开始和结尾的名称是由枚举保留而不可使用的；在枚举中定\n义的其他属性将成为该枚举的成员，例外项则包括特殊方法 (__str__(), __add__(), etc.)、描述器\n(方法也属于描述器) 以及在 _ignore_ 中列出的变量名。 |  |\n\n注意：如果你的枚举定义了 __new__() 和/或 __init__()，则给予枚举成员的任何值都将被传递给\n这些方法。 参见 Planet 中的示例。\n备注: 如果定义了 __new__() 方法，它会在创建 Enum 成员期间被使用；随后它将被 Enum 的\n__new__() 所替换，该方法会在类创建后被用于查找现有成员。 详情参见 何时应使用 __new__()\n或 __init__()。\n受限的 Enum 子类化\n新建的 Enum 类必须包含：一个枚举基类、至多一种数据类型和按需提供的基于 object 的混合类。\n这些基类的顺序如下:\nclass EnumName([mix-in, ...,] [data-type,] base-enum):\npass\n仅当未定义任何成员时，枚举类才允许被子类化。因此不得有以下写法:\n>>> class MoreColor(Color):\n... PINK = 17\n...\nTraceback (most recent call last):\n...\nTypeError: <enum 'MoreColor'> cannot extend <enum 'Color'>\n但以下代码是可以的:\n>>> class Foo(Enum):\n... def some_behavior(self):\n... pass\n...\n>>> class Bar(Foo):\n... HAPPY = 1\n... SAD = 2\n...\n如果定义了成员的枚举也能被子类化，则类型与实例的某些重要不可变规则将会被破坏。另一方\n面，一组枚举类共享某些操作也是合理的。（请参阅例程 OrderedEnum ）\n数据类支持\n当从 dataclass 继承时，__repr__() 将忽略被继承类的名称。 例如:\n>>> from dataclasses import dataclass, field\n>>> @dataclass\n... class CreatureDataMixin:\n... size: str\n... legs: int\n... tail: bool = field(repr=False, default=True)\n...\n>>> class Creature(CreatureDataMixin, Enum):\n... BEETLE = 'small', 6\n\n|  | 注意：如果你的枚举定义了 __new__() 和/或 __init__()，则给予枚举成员的任何值都将被传递给\n这些方法。 参见 Planet 中的示例。 |  |\n| --- | --- | --- |\n|  | 备注: 如果定义了 __new__() 方法，它会在创建 Enum 成员期间被使用；随后它将被 Enum 的\n__new__() 所替换，该方法会在类创建后被用于查找现有成员。 详情参见 何时应使用 __new__()\n或 __init__()。 |  |\n|  | 受限的 Enum 子类化\n新建的 Enum 类必须包含：一个枚举基类、至多一种数据类型和按需提供的基于 object 的混合类。\n这些基类的顺序如下: |  |\n|  | class EnumName([mix-in, ...,] [data-type,] base-enum):\npass |  |\n|  | 仅当未定义任何成员时，枚举类才允许被子类化。因此不得有以下写法: |  |\n|  | >>> class MoreColor(Color):\n... PINK = 17\n...\nTraceback (most recent call last):\n...\nTypeError: <enum 'MoreColor'> cannot extend <enum 'Color'> |  |\n|  | 但以下代码是可以的: |  |\n|  | >>> class Foo(Enum):\n... def some_behavior(self):\n... pass\n...\n>>> class Bar(Foo):\n... HAPPY = 1\n... SAD = 2\n... |  |\n|  | 如果定义了成员的枚举也能被子类化，则类型与实例的某些重要不可变规则将会被破坏。另一方\n面，一组枚举类共享某些操作也是合理的。（请参阅例程 OrderedEnum ）\n数据类支持\n当从 dataclass 继承时，__repr__() 将忽略被继承类的名称。 例如: |  |\n|  | >>> from dataclasses import dataclass, field\n>>> @dataclass\n... class CreatureDataMixin:\n... size: str\n... legs: int\n... tail: bool = field(repr=False, default=True)\n...\n>>> class Creature(CreatureDataMixin, Enum):\n... BEETLE = 'small', 6 |  |\n\n... DOG = 'medium', 4\n...\n>>> Creature.DOG\n<Creature.DOG: size='medium', legs=4>\n使用 dataclass() 参数 repr=False 来使用标准的 repr()。\n在 3.12 版本发生变更: 只有数据类字段会被显示在值区域中，数据类名称不会被显示。\n备注: 向 Enum 及其子类添加 dataclass() 装饰器是不受支持的。 它不会引发任何错误，但会\n在运行时产生非常怪异的结果，例如不同的成员彼此相等:\n>>> @dataclass # 不要这样做：没有任何意义\n... class Color(Enum):\n... RED = 1\n... BLUE = 2\n...\n>>> Color.RED is Color.BLUE\nFalse\n>>> Color.RED == Color.BLUE # 问题在这里：它们不应该相等\nTrue\n打包（pickle）\n枚举类型可以被打包和解包:\n>>> from test.test_enum import Fruit\n>>> from pickle import dumps, loads\n>>> Fruit.TOMATO is loads(dumps(Fruit.TOMATO))\nTrue\n打包的常规限制同样适用于枚举类型：必须在模块的最高层级定义，因为解包操作要求可从该模块\n导入。\n备注: 用 pickle 协议版本 4 可以轻松地将嵌入其他类中的枚举进行打包。\n通过在枚举类中定义 __reduce_ex__()，可以修改枚举成员的 pickled/unpicled 方式。默认方法是\n根据值进行的，但具有复杂值的枚举可能需要根据名称进行:\n>>> import enum\n>>> class MyEnum(enum.Enum):\n... __reduce_ex__ = enum.pickle_by_enum_name\n备注: 不建议为旗标使用基于名称的方式，因为未命名的别名将无法解封。\n函数式 API\nEnum 类可调用并提供了以下函数式 API：\n\n|  | ... DOG = 'medium', 4\n...\n>>> Creature.DOG\n<Creature.DOG: size='medium', legs=4> |  |\n| --- | --- | --- |\n|  | 使用 dataclass() 参数 repr=False 来使用标准的 repr()。\n在 3.12 版本发生变更: 只有数据类字段会被显示在值区域中，数据类名称不会被显示。 |  |\n|  | 备注: 向 Enum 及其子类添加 dataclass() 装饰器是不受支持的。 它不会引发任何错误，但会\n在运行时产生非常怪异的结果，例如不同的成员彼此相等:\n>>> @dataclass # 不要这样做：没有任何意义\n... class Color(Enum):\n... RED = 1\n... BLUE = 2\n...\n>>> Color.RED is Color.BLUE\nFalse\n>>> Color.RED == Color.BLUE # 问题在这里：它们不应该相等\nTrue |  |\n|  | 打包（pickle）\n枚举类型可以被打包和解包: |  |\n|  | >>> from test.test_enum import Fruit\n>>> from pickle import dumps, loads\n>>> Fruit.TOMATO is loads(dumps(Fruit.TOMATO))\nTrue |  |\n|  | 打包的常规限制同样适用于枚举类型：必须在模块的最高层级定义，因为解包操作要求可从该模块\n导入。 |  |\n|  | 备注: 用 pickle 协议版本 4 可以轻松地将嵌入其他类中的枚举进行打包。 |  |\n|  | 通过在枚举类中定义 __reduce_ex__()，可以修改枚举成员的 pickled/unpicled 方式。默认方法是\n根据值进行的，但具有复杂值的枚举可能需要根据名称进行: |  |\n|  | >>> import enum\n>>> class MyEnum(enum.Enum):\n... __reduce_ex__ = enum.pickle_by_enum_name |  |\n|  |  |  |\n|  | 备注: 不建议为旗标使用基于名称的方式，因为未命名的别名将无法解封。 |  |\n|  | 函数式 API\nEnum 类可调用并提供了以下函数式 API： |  |\n\n>>> Animal = Enum('Animal', 'ANT BEE CAT DOG')\n>>> Animal\n<enum 'Animal'>\n>>> Animal.ANT\n<Animal.ANT: 1>\n>>> list(Animal)\n[<Animal.ANT: 1>, <Animal.BEE: 2>, <Animal.CAT: 3>, <Animal.DOG: 4>]\n该 API 的语义类似于 namedtuple。调用 Enum 的第一个参数是枚举的名称。\n第二个参数是枚举成员名称的 来源。它可以是以空白分隔的名称字符串、名称序列、包含键/值对的\n2 元组序列或名称到值的映射（如字典）。后两个选项可为枚举指定任意值；其他选项则自动指定从\n1 开始的递增整数（使用 start 参数可指定不同的起始值）。返回值是一个从 Enum 派生的新类。\n也就是说，上述对 Animal 的赋值相当于：\n>>> class Animal(Enum):\n... ANT = 1\n... BEE = 2\n... CAT = 3\n... DOG = 4\n...\n默认从 1 开始而非 0 ，因为 0 是布尔值 False ，但默认的枚举成员都被视作 True 。\n对使用函数式 API 创建的枚举进行封存，可能会很棘手，因为要使用栈帧的实现细节来尝试找出枚\n举是在哪个模块中创建的（例如当你使用了另一个模块中的实用函数时它就可能失败，在\nIronPython 或 Jython 上也可能无效）。解决办法是像下面这样显式地指定模块名称：\n>>> Animal = Enum('Animal', 'ANT BEE CAT DOG', module=__name__)\n警告: 如果未提供 module，且 Enum 无法确定是哪个模块，新的 Enum 成员将不可被解封；为\n了让错误尽量靠近源头，封存将被禁用。\n在某些情况下，新的 pickle 版本 4 协议还需要 __qualname__ 在 pickle 能够找到类的位置。 例如，\n如果该类是在全局作用域内的 SomeData 类中可见:\n>>> Animal = Enum('Animal', 'ANT BEE CAT DOG', qualname='SomeData.Animal')\n完整的签名为:\nEnum(\nvalue='NewEnumName',\nnames=<...>,\n*,\nmodule='...',\nqualname='...',\ntype=<mixed-in class>,\nstart=1,\n)\nvalue: 新枚举类将会作为其名称记录的值。\n\n|  | >>> Animal = Enum('Animal', 'ANT BEE CAT DOG')\n>>> Animal\n<enum 'Animal'>\n>>> Animal.ANT\n<Animal.ANT: 1>\n>>> list(Animal)\n[<Animal.ANT: 1>, <Animal.BEE: 2>, <Animal.CAT: 3>, <Animal.DOG: 4>] |  |\n| --- | --- | --- |\n|  | 该 API 的语义类似于 namedtuple。调用 Enum 的第一个参数是枚举的名称。\n第二个参数是枚举成员名称的 来源。它可以是以空白分隔的名称字符串、名称序列、包含键/值对的\n2 元组序列或名称到值的映射（如字典）。后两个选项可为枚举指定任意值；其他选项则自动指定从\n1 开始的递增整数（使用 start 参数可指定不同的起始值）。返回值是一个从 Enum 派生的新类。\n也就是说，上述对 Animal 的赋值相当于： |  |\n|  | >>> class Animal(Enum):\n... ANT = 1\n... BEE = 2\n... CAT = 3\n... DOG = 4\n... |  |\n|  | 默认从 1 开始而非 0 ，因为 0 是布尔值 False ，但默认的枚举成员都被视作 True 。\n对使用函数式 API 创建的枚举进行封存，可能会很棘手，因为要使用栈帧的实现细节来尝试找出枚\n举是在哪个模块中创建的（例如当你使用了另一个模块中的实用函数时它就可能失败，在\nIronPython 或 Jython 上也可能无效）。解决办法是像下面这样显式地指定模块名称： |  |\n|  | >>> Animal = Enum('Animal', 'ANT BEE CAT DOG', module=__name__) |  |\n|  |  |  |\n|  | 警告: 如果未提供 module，且 Enum 无法确定是哪个模块，新的 Enum 成员将不可被解封；为\n了让错误尽量靠近源头，封存将被禁用。 |  |\n|  | 在某些情况下，新的 pickle 版本 4 协议还需要 __qualname__ 在 pickle 能够找到类的位置。 例如，\n如果该类是在全局作用域内的 SomeData 类中可见: |  |\n|  | >>> Animal = Enum('Animal', 'ANT BEE CAT DOG', qualname='SomeData.Animal') |  |\n|  | 完整的签名为: |  |\n|  | Enum(\nvalue='NewEnumName',\nnames=<...>,\n*,\nmodule='...',\nqualname='...',\ntype=<mixed-in class>,\nstart=1,\n) |  |\n|  | value: 新枚举类将会作为其名称记录的值。 |  |\n\nnames: 枚举的成员。 这可以是一个用空格或逗号分隔的字符串（值将从 1 开始除非另外指定）:\n'RED GREEN BLUE' | 'RED,GREEN,BLUE' | 'RED, GREEN, BLUE'\n或是一个名称的迭代器对象:\n['RED', 'GREEN', 'BLUE']\n或是一个 (名称, 值) 对的迭代器对象:\n[('CYAN', 4), ('MAGENTA', 5), ('YELLOW', 6)]\n或是一个映射对象:\n{'CHARTREUSE': 7, 'SEA_GREEN': 11, 'ROSEMARY': 42}\nmodule: 新枚举类所在的模块名。\nqualname: 新枚举类在模块内的位置。\ntype: 要混入到新枚举类的类型。\nstart: 当只传入名称时要使用的起始计数编号。\n在 3.5 版本发生变更: 增加了 start 形参。\n派生的枚举\nIntEnum\n所提供的第一个变种 Enum 同时也是 int 的一个子类。 IntEnum 的成员可与整数进行比较；通过扩\n展，不同类型的整数枚举也可以相互进行比较:\n>>> from enum import IntEnum\n>>> class Shape(IntEnum):\n... CIRCLE = 1\n... SQUARE = 2\n...\n>>> class Request(IntEnum):\n... POST = 1\n... GET = 2\n...\n>>> Shape == 1\nFalse\n>>> Shape.CIRCLE == 1\nTrue\n>>> Shape.CIRCLE == Request.POST\nTrue\n不过，它们仍然不可与标准 Enum 枚举进行比较:\n>>> class Shape(IntEnum):\n... CIRCLE = 1\n\n|  | names: 枚举的成员。 这可以是一个用空格或逗号分隔的字符串（值将从 1 开始除非另外指定）:\n'RED GREEN BLUE' | 'RED,GREEN,BLUE' | 'RED, GREEN, BLUE'\n或是一个名称的迭代器对象:\n['RED', 'GREEN', 'BLUE']\n或是一个 (名称, 值) 对的迭代器对象:\n[('CYAN', 4), ('MAGENTA', 5), ('YELLOW', 6)]\n或是一个映射对象:\n{'CHARTREUSE': 7, 'SEA_GREEN': 11, 'ROSEMARY': 42}\nmodule: 新枚举类所在的模块名。\nqualname: 新枚举类在模块内的位置。\ntype: 要混入到新枚举类的类型。\nstart: 当只传入名称时要使用的起始计数编号。\n在 3.5 版本发生变更: 增加了 start 形参。\n派生的枚举\nIntEnum\n所提供的第一个变种 Enum 同时也是 int 的一个子类。 IntEnum 的成员可与整数进行比较；通过扩\n展，不同类型的整数枚举也可以相互进行比较: |  |\n| --- | --- | --- |\n|  | >>> from enum import IntEnum\n>>> class Shape(IntEnum):\n... CIRCLE = 1\n... SQUARE = 2\n...\n>>> class Request(IntEnum):\n... POST = 1\n... GET = 2\n...\n>>> Shape == 1\nFalse\n>>> Shape.CIRCLE == 1\nTrue\n>>> Shape.CIRCLE == Request.POST\nTrue |  |\n|  | 不过，它们仍然不可与标准 Enum 枚举进行比较: |  |\n|  | >>> class Shape(IntEnum):\n... CIRCLE = 1 |  |\n\n... SQUARE = 2\n...\n>>> class Color(Enum):\n... RED = 1\n... GREEN = 2\n...\n>>> Shape.CIRCLE == Color.RED\nFalse\nIntEnum 值在其他方面的行为都如你预期的一样类似于整数:\n>>> int(Shape.CIRCLE)\n1\n>>> ['a', 'b', 'c'][Shape.CIRCLE]\n'b'\n>>> [i for i in range(Shape.SQUARE)]\n[0, 1]\nStrEnum\n所提供的第二种 Enum 变体同时也是 str 的一个子类。 StrEnum 的成员可与字符串进行比较；通过\n扩展，不同类型的字符串枚举也可以相互进行比较。\nAdded in version 3.11.\nIntFlag\n所提供的下一种 Enum 变体 IntFlag 也是基于 int 的。 不同之处在于 IntFlag 成员可以用位运算\n符 (&, |, ^, ~) 进行组合并且如果可能的话其结果仍将是 IntFlag 成员。 与 IntEnum 类似，\nIntFlag 成员也是整数并且可以用于任何使用 int 的地方。\n备注: 除位操作外，其他所有对 IntFlag 成员的操作，都会失去 IntFlag 成员资格。\n导致 IntFlag 值无效的位操作将失去 IntFlag 成员资格。详见 FlagBoundary。\nAdded in version 3.6.\n在 3.11 版本发生变更.\n示例 IntFlag 类:\n>>> from enum import IntFlag\n>>> class Perm(IntFlag):\n... R = 4\n... W = 2\n... X = 1\n...\n>>> Perm.R | Perm.W\n<Perm.R|W: 6>\n>>> Perm.R + Perm.W\n6\n>>> RW = Perm.R | Perm.W\n\n|  | ... SQUARE = 2\n...\n>>> class Color(Enum):\n... RED = 1\n... GREEN = 2\n...\n>>> Shape.CIRCLE == Color.RED\nFalse |  |\n| --- | --- | --- |\n|  | IntEnum 值在其他方面的行为都如你预期的一样类似于整数: |  |\n|  | >>> int(Shape.CIRCLE)\n1\n>>> ['a', 'b', 'c'][Shape.CIRCLE]\n'b'\n>>> [i for i in range(Shape.SQUARE)]\n[0, 1] |  |\n|  | StrEnum\n所提供的第二种 Enum 变体同时也是 str 的一个子类。 StrEnum 的成员可与字符串进行比较；通过\n扩展，不同类型的字符串枚举也可以相互进行比较。\nAdded in version 3.11.\nIntFlag\n所提供的下一种 Enum 变体 IntFlag 也是基于 int 的。 不同之处在于 IntFlag 成员可以用位运算\n符 (&, |, ^, ~) 进行组合并且如果可能的话其结果仍将是 IntFlag 成员。 与 IntEnum 类似，\nIntFlag 成员也是整数并且可以用于任何使用 int 的地方。 |  |\n|  | 备注: 除位操作外，其他所有对 IntFlag 成员的操作，都会失去 IntFlag 成员资格。\n导致 IntFlag 值无效的位操作将失去 IntFlag 成员资格。详见 FlagBoundary。 |  |\n|  | Added in version 3.6.\n在 3.11 版本发生变更.\n示例 IntFlag 类: |  |\n|  | >>> from enum import IntFlag\n>>> class Perm(IntFlag):\n... R = 4\n... W = 2\n... X = 1\n...\n>>> Perm.R | Perm.W\n<Perm.R|W: 6>\n>>> Perm.R + Perm.W\n6\n>>> RW = Perm.R | Perm.W |  |\n\n>>> Perm.R in RW\nTrue\n对于组合同样可以进行命名:\n>>> class Perm(IntFlag):\n... R = 4\n... W = 2\n... X = 1\n... RWX = 7\n...\n>>> Perm.RWX\n<Perm.RWX: 7>\n>>> ~Perm.RWX\n<Perm: 0>\n>>> Perm(7)\n<Perm.RWX: 7>\n备注: 命名的枚举组合被视作别名。别名在迭代过程中不会显示，但可以通过值查询返回。\n在 3.11 版本发生变更.\nIntFlag 和 Enum 的另一个重要区别在于如果没有设置任何旗标（值为 0），则其布尔值为 False:\n>>> Perm.R & Perm.X\n<Perm: 0>\n>>> bool(Perm.R & Perm.X)\nFalse\n因为 IntFlag 成员也是 int 的子类，他们可以相互组合（但可能会失去 IntFlag 成员资格:\n>>> Perm.X | 4\n<Perm.R|X: 5>\n>>> Perm.X + 8\n9\n备注: 否运算符 ~，始终会返回一个 IntFlag 成员的正值:\n>>> (~Perm.X).value == (Perm.R|Perm.W).value == 6\nTrue\nIntFlag 成员也可被迭代遍历:\n>>> list(RW)\n[<Perm.R: 4>, <Perm.W: 2>]\nAdded in version 3.11.\n标志\n\n|  | >>> Perm.R in RW\nTrue |  |\n| --- | --- | --- |\n|  | 对于组合同样可以进行命名: |  |\n|  | >>> class Perm(IntFlag):\n... R = 4\n... W = 2\n... X = 1\n... RWX = 7\n...\n>>> Perm.RWX\n<Perm.RWX: 7>\n>>> ~Perm.RWX\n<Perm: 0>\n>>> Perm(7)\n<Perm.RWX: 7> |  |\n|  |  |  |\n|  | 备注: 命名的枚举组合被视作别名。别名在迭代过程中不会显示，但可以通过值查询返回。 |  |\n|  | 在 3.11 版本发生变更.\nIntFlag 和 Enum 的另一个重要区别在于如果没有设置任何旗标（值为 0），则其布尔值为 False: |  |\n|  | >>> Perm.R & Perm.X\n<Perm: 0>\n>>> bool(Perm.R & Perm.X)\nFalse |  |\n|  | 因为 IntFlag 成员也是 int 的子类，他们可以相互组合（但可能会失去 IntFlag 成员资格: |  |\n|  | >>> Perm.X | 4\n<Perm.R|X: 5>\n>>> Perm.X + 8\n9 |  |\n|  |  |  |\n|  | 备注: 否运算符 ~，始终会返回一个 IntFlag 成员的正值:\n>>> (~Perm.X).value == (Perm.R|Perm.W).value == 6\nTrue |  |\n|  | IntFlag 成员也可被迭代遍历: |  |\n|  | >>> list(RW)\n[<Perm.R: 4>, <Perm.W: 2>] |  |\n|  | Added in version 3.11.\n标志 |  |\n\n最后一个变体是 Flag。与 IntFlag 类似，Flag 成员可用按位运算符 (&, |, ^, ~) 组合。与 IntFlag\n不同的是，它们不可与其它 Flag 枚举或 int 进行组合或比较。 虽然可以直接指定值，但推荐使用\nauto 作为值来让 Flag 选择适当的值。\nAdded in version 3.6.\n与 IntFlag 类似，如果 Flag 成员的某种组合导致没有设置任何旗标，则其布尔值为 False:\n>>> from enum import Flag, auto\n>>> class Color(Flag):\n... RED = auto()\n... BLUE = auto()\n... GREEN = auto()\n...\n>>> Color.RED & Color.GREEN\n<Color: 0>\n>>> bool(Color.RED & Color.GREEN)\nFalse\n单个旗标的值应当为二的乘方 (1, 2, 4, 8, ...)，而旗标的组合则无此限制:\n>>> class Color(Flag):\n... RED = auto()\n... BLUE = auto()\n... GREEN = auto()\n... WHITE = RED | BLUE | GREEN\n...\n>>> Color.WHITE\n<Color.WHITE: 7>\n对 \"no flags set\" 条件指定一个名称并不会改变其布尔值:\n>>> class Color(Flag):\n... BLACK = 0\n... RED = auto()\n... BLUE = auto()\n... GREEN = auto()\n...\n>>> Color.BLACK\n<Color.BLACK: 0>\n>>> bool(Color.BLACK)\nFalse\nFlag 成员也可被迭代遍历:\n>>> purple = Color.RED | Color.BLUE\n>>> list(purple)\n[<Color.RED: 1>, <Color.BLUE: 2>]\nAdded in version 3.11.\n备注: 对于大多数新代码，强烈推荐使用 Enum 和 Flag，因为 IntEnum 和 IntFlag 打破了枚举\n的某些语义约定（例如可以同整数进行比较，并因而导致此行为被传递给其他无关的枚举）。\n\n|  | 最后一个变体是 Flag。与 IntFlag 类似，Flag 成员可用按位运算符 (&, |, ^, ~) 组合。与 IntFlag\n不同的是，它们不可与其它 Flag 枚举或 int 进行组合或比较。 虽然可以直接指定值，但推荐使用\nauto 作为值来让 Flag 选择适当的值。\nAdded in version 3.6.\n与 IntFlag 类似，如果 Flag 成员的某种组合导致没有设置任何旗标，则其布尔值为 False: |  |\n| --- | --- | --- |\n|  | >>> from enum import Flag, auto\n>>> class Color(Flag):\n... RED = auto()\n... BLUE = auto()\n... GREEN = auto()\n...\n>>> Color.RED & Color.GREEN\n<Color: 0>\n>>> bool(Color.RED & Color.GREEN)\nFalse |  |\n|  | 单个旗标的值应当为二的乘方 (1, 2, 4, 8, ...)，而旗标的组合则无此限制: |  |\n|  | >>> class Color(Flag):\n... RED = auto()\n... BLUE = auto()\n... GREEN = auto()\n... WHITE = RED | BLUE | GREEN\n...\n>>> Color.WHITE\n<Color.WHITE: 7> |  |\n|  | 对 \"no flags set\" 条件指定一个名称并不会改变其布尔值: |  |\n|  | >>> class Color(Flag):\n... BLACK = 0\n... RED = auto()\n... BLUE = auto()\n... GREEN = auto()\n...\n>>> Color.BLACK\n<Color.BLACK: 0>\n>>> bool(Color.BLACK)\nFalse |  |\n|  | Flag 成员也可被迭代遍历: |  |\n|  | >>> purple = Color.RED | Color.BLUE\n>>> list(purple)\n[<Color.RED: 1>, <Color.BLUE: 2>] |  |\n|  | Added in version 3.11. |  |\n|  | 备注: 对于大多数新代码，强烈推荐使用 Enum 和 Flag，因为 IntEnum 和 IntFlag 打破了枚举\n的某些语义约定（例如可以同整数进行比较，并因而导致此行为被传递给其他无关的枚举）。 |  |\n\nIntEnum 和 IntFlag 的使用应当仅限于 Enum 和 Flag 无法使用的场合；例如，当使用枚举替代\n整数常量时，或是与其他系统进行交互操作时。\n其他事项\n虽然 IntEnum 是 enum 模块的一部分，但要独立实现也应该相当容易:\nclass IntEnum(int, ReprEnum): # 或用 Enum 而不是 ReprEnum\npass\n这里演示了类似的派生枚举可以如何被定义；例如，一个混入了 float 而不是 int 的 FloatEnum。\n几条规则：\n1. 当子类化 Enum 时，混入类型必须出现在基类序列中的 Enum 类本身之前，如以上 IntEnum\n的例子所示。\n2. 混入类型必须是可子类化的。 例如，bool 和 range 是不可子类化的因而如果被用作混入类\n型就将在枚举创建期间抛出错误。\n3. 虽然 Enum 可以拥有任意类型的成员，不过一旦你混合了附加类型，则所有成员必须为相应类\n型的值，如在上面的例子中即为 int。 此限制不适用于仅添加方法而未指定另一数据类型的\n混合类。\n4. 当混合了另一数据类型时，value 属性将 不同于 枚举成员本身，不过它们仍会保持等价且比\n较结果也相等。\n5. data type 是一个定义了 __new__() 的混入对象，或者是一个 dataclass\n6. % 形式的格式化： %s 和 %r 会分别调用 Enum 类的 __str__() 和 __repr__()；其他代码\n（如 %i 或 %h 用于 IntEnum）会将枚举成员当作对应的混入类型。\n7. 格式化字符串字面值, str.format() 和 format() 将使用枚举的 __str__() 方法。\n备注: 由于 IntEnum, IntFlag 和 StrEnum 被设计为现有常量的无缝替换，它们的 __str__()\n方法已被重置为其数据类型的 __str__() 方法。\n何时应使用 __new__() 或 __init__()\n当你想要定制 Enum 成员的实际值时你必须使用 __new__()。 任何其他修改则可使用 __new__() 或\n__init__()，其中 __init__() 更为推荐。\n举例来说，如果你要向构造器传入多个条目，但只希望将其中一个作为值:\n>>> class Coordinate(bytes, Enum):\n... \"\"\"\n... Coordinate with binary codes that can be indexed by the int code.\n... \"\"\"\n... def __new__(cls, value, label, unit):\n... obj = bytes.__new__(cls, [value])\n... obj._value_ = value\n... obj.label = label\n... obj.unit = unit\n... return obj\n... PX = (0, 'P.X', 'km')\n\n|  | IntEnum 和 IntFlag 的使用应当仅限于 Enum 和 Flag 无法使用的场合；例如，当使用枚举替代\n整数常量时，或是与其他系统进行交互操作时。 |  |\n| --- | --- | --- |\n|  | 其他事项\n虽然 IntEnum 是 enum 模块的一部分，但要独立实现也应该相当容易: |  |\n|  | class IntEnum(int, ReprEnum): # 或用 Enum 而不是 ReprEnum\npass |  |\n|  | 这里演示了类似的派生枚举可以如何被定义；例如，一个混入了 float 而不是 int 的 FloatEnum。\n几条规则：\n1. 当子类化 Enum 时，混入类型必须出现在基类序列中的 Enum 类本身之前，如以上 IntEnum\n的例子所示。\n2. 混入类型必须是可子类化的。 例如，bool 和 range 是不可子类化的因而如果被用作混入类\n型就将在枚举创建期间抛出错误。\n3. 虽然 Enum 可以拥有任意类型的成员，不过一旦你混合了附加类型，则所有成员必须为相应类\n型的值，如在上面的例子中即为 int。 此限制不适用于仅添加方法而未指定另一数据类型的\n混合类。\n4. 当混合了另一数据类型时，value 属性将 不同于 枚举成员本身，不过它们仍会保持等价且比\n较结果也相等。\n5. data type 是一个定义了 __new__() 的混入对象，或者是一个 dataclass\n6. % 形式的格式化： %s 和 %r 会分别调用 Enum 类的 __str__() 和 __repr__()；其他代码\n（如 %i 或 %h 用于 IntEnum）会将枚举成员当作对应的混入类型。\n7. 格式化字符串字面值, str.format() 和 format() 将使用枚举的 __str__() 方法。 |  |\n|  | 备注: 由于 IntEnum, IntFlag 和 StrEnum 被设计为现有常量的无缝替换，它们的 __str__()\n方法已被重置为其数据类型的 __str__() 方法。 |  |\n|  | 何时应使用 __new__() 或 __init__()\n当你想要定制 Enum 成员的实际值时你必须使用 __new__()。 任何其他修改则可使用 __new__() 或\n__init__()，其中 __init__() 更为推荐。\n举例来说，如果你要向构造器传入多个条目，但只希望将其中一个作为值: |  |\n|  | >>> class Coordinate(bytes, Enum):\n... \"\"\"\n... Coordinate with binary codes that can be indexed by the int code.\n... \"\"\"\n... def __new__(cls, value, label, unit):\n... obj = bytes.__new__(cls, [value])\n... obj._value_ = value\n... obj.label = label\n... obj.unit = unit\n... return obj\n... PX = (0, 'P.X', 'km') |  |\n\n... PY = (1, 'P.Y', 'km')\n... VX = (2, 'V.X', 'km/s')\n... VY = (3, 'V.Y', 'km/s')\n...\n>>> print(Coordinate['PY'])\nCoordinate.PY\n>>> print(Coordinate(3))\nCoordinate.VY\n警告: 不要 调用 super().__new__()，因为只能找到仅用于查找的 __new__；请改为直接使用\n该数据类型。\n细节要点\n支持的 __dunder__ 名称\n__members__ 是一个由 member_name:member 条目组成的只读有序映射。 它只在类上可用。\n如果指定了 __new__()，它必须创建并返回枚举成员；相应地设置成员的 _value_ 也是一个很好的\n主意。 一旦所有成员都创建完成它将不再被使用。\n支持的 _sunder_ 名称\n_name_ -- 成员的名称\n_value_ -- 成员的值；可在 __new__ 中设置\n_missing_() -- 当未找到某个值时所使用的查找函数；可被重写\n_ignore_ -- 一个名称列表，可以为 list 或 str，它不会被转化为成员，并将从最终类中移除\n_generate_next_value_() -- 用于为枚举成员获取适当的值；可被重写\n_add_alias_() -- 添加一个新名称作为现有成员的别名。\n_add_value_alias_() -- 添加一个新值作为现有成员的别名。 参见 MultiValueEnum 中的示例。\n备注: 对于标准的 Enum 类来说下一个被选择的值将是已有的最高值加一。\n对于 Flag 类来说下一个选择的值将是下一个最高的二的幂数。\n在 3.13 版本发生变更: 在之前版本中将会使用最近的值而不是最高的值。\nAdded in version 3.6: _missing_, _order_, _generate_next_value_\nAdded in version 3.7: _ignore_\nAdded in version 3.13: _add_alias_, _add_value_alias_\n\n|  | ... PY = (1, 'P.Y', 'km')\n... VX = (2, 'V.X', 'km/s')\n... VY = (3, 'V.Y', 'km/s')\n...\n>>> print(Coordinate['PY'])\nCoordinate.PY\n>>> print(Coordinate(3))\nCoordinate.VY |  |\n| --- | --- | --- |\n|  |  |  |\n|  | 警告: 不要 调用 super().__new__()，因为只能找到仅用于查找的 __new__；请改为直接使用\n该数据类型。 |  |\n|  | 细节要点\n支持的 __dunder__ 名称\n__members__ 是一个由 member_name:member 条目组成的只读有序映射。 它只在类上可用。\n如果指定了 __new__()，它必须创建并返回枚举成员；相应地设置成员的 _value_ 也是一个很好的\n主意。 一旦所有成员都创建完成它将不再被使用。\n支持的 _sunder_ 名称\n_name_ -- 成员的名称\n_value_ -- 成员的值；可在 __new__ 中设置\n_missing_() -- 当未找到某个值时所使用的查找函数；可被重写\n_ignore_ -- 一个名称列表，可以为 list 或 str，它不会被转化为成员，并将从最终类中移除\n_generate_next_value_() -- 用于为枚举成员获取适当的值；可被重写\n_add_alias_() -- 添加一个新名称作为现有成员的别名。\n_add_value_alias_() -- 添加一个新值作为现有成员的别名。 参见 MultiValueEnum 中的示例。\n备注: 对于标准的 Enum 类来说下一个被选择的值将是已有的最高值加一。\n对于 Flag 类来说下一个选择的值将是下一个最高的二的幂数。\n在 3.13 版本发生变更: 在之前版本中将会使用最近的值而不是最高的值。\nAdded in version 3.6: _missing_, _order_, _generate_next_value_\nAdded in version 3.7: _ignore_\nAdded in version 3.13: _add_alias_, _add_value_alias_ |  |\n\n用于帮助 Python 2 / Python 3 代码保持同步以便提供 _order_ 属性。 它将与枚举的实际顺序进行\n检查并会在两者不匹配时引发错误:\n>>> class Color(Enum):\n... _order_ = 'RED GREEN BLUE'\n... RED = 1\n... BLUE = 3\n... GREEN = 2\n...\nTraceback (most recent call last):\n...\nTypeError: member order does not match _order_:\n['RED', 'BLUE', 'GREEN']\n['RED', 'GREEN', 'BLUE']\n备注: 在 Python 2 代码中 _order_ 属性是必须的，因为定义顺序在被记录之前就已丢失。\n_Private__names\n私有名称 不会被转换为枚举成员，而是保持为普通属性。\n在 3.11 版本发生变更.\nEnum 成员类型\n枚举成员是其枚举类的实例，并且通常以 EnumClass.member 的形式来访问。 在特定场景下，如编\n写自定义枚举行为，可直接从一个成员访问另一个成员的能力是很有用的，并且是受支持的；但\n是，为了避免成员名与混入类属性/方法之间发生名称冲突，强烈建议使用大写形式的名称。\n在 3.5 版本发生变更.\n创建与其他数据类型混合的成员\n当使用 Enum 来子类化其他数据类型，如 int 或 str 时，所有在 = 之后的值都会被传递给该数据类\n型的构造器。 例如:\n>>> class MyEnum(IntEnum): # help(int) -> int(x, base=10) -> integer\n... example = '11', 16 # 这样 x='11' 而 base=16\n...\n>>> MyEnum.example.value # 而 hex(11) 为...\n17\nEnum 类和成员的布尔值\n与非 Enum 类型（如 int、str 等）混合的枚举类会根据混合类型的规则进行计算；否则，所有成员\n都计算为 True。为了使你自己的枚举的布尔值取决于成员的值，请在你的类中添加以下内容:\ndef __bool__(self):\nreturn bool(self.value)\n\n|  | 用于帮助 Python 2 / Python 3 代码保持同步以便提供 _order_ 属性。 它将与枚举的实际顺序进行\n检查并会在两者不匹配时引发错误: |  |\n| --- | --- | --- |\n|  | >>> class Color(Enum):\n... _order_ = 'RED GREEN BLUE'\n... RED = 1\n... BLUE = 3\n... GREEN = 2\n...\nTraceback (most recent call last):\n...\nTypeError: member order does not match _order_:\n['RED', 'BLUE', 'GREEN']\n['RED', 'GREEN', 'BLUE'] |  |\n|  |  |  |\n|  | 备注: 在 Python 2 代码中 _order_ 属性是必须的，因为定义顺序在被记录之前就已丢失。 |  |\n|  | _Private__names\n私有名称 不会被转换为枚举成员，而是保持为普通属性。\n在 3.11 版本发生变更.\nEnum 成员类型\n枚举成员是其枚举类的实例，并且通常以 EnumClass.member 的形式来访问。 在特定场景下，如编\n写自定义枚举行为，可直接从一个成员访问另一个成员的能力是很有用的，并且是受支持的；但\n是，为了避免成员名与混入类属性/方法之间发生名称冲突，强烈建议使用大写形式的名称。\n在 3.5 版本发生变更.\n创建与其他数据类型混合的成员\n当使用 Enum 来子类化其他数据类型，如 int 或 str 时，所有在 = 之后的值都会被传递给该数据类\n型的构造器。 例如: |  |\n|  | >>> class MyEnum(IntEnum): # help(int) -> int(x, base=10) -> integer\n... example = '11', 16 # 这样 x='11' 而 base=16\n...\n>>> MyEnum.example.value # 而 hex(11) 为...\n17 |  |\n|  | Enum 类和成员的布尔值\n与非 Enum 类型（如 int、str 等）混合的枚举类会根据混合类型的规则进行计算；否则，所有成员\n都计算为 True。为了使你自己的枚举的布尔值取决于成员的值，请在你的类中添加以下内容: |  |\n|  | def __bool__(self):\nreturn bool(self.value) |  |\n|  |  |  |\n\n普通的 Enum 类总是计算为 True。\n带有方法的 Enum 类\n如果你给你的枚举子类提供了额外的方法，如下面的 Planet 类那样，这些方法将显示在成员的，而\n不是类的 dir() 中:\n>>> dir(Planet)\n['EARTH', 'JUPITER', 'MARS', 'MERCURY', 'NEPTUNE', 'SATURN', 'URANUS', 'VENUS', '_\n>>> dir(Planet.EARTH)\n['__class__', '__doc__', '__module__', 'mass', 'name', 'radius', 'surface_gravity'\n组合 Flag 的成员\n遍历 Flag 成员的组合将只返回由一个比特组成的成员:\n>>> class Color(Flag):\n... RED = auto()\n... GREEN = auto()\n... BLUE = auto()\n... MAGENTA = RED | BLUE\n... YELLOW = RED | GREEN\n... CYAN = GREEN | BLUE\n...\n>>> Color(3) # named combination\n<Color.YELLOW: 3>\n>>> Color(7) # not named combination\n<Color.RED|GREEN|BLUE: 7>\nFlag 和 IntFlag 的细节\n使用以下代码段作为我们的例子:\n>>> class Color(IntFlag):\n... BLACK = 0\n... RED = 1\n... GREEN = 2\n... BLUE = 4\n... PURPLE = RED | BLUE\n... WHITE = RED | GREEN | BLUE\n...\n下列情况为True:\n单比特标志是典型的\n多比特和零比特标志是别名\n迭代过程中只返回典型的标志:\n>>> list(Color.WHITE)\n[<Color.RED: 1>, <Color.GREEN: 2>, <Color.BLUE: 4>]\n\n|  | 普通的 Enum 类总是计算为 True。\n带有方法的 Enum 类\n如果你给你的枚举子类提供了额外的方法，如下面的 Planet 类那样，这些方法将显示在成员的，而\n不是类的 dir() 中: |  |  |\n| --- | --- | --- | --- |\n|  | >>> dir(Planet)\n['EARTH', 'JUPITER', 'MARS', 'MERCURY', 'NEPTUNE', 'SATURN', 'URANUS', 'VENUS', '_\n>>> dir(Planet.EARTH)\n['__class__', '__doc__', '__module__', 'mass', 'name', 'radius', 'surface_gravity' |  |  |\n|  | 组合 Flag 的成员\n遍历 Flag 成员的组合将只返回由一个比特组成的成员: |  |  |\n|  | >>> class Color(Flag):\n... RED = auto()\n... GREEN = auto()\n... BLUE = auto()\n... MAGENTA = RED | BLUE\n... YELLOW = RED | GREEN\n... CYAN = GREEN | BLUE\n...\n>>> Color(3) # named combination\n<Color.YELLOW: 3>\n>>> Color(7) # not named combination\n<Color.RED|GREEN|BLUE: 7> |  |  |\n|  | Flag 和 IntFlag 的细节\n使用以下代码段作为我们的例子: |  |  |\n|  | >>> class Color(IntFlag):\n... BLACK = 0\n... RED = 1\n... GREEN = 2\n... BLUE = 4\n... PURPLE = RED | BLUE\n... WHITE = RED | GREEN | BLUE\n... |  |  |\n|  | 下列情况为True:\n单比特标志是典型的\n多比特和零比特标志是别名\n迭代过程中只返回典型的标志:\n>>> list(Color.WHITE)\n[<Color.RED: 1>, <Color.GREEN: 2>, <Color.BLUE: 4>] |  |  |\n\n取负一个标志或标志集会返回一个新的标志/标志集和其对应的正整数值:\n>>> Color.BLUE\n<Color.BLUE: 4>\n>>> ~Color.BLUE\n<Color.RED|GREEN: 3>\n伪标志的名称是由其成员的名称构建的:\n>>> (Color.RED | Color.GREEN).name\n'RED|GREEN'\n>>> class Perm(IntFlag):\n... R = 4\n... W = 2\n... X = 1\n...\n>>> (Perm.R & Perm.W).name is None # effectively Perm(0)\nTrue\n多位标志，又称别名，可以从操作中返回:\n>>> Color.RED | Color.BLUE\n<Color.PURPLE: 5>\n>>> Color(7) # or Color(-1)\n<Color.WHITE: 7>\n>>> Color(0)\n<Color.BLACK: 0>\n成员 / 包含检测：零值旗标总是会被视为包含:\n>>> Color.BLACK in Color.WHITE\nTrue\n在其他情况下，仅当一个旗标的所有比特位都包含于另一个旗标中才会返回 True:\n>>> Color.PURPLE in Color.WHITE\nTrue\n>>> Color.GREEN in Color.PURPLE\nFalse\n有一个新的边界机制，控制如何处理超出范围的/无效的比特: STRICT，CONFORM，EJECT，KEEP。\nSTRICT --> 当出现无效的值时，会触发一个异常。\nCONFORM --> 丢弃任何无效的比特\nEJECT --> 失去Flag的状态，成为一个普通的int，其值为给定值。\nKEEP --> 保留额外的比特\n保留Flag状态和额外的比特\n额外的比特不会在迭代中显示出来\n\n|  | 取负一个标志或标志集会返回一个新的标志/标志集和其对应的正整数值:\n>>> Color.BLUE\n<Color.BLUE: 4>\n>>> ~Color.BLUE\n<Color.RED|GREEN: 3>\n伪标志的名称是由其成员的名称构建的:\n>>> (Color.RED | Color.GREEN).name\n'RED|GREEN'\n>>> class Perm(IntFlag):\n... R = 4\n... W = 2\n... X = 1\n...\n>>> (Perm.R & Perm.W).name is None # effectively Perm(0)\nTrue\n多位标志，又称别名，可以从操作中返回:\n>>> Color.RED | Color.BLUE\n<Color.PURPLE: 5>\n>>> Color(7) # or Color(-1)\n<Color.WHITE: 7>\n>>> Color(0)\n<Color.BLACK: 0>\n成员 / 包含检测：零值旗标总是会被视为包含:\n>>> Color.BLACK in Color.WHITE\nTrue\n在其他情况下，仅当一个旗标的所有比特位都包含于另一个旗标中才会返回 True:\n>>> Color.PURPLE in Color.WHITE\nTrue\n>>> Color.GREEN in Color.PURPLE\nFalse\n有一个新的边界机制，控制如何处理超出范围的/无效的比特: STRICT，CONFORM，EJECT，KEEP。\nSTRICT --> 当出现无效的值时，会触发一个异常。\nCONFORM --> 丢弃任何无效的比特\nEJECT --> 失去Flag的状态，成为一个普通的int，其值为给定值。\nKEEP --> 保留额外的比特\n保留Flag状态和额外的比特\n额外的比特不会在迭代中显示出来 |  |\n| --- | --- | --- |\n\n在repr()和str()中确实显示了额外的比特\n默认的标志为 STRICT，IntFlag 默认为 EJECT，_convert_ 默认为 KEEP (需要 KEEP 的例子见\nssl.Options)。\n枚举和旗标有何差异？\nEnum有一个自定义的元类，它影响到派生的 Enum 类和它们的实例（成员）的许多方面。\n枚举类\nEnumType 元类负责提供 __contains__(), __dir__(), __iter__() 及其他方法来允许人们在 Enum\n类上做一些在常规类上会失败的事情，比如 list(Color) 或 some_enum_var in Color。\nEnumType 负责确保最终的 Enum 类上的各种其他方法是正确的（比如 __new__(),\n__getnewargs__(), __str__() 和 __repr__() 等）。\n旗标类\n旗标具有扩展的别名视图：为了符合规范，旗标的值必须为二的乘方，且名称不可重复。 因此，除\n了别名的定义 Enum 之外，没有值 (即 0) 或是几个二的乘方值之和 (如 3) 的旗标也会被视为别名。\n枚举成员（即实例）\n有关枚举成员的最有趣的一点在于它们都是单例。 EnumType 会在创建枚举类本身时全部创建它\n们，然后放置一个自定义的 __new__() 以通过只返回现有的成员实例来确保没有新的成员被实例\n化。\n旗标成员\n旗标成员可以如 Flag 类一样被迭代，并且只有规范的成员会被返回。 例如:\n>>> list(Color)\n[<Color.RED: 1>, <Color.GREEN: 2>, <Color.BLUE: 4>]\n（请注意 BLACK, PURPLE 和 WHITE 将不显示。）\n对一个旗标成员取反将返回对应的正值，而不是负值 --- 例如:\n>>> ~Color.RED\n<Color.GREEN|BLUE: 6>\n旗标成员具有与它们所包含的二的乘方值的数量相对应的长度。 例如:\n>>> len(Color.PURPLE)\n2\n枚举指导手册\n\n|  | 在repr()和str()中确实显示了额外的比特\n默认的标志为 STRICT，IntFlag 默认为 EJECT，_convert_ 默认为 KEEP (需要 KEEP 的例子见\nssl.Options)。\n枚举和旗标有何差异？\nEnum有一个自定义的元类，它影响到派生的 Enum 类和它们的实例（成员）的许多方面。\n枚举类\nEnumType 元类负责提供 __contains__(), __dir__(), __iter__() 及其他方法来允许人们在 Enum\n类上做一些在常规类上会失败的事情，比如 list(Color) 或 some_enum_var in Color。\nEnumType 负责确保最终的 Enum 类上的各种其他方法是正确的（比如 __new__(),\n__getnewargs__(), __str__() 和 __repr__() 等）。\n旗标类\n旗标具有扩展的别名视图：为了符合规范，旗标的值必须为二的乘方，且名称不可重复。 因此，除\n了别名的定义 Enum 之外，没有值 (即 0) 或是几个二的乘方值之和 (如 3) 的旗标也会被视为别名。\n枚举成员（即实例）\n有关枚举成员的最有趣的一点在于它们都是单例。 EnumType 会在创建枚举类本身时全部创建它\n们，然后放置一个自定义的 __new__() 以通过只返回现有的成员实例来确保没有新的成员被实例\n化。\n旗标成员\n旗标成员可以如 Flag 类一样被迭代，并且只有规范的成员会被返回。 例如: |  |\n| --- | --- | --- |\n|  | >>> list(Color)\n[<Color.RED: 1>, <Color.GREEN: 2>, <Color.BLUE: 4>] |  |\n|  | （请注意 BLACK, PURPLE 和 WHITE 将不显示。）\n对一个旗标成员取反将返回对应的正值，而不是负值 --- 例如: |  |\n|  | >>> ~Color.RED\n<Color.GREEN|BLUE: 6> |  |\n|  | 旗标成员具有与它们所包含的二的乘方值的数量相对应的长度。 例如: |  |\n|  | >>> len(Color.PURPLE)\n2 |  |\n|  | 枚举指导手册 |  |\n\n虽然 Enum, IntEnum, StrEnum, Flag 和 IntFlag 有望能涵盖大多数的使用情况，但它们不能涵盖所\n有情况。 这里有一些不同类型的枚举的方法，可以直接使用，或者作为创建定制枚举的范例。\n省略值\n在许多应用场景中，人们并不关心枚举的实际值是什么。 有几种方式可用来定义这种类型的简单枚\n举:\n使用 auto 的实例作为值\n使用 object 的实例作为值\n使用描述性的字符串作为值\n使用一个元组作为值并用自定义的 __new__() 以一个 int 值来替代该元组\n使用以上任何一种方法均可向用户指明值并不重要，并且使人能够添加、移除或重排序成员而不必\n改变其余成员的数值。\n使用 auto\n使用 auto 的形式如下:\n>>> class Color(Enum):\n... RED = auto()\n... BLUE = auto()\n... GREEN = auto()\n...\n>>> Color.GREEN\n<Color.GREEN: 3>\n使用 object\n使用 object 的形式如下:\n>>> class Color(Enum):\n... RED = object()\n... GREEN = object()\n... BLUE = object()\n...\n>>> Color.GREEN\n<Color.GREEN: <object object at 0x...>>\n这也是一个可以说明为什么你会需要编写自己的 __repr__() 的好例子:\n>>> class Color(Enum):\n... RED = object()\n... GREEN = object()\n... BLUE = object()\n... def __repr__(self):\n... return \"<%s.%s>\" % (self.__class__.__name__, self._name_)\n...\n>>> Color.GREEN\n<Color.GREEN>\n\n|  | 虽然 Enum, IntEnum, StrEnum, Flag 和 IntFlag 有望能涵盖大多数的使用情况，但它们不能涵盖所\n有情况。 这里有一些不同类型的枚举的方法，可以直接使用，或者作为创建定制枚举的范例。\n省略值\n在许多应用场景中，人们并不关心枚举的实际值是什么。 有几种方式可用来定义这种类型的简单枚\n举:\n使用 auto 的实例作为值\n使用 object 的实例作为值\n使用描述性的字符串作为值\n使用一个元组作为值并用自定义的 __new__() 以一个 int 值来替代该元组\n使用以上任何一种方法均可向用户指明值并不重要，并且使人能够添加、移除或重排序成员而不必\n改变其余成员的数值。\n使用 auto\n使用 auto 的形式如下: |  |\n| --- | --- | --- |\n|  | >>> class Color(Enum):\n... RED = auto()\n... BLUE = auto()\n... GREEN = auto()\n...\n>>> Color.GREEN\n<Color.GREEN: 3> |  |\n|  | 使用 object\n使用 object 的形式如下: |  |\n|  | >>> class Color(Enum):\n... RED = object()\n... GREEN = object()\n... BLUE = object()\n...\n>>> Color.GREEN\n<Color.GREEN: <object object at 0x...>> |  |\n|  | 这也是一个可以说明为什么你会需要编写自己的 __repr__() 的好例子: |  |\n|  | >>> class Color(Enum):\n... RED = object()\n... GREEN = object()\n... BLUE = object()\n... def __repr__(self):\n... return \"<%s.%s>\" % (self.__class__.__name__, self._name_)\n...\n>>> Color.GREEN\n<Color.GREEN> |  |\n|  |  |  |\n\n使用描述性字符串\n使用字符串作为值的形式如下:\n>>> class Color(Enum):\n... RED = 'stop'\n... GREEN = 'go'\n... BLUE = 'too fast!'\n...\n>>> Color.GREEN\n<Color.GREEN: 'go'>\n使用自定义的 __new__()\n使用自动编号的 __new__() 看起来会是这样:\n>>> class AutoNumber(Enum):\n... def __new__(cls):\n... value = len(cls.__members__) + 1\n... obj = object.__new__(cls)\n... obj._value_ = value\n... return obj\n...\n>>> class Color(AutoNumber):\n... RED = ()\n... GREEN = ()\n... BLUE = ()\n...\n>>> Color.GREEN\n<Color.GREEN: 2>\n要实现更通用的 AutoNumber，请添加 *args 到签名中:\n>>> class AutoNumber(Enum):\n... def __new__(cls, *args): # 这是相比上面的唯一改变\n... value = len(cls.__members__) + 1\n... obj = object.__new__(cls)\n... obj._value_ = value\n... return obj\n...\n这样当你从 AutoNumber 继承时你将可以编写你自己的 __init__ 来处理任何附加参数:\n>>> class Swatch(AutoNumber):\n... def __init__(self, pantone='unknown'):\n... self.pantone = pantone\n... AUBURN = '3497'\n... SEA_GREEN = '1246'\n... BLEACHED_CORAL = () # 新的颜色，还没有 Pantone 代码！\n...\n>>> Swatch.SEA_GREEN\n<Swatch.SEA_GREEN: 2>\n>>> Swatch.SEA_GREEN.pantone\n'1246'\n\n|  | 使用描述性字符串\n使用字符串作为值的形式如下: |  |\n| --- | --- | --- |\n|  | >>> class Color(Enum):\n... RED = 'stop'\n... GREEN = 'go'\n... BLUE = 'too fast!'\n...\n>>> Color.GREEN\n<Color.GREEN: 'go'> |  |\n|  | 使用自定义的 __new__()\n使用自动编号的 __new__() 看起来会是这样: |  |\n|  | >>> class AutoNumber(Enum):\n... def __new__(cls):\n... value = len(cls.__members__) + 1\n... obj = object.__new__(cls)\n... obj._value_ = value\n... return obj\n...\n>>> class Color(AutoNumber):\n... RED = ()\n... GREEN = ()\n... BLUE = ()\n...\n>>> Color.GREEN\n<Color.GREEN: 2> |  |\n|  | 要实现更通用的 AutoNumber，请添加 *args 到签名中: |  |\n|  | >>> class AutoNumber(Enum):\n... def __new__(cls, *args): # 这是相比上面的唯一改变\n... value = len(cls.__members__) + 1\n... obj = object.__new__(cls)\n... obj._value_ = value\n... return obj\n... |  |\n|  | 这样当你从 AutoNumber 继承时你将可以编写你自己的 __init__ 来处理任何附加参数: |  |\n|  | >>> class Swatch(AutoNumber):\n... def __init__(self, pantone='unknown'):\n... self.pantone = pantone\n... AUBURN = '3497'\n... SEA_GREEN = '1246'\n... BLEACHED_CORAL = () # 新的颜色，还没有 Pantone 代码！\n...\n>>> Swatch.SEA_GREEN\n<Swatch.SEA_GREEN: 2>\n>>> Swatch.SEA_GREEN.pantone\n'1246' |  |\n\n>>> Swatch.BLEACHED_CORAL.pantone\n'unknown'\n备注: 如果定义了 __new__() 方法，它会在创建 Enum 成员期间被使用；随后它将被 Enum 的\n__new__() 所替换，该方法会在类创建后被用来查找现有成员。\n警告: 不要 调用 super().__new__()，因为只能找到仅用于查找的 __new__；请改为直接使用\n该数据类型 -- 例如:\nobj = int.__new__(cls, value)\nOrderedEnum\n一个有序枚举，它不是基于 IntEnum，因此保持了正常的 Enum 不变特性（例如不可与其他枚举进\n行比较）:\n>>> class OrderedEnum(Enum):\n... def __ge__(self, other):\n... if self.__class__ is other.__class__:\n... return self.value >= other.value\n... return NotImplemented\n... def __gt__(self, other):\n... if self.__class__ is other.__class__:\n... return self.value > other.value\n... return NotImplemented\n... def __le__(self, other):\n... if self.__class__ is other.__class__:\n... return self.value <= other.value\n... return NotImplemented\n... def __lt__(self, other):\n... if self.__class__ is other.__class__:\n... return self.value < other.value\n... return NotImplemented\n...\n>>> class Grade(OrderedEnum):\n... A = 5\n... B = 4\n... C = 3\n... D = 2\n... F = 1\n...\n>>> Grade.C < Grade.A\nTrue\nDuplicateFreeEnum\n如果发现重复的成员名称则会引发一个错误而不是创建一个别名:\n>>> class DuplicateFreeEnum(Enum):\n... def __init__(self, *args):\n... cls = self.__class__\n... if any(self.value == e.value for e in cls):\n... a = self.name\n\n|  | >>> Swatch.BLEACHED_CORAL.pantone\n'unknown' |  |\n| --- | --- | --- |\n|  |  |  |\n|  | 备注: 如果定义了 __new__() 方法，它会在创建 Enum 成员期间被使用；随后它将被 Enum 的\n__new__() 所替换，该方法会在类创建后被用来查找现有成员。 |  |\n|  |  |  |\n|  | 警告: 不要 调用 super().__new__()，因为只能找到仅用于查找的 __new__；请改为直接使用\n该数据类型 -- 例如:\nobj = int.__new__(cls, value) |  |\n|  | OrderedEnum\n一个有序枚举，它不是基于 IntEnum，因此保持了正常的 Enum 不变特性（例如不可与其他枚举进\n行比较）: |  |\n|  | >>> class OrderedEnum(Enum):\n... def __ge__(self, other):\n... if self.__class__ is other.__class__:\n... return self.value >= other.value\n... return NotImplemented\n... def __gt__(self, other):\n... if self.__class__ is other.__class__:\n... return self.value > other.value\n... return NotImplemented\n... def __le__(self, other):\n... if self.__class__ is other.__class__:\n... return self.value <= other.value\n... return NotImplemented\n... def __lt__(self, other):\n... if self.__class__ is other.__class__:\n... return self.value < other.value\n... return NotImplemented\n...\n>>> class Grade(OrderedEnum):\n... A = 5\n... B = 4\n... C = 3\n... D = 2\n... F = 1\n...\n>>> Grade.C < Grade.A\nTrue |  |\n|  | DuplicateFreeEnum\n如果发现重复的成员名称则会引发一个错误而不是创建一个别名: |  |\n|  | >>> class DuplicateFreeEnum(Enum):\n... def __init__(self, *args):\n... cls = self.__class__\n... if any(self.value == e.value for e in cls):\n... a = self.name |  |\n\n... e = cls(self.value).name\n... raise ValueError(\n... \"aliases not allowed in DuplicateFreeEnum: %r --> %r\"\n... % (a, e))\n...\n>>> class Color(DuplicateFreeEnum):\n... RED = 1\n... GREEN = 2\n... BLUE = 3\n... GRENE = 2\n...\nTraceback (most recent call last):\n...\nValueError: aliases not allowed in DuplicateFreeEnum: 'GRENE' --> 'GREEN'\n备注: 这个例子适用于子类化 Enum 来添加或改变禁用别名以及其他行为。 如果需要的改变只是\n禁用别名，也可以选择使用 unique() 装饰器。\nMultiValueEnum\n支持每个成员有多个值:\n>>> class MultiValueEnum(Enum):\n... def __new__(cls, value, *values):\n... self = object.__new__(cls)\n... self._value_ = value\n... for v in values:\n... self._add_value_alias_(v)\n... return self\n...\n>>> class DType(MultiValueEnum):\n... float32 = 'f', 8\n... double64 = 'd', 9\n...\n>>> DType('f')\n<DType.float32: 'f'>\n>>> DType(9)\n<DType.double64: 'd'>\nPlanet\n如果定义了 __new__() 或 __init__()，则枚举成员的值将被传给这些方法:\n>>> class Planet(Enum):\n... MERCURY = (3.303e+23, 2.4397e6)\n... VENUS = (4.869e+24, 6.0518e6)\n... EARTH = (5.976e+24, 6.37814e6)\n... MARS = (6.421e+23, 3.3972e6)\n... JUPITER = (1.9e+27, 7.1492e7)\n... SATURN = (5.688e+26, 6.0268e7)\n... URANUS = (8.686e+25, 2.5559e7)\n... NEPTUNE = (1.024e+26, 2.4746e7)\n... def __init__(self, mass, radius):\n... self.mass = mass # in kilograms\n... self.radius = radius # in meters\n... @property\n\n|  | ... e = cls(self.value).name\n... raise ValueError(\n... \"aliases not allowed in DuplicateFreeEnum: %r --> %r\"\n... % (a, e))\n...\n>>> class Color(DuplicateFreeEnum):\n... RED = 1\n... GREEN = 2\n... BLUE = 3\n... GRENE = 2\n...\nTraceback (most recent call last):\n...\nValueError: aliases not allowed in DuplicateFreeEnum: 'GRENE' --> 'GREEN' |  |\n| --- | --- | --- |\n|  |  |  |\n|  | 备注: 这个例子适用于子类化 Enum 来添加或改变禁用别名以及其他行为。 如果需要的改变只是\n禁用别名，也可以选择使用 unique() 装饰器。 |  |\n|  | MultiValueEnum\n支持每个成员有多个值: |  |\n|  | >>> class MultiValueEnum(Enum):\n... def __new__(cls, value, *values):\n... self = object.__new__(cls)\n... self._value_ = value\n... for v in values:\n... self._add_value_alias_(v)\n... return self\n...\n>>> class DType(MultiValueEnum):\n... float32 = 'f', 8\n... double64 = 'd', 9\n...\n>>> DType('f')\n<DType.float32: 'f'>\n>>> DType(9)\n<DType.double64: 'd'> |  |\n|  | Planet\n如果定义了 __new__() 或 __init__()，则枚举成员的值将被传给这些方法: |  |\n|  | >>> class Planet(Enum):\n... MERCURY = (3.303e+23, 2.4397e6)\n... VENUS = (4.869e+24, 6.0518e6)\n... EARTH = (5.976e+24, 6.37814e6)\n... MARS = (6.421e+23, 3.3972e6)\n... JUPITER = (1.9e+27, 7.1492e7)\n... SATURN = (5.688e+26, 6.0268e7)\n... URANUS = (8.686e+25, 2.5559e7)\n... NEPTUNE = (1.024e+26, 2.4746e7)\n... def __init__(self, mass, radius):\n... self.mass = mass # in kilograms\n... self.radius = radius # in meters\n... @property |  |\n\n... def surface_gravity(self):\n... # universal gravitational constant (m3 kg-1 s-2)\n... G = 6.67300E-11\n... return G * self.mass / (self.radius * self.radius)\n...\n>>> Planet.EARTH.value\n(5.976e+24, 6378140.0)\n>>> Planet.EARTH.surface_gravity\n9.802652743337129\nTimePeriod\n一个演示如何使用 _ignore_ 属性的例子:\n>>> from datetime import timedelta\n>>> class Period(timedelta, Enum):\n... \"different lengths of time\"\n... _ignore_ = 'Period i'\n... Period = vars()\n... for i in range(367):\n... Period['day_%d' % i] = i\n...\n>>> list(Period)[:2]\n[<Period.day_0: datetime.timedelta(0)>, <Period.day_1: datetime.timedelta(days=1)>\n>>> list(Period)[-2:]\n[<Period.day_365: datetime.timedelta(days=365)>, <Period.day_366: datetime.timedel\n子类化 EnumType\n虽然大多数枚举需求可以通过自定义 Enum 子类来满足，无论是用类装饰器还是自定义函数，\nEnumType 可以被子类化以提供不同的枚举体验。\n\n| ... def surface_gravity(self):\n... # universal gravitational constant (m3 kg-1 s-2)\n... G = 6.67300E-11\n... return G * self.mass / (self.radius * self.radius)\n...\n>>> Planet.EARTH.value\n(5.976e+24, 6378140.0)\n>>> Planet.EARTH.surface_gravity\n9.802652743337129\nTimePeriod\n一个演示如何使用 _ignore_ 属性的例子:\n>>> from datetime import timedelta\n>>> class Period(timedelta, Enum):\n... \"different lengths of time\"\n... _ignore_ = 'Period i'\n... Period = vars()\n... for i in range(367):\n... Period['day_%d' % i] = i\n...\n>>> list(Period)[:2]\n[<Period.day_0: datetime.timedelta(0)>, <Period.day_1: datetime.timedelta(days=1)>\n>>> list(Period)[-2:]\n[<Period.day_365: datetime.timedelta(days=365)>, <Period.day_366: datetime.timedel\n子类化 EnumType\n虽然大多数枚举需求可以通过自定义 Enum 子类来满足，无论是用类装饰器还是自定义函数，\nEnumType 可以被子类化以提供不同的枚举体验。 | ... def surface_gravity(self):\n... # universal gravitational constant (m3 kg-1 s-2)\n... G = 6.67300E-11\n... return G * self.mass / (self.radius * self.radius)\n...\n>>> Planet.EARTH.value\n(5.976e+24, 6378140.0)\n>>> Planet.EARTH.surface_gravity\n9.802652743337129 |  |  |\n| --- | --- | --- | --- |\n|  | TimePeriod\n一个演示如何使用 _ignore_ 属性的例子: |  |  |\n|  | >>> from datetime import timedelta\n>>> class Period(timedelta, Enum):\n... \"different lengths of time\"\n... _ignore_ = 'Period i'\n... Period = vars()\n... for i in range(367):\n... Period['day_%d' % i] = i\n...\n>>> list(Period)[:2]\n[<Period.day_0: datetime.timedelta(0)>, <Period.day_1: datetime.timedelta(days=1)>\n>>> list(Period)[-2:]\n[<Period.day_365: datetime.timedelta(days=365)>, <Period.day_366: datetime.timedel |  |  |\n|  | 子类化 EnumType\n虽然大多数枚举需求可以通过自定义 Enum 子类来满足，无论是用类装饰器还是自定义函数，\nEnumType 可以被子类化以提供不同的枚举体验。 |  |  |", "metadata": {"title": "05_Enum_指南", "source": "md_docs\\python_howto_md\\05_Enum_指南.md", "doc_type": "指南", "language": "中文", "doc_id": "26cf0d0c"}}
{"doc_id": "9550601e", "content": "函数式编程指引\n作者: A. M. Kuchling\n发布版本: 0.32\n本文档提供恰当的 Python 函数式编程范例，在函数式编程简单的介绍之后，将简单介绍Python中关\n于函数式编程的特性如 iterator 和 generator 以及相关库模块如 itertools 和 functools 等。\n概述\n本章介绍函数式编程的基本概念。如您仅想学习 Python 语言的特性，可跳过本章直接查看 迭代器.\n编程语言支持通过以下几种方式来解构具体问题：\n大多数的编程语言都是 过程式 的，所谓程序就是一连串告诉计算机怎样处理程序输入的指令。\nC、Pascal 甚至 Unix shells 都是过程式语言。\n在 声明式 语言中，你编写一个用来描述待解决问题的说明，并且这个语言的具体实现会指明怎样\n高效的进行计算。 SQL 可能是你最熟悉的声明式语言了。 一个 SQL 查询语句描述了你想要检索\n的数据集，并且 SQL 引擎会决定是扫描整张表还是使用索引，应该先执行哪些子句等等。\n面向对象 程序会操作一组对象。 对象拥有内部状态，并能够以某种方式支持请求和修改这个内部\n状态的方法。Smalltalk 和 Java 都是面向对象的语言。 C++ 和 Python 支持面向对象编程，但并\n不强制使用面向对象特性。\n函数式 编程则将一个问题分解成一系列函数。 理想情况下，函数只接受输入并输出结果，对一个\n给定的输入也不会有影响输出的内部状态。 著名的函数式语言有 ML 家族（Standard ML，Ocaml\n以及其他变种）和 Haskell。\n一些语言的设计者选择强调一种特定的编程方式。 这通常会让以不同的方式来编写程序变得困难。\n其他多范式语言则支持几种不同的编程方式。Lisp，C++ 和 Python 都是多范式语言；使用这些语\n言，你可以编写主要为过程式，面向对象或者函数式的程序和函数库。在大型程序中，不同的部分\n可能会采用不同的方式编写；比如 GUI 可能是面向对象的而处理逻辑则是过程式或者函数式。\n在函数式程序里，输入会流经一系列函数。每个函数接受输入并输出结果。函数式风格反对使用带\n有副作用的函数，这些副作用会修改内部状态，或者引起一些无法体现在函数的返回值中的变化。\n完全不产生副作用的函数被称作“纯函数”。消除副作用意味着不能使用随程序运行而更新的数据结\n构；每个函数的输出必须只依赖于输入。\n有些语言对纯洁性要求非常严格，甚至没有诸如 a=3 或 c = a + b 之类的赋值语句，但很难避免所\n有的副作用，如打印到屏幕上或写到磁盘文件之类的副作用。另一个例子是调用 print() 或\ntime.sleep() 函数，它们都没有返回一个有用的值。这两个函数被调用只是为了它们的副作用，即\n向屏幕发送一些文本或暂停执行一秒钟。\n函数式风格的 Python 程序并不会极端到消除所有 I/O 或者赋值的程度；相反，他们会提供像函数式\n一样的接口，但会在内部使用非函数式的特性。比如，函数的实现仍然会使用局部变量，但不会修\n\n| 作者: |\n| --- |\n| 发布版本: |\n\n改全局变量或者有其他副作用。\n函数式编程可以被认为是面向对象编程的对立面。对象就像是颗小胶囊，包裹着内部状态和随之而\n来的能让你修改这个内部状态的一组调用方法，以及由正确的状态变化所构成的程序。函数式编程\n希望尽可能地消除状态变化，只和流经函数的数据打交道。在 Python 里你可以把两种编程方式结合\n起来，在你的应用（电子邮件信息，事务处理）中编写接受和返回对象实例的函数。\n函数式设计在工作中看起来是个奇怪的约束。为什么你要消除对象和副作用呢？不过函数式风格有\n其理论和实践上的优点：\n形式证明。\n模块化。\n组合性。\n易于调试和测试。\n形式证明\n一个理论上的优点是，构造数学证明来说明函数式程序是正确的相对更容易些。\n很长时间，研究者们对寻找证明程序正确的数学方法都很感兴趣。这和通过大量输入来测试，并得\n出程序的输出基本正确，或者阅读一个程序的源代码然后得出代码看起来没问题不同；相反，这里\n的目标是一个严格的证明，证明程序对所有可能的输入都能给出正确的结果。\n证明程序正确性所用到的技术是写出 不变量，也就是对于输入数据和程序中的变量永远为真的特\n性。然后对每行代码，你说明这行代码执行前的不变量 X 和 Y 以及执行后稍有不同的不变量 X' 和 Y'\n为真。如此一直到程序结束，这时候在程序的输出上，不变量应该会与期望的状态一致。\n函数式编程之所以要消除赋值，是因为赋值在这个技术中难以处理；赋值可能会破坏赋值前为真的\n不变量，却并不产生任何可以传递下去的新的不变量。\n不幸的是，证明程序的正确性很大程度上是经验性质的，而且和 Python 软件无关。即使是微不足道\n的程序都需要几页长的证明；一个中等复杂的程序的正确性证明会非常庞大，而且，极少甚至没有\n你日常所使用的程序（Python 解释器，XML 解析器，浏览器）的正确性能够被证明。即使你写出或\n者生成一个证明，验证证明也会是一个问题；里面可能出了差错，而你错误地相信你证明了程序的\n正确性。\n模块化\n函数式编程的一个更实用的优点是，它强制你把问题分解成小的方面。因此程序会更加模块化。相\n对于一个进行了复杂变换的大型函数，一个小的函数更明确，更易于编写, 也更易于阅读和检查错\n误。\n易于调试和测试\n测试和调试函数式程序相对来说更容易。\n\n|  | 改全局变量或者有其他副作用。\n函数式编程可以被认为是面向对象编程的对立面。对象就像是颗小胶囊，包裹着内部状态和随之而\n来的能让你修改这个内部状态的一组调用方法，以及由正确的状态变化所构成的程序。函数式编程\n希望尽可能地消除状态变化，只和流经函数的数据打交道。在 Python 里你可以把两种编程方式结合\n起来，在你的应用（电子邮件信息，事务处理）中编写接受和返回对象实例的函数。\n函数式设计在工作中看起来是个奇怪的约束。为什么你要消除对象和副作用呢？不过函数式风格有\n其理论和实践上的优点：\n形式证明。\n模块化。\n组合性。\n易于调试和测试。\n形式证明\n一个理论上的优点是，构造数学证明来说明函数式程序是正确的相对更容易些。\n很长时间，研究者们对寻找证明程序正确的数学方法都很感兴趣。这和通过大量输入来测试，并得\n出程序的输出基本正确，或者阅读一个程序的源代码然后得出代码看起来没问题不同；相反，这里\n的目标是一个严格的证明，证明程序对所有可能的输入都能给出正确的结果。\n证明程序正确性所用到的技术是写出 不变量，也就是对于输入数据和程序中的变量永远为真的特\n性。然后对每行代码，你说明这行代码执行前的不变量 X 和 Y 以及执行后稍有不同的不变量 X' 和 Y'\n为真。如此一直到程序结束，这时候在程序的输出上，不变量应该会与期望的状态一致。\n函数式编程之所以要消除赋值，是因为赋值在这个技术中难以处理；赋值可能会破坏赋值前为真的\n不变量，却并不产生任何可以传递下去的新的不变量。\n不幸的是，证明程序的正确性很大程度上是经验性质的，而且和 Python 软件无关。即使是微不足道\n的程序都需要几页长的证明；一个中等复杂的程序的正确性证明会非常庞大，而且，极少甚至没有\n你日常所使用的程序（Python 解释器，XML 解析器，浏览器）的正确性能够被证明。即使你写出或\n者生成一个证明，验证证明也会是一个问题；里面可能出了差错，而你错误地相信你证明了程序的\n正确性。\n模块化\n函数式编程的一个更实用的优点是，它强制你把问题分解成小的方面。因此程序会更加模块化。相\n对于一个进行了复杂变换的大型函数，一个小的函数更明确，更易于编写, 也更易于阅读和检查错\n误。\n易于调试和测试\n测试和调试函数式程序相对来说更容易。 |  |\n| --- | --- | --- |\n\n调试很简单是因为函数通常都很小而且清晰明确。当程序无法工作的时候，每个函数都是一个可以\n检查数据是否正确的接入点。你可以通过查看中间输入和输出迅速找到出错的函数。\n测试更容易是因为每个函数都是单元测试的潜在目标。在执行测试前，函数并不依赖于需要重现的\n系统状态；相反，你只需要给出正确的输入，然后检查输出是否和期望的结果一致。\n组合性\n当你编写函数式风格的程序时，你会写出很多带有不同输入和输出的函数。其中一些不可避免地会\n局限于特定的应用，但其他的却可以广泛的用在程序中。举例来说，一个接受文件夹目录返回所有\n文件夹中的 XML 文件的函数； 或是一个接受文件名，然后返回文件内容的函数，都可以应用在很多\n不同的场合。\n久而久之你会形成一个个人工具库。通常你可以重新组织已有的函数来组成新的程序，然后为当前\n的工作写一些特殊的函数。\n迭代器\n我会从 Python 的一个语言特性， 编写函数式风格程序的重要基石开始说起：迭代器。\n迭代器是一个表示数据流的对象；这个对象每次只返回一个元素。Python 迭代器必须支持\n__next__() 方法；这个方法不接受参数，并总是返回数据流中的下一个元素。如果数据流中没有元\n素，__next__() 会抛出 StopIteration 异常。迭代器未必是有限的；完全有理由构造一个输出无\n限数据流的迭代器。\n内置的 iter() 函数接受任意对象并试图返回一个迭代器来输出对象的内容或元素，并会在对象不\n支持迭代的时候抛出 TypeError 异常。Python 有几种内置数据类型支持迭代，最常见的就是列表和\n字典。如果一个对象能生成迭代器，那么它就会被称作 iterable。\n你可以手动试验迭代器的接口。\n>>> L = [1, 2, 3]\n>>> it = iter(L)\n>>> it\n<...iterator object at ...>\n>>> it.__next__() # same as next(it)\n1\n>>> next(it)\n2\n>>> next(it)\n3\n>>> next(it)\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nStopIteration\n>>>\nPython 有不少要求使用可迭代的对象的地方，其中最重要的就是 for 表达式。在表达式 for X in\nY，Y 要么自身是一个迭代器，要么能够由 iter() 创建一个迭代器。以下两种表达是等价的:\nfor i in iter(obj):\nprint(i)\n\n|  |  | 调试很简单是因为函数通常都很小而且清晰明确。当程序无法工作的时候，每个函数都是一个可以\n检查数据是否正确的接入点。你可以通过查看中间输入和输出迅速找到出错的函数。\n测试更容易是因为每个函数都是单元测试的潜在目标。在执行测试前，函数并不依赖于需要重现的\n系统状态；相反，你只需要给出正确的输入，然后检查输出是否和期望的结果一致。\n组合性\n当你编写函数式风格的程序时，你会写出很多带有不同输入和输出的函数。其中一些不可避免地会\n局限于特定的应用，但其他的却可以广泛的用在程序中。举例来说，一个接受文件夹目录返回所有\n文件夹中的 XML 文件的函数； 或是一个接受文件名，然后返回文件内容的函数，都可以应用在很多\n不同的场合。\n久而久之你会形成一个个人工具库。通常你可以重新组织已有的函数来组成新的程序，然后为当前\n的工作写一些特殊的函数。\n迭代器\n我会从 Python 的一个语言特性， 编写函数式风格程序的重要基石开始说起：迭代器。\n迭代器是一个表示数据流的对象；这个对象每次只返回一个元素。Python 迭代器必须支持\n__next__() 方法；这个方法不接受参数，并总是返回数据流中的下一个元素。如果数据流中没有元\n素，__next__() 会抛出 StopIteration 异常。迭代器未必是有限的；完全有理由构造一个输出无\n限数据流的迭代器。\n内置的 iter() 函数接受任意对象并试图返回一个迭代器来输出对象的内容或元素，并会在对象不\n支持迭代的时候抛出 TypeError 异常。Python 有几种内置数据类型支持迭代，最常见的就是列表和\n字典。如果一个对象能生成迭代器，那么它就会被称作 iterable。\n你可以手动试验迭代器的接口。 |  |\n| --- | --- | --- | --- |\n|  |  | >>> L = [1, 2, 3]\n>>> it = iter(L)\n>>> it\n<...iterator object at ...>\n>>> it.__next__() # same as next(it)\n1\n>>> next(it)\n2\n>>> next(it)\n3\n>>> next(it)\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nStopIteration\n>>> |  |\n|  |  | Python 有不少要求使用可迭代的对象的地方，其中最重要的就是 for 表达式。在表达式 for X in\nY，Y 要么自身是一个迭代器，要么能够由 iter() 创建一个迭代器。以下两种表达是等价的: |  |\n|  |  | Y |  |\n|  |  |  |  |\n|  |  | for i in iter(obj):\nprint(i) |  |\n\nfor i in obj:\nprint(i)\n可以用 list() 或 tuple() 这样的构造函数把迭代器具体化成列表或元组:\n>>> L = [1, 2, 3]\n>>> iterator = iter(L)\n>>> t = tuple(iterator)\n>>> t\n(1, 2, 3)\n序列的解压操作也支持迭代器：如果你知道一个迭代器能够返回 N 个元素，你可以把他们解压到有\nN 个元素的元组:\n>>> L = [1, 2, 3]\n>>> iterator = iter(L)\n>>> a, b, c = iterator\n>>> a, b, c\n(1, 2, 3)\n像 max() 和 min() 这样的内置函数可以接受单个迭代器参数，然后返回其中最大或者最小的元素。\n\"in\" 和 \"not in\" 操作也支持迭代器：如果能够在迭代器 iterator 返回的数据流中找到 X 的话，则\nX in iterator 为真。很显然，如果迭代器是无限的，这么做你就会遇到问题；max() 和 min() 永\n远也不会返回；如果元素 X 也不出现在数据流中， \"in\" 和 \"not in\" 操作同样也永远不会返回。\n注意你只能在迭代器中顺序前进；没有获取前一个元素的方法，除非重置迭代器，或者重新复制一\n份。迭代器对象可以提供这些额外的功能，但迭代器协议只明确了 __next__() 方法。函数可能因\n此而耗尽迭代器的输出，如果你要对同样的数据流做不同的操作，你必须重新创建一个迭代器。\n支持迭代器的数据类型\n我们已经知道列表和元组支持迭代器。实际上，Python 中的任何序列类型，比如字符串，都自动支\n持创建迭代器。\n对字典调用 iter() 会返回一个遍历字典的键的迭代器:\n>>> m = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n... 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n>>> for key in m:\n... print(key, m[key])\nJan 1\nFeb 2\nMar 3\nApr 4\nMay 5\nJun 6\nJul 7\nAug 8\nSep 9\nOct 10\n\n|  | for i in obj:\nprint(i) |  |\n| --- | --- | --- |\n|  | 可以用 list() 或 tuple() 这样的构造函数把迭代器具体化成列表或元组: |  |\n|  | >>> L = [1, 2, 3]\n>>> iterator = iter(L)\n>>> t = tuple(iterator)\n>>> t\n(1, 2, 3) |  |\n|  | 序列的解压操作也支持迭代器：如果你知道一个迭代器能够返回 N 个元素，你可以把他们解压到有\nN 个元素的元组: |  |\n|  | >>> L = [1, 2, 3]\n>>> iterator = iter(L)\n>>> a, b, c = iterator\n>>> a, b, c\n(1, 2, 3) |  |\n|  | 像 max() 和 min() 这样的内置函数可以接受单个迭代器参数，然后返回其中最大或者最小的元素。\n\"in\" 和 \"not in\" 操作也支持迭代器：如果能够在迭代器 iterator 返回的数据流中找到 X 的话，则\nX in iterator 为真。很显然，如果迭代器是无限的，这么做你就会遇到问题；max() 和 min() 永\n远也不会返回；如果元素 X 也不出现在数据流中， \"in\" 和 \"not in\" 操作同样也永远不会返回。\n注意你只能在迭代器中顺序前进；没有获取前一个元素的方法，除非重置迭代器，或者重新复制一\n份。迭代器对象可以提供这些额外的功能，但迭代器协议只明确了 __next__() 方法。函数可能因\n此而耗尽迭代器的输出，如果你要对同样的数据流做不同的操作，你必须重新创建一个迭代器。\n支持迭代器的数据类型\n我们已经知道列表和元组支持迭代器。实际上，Python 中的任何序列类型，比如字符串，都自动支\n持创建迭代器。\n对字典调用 iter() 会返回一个遍历字典的键的迭代器: |  |\n|  | >>> m = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n... 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n>>> for key in m:\n... print(key, m[key])\nJan 1\nFeb 2\nMar 3\nApr 4\nMay 5\nJun 6\nJul 7\nAug 8\nSep 9\nOct 10 |  |\n\nNov 11\nDec 12\n注意从 Python 3.7 开始，字典的遍历顺序一定和输入顺序一样。先前的版本并没有明确这一点，所\n以不同的实现可能不一致。\n对字典使用 iter() 总是会遍历键，但字典也有返回其他迭代器的方法。如果你只遍历值或者键/值\n对，你可以明确地调用 values() 或 items() 方法得到合适的迭代器。\ndict() 构造函数可以接受一个迭代器，然后返回一个有限的 (key, value) 元组的数据流:\n>>> L = [('Italy', 'Rome'), ('France', 'Paris'), ('US', 'Washington DC')]\n>>> dict(iter(L))\n{'Italy': 'Rome', 'France': 'Paris', 'US': 'Washington DC'}\n文件也可以通过调用 readline() 来遍历，直到穷尽文件中所有的行。这意味着你可以像这样读取\n文件中的每一行:\nfor line in file:\n# 对每一行执行某些操作\n...\n集合可以从可遍历的对象获取内容，也可以让你遍历集合的元素:\n>>> S = {2, 3, 5, 7, 11, 13}\n>>> for i in S:\n... print(i)\n2\n3\n5\n7\n11\n13\n生成器表达式和列表推导式\n迭代器的输出有两个很常见的使用方式，1) 对每一个元素执行操作，2) 选择一个符合条件的元素子\n集。比如，给定一个字符串列表，你可能想去掉每个字符串尾部的空白字符，或是选出所有包含给\n定子串的字符串。\n列表推导式和生成器表达式 (简写: \"listcomp\" 和 \"genexp\") 让这些操作更加简明，这个形式借鉴自函\n数式编程语言 Haskell (https://www.haskell.org/)。 你可以用以下代码去掉一个字符串流中的所有空\n白符:\n>>> line_list = [' line 1\\n', 'line 2 \\n', ' \\n', '']\n>>> # 生成器表达式 -- 返回迭代器\n>>> stripped_iter = (line.strip() for line in line_list)\n>>> # 列表推导式 -- 返回列表\n>>> stripped_list = [line.strip() for line in line_list]\n\n|  | Nov 11\nDec 12 |  |\n| --- | --- | --- |\n|  | 注意从 Python 3.7 开始，字典的遍历顺序一定和输入顺序一样。先前的版本并没有明确这一点，所\n以不同的实现可能不一致。\n对字典使用 iter() 总是会遍历键，但字典也有返回其他迭代器的方法。如果你只遍历值或者键/值\n对，你可以明确地调用 values() 或 items() 方法得到合适的迭代器。\ndict() 构造函数可以接受一个迭代器，然后返回一个有限的 (key, value) 元组的数据流: |  |\n|  | >>> L = [('Italy', 'Rome'), ('France', 'Paris'), ('US', 'Washington DC')]\n>>> dict(iter(L))\n{'Italy': 'Rome', 'France': 'Paris', 'US': 'Washington DC'} |  |\n|  | 文件也可以通过调用 readline() 来遍历，直到穷尽文件中所有的行。这意味着你可以像这样读取\n文件中的每一行: |  |\n|  | for line in file:\n# 对每一行执行某些操作\n... |  |\n|  | 集合可以从可遍历的对象获取内容，也可以让你遍历集合的元素: |  |\n|  | >>> S = {2, 3, 5, 7, 11, 13}\n>>> for i in S:\n... print(i)\n2\n3\n5\n7\n11\n13 |  |\n|  | 生成器表达式和列表推导式\n迭代器的输出有两个很常见的使用方式，1) 对每一个元素执行操作，2) 选择一个符合条件的元素子\n集。比如，给定一个字符串列表，你可能想去掉每个字符串尾部的空白字符，或是选出所有包含给\n定子串的字符串。\n列表推导式和生成器表达式 (简写: \"listcomp\" 和 \"genexp\") 让这些操作更加简明，这个形式借鉴自函\n数式编程语言 Haskell (https://www.haskell.org/)。 你可以用以下代码去掉一个字符串流中的所有空\n白符: |  |\n|  | >>> line_list = [' line 1\\n', 'line 2 \\n', ' \\n', '']\n>>> # 生成器表达式 -- 返回迭代器\n>>> stripped_iter = (line.strip() for line in line_list)\n>>> # 列表推导式 -- 返回列表\n>>> stripped_list = [line.strip() for line in line_list] |  |\n|  |  |  |\n\n你可以加上条件语句 \"if\" 来选取特定的元素:\n>>> stripped_list = [line.strip() for line in line_list\n... if line != \"\"]\n通过列表推导式，你会获得一个 Python 列表；stripped_list 就是一个包含所有结果行的列表，\n并不是迭代器。 生成器表达式会返回一个迭代器，它在必要的时候计算结果，避免一次性生成所有\n的值。 这意味着，如果迭代器返回一个无限数据流或者大量的数据，列表推导式就不太好用了。 这\n种情况下生成器表达式会更受青睐。\n生成器表达式两边使用圆括号 (\"()\") ，而列表推导式则使用方括号 (\"[]\")。生成器表达式的形式为:\n( expression for expr in sequence1\nif condition1\nfor expr2 in sequence2\nif condition2\nfor expr3 in sequence3\n...\nif condition3\nfor exprN in sequenceN\nif conditionN )\n再次说明，列表推导式只有两边的括号不一样（方括号而不是圆括号）。\n这些生成用于输出的元素会成为 expression 的后继值。其中 if 语句是可选的；如果给定的话\nexpression 只会在符合条件时计算并加入到结果中。\n生成器表达式总是写在圆括号里面，不过也可以算上调用函数时用的括号。如果你想即时创建一个\n传递给函数的迭代器，可以这么写:\nobj_total = sum(obj.count for obj in list_all_objects())\n其中 for...in 语句包含了将要遍历的序列。这些序列并不必须同样长，因为它们会从左往右开始\n遍历，而 不是 同时执行。对每个 sequence1 中的元素，sequence2 会从头开始遍历。sequence3\n会对每个 sequence1 和 sequence2 的元素对开始遍历。\n换句话说，列表推导式器是和下面的 Python 代码等价:\nfor expr1 in sequence1:\nif not (condition1):\ncontinue # 跳过此元素\nfor expr2 in sequence2:\nif not (condition2):\ncontinue # 跳过此元素\n...\nfor exprN in sequenceN:\nif not (conditionN):\ncontinue # 跳过此元素\n# 输出表达式的值。\n\n|  | 你可以加上条件语句 \"if\" 来选取特定的元素: |  |\n| --- | --- | --- |\n|  | >>> stripped_list = [line.strip() for line in line_list\n... if line != \"\"] |  |\n|  | 通过列表推导式，你会获得一个 Python 列表；stripped_list 就是一个包含所有结果行的列表，\n并不是迭代器。 生成器表达式会返回一个迭代器，它在必要的时候计算结果，避免一次性生成所有\n的值。 这意味着，如果迭代器返回一个无限数据流或者大量的数据，列表推导式就不太好用了。 这\n种情况下生成器表达式会更受青睐。\n生成器表达式两边使用圆括号 (\"()\") ，而列表推导式则使用方括号 (\"[]\")。生成器表达式的形式为: |  |\n|  | ( expression for expr in sequence1\nif condition1\nfor expr2 in sequence2\nif condition2\nfor expr3 in sequence3\n...\nif condition3\nfor exprN in sequenceN\nif conditionN ) |  |\n|  | 再次说明，列表推导式只有两边的括号不一样（方括号而不是圆括号）。\n这些生成用于输出的元素会成为 expression 的后继值。其中 if 语句是可选的；如果给定的话\nexpression 只会在符合条件时计算并加入到结果中。\n生成器表达式总是写在圆括号里面，不过也可以算上调用函数时用的括号。如果你想即时创建一个\n传递给函数的迭代器，可以这么写: |  |\n|  | obj_total = sum(obj.count for obj in list_all_objects()) |  |\n|  | 其中 for...in 语句包含了将要遍历的序列。这些序列并不必须同样长，因为它们会从左往右开始\n遍历，而 不是 同时执行。对每个 sequence1 中的元素，sequence2 会从头开始遍历。sequence3\n会对每个 sequence1 和 sequence2 的元素对开始遍历。\n换句话说，列表推导式器是和下面的 Python 代码等价: |  |\n|  | for expr1 in sequence1:\nif not (condition1):\ncontinue # 跳过此元素\nfor expr2 in sequence2:\nif not (condition2):\ncontinue # 跳过此元素\n...\nfor exprN in sequenceN:\nif not (conditionN):\ncontinue # 跳过此元素\n# 输出表达式的值。 |  |\n|  |  |  |\n\n这说明，如果有多个 for...in 语句而没有 if 语句，输出结果的长度就是所有序列长度的乘积。如\n果你的两个列表长度为3，那么输出的列表长度就是9:\n>>> seq1 = 'abc'\n>>> seq2 = (1, 2, 3)\n>>> [(x, y) for x in seq1 for y in seq2]\n[('a', 1), ('a', 2), ('a', 3),\n('b', 1), ('b', 2), ('b', 3),\n('c', 1), ('c', 2), ('c', 3)]\n为了不让 Python 语法变得含糊，如果 expression 会生成元组，那这个元组必须要用括号括起来。\n下面第一个列表推导式语法错误，第二个则是正确的:\n# 语法错误\n[x, y for x in seq1 for y in seq2]\n# 正确\n[(x, y) for x in seq1 for y in seq2]\n生成器\n生成器是一类用来简化编写迭代器工作的特殊函数。普通的函数计算并返回一个值，而生成器返回\n一个能返回数据流的迭代器。\n毫无疑问，你已经对如何在 Python 和 C 中调用普通函数很熟悉了，这时候函数会获得一个创建局部\n变量的私有命名空间。当函数到达 return 表达式时，局部变量会被销毁然后把返回给调用者。之\n后调用同样的函数时会创建一个新的私有命名空间和一组全新的局部变量。但是，如果在退出一个\n函数时不扔掉局部变量会如何呢？如果稍后你能够从退出函数的地方重新恢复又如何呢？这就是生\n成器所提供的；他们可以被看成可恢复的函数。\n这里有简单的生成器函数示例:\n>>> def generate_ints(N):\n... for i in range(N):\n... yield i\n任何包含了 yield 关键字的函数都是生成器函数；Python 的 bytecode 编译器会在编译的时候检测\n到并因此而特殊处理。\n当你调用一个生成器函数，它并不会返回单独的值，而是返回一个支持生成器协议的生成器对象。\n当执行 yield 表达式时，生成器会输出 i 的值，就像 return 表达式一样。yield 和 return 最大\n的区别在于，到达 yield 的时候生成器的执行状态会挂起并保留局部变量。在下一次调用生成器\n__next__() 方法的时候，函数会恢复执行。\n这里有一个 generate_ints() 生成器的示例:\n>>> gen = generate_ints(3)\n>>> gen\n<generator object generate_ints at ...>\n>>> next(gen)\n0\n>>> next(gen)\n\n|  | 这说明，如果有多个 for...in 语句而没有 if 语句，输出结果的长度就是所有序列长度的乘积。如\n果你的两个列表长度为3，那么输出的列表长度就是9: |  |\n| --- | --- | --- |\n|  | >>> seq1 = 'abc'\n>>> seq2 = (1, 2, 3)\n>>> [(x, y) for x in seq1 for y in seq2]\n[('a', 1), ('a', 2), ('a', 3),\n('b', 1), ('b', 2), ('b', 3),\n('c', 1), ('c', 2), ('c', 3)] |  |\n|  | 为了不让 Python 语法变得含糊，如果 expression 会生成元组，那这个元组必须要用括号括起来。\n下面第一个列表推导式语法错误，第二个则是正确的: |  |\n|  | # 语法错误\n[x, y for x in seq1 for y in seq2]\n# 正确\n[(x, y) for x in seq1 for y in seq2] |  |\n|  | 生成器\n生成器是一类用来简化编写迭代器工作的特殊函数。普通的函数计算并返回一个值，而生成器返回\n一个能返回数据流的迭代器。\n毫无疑问，你已经对如何在 Python 和 C 中调用普通函数很熟悉了，这时候函数会获得一个创建局部\n变量的私有命名空间。当函数到达 return 表达式时，局部变量会被销毁然后把返回给调用者。之\n后调用同样的函数时会创建一个新的私有命名空间和一组全新的局部变量。但是，如果在退出一个\n函数时不扔掉局部变量会如何呢？如果稍后你能够从退出函数的地方重新恢复又如何呢？这就是生\n成器所提供的；他们可以被看成可恢复的函数。\n这里有简单的生成器函数示例: |  |\n|  | >>> def generate_ints(N):\n... for i in range(N):\n... yield i |  |\n|  | 任何包含了 yield 关键字的函数都是生成器函数；Python 的 bytecode 编译器会在编译的时候检测\n到并因此而特殊处理。\n当你调用一个生成器函数，它并不会返回单独的值，而是返回一个支持生成器协议的生成器对象。\n当执行 yield 表达式时，生成器会输出 i 的值，就像 return 表达式一样。yield 和 return 最大\n的区别在于，到达 yield 的时候生成器的执行状态会挂起并保留局部变量。在下一次调用生成器\n__next__() 方法的时候，函数会恢复执行。\n这里有一个 generate_ints() 生成器的示例: |  |\n|  | >>> gen = generate_ints(3)\n>>> gen\n<generator object generate_ints at ...>\n>>> next(gen)\n0\n>>> next(gen) |  |\n\n1\n>>> next(gen)\n2\n>>> next(gen)\nTraceback (most recent call last):\nFile \"stdin\", line 1, in <module>\nFile \"stdin\", line 2, in generate_ints\nStopIteration\n同样，你可以写出 for i in generate_ints(5)，或者 a, b, c = generate_ints(3)。\n在生成器函数里面，return value 会触发从 __next__() 方法抛出 StopIteration(value) 异\n常。一旦抛出这个异常，或者函数结束，处理数据的过程就会停止，生成器也不会再生成新的值。\n你可以手动编写自己的类来达到生成器的效果，把生成器的所有局部变量作为实例的成员变量存储\n起来。 比如，可以这么返回一个整数列表：把 self.count 设为0，然后通过 __next__() 方法增加\n并返回 self.count。 然而，对于一个中等复杂程度的生成器，写出一个相应的类可能会相当繁\n杂。\n包含在 Python 库中的测试套件 Lib/test/test_generators.py 里有很多非常有趣的例子。这里是一个\n用生成器实现树的递归中序遍历示例。:\n# 一个按内部顺序生成 Tree 叶子节点的递归生成器。\ndef inorder(t):\nif t:\nfor x in inorder(t.left):\nyield x\nyield t.label\nfor x in inorder(t.right):\nyield x\n另外两个 test_generators.py 中的例子给出了 N 皇后问题（在 NxN 的棋盘上放置 N 个皇后，任\n何一个都不能吃掉另一个），以及马的遍历路线（在NxN 的棋盘上给马找出一条不重复的走过所有\n格子的路线）的解。\n向生成器传递值\n在 Python 2.4 及之前的版本中，生成器只产生输出。一旦调用生成器的代码创建一个迭代器，就没\n有办法在函数恢复执行的时候向它传递新的信息。你可以设法实现这个功能，让生成器引用一个全\n局变量或者一个调用者可以修改的可变对象，但是这些方法都很繁杂。\n在 Python 2.5 里有一个简单的将值传递给生成器的方法。yield 变成了一个表达式，返回一个可以\n赋给变量或执行操作的值:\nval = (yield i)\n我建议你在处理 yield 表达式返回值的时候， 总是 两边写上括号，就像上面的例子一样。括号并\n不总是必须的，但是比起记住什么时候需要括号，写出来会更容易一点。\n\n|  | 1\n>>> next(gen)\n2\n>>> next(gen)\nTraceback (most recent call last):\nFile \"stdin\", line 1, in <module>\nFile \"stdin\", line 2, in generate_ints\nStopIteration |  |\n| --- | --- | --- |\n|  | 同样，你可以写出 for i in generate_ints(5)，或者 a, b, c = generate_ints(3)。\n在生成器函数里面，return value 会触发从 __next__() 方法抛出 StopIteration(value) 异\n常。一旦抛出这个异常，或者函数结束，处理数据的过程就会停止，生成器也不会再生成新的值。\n你可以手动编写自己的类来达到生成器的效果，把生成器的所有局部变量作为实例的成员变量存储\n起来。 比如，可以这么返回一个整数列表：把 self.count 设为0，然后通过 __next__() 方法增加\n并返回 self.count。 然而，对于一个中等复杂程度的生成器，写出一个相应的类可能会相当繁\n杂。\n包含在 Python 库中的测试套件 Lib/test/test_generators.py 里有很多非常有趣的例子。这里是一个\n用生成器实现树的递归中序遍历示例。: |  |\n|  | # 一个按内部顺序生成 Tree 叶子节点的递归生成器。\ndef inorder(t):\nif t:\nfor x in inorder(t.left):\nyield x\nyield t.label\nfor x in inorder(t.right):\nyield x |  |\n|  | 另外两个 test_generators.py 中的例子给出了 N 皇后问题（在 NxN 的棋盘上放置 N 个皇后，任\n何一个都不能吃掉另一个），以及马的遍历路线（在NxN 的棋盘上给马找出一条不重复的走过所有\n格子的路线）的解。\n向生成器传递值\n在 Python 2.4 及之前的版本中，生成器只产生输出。一旦调用生成器的代码创建一个迭代器，就没\n有办法在函数恢复执行的时候向它传递新的信息。你可以设法实现这个功能，让生成器引用一个全\n局变量或者一个调用者可以修改的可变对象，但是这些方法都很繁杂。\n在 Python 2.5 里有一个简单的将值传递给生成器的方法。yield 变成了一个表达式，返回一个可以\n赋给变量或执行操作的值: |  |\n|  | val = (yield i) |  |\n|  | 我建议你在处理 yield 表达式返回值的时候， 总是 两边写上括号，就像上面的例子一样。括号并\n不总是必须的，但是比起记住什么时候需要括号，写出来会更容易一点。 |  |\n\n（PEP 342 解释了具体的规则，也就是 yield 表达式必须括起来，除非是出现在最顶级的赋值表达\n式的右边。这意味着你可以写 val = yield i，但是必须在操作的时候加上括号，就像 val =\n(yield i) + 12）\n可以调用 send(value)() <generator.send> 方法向生成器发送值。这个方法会恢复执行生成器的\n代码，然后 yield 表达式返回特定的值。 如果调用普通的 __next__() 方法，yield 会返回\nNone。\n这里有一个简单的每次加1的计数器，并允许改变内部计数器的值。\ndef counter(maximum):\ni = 0\nwhile i < maximum:\nval = (yield i)\n# 如果提供了值，则改变计数器\nif val is not None:\ni = val\nelse:\ni += 1\n这是改变计数器的一个示例\n>>> it = counter(10)\n>>> next(it)\n0\n>>> next(it)\n1\n>>> it.send(8)\n8\n>>> next(it)\n9\n>>> next(it)\nTraceback (most recent call last):\nFile \"t.py\", line 15, in <module>\nit.next()\nStopIteration\n因为 yield 很多时候会返回 None，所以你应该总是检查这个情况。不要在表达式中使用 yield 的\n值，除非你确定 send() 是唯一的用来恢复你的生成器函数的方法。\n除了 send() 之外，生成器还有两个其他的方法:\nthrow(value) 用于在生成器内部抛出异常；这个异常会在生成器暂停执行的时候由 yield 表达\n式抛出。\nclose() 会向生成器发送一个 GeneratorExit 异常来终结迭代。 当接收到此异常时，生成器的\n代码必须引发 GeneratorExit 或者 StopIteration；捕获此异常并作任何其他操作都是非法的\n并会触发 RuntimeError。 close() 还会在生成器被作为垃圾回收时由 Python 的垃圾回收器调\n用。\n如果你要在 GeneratorExit 发生的时候清理代码，我建议使用 try: ... finally: 组合来代替\nGeneratorExit。\n\n|  |  | （PEP 342 解释了具体的规则，也就是 yield 表达式必须括起来，除非是出现在最顶级的赋值表达\n式的右边。这意味着你可以写 val = yield i，但是必须在操作的时候加上括号，就像 val =\n(yield i) + 12）\n可以调用 send(value)() <generator.send> 方法向生成器发送值。这个方法会恢复执行生成器的\n代码，然后 yield 表达式返回特定的值。 如果调用普通的 __next__() 方法，yield 会返回\nNone。\n这里有一个简单的每次加1的计数器，并允许改变内部计数器的值。 |  |  |  |\n| --- | --- | --- | --- | --- | --- |\n|  |  |  | val = |  |  |\n|  |  |  |  |  |  |\n|  |  | (yield i) + 12 |  |  |  |\n|  |  |  |  |  |  |\n|  |  | def counter(maximum):\ni = 0\nwhile i < maximum:\nval = (yield i)\n# 如果提供了值，则改变计数器\nif val is not None:\ni = val\nelse:\ni += 1 |  |  |  |\n|  |  | 这是改变计数器的一个示例 |  |  |  |\n|  |  | >>> it = counter(10)\n>>> next(it)\n0\n>>> next(it)\n1\n>>> it.send(8)\n8\n>>> next(it)\n9\n>>> next(it)\nTraceback (most recent call last):\nFile \"t.py\", line 15, in <module>\nit.next()\nStopIteration |  |  |  |\n|  |  | 因为 yield 很多时候会返回 None，所以你应该总是检查这个情况。不要在表达式中使用 yield 的\n值，除非你确定 send() 是唯一的用来恢复你的生成器函数的方法。\n除了 send() 之外，生成器还有两个其他的方法:\nthrow(value) 用于在生成器内部抛出异常；这个异常会在生成器暂停执行的时候由 yield 表达\n式抛出。\nclose() 会向生成器发送一个 GeneratorExit 异常来终结迭代。 当接收到此异常时，生成器的\n代码必须引发 GeneratorExit 或者 StopIteration；捕获此异常并作任何其他操作都是非法的\n并会触发 RuntimeError。 close() 还会在生成器被作为垃圾回收时由 Python 的垃圾回收器调\n用。\n如果你要在 GeneratorExit 发生的时候清理代码，我建议使用 try: ... finally: 组合来代替\nGeneratorExit。 |  |  |  |\n\n这些改变的累积效应是，让生成器从单向的信息生产者变成了既是生产者，又是消费者。\n生成器也可以成为 协程 ，一种更广义的子过程形式。子过程可以从一个地方进入，然后从另一个地\n方退出（从函数的顶端进入，从 return 语句退出），而协程可以进入，退出，然后在很多不同的\n地方恢复（yield 语句）。\n内置函数\n我们可以看看迭代器常常用到的函数的更多细节。\nPython 内置的两个函数 map() 和 filter() 复制了生成器表达式的两个特性:\nmap(f, iterA, iterB, ...) 返回一个遍历序列的迭代器\nf(iterA[0], iterB[0]), f(iterA[1], iterB[1]), f(iterA[2], iterB[2]), ....\n>>> def upper(s):\n... return s.upper()\n>>> list(map(upper, ['sentence', 'fragment']))\n['SENTENCE', 'FRAGMENT']\n>>> [upper(s) for s in ['sentence', 'fragment']]\n['SENTENCE', 'FRAGMENT']\n你当然也可以用列表推导式达到同样的效果。\nfilter(predicate, iter) 返回一个遍历序列中满足指定条件的元素的迭代器，和列表推导式的功\n能相似。 predicate （谓词）是一个在特定条件下返回真值的函数；要使用函数 filter()，谓词函\n数必须只能接受一个参数。\n>>> def is_even(x):\n... return (x % 2) == 0\n>>> list(filter(is_even, range(10)))\n[0, 2, 4, 6, 8]\n这也可以写成列表推导式:\n>>> list(x for x in range(10) if is_even(x))\n[0, 2, 4, 6, 8]\nenumerate(iter, start=0) 计数可迭代对象中的元素，然后返回包含每个计数（从 start 开始）\n和元素两个值的元组。:\n>>> for item in enumerate(['subject', 'verb', 'object']):\n... print(item)\n(0, 'subject')\n(1, 'verb')\n(2, 'object')\nenumerate() 常常用于遍历列表并记录达到特定条件时的下标:\n\n|  | 这些改变的累积效应是，让生成器从单向的信息生产者变成了既是生产者，又是消费者。\n生成器也可以成为 协程 ，一种更广义的子过程形式。子过程可以从一个地方进入，然后从另一个地\n方退出（从函数的顶端进入，从 return 语句退出），而协程可以进入，退出，然后在很多不同的\n地方恢复（yield 语句）。\n内置函数\n我们可以看看迭代器常常用到的函数的更多细节。\nPython 内置的两个函数 map() 和 filter() 复制了生成器表达式的两个特性:\nmap(f, iterA, iterB, ...) 返回一个遍历序列的迭代器\nf(iterA[0], iterB[0]), f(iterA[1], iterB[1]), f(iterA[2], iterB[2]), ....\n>>> def upper(s):\n... return s.upper()\n>>> list(map(upper, ['sentence', 'fragment']))\n['SENTENCE', 'FRAGMENT']\n>>> [upper(s) for s in ['sentence', 'fragment']]\n['SENTENCE', 'FRAGMENT']\n你当然也可以用列表推导式达到同样的效果。\nfilter(predicate, iter) 返回一个遍历序列中满足指定条件的元素的迭代器，和列表推导式的功\n能相似。 predicate （谓词）是一个在特定条件下返回真值的函数；要使用函数 filter()，谓词函\n数必须只能接受一个参数。 |  |\n| --- | --- | --- |\n|  | >>> def is_even(x):\n... return (x % 2) == 0 |  |\n|  |  |  |\n|  | >>> list(filter(is_even, range(10)))\n[0, 2, 4, 6, 8] |  |\n|  | 这也可以写成列表推导式: |  |\n|  | >>> list(x for x in range(10) if is_even(x))\n[0, 2, 4, 6, 8] |  |\n|  | enumerate(iter, start=0) 计数可迭代对象中的元素，然后返回包含每个计数（从 start 开始）\n和元素两个值的元组。: |  |\n|  | >>> for item in enumerate(['subject', 'verb', 'object']):\n... print(item)\n(0, 'subject')\n(1, 'verb')\n(2, 'object') |  |\n|  | enumerate() 常常用于遍历列表并记录达到特定条件时的下标: |  |\n\nf = open('data.txt', 'r')\nfor i, line in enumerate(f):\nif line.strip() == '':\nprint('Blank line at line #%i' % i)\nsorted(iterable, key=None, reverse=False) 会将 iterable 中的元素收集到一个列表中，然后\n排序并返回结果。其中 key 和 reverse 参数会传递给所创建列表的 sort() 方法。:\n>>> import random\n>>> # Generate 8 random numbers between [0, 10000)\n>>> rand_list = random.sample(range(10000), 8)\n>>> rand_list\n[769, 7953, 9828, 6431, 8442, 9878, 6213, 2207]\n>>> sorted(rand_list)\n[769, 2207, 6213, 6431, 7953, 8442, 9828, 9878]\n>>> sorted(rand_list, reverse=True)\n[9878, 9828, 8442, 7953, 6431, 6213, 2207, 769]\n（对排序更详细的讨论可参见 排序的技术。）\n内置函数 any(iter) 和 all(iter) 会查看一个可迭代对象内容的逻辑值。any() 在可迭代对象中\n任意一个元素为真时返回 True，而 all() 在所有元素为真时返回 True:\n>>> any([0, 1, 0])\nTrue\n>>> any([0, 0, 0])\nFalse\n>>> any([1, 1, 1])\nTrue\n>>> all([0, 1, 0])\nFalse\n>>> all([0, 0, 0])\nFalse\n>>> all([1, 1, 1])\nTrue\nzip(iterA, iterB, ...) 从每个可迭代对象中选取单个元素组成列表并返回:\nzip(['a', 'b', 'c'], (1, 2, 3)) =>\n('a', 1), ('b', 2), ('c', 3)\n它并不会在内存创建一个列表并因此在返回前而耗尽输入的迭代器；相反，只有在被请求的时候元\n组才会创建并返回。（这种行为的技术术语叫惰性计算，参见 lazy evaluation.）\n这个迭代器设计用于长度相同的可迭代对象。如果可迭代对象的长度不一致，返回的数据流的长度\n会和最短的可迭代对象相同\nzip(['a', 'b'], (1, 2, 3)) =>\n('a', 1), ('b', 2)\n然而，你应该避免这种情况，因为所有从更长的迭代器中取出的元素都会被丢弃。这意味着之后你\n也无法冒着跳过被丢弃元素的风险来继续使用这个迭代器。\n\n|  | f = open('data.txt', 'r')\nfor i, line in enumerate(f):\nif line.strip() == '':\nprint('Blank line at line #%i' % i) |  |\n| --- | --- | --- |\n|  | sorted(iterable, key=None, reverse=False) 会将 iterable 中的元素收集到一个列表中，然后\n排序并返回结果。其中 key 和 reverse 参数会传递给所创建列表的 sort() 方法。: |  |\n|  | >>> import random\n>>> # Generate 8 random numbers between [0, 10000)\n>>> rand_list = random.sample(range(10000), 8)\n>>> rand_list\n[769, 7953, 9828, 6431, 8442, 9878, 6213, 2207]\n>>> sorted(rand_list)\n[769, 2207, 6213, 6431, 7953, 8442, 9828, 9878]\n>>> sorted(rand_list, reverse=True)\n[9878, 9828, 8442, 7953, 6431, 6213, 2207, 769] |  |\n|  | （对排序更详细的讨论可参见 排序的技术。）\n内置函数 any(iter) 和 all(iter) 会查看一个可迭代对象内容的逻辑值。any() 在可迭代对象中\n任意一个元素为真时返回 True，而 all() 在所有元素为真时返回 True: |  |\n|  | >>> any([0, 1, 0])\nTrue\n>>> any([0, 0, 0])\nFalse\n>>> any([1, 1, 1])\nTrue\n>>> all([0, 1, 0])\nFalse\n>>> all([0, 0, 0])\nFalse\n>>> all([1, 1, 1])\nTrue |  |\n|  | zip(iterA, iterB, ...) 从每个可迭代对象中选取单个元素组成列表并返回: |  |\n|  | zip(['a', 'b', 'c'], (1, 2, 3)) =>\n('a', 1), ('b', 2), ('c', 3) |  |\n|  | 它并不会在内存创建一个列表并因此在返回前而耗尽输入的迭代器；相反，只有在被请求的时候元\n组才会创建并返回。（这种行为的技术术语叫惰性计算，参见 lazy evaluation.）\n这个迭代器设计用于长度相同的可迭代对象。如果可迭代对象的长度不一致，返回的数据流的长度\n会和最短的可迭代对象相同 |  |\n|  | zip(['a', 'b'], (1, 2, 3)) =>\n('a', 1), ('b', 2) |  |\n|  | 然而，你应该避免这种情况，因为所有从更长的迭代器中取出的元素都会被丢弃。这意味着之后你\n也无法冒着跳过被丢弃元素的风险来继续使用这个迭代器。 |  |\n\nitertools 模块\nitertools 模块包含很多常用的迭代器以及用于组合多个迭代器的函数。 本节会用一些小例子来介\n绍这个模块的内容。\n这个模块里的函数大致可以分为几类：\n从已有的迭代器创建新的迭代器的函数。\n接受迭代器元素作为参数的函数。\n选取部分迭代器输出的函数。\n给迭代器输出分组的函数。\n创建新的迭代器\nitertools.count(start, step) 返回一个等分的无限数据流。初始值默认为0，间隔默认为1，你\n也选择可以指定初始值和间隔:\nitertools.count() =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\nitertools.count(10) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.count(10, 5) =>\n10, 15, 20, 25, 30, 35, 40, 45, 50, 55, ...\nitertools.cycle(iter) 保存一份所提供的可迭代对象的副本，并返回一个能产生整个可迭代对象\n序列的新迭代器。新迭代器会无限重复这些元素。:\nitertools.cycle([1, 2, 3, 4, 5]) =>\n1, 2, 3, 4, 5, 1, 2, 3, 4, 5, ...\nitertools.repeat(elem, [n]) 返回 n 次所提供的元素，当 n 不存在时，返回无数次所提供的元\n素。\nitertools.repeat('abc') =>\nabc, abc, abc, abc, abc, abc, abc, abc, abc, abc, ...\nitertools.repeat('abc', 5) =>\nabc, abc, abc, abc, abc\nitertools.chain(iterA, iterB, ...) 接受任意数量的可迭代对象作为输入，首先返回第一个迭\n代器的所有元素，然后是第二个的所有元素，如此一直进行下去，直到消耗掉所有输入的可迭代对\n象。\nitertools.chain(['a', 'b', 'c'], (1, 2, 3)) =>\na, b, c, 1, 2, 3\nitertools.islice(iter, [start], stop, [step]) 返回一个所输入的迭代器切片的数据流。如\n果只单独给定 stop 参数的话，它会返回从起始算起 stop 个数量的元素。如果你提供了起始下标\n\n|  | itertools 模块\nitertools 模块包含很多常用的迭代器以及用于组合多个迭代器的函数。 本节会用一些小例子来介\n绍这个模块的内容。\n这个模块里的函数大致可以分为几类：\n从已有的迭代器创建新的迭代器的函数。\n接受迭代器元素作为参数的函数。\n选取部分迭代器输出的函数。\n给迭代器输出分组的函数。\n创建新的迭代器\nitertools.count(start, step) 返回一个等分的无限数据流。初始值默认为0，间隔默认为1，你\n也选择可以指定初始值和间隔: |  |\n| --- | --- | --- |\n|  | itertools.count() =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\nitertools.count(10) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.count(10, 5) =>\n10, 15, 20, 25, 30, 35, 40, 45, 50, 55, ... |  |\n|  | itertools.cycle(iter) 保存一份所提供的可迭代对象的副本，并返回一个能产生整个可迭代对象\n序列的新迭代器。新迭代器会无限重复这些元素。: |  |\n|  | itertools.cycle([1, 2, 3, 4, 5]) =>\n1, 2, 3, 4, 5, 1, 2, 3, 4, 5, ... |  |\n|  | itertools.repeat(elem, [n]) 返回 n 次所提供的元素，当 n 不存在时，返回无数次所提供的元\n素。 |  |\n|  | itertools.repeat('abc') =>\nabc, abc, abc, abc, abc, abc, abc, abc, abc, abc, ...\nitertools.repeat('abc', 5) =>\nabc, abc, abc, abc, abc |  |\n|  | itertools.chain(iterA, iterB, ...) 接受任意数量的可迭代对象作为输入，首先返回第一个迭\n代器的所有元素，然后是第二个的所有元素，如此一直进行下去，直到消耗掉所有输入的可迭代对\n象。 |  |\n|  | itertools.chain(['a', 'b', 'c'], (1, 2, 3)) =>\na, b, c, 1, 2, 3 |  |\n|  | itertools.islice(iter, [start], stop, [step]) 返回一个所输入的迭代器切片的数据流。如\n果只单独给定 stop 参数的话，它会返回从起始算起 stop 个数量的元素。如果你提供了起始下标 |  |\n\nstart，你会得到 stop-start 个元素；如果你给定了 step 参数，数据流会跳过相应的元素。和 Python\n里的字符串和列表切片不同，你不能在 start, stop 或者 step 这些参数中使用负数。:\nitertools.islice(range(10), 8) =>\n0, 1, 2, 3, 4, 5, 6, 7\nitertools.islice(range(10), 2, 8) =>\n2, 3, 4, 5, 6, 7\nitertools.islice(range(10), 2, 8, 2) =>\n2, 4, 6\nitertools.tee(iter, [n]) 可以复制一个迭代器；它返回 n 个能够返回源迭代器内容的独立迭代\n器。如果你不提供参数 n，默认值为 2。复制迭代器需要保存源迭代器的一部分内容，因此在源迭代\n器比较大的时候会显著地占用内存；同时，在所有新迭代器中，有一个迭代器会比其他迭代器占用\n更多的内存。\nitertools.tee( itertools.count() ) =>\niterA, iterB\nwhere iterA ->\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\nand iterB ->\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\n对元素使用函数\noperator 模块包含一组对应于 Python 操作符的函数。比如 operator.add(a, b) （把两个数加起\n来），operator.ne(a, b) （和 a != b 相同），以及 operator.attrgetter('id') （返回获取\n.id 属性的可调用对象）。\nitertools.starmap(func, iter) 假定可迭代对象能够返回一个元组的流，并且利用这些元组作为\n参数来调用 func:\nitertools.starmap(os.path.join,\n[('/bin', 'python'), ('/usr', 'bin', 'java'),\n('/usr', 'bin', 'perl'), ('/usr', 'bin', 'ruby')])\n=>\n/bin/python, /usr/bin/java, /usr/bin/perl, /usr/bin/ruby\n选择元素\n另外一系列函数根据谓词选取一个迭代器中元素的子集。\nitertools.filterfalse(predicate, iter) 和 filter() 相反，返回所有让 predicate 返回 false\n的元素:\nitertools.filterfalse(is_even, itertools.count()) =>\n1, 3, 5, 7, 9, 11, 13, 15, ...\nitertools.takewhile(predicate, iter) 返回一直让 predicate 返回 true 的元素。一旦\npredicate 返回 false，迭代器就会发出终止结果的信号。:\n\n|  | start，你会得到 stop-start 个元素；如果你给定了 step 参数，数据流会跳过相应的元素。和 Python\n里的字符串和列表切片不同，你不能在 start, stop 或者 step 这些参数中使用负数。: |  |\n| --- | --- | --- |\n|  | itertools.islice(range(10), 8) =>\n0, 1, 2, 3, 4, 5, 6, 7\nitertools.islice(range(10), 2, 8) =>\n2, 3, 4, 5, 6, 7\nitertools.islice(range(10), 2, 8, 2) =>\n2, 4, 6 |  |\n|  | itertools.tee(iter, [n]) 可以复制一个迭代器；它返回 n 个能够返回源迭代器内容的独立迭代\n器。如果你不提供参数 n，默认值为 2。复制迭代器需要保存源迭代器的一部分内容，因此在源迭代\n器比较大的时候会显著地占用内存；同时，在所有新迭代器中，有一个迭代器会比其他迭代器占用\n更多的内存。 |  |\n|  | itertools.tee( itertools.count() ) =>\niterA, iterB\nwhere iterA ->\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\nand iterB ->\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ... |  |\n|  | 对元素使用函数\noperator 模块包含一组对应于 Python 操作符的函数。比如 operator.add(a, b) （把两个数加起\n来），operator.ne(a, b) （和 a != b 相同），以及 operator.attrgetter('id') （返回获取\n.id 属性的可调用对象）。\nitertools.starmap(func, iter) 假定可迭代对象能够返回一个元组的流，并且利用这些元组作为\n参数来调用 func: |  |\n|  | itertools.starmap(os.path.join,\n[('/bin', 'python'), ('/usr', 'bin', 'java'),\n('/usr', 'bin', 'perl'), ('/usr', 'bin', 'ruby')])\n=>\n/bin/python, /usr/bin/java, /usr/bin/perl, /usr/bin/ruby |  |\n|  | 选择元素\n另外一系列函数根据谓词选取一个迭代器中元素的子集。\nitertools.filterfalse(predicate, iter) 和 filter() 相反，返回所有让 predicate 返回 false\n的元素: |  |\n|  | itertools.filterfalse(is_even, itertools.count()) =>\n1, 3, 5, 7, 9, 11, 13, 15, ... |  |\n|  | itertools.takewhile(predicate, iter) 返回一直让 predicate 返回 true 的元素。一旦\npredicate 返回 false，迭代器就会发出终止结果的信号。: |  |\n\ndef less_than_10(x):\nreturn x < 10\nitertools.takewhile(less_than_10, itertools.count()) =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nitertools.takewhile(is_even, itertools.count()) =>\n0\nitertools.dropwhile(predicate, iter) 在 predicate 返回 true 的时候丢弃元素，并且返回可迭\n代对象的剩余结果。:\nitertools.dropwhile(less_than_10, itertools.count()) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.dropwhile(is_even, itertools.count()) =>\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...\nitertools.compress(data, selectors) 接受两个迭代器，然后返回 data 中使相应地 selector 中\n的元素为真的元素；它会在任一个迭代器耗尽的时候停止:\nitertools.compress([1, 2, 3, 4, 5], [True, True, False, False, True]) =>\n1, 2, 5\n组合函数\nitertools.combinations(iterable, r) 返回一个迭代器，它能给出输入迭代器中所包含的元素\n的所有可能的 r 元元组的组合。:\nitertools.combinations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(2, 3), (2, 4), (2, 5),\n(3, 4), (3, 5),\n(4, 5)\nitertools.combinations([1, 2, 3, 4, 5], 3) =>\n(1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5),\n(2, 3, 4), (2, 3, 5), (2, 4, 5),\n(3, 4, 5)\n每个元组中的元素保持着 可迭代对象 返回他们的顺序。例如，在上面的例子中数字 1 总是会在 2, 3,\n4 或 5 前面。一个类似的函数，itertools.permutations(iterable, r=None)，取消了保持顺序\n的限制，返回所有可能的长度为 r 的排列:\nitertools.permutations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(2, 1), (2, 3), (2, 4), (2, 5),\n(3, 1), (3, 2), (3, 4), (3, 5),\n(4, 1), (4, 2), (4, 3), (4, 5),\n(5, 1), (5, 2), (5, 3), (5, 4)\nitertools.permutations([1, 2, 3, 4, 5]) =>\n(1, 2, 3, 4, 5), (1, 2, 3, 5, 4), (1, 2, 4, 3, 5),\n\n|  | def less_than_10(x):\nreturn x < 10\nitertools.takewhile(less_than_10, itertools.count()) =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nitertools.takewhile(is_even, itertools.count()) =>\n0 |  |\n| --- | --- | --- |\n|  | itertools.dropwhile(predicate, iter) 在 predicate 返回 true 的时候丢弃元素，并且返回可迭\n代对象的剩余结果。: |  |\n|  | itertools.dropwhile(less_than_10, itertools.count()) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.dropwhile(is_even, itertools.count()) =>\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ... |  |\n|  | itertools.compress(data, selectors) 接受两个迭代器，然后返回 data 中使相应地 selector 中\n的元素为真的元素；它会在任一个迭代器耗尽的时候停止: |  |\n|  | itertools.compress([1, 2, 3, 4, 5], [True, True, False, False, True]) =>\n1, 2, 5 |  |\n|  | 组合函数\nitertools.combinations(iterable, r) 返回一个迭代器，它能给出输入迭代器中所包含的元素\n的所有可能的 r 元元组的组合。: |  |\n|  | itertools.combinations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(2, 3), (2, 4), (2, 5),\n(3, 4), (3, 5),\n(4, 5)\nitertools.combinations([1, 2, 3, 4, 5], 3) =>\n(1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5),\n(2, 3, 4), (2, 3, 5), (2, 4, 5),\n(3, 4, 5) |  |\n|  | 每个元组中的元素保持着 可迭代对象 返回他们的顺序。例如，在上面的例子中数字 1 总是会在 2, 3,\n4 或 5 前面。一个类似的函数，itertools.permutations(iterable, r=None)，取消了保持顺序\n的限制，返回所有可能的长度为 r 的排列: |  |\n|  | itertools.permutations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(2, 1), (2, 3), (2, 4), (2, 5),\n(3, 1), (3, 2), (3, 4), (3, 5),\n(4, 1), (4, 2), (4, 3), (4, 5),\n(5, 1), (5, 2), (5, 3), (5, 4)\nitertools.permutations([1, 2, 3, 4, 5]) =>\n(1, 2, 3, 4, 5), (1, 2, 3, 5, 4), (1, 2, 4, 3, 5), |  |\n\n...\n(5, 4, 3, 2, 1)\n如果你不提供 r 参数的值，它会使用可迭代对象的长度，也就是说会排列所有的元素。\n注意这些函数会输出所有可能的位置组合，并不要求 可迭代对象 的内容不重复:\nitertools.permutations('aba', 3) =>\n('a', 'b', 'a'), ('a', 'a', 'b'), ('b', 'a', 'a'),\n('b', 'a', 'a'), ('a', 'a', 'b'), ('a', 'b', 'a')\n同一个元组 ('a', 'a', 'b') 出现了两次，但是两个 'a' 字符来自不同的位置。\nitertools.combinations_with_replacement(iterable, r) 函数放松了一个不同的限制：元组\n中的元素可以重复。从概念讲，为每个元组第一个位置选取一个元素，然后在选择第二个元素前替\n换掉它。:\nitertools.combinations_with_replacement([1, 2, 3, 4, 5], 2) =>\n(1, 1), (1, 2), (1, 3), (1, 4), (1, 5),\n(2, 2), (2, 3), (2, 4), (2, 5),\n(3, 3), (3, 4), (3, 5),\n(4, 4), (4, 5),\n(5, 5)\n为元素分组\n我要讨论的最后一个函数，itertools.groupby(iter,key_func=None)，是最复杂的函数。\nkey_func(elem) 是一个可以对迭代器返回的每个元素计算键值的函数。 如果你不提供这个键值函\n数，它就会简化成每个元素自身。\ngroupby() 从所依据的可迭代对象中连续地收集具有相同值的元素，然后返回一个长度为2的元组的\n数据流, 每个元组包含键值以及对应这个键值的元素所组成的迭代器。\ncity_list = [('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL'),\n('Anchorage', 'AK'), ('Nome', 'AK'),\n('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ'),\n...\n]\ndef get_state(city_state):\nreturn city_state[1]\nitertools.groupby(city_list, get_state) =>\n('AL', iterator-1),\n('AK', iterator-2),\n('AZ', iterator-3), ...\nwhere\niterator-1 =>\n('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL')\niterator-2 =>\n('Anchorage', 'AK'), ('Nome', 'AK')\niterator-3 =>\n('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ')\n\n|  | ...\n(5, 4, 3, 2, 1) |  |\n| --- | --- | --- |\n|  | 如果你不提供 r 参数的值，它会使用可迭代对象的长度，也就是说会排列所有的元素。\n注意这些函数会输出所有可能的位置组合，并不要求 可迭代对象 的内容不重复: |  |\n|  | itertools.permutations('aba', 3) =>\n('a', 'b', 'a'), ('a', 'a', 'b'), ('b', 'a', 'a'),\n('b', 'a', 'a'), ('a', 'a', 'b'), ('a', 'b', 'a') |  |\n|  | 同一个元组 ('a', 'a', 'b') 出现了两次，但是两个 'a' 字符来自不同的位置。\nitertools.combinations_with_replacement(iterable, r) 函数放松了一个不同的限制：元组\n中的元素可以重复。从概念讲，为每个元组第一个位置选取一个元素，然后在选择第二个元素前替\n换掉它。: |  |\n|  | itertools.combinations_with_replacement([1, 2, 3, 4, 5], 2) =>\n(1, 1), (1, 2), (1, 3), (1, 4), (1, 5),\n(2, 2), (2, 3), (2, 4), (2, 5),\n(3, 3), (3, 4), (3, 5),\n(4, 4), (4, 5),\n(5, 5) |  |\n|  | 为元素分组\n我要讨论的最后一个函数，itertools.groupby(iter,key_func=None)，是最复杂的函数。\nkey_func(elem) 是一个可以对迭代器返回的每个元素计算键值的函数。 如果你不提供这个键值函\n数，它就会简化成每个元素自身。\ngroupby() 从所依据的可迭代对象中连续地收集具有相同值的元素，然后返回一个长度为2的元组的\n数据流, 每个元组包含键值以及对应这个键值的元素所组成的迭代器。 |  |\n|  | city_list = [('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL'),\n('Anchorage', 'AK'), ('Nome', 'AK'),\n('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ'),\n...\n]\ndef get_state(city_state):\nreturn city_state[1]\nitertools.groupby(city_list, get_state) =>\n('AL', iterator-1),\n('AK', iterator-2),\n('AZ', iterator-3), ...\nwhere\niterator-1 =>\n('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL')\niterator-2 =>\n('Anchorage', 'AK'), ('Nome', 'AK')\niterator-3 =>\n('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ') |  |\n|  |  |  |\n\ngroupby() 假定了所依据的可迭代对象的内容已经根据键值排序。注意，返回的迭代器也会使用所\n依据的可迭代对象，所以在请求迭代器 2和相应的键之前你必须先消耗迭代器 1 的结果。\nfunctools 模块\nfunctools 模块包含一些高阶函数。 高阶函数 接受一个或多个函数作为输入并返回一个新的函数。\n这个模块中最有用的工具是 functools.partial() 函数。\n对于用函数式风格编写的程序，有时你会希望通过给定部分参数，将已有的函数构变形称新的函\n数。考虑一个 Python 函数 f(a, b, c)；你希望创建一个和 f(1, b, c) 等价的新函数 g(b, c)；\n也就是说你给定了 f() 的一个参数的值。这就是所谓的“部分函数应用”。\npartial() 接受参数 (function, arg1, arg2, ..., kwarg1=value1, kwarg2=value2)。它会返\n回一个可调用的对象，所以你能够直接调用这个结果以使用给定参数的 function。\n这里有一个很小但很现实的例子:\nimport functools\ndef log(message, subsystem):\n\"\"\"将 'message' 的内容写到指定的子系统。\"\"\"\nprint('%s: %s' % (subsystem, message))\n...\nserver_log = functools.partial(log, subsystem='server')\nserver_log('Unable to open socket')\nfunctools.reduce(func, iter, [initial_value]) 持续地在可迭代对象的所有元素上执行操\n作，因此它不能够用在无限的可迭代对象上。func 必须是一个接受两个元素并返回一个值的函数。\nfunctools.reduce() 接受迭代器返回的前两个元素 A 和 B 并计算 func(A, B) 。然后它会请求第\n三个元素，C，计算 func(func(A, B), C)，然后把这个结果再和第四个元素组合并返回，如此继\n续下去直到消耗整个可迭代对象。如果输入的可迭代对象完全不返回任何值，TypeError 异常就会\n抛出。如果提供了初值(initial value)，它会被用作起始值，也就是先计算 func(initial_value, A)\n。:\n>>> import operator, functools\n>>> functools.reduce(operator.concat, ['A', 'BB', 'C'])\n'ABBC'\n>>> functools.reduce(operator.concat, [])\nTraceback (most recent call last):\n...\nTypeError: reduce() of empty sequence with no initial value\n>>> functools.reduce(operator.mul, [1, 2, 3], 1)\n6\n>>> functools.reduce(operator.mul, [], 1)\n1\n如果你在 functools.reduce() 中使用 operator.add()，你就会把可迭代对象中的所有元素加起\n来.这种情况非常常见, 所以 Python 有一个特殊的内置函数 sum():\n\n|  | groupby() 假定了所依据的可迭代对象的内容已经根据键值排序。注意，返回的迭代器也会使用所\n依据的可迭代对象，所以在请求迭代器 2和相应的键之前你必须先消耗迭代器 1 的结果。\nfunctools 模块\nfunctools 模块包含一些高阶函数。 高阶函数 接受一个或多个函数作为输入并返回一个新的函数。\n这个模块中最有用的工具是 functools.partial() 函数。\n对于用函数式风格编写的程序，有时你会希望通过给定部分参数，将已有的函数构变形称新的函\n数。考虑一个 Python 函数 f(a, b, c)；你希望创建一个和 f(1, b, c) 等价的新函数 g(b, c)；\n也就是说你给定了 f() 的一个参数的值。这就是所谓的“部分函数应用”。\npartial() 接受参数 (function, arg1, arg2, ..., kwarg1=value1, kwarg2=value2)。它会返\n回一个可调用的对象，所以你能够直接调用这个结果以使用给定参数的 function。\n这里有一个很小但很现实的例子: |  |\n| --- | --- | --- |\n|  | import functools\ndef log(message, subsystem):\n\"\"\"将 'message' 的内容写到指定的子系统。\"\"\"\nprint('%s: %s' % (subsystem, message))\n...\nserver_log = functools.partial(log, subsystem='server')\nserver_log('Unable to open socket') |  |\n|  | functools.reduce(func, iter, [initial_value]) 持续地在可迭代对象的所有元素上执行操\n作，因此它不能够用在无限的可迭代对象上。func 必须是一个接受两个元素并返回一个值的函数。\nfunctools.reduce() 接受迭代器返回的前两个元素 A 和 B 并计算 func(A, B) 。然后它会请求第\n三个元素，C，计算 func(func(A, B), C)，然后把这个结果再和第四个元素组合并返回，如此继\n续下去直到消耗整个可迭代对象。如果输入的可迭代对象完全不返回任何值，TypeError 异常就会\n抛出。如果提供了初值(initial value)，它会被用作起始值，也就是先计算 func(initial_value, A)\n。: |  |\n|  | >>> import operator, functools\n>>> functools.reduce(operator.concat, ['A', 'BB', 'C'])\n'ABBC'\n>>> functools.reduce(operator.concat, [])\nTraceback (most recent call last):\n...\nTypeError: reduce() of empty sequence with no initial value\n>>> functools.reduce(operator.mul, [1, 2, 3], 1)\n6\n>>> functools.reduce(operator.mul, [], 1)\n1 |  |\n|  | 如果你在 functools.reduce() 中使用 operator.add()，你就会把可迭代对象中的所有元素加起\n来.这种情况非常常见, 所以 Python 有一个特殊的内置函数 sum(): |  |\n\n>>> import functools, operator\n>>> functools.reduce(operator.add, [1, 2, 3, 4], 0)\n10\n>>> sum([1, 2, 3, 4])\n10\n>>> sum([])\n0\n不过, 对于很多使用 functools.reduce() 的情形, 使用明显的 for 循环会更清晰:\nimport functools\n# 作为以下语句的替代：\nproduct = functools.reduce(operator.mul, [1, 2, 3], 1)\n# 你可以这样写：\nproduct = 1\nfor i in [1, 2, 3]:\nproduct *= i\n一个相关的函数是 itertools.accumulate(iterable, func=operator.add)。 它执行同样的计\n算，但 accumulate() 不是仅仅返回最终结果，而是返回一个会产生每个部分结果的迭代器:\nitertools.accumulate([1, 2, 3, 4, 5]) =>\n1, 3, 6, 10, 15\nitertools.accumulate([1, 2, 3, 4, 5], operator.mul) =>\n1, 2, 6, 24, 120\noperator 模块\n前面已经提到了 operator 模块。它包含一系列对应于 Python 操作符的函数。在函数式风格的代码\n中，这些函数通常很有用，可以帮你省下不少时间，避免写一些琐碎的仅仅执行一个简单操作的函\n数。\n这个模块里的一些函数：\n数学运算： add()，sub()，mul()，floordiv()，abs()， ...\n逻辑运算： not_()，truth()。\n位运算： and_()，or_()，invert()。\n比较： eq()，ne()，lt()，le()，gt()，和 ge()。\n确认对象： is_()，is_not()。\n全部函数列表可以参考 operator 模块的文档。\n小函数和 lambda 表达式\n编写函数式风格程序时，你会经常需要很小的函数，作为谓词函数或者以某种方式来组合元素。\n如果合适的 Python 内置的或者其他模块中的函数，你就一点也不需要定义新的函数:\nstripped_lines = [line.strip() for line in lines]\n\n|  | >>> import functools, operator\n>>> functools.reduce(operator.add, [1, 2, 3, 4], 0)\n10\n>>> sum([1, 2, 3, 4])\n10\n>>> sum([])\n0 |  |\n| --- | --- | --- |\n|  | 不过, 对于很多使用 functools.reduce() 的情形, 使用明显的 for 循环会更清晰: |  |\n|  | import functools\n# 作为以下语句的替代：\nproduct = functools.reduce(operator.mul, [1, 2, 3], 1)\n# 你可以这样写：\nproduct = 1\nfor i in [1, 2, 3]:\nproduct *= i |  |\n|  | 一个相关的函数是 itertools.accumulate(iterable, func=operator.add)。 它执行同样的计\n算，但 accumulate() 不是仅仅返回最终结果，而是返回一个会产生每个部分结果的迭代器: |  |\n|  | itertools.accumulate([1, 2, 3, 4, 5]) =>\n1, 3, 6, 10, 15\nitertools.accumulate([1, 2, 3, 4, 5], operator.mul) =>\n1, 2, 6, 24, 120 |  |\n|  | operator 模块\n前面已经提到了 operator 模块。它包含一系列对应于 Python 操作符的函数。在函数式风格的代码\n中，这些函数通常很有用，可以帮你省下不少时间，避免写一些琐碎的仅仅执行一个简单操作的函\n数。\n这个模块里的一些函数：\n数学运算： add()，sub()，mul()，floordiv()，abs()， ...\n逻辑运算： not_()，truth()。\n位运算： and_()，or_()，invert()。\n比较： eq()，ne()，lt()，le()，gt()，和 ge()。\n确认对象： is_()，is_not()。\n全部函数列表可以参考 operator 模块的文档。\n小函数和 lambda 表达式\n编写函数式风格程序时，你会经常需要很小的函数，作为谓词函数或者以某种方式来组合元素。\n如果合适的 Python 内置的或者其他模块中的函数，你就一点也不需要定义新的函数: |  |\n|  | stripped_lines = [line.strip() for line in lines] |  |\n\nexisting_files = filter(os.path.exists, file_list)\n如果不存在你需要的函数，你就必须自己编写。一个编写小函数的方式是使用 lambda 表达式。\nlambda 接受一组参数以及组合这些参数的表达式，它会创建一个返回表达式值的匿名函数:\nadder = lambda x, y: x+y\nprint_assign = lambda name, value: name + '=' + str(value)\n另一种替代方案就是通常的使用 def 语句来定义函数:\ndef adder(x, y):\nreturn x + y\ndef print_assign(name, value):\nreturn name + '=' + str(value)\n哪一种更受青睐呢？这是一个风格问题；我通常的做法是避免使用 lambda。\n我这么偏好的一个原因是，lambda 能够定义的函数非常受限。函数的结果必须能够作为单独的表达\n式来计算，这意味着你不能使用多路 if... elif... else 比较，或者 try... except 语句。如果\n你尝试在 lambda 语句中做太多事情，你最终会把表达式过于复杂以至于难以阅读。你能快速的说\n出下面的代码做了什么事情吗？:\nimport functools\ntotal = functools.reduce(lambda a, b: (0, a[1] + b[1]), items)[1]\n你可以弄明白，不过要花上时间来理清表达式来搞清楚发生了什么。使用一个简短的嵌套的 def 语\n句可以让情况变得更好:\nimport functools\ndef combine(a, b):\nreturn 0, a[1] + b[1]\ntotal = functools.reduce(combine, items)[1]\n如果我仅仅使用一个 for 循环会更好:\ntotal = 0\nfor a, b in items:\ntotal += b\n或者使用内置的 sum() 和一个生成器表达式:\ntotal = sum(b for a, b in items)\n许多使用 functools.reduce() 的情形可以更清晰地写成 for 循环的形式。\nFredrik Lundh 曾经建议以下一组规则来重构 lambda 的使用:\n1. 写一个 lambda 函数。\n\n|  | existing_files = filter(os.path.exists, file_list) |  |\n| --- | --- | --- |\n|  | 如果不存在你需要的函数，你就必须自己编写。一个编写小函数的方式是使用 lambda 表达式。\nlambda 接受一组参数以及组合这些参数的表达式，它会创建一个返回表达式值的匿名函数: |  |\n|  | adder = lambda x, y: x+y\nprint_assign = lambda name, value: name + '=' + str(value) |  |\n|  | 另一种替代方案就是通常的使用 def 语句来定义函数: |  |\n|  | def adder(x, y):\nreturn x + y\ndef print_assign(name, value):\nreturn name + '=' + str(value) |  |\n|  | 哪一种更受青睐呢？这是一个风格问题；我通常的做法是避免使用 lambda。\n我这么偏好的一个原因是，lambda 能够定义的函数非常受限。函数的结果必须能够作为单独的表达\n式来计算，这意味着你不能使用多路 if... elif... else 比较，或者 try... except 语句。如果\n你尝试在 lambda 语句中做太多事情，你最终会把表达式过于复杂以至于难以阅读。你能快速的说\n出下面的代码做了什么事情吗？: |  |\n|  | import functools\ntotal = functools.reduce(lambda a, b: (0, a[1] + b[1]), items)[1] |  |\n|  | 你可以弄明白，不过要花上时间来理清表达式来搞清楚发生了什么。使用一个简短的嵌套的 def 语\n句可以让情况变得更好: |  |\n|  | import functools\ndef combine(a, b):\nreturn 0, a[1] + b[1]\ntotal = functools.reduce(combine, items)[1] |  |\n|  | 如果我仅仅使用一个 for 循环会更好: |  |\n|  | total = 0\nfor a, b in items:\ntotal += b |  |\n|  | 或者使用内置的 sum() 和一个生成器表达式: |  |\n|  | total = sum(b for a, b in items) |  |\n|  | 许多使用 functools.reduce() 的情形可以更清晰地写成 for 循环的形式。\nFredrik Lundh 曾经建议以下一组规则来重构 lambda 的使用:\n1. 写一个 lambda 函数。 |  |\n\n2. 写一句注释来说明这个 lambda 究竟干了什么。\n3. 研究一会这个注释，然后想出一个抓住注释本质的名字。\n4. 用这个名字，把这个 lambda 改写成 def 语句。\n5. 把注释去掉。\n我非常喜欢这些规则，不过你完全有权利争辩这种消除 lambda 的风格是不是更好。\n修订记录和致谢\n作者要感谢以下人员对本文各种草稿给予的建议，更正和协助：Ian Bicking,Nick Coghlan, Nick\nEfford, Raymond Hettinger, Jim Jewett, Mike Krell,Leandro Lameiro, Jussi Salmela, Collin Winter,\nBlake Winton。\n0.1 版: 2006 年 6 月 30 日发布。\n0.11 版: 2006 年 7 月 1 日发布。 修正拼写错误。\n0.2 版: 2006 年 7 月 10 日发布。 将 genexp 与 listcomp 两节合二为一。 修正拼写错误。\n0.21 版: 加入了 tutor 邮件列表中建议的更多参考文件。\n0.30 版: 添加了有关 functional 模块的小节，由 Collin Winter 撰写；添加了有关 operator 模块的\n简短小节；其他少量修改。\n参考文献\n通用文献\nStructure and Interpretation of Computer Programs, Harold Abelson 和 Gerald Jay Sussman 与\nJulie Sussman 著。 该书可在 https://mitpress.mit.edu/sicp 获取。 在这部计算机科学的经典教科书\n中，第 2 和第 3 章讨论了使用序列和流来组织程序内部的数据传递。 书中的示例使用了 Scheme 语\n言，但这些章节中介绍的许多设计理念同样适用于函数式风格的 Python 代码。\nhttps://defmacro.org/2006/06/19/fp.html: 一个使用 Java 示例并且具有详细的历史说明的函数式编\n程的总体介绍。\nhttps://en.wikipedia.org/wiki/Functional_programming: 一般性的函数式编程的 Wikipedia 条目。\nhttps://en.wikipedia.org/wiki/Coroutine: 协程条目。\nhttps://en.wikipedia.org/wiki/Partial_application: 部分化函数应用相关概念的条目。\nhttps://en.wikipedia.org/wiki/Currying: 函数柯里化条目。\nPython 相关\nhttps://gnosis.cx/TPiP/: David Mertz 书中的第一章 Text Processing in Python 中标题为 \"Utilizing\nHigher-Order Functions in Text Processing\" 的小节讨论了针对文本处理的函数式编程。\n\n|  | 2. 写一句注释来说明这个 lambda 究竟干了什么。\n3. 研究一会这个注释，然后想出一个抓住注释本质的名字。\n4. 用这个名字，把这个 lambda 改写成 def 语句。\n5. 把注释去掉。\n我非常喜欢这些规则，不过你完全有权利争辩这种消除 lambda 的风格是不是更好。\n修订记录和致谢\n作者要感谢以下人员对本文各种草稿给予的建议，更正和协助：Ian Bicking,Nick Coghlan, Nick\nEfford, Raymond Hettinger, Jim Jewett, Mike Krell,Leandro Lameiro, Jussi Salmela, Collin Winter,\nBlake Winton。\n0.1 版: 2006 年 6 月 30 日发布。\n0.11 版: 2006 年 7 月 1 日发布。 修正拼写错误。\n0.2 版: 2006 年 7 月 10 日发布。 将 genexp 与 listcomp 两节合二为一。 修正拼写错误。\n0.21 版: 加入了 tutor 邮件列表中建议的更多参考文件。\n0.30 版: 添加了有关 functional 模块的小节，由 Collin Winter 撰写；添加了有关 operator 模块的\n简短小节；其他少量修改。\n参考文献\n通用文献\nStructure and Interpretation of Computer Programs, Harold Abelson 和 Gerald Jay Sussman 与\nJulie Sussman 著。 该书可在 https://mitpress.mit.edu/sicp 获取。 在这部计算机科学的经典教科书\n中，第 2 和第 3 章讨论了使用序列和流来组织程序内部的数据传递。 书中的示例使用了 Scheme 语\n言，但这些章节中介绍的许多设计理念同样适用于函数式风格的 Python 代码。\nhttps://defmacro.org/2006/06/19/fp.html: 一个使用 Java 示例并且具有详细的历史说明的函数式编\n程的总体介绍。\nhttps://en.wikipedia.org/wiki/Functional_programming: 一般性的函数式编程的 Wikipedia 条目。\nhttps://en.wikipedia.org/wiki/Coroutine: 协程条目。\nhttps://en.wikipedia.org/wiki/Partial_application: 部分化函数应用相关概念的条目。\nhttps://en.wikipedia.org/wiki/Currying: 函数柯里化条目。\nPython 相关\nhttps://gnosis.cx/TPiP/: David Mertz 书中的第一章 Text Processing in Python 中标题为 \"Utilizing\nHigher-Order Functions in Text Processing\" 的小节讨论了针对文本处理的函数式编程。 |  |\n| --- | --- | --- |\n\nMertz 还在 IBM 的 DeveloperWorks 站点上针对函数式编程撰写了一系列共 3 篇文章；参见 part 1,\npart 2 和 part 3,\nPython 文档\nitertools 模块文档。\nfunctools 模块文档。\noperator 模块文档。\nPEP 289: \"Generator Expressions\"\nPEP 342: \"Coroutines via Enhanced Generators\" 描述了 Python 2.5 中新的生成器特性。", "metadata": {"title": "06_函数式编程指引", "source": "md_docs\\python_howto_md\\06_函数式编程指引.md", "doc_type": "指南", "language": "中文", "doc_id": "9550601e"}}
{"doc_id": "05482666", "content": "ipaddress模块介绍\n作者: Peter Moody\n作者: Nick Coghlan\n概述\n本文档旨在简要介绍 ipaddress 模块。 它主要针对那些不熟悉 IP 网络术语的用户，但也可能对\n想要速览 ipaddress 如何代表IP网络寻址概念的网络工程师有用。\n创建 Address/Network/Interface 对象\n因为 ipaddress 是一个用于检查和操作 IP 地址的模块，你要做的第一件事就是创建一些对象。 您\n可以使用 ipaddress 从字符串和整数创建对象。\n关于IP版本的说明\n对于不太熟悉 IP 寻址的读者来说，重要的一点是知道互联网协议 (IP) 目前正在从第 4 版协议迁移到\n第 6 版。 进行这样的迁移主要是因为第 4 版协议无法提供足够的地址来满足全世界的需求，特别是\n考虑到有越来越多的设备连接到了互联网中。\n解释协议的两个版本之间的差异的细节超出了本介绍的范围，但读者需要至少知道存在这两个版\n本，并且有时需要强制使用一个版本或其他版本。\nIP主机地址\n通常称为“主机地址”的地址是使用IP寻址时最基本的单元。 创建地址的最简单方法是使用\nipaddress.ip_address() 工厂函数，该函数根据传入的值自动确定是创建 IPv4 还是 IPv6 地址：\n>>> ipaddress.ip_address('192.0.2.1')\nIPv4Address('192.0.2.1')\n>>> ipaddress.ip_address('2001:DB8::1')\nIPv6Address('2001:db8::1')\n地址也可以直接从整数创建，适配32位的值并假定为IPv4地址:\n>>> ipaddress.ip_address(3221225985)\nIPv4Address('192.0.2.1')\n>>> ipaddress.ip_address(42540766411282592856903984951653826561)\nIPv6Address('2001:db8::1')\n要强制使用IPv4或IPv6地址，可以直接调用相关的类。 这对于强制为小整数创建IPv6地址特别有用:\n\n| ipaddress模块介绍\n作者: Peter Moody\n作者: Nick Coghlan |\n| --- |\n| 概述\n本文档旨在简要介绍 ipaddress 模块。 它主要针对那些不熟悉 IP 网络术语的用户，但也可能对\n想要速览 ipaddress 如何代表IP网络寻址概念的网络工程师有用。 |\n| 创建 Address/Network/Interface 对象\n因为 ipaddress 是一个用于检查和操作 IP 地址的模块，你要做的第一件事就是创建一些对象。 您\n可以使用 ipaddress 从字符串和整数创建对象。\n关于IP版本的说明\n对于不太熟悉 IP 寻址的读者来说，重要的一点是知道互联网协议 (IP) 目前正在从第 4 版协议迁移到\n第 6 版。 进行这样的迁移主要是因为第 4 版协议无法提供足够的地址来满足全世界的需求，特别是\n考虑到有越来越多的设备连接到了互联网中。\n解释协议的两个版本之间的差异的细节超出了本介绍的范围，但读者需要至少知道存在这两个版\n本，并且有时需要强制使用一个版本或其他版本。\nIP主机地址\n通常称为“主机地址”的地址是使用IP寻址时最基本的单元。 创建地址的最简单方法是使用\nipaddress.ip_address() 工厂函数，该函数根据传入的值自动确定是创建 IPv4 还是 IPv6 地址： |\n| >>> ipaddress.ip_address('192.0.2.1')\nIPv4Address('192.0.2.1')\n>>> ipaddress.ip_address('2001:DB8::1')\nIPv6Address('2001:db8::1') |\n| 地址也可以直接从整数创建，适配32位的值并假定为IPv4地址: |\n| >>> ipaddress.ip_address(3221225985)\nIPv4Address('192.0.2.1')\n>>> ipaddress.ip_address(42540766411282592856903984951653826561)\nIPv6Address('2001:db8::1') |\n| 要强制使用IPv4或IPv6地址，可以直接调用相关的类。 这对于强制为小整数创建IPv6地址特别有用: |\n\n| 作者: |\n| --- |\n| 作者: |\n\n>>> ipaddress.ip_address(1)\nIPv4Address('0.0.0.1')\n>>> ipaddress.IPv4Address(1)\nIPv4Address('0.0.0.1')\n>>> ipaddress.IPv6Address(1)\nIPv6Address('::1')\n定义网络\n主机地址通常组合在一起形成IP网络，因此 ipaddress 提供了一种创建、检查和操作网络定义的方\n法。 IP网络对象由字符串构成，这些字符串定义作为该网络一部分的主机地址范围。 该信息的最简\n单形式是“网络地址/网络前缀”对，其中前缀定义了比较的前导比特数，以确定地址是否是网络的一\n部分，并且网络地址定义了那些位的预期值。\n对于地址，提供了一个自动确定正确IP版本的工厂函数:\n>>> ipaddress.ip_network('192.0.2.0/24')\nIPv4Network('192.0.2.0/24')\n>>> ipaddress.ip_network('2001:db8::0/96')\nIPv6Network('2001:db8::/96')\n网络对象不能设置任何主机位。 这样做的实际效果是 192.0.2.1/24 没有描述网络。 这种定义被称\n为接口对象，因为网络上IP表示法通常用于描述给定网络上的计算机的网络接口，并在下一节中进一\n步描述。\n默认情况下，尝试创建一个设置了主机位的网络对象将导致 ValueError 被引发。 要请求将附加位\n强制为零，可以将标志 strict=False 传递给构造函数:\n>>> ipaddress.ip_network('192.0.2.1/24')\nTraceback (most recent call last):\n...\nValueError: 192.0.2.1/24 has host bits set\n>>> ipaddress.ip_network('192.0.2.1/24', strict=False)\nIPv4Network('192.0.2.0/24')\n虽然字符串形式提供了更大的灵活性，但网络也可以用整数定义，就像主机地址一样。 在这种情况\n下，网络被认为只包含由整数标识的单个地址，因此网络前缀包括整个网络地址:\n>>> ipaddress.ip_network(3221225984)\nIPv4Network('192.0.2.0/32')\n>>> ipaddress.ip_network(42540766411282592856903984951653826560)\nIPv6Network('2001:db8::/128')\n与地址一样，可以通过直接调用类构造函数而不是使用工厂函数来强制创建特定类型的网络。\n主机接口\n如上所述，如果您需要描述特定网络上的地址，则地址和网络类都不够。 像 192.0.2.1/24 这样的\n表示法通常被网络工程师和为防火墙和路由器编写工具的人用作“ 192.0.2.0/24 网络上的主机\n192.0.2.1 ”的简写。因此，ipaddress 提供了一组将地址与特定网络相关联的混合类。用于创建的\n接口与用于定义网络对象的接口相同，除了地址部分不限于是网络地址。\n\n|  | >>> ipaddress.ip_address(1)\nIPv4Address('0.0.0.1')\n>>> ipaddress.IPv4Address(1)\nIPv4Address('0.0.0.1')\n>>> ipaddress.IPv6Address(1)\nIPv6Address('::1') |  |\n| --- | --- | --- |\n|  | 定义网络\n主机地址通常组合在一起形成IP网络，因此 ipaddress 提供了一种创建、检查和操作网络定义的方\n法。 IP网络对象由字符串构成，这些字符串定义作为该网络一部分的主机地址范围。 该信息的最简\n单形式是“网络地址/网络前缀”对，其中前缀定义了比较的前导比特数，以确定地址是否是网络的一\n部分，并且网络地址定义了那些位的预期值。\n对于地址，提供了一个自动确定正确IP版本的工厂函数: |  |\n|  | >>> ipaddress.ip_network('192.0.2.0/24')\nIPv4Network('192.0.2.0/24')\n>>> ipaddress.ip_network('2001:db8::0/96')\nIPv6Network('2001:db8::/96') |  |\n|  | 网络对象不能设置任何主机位。 这样做的实际效果是 192.0.2.1/24 没有描述网络。 这种定义被称\n为接口对象，因为网络上IP表示法通常用于描述给定网络上的计算机的网络接口，并在下一节中进一\n步描述。\n默认情况下，尝试创建一个设置了主机位的网络对象将导致 ValueError 被引发。 要请求将附加位\n强制为零，可以将标志 strict=False 传递给构造函数: |  |\n|  | >>> ipaddress.ip_network('192.0.2.1/24')\nTraceback (most recent call last):\n...\nValueError: 192.0.2.1/24 has host bits set\n>>> ipaddress.ip_network('192.0.2.1/24', strict=False)\nIPv4Network('192.0.2.0/24') |  |\n|  | 虽然字符串形式提供了更大的灵活性，但网络也可以用整数定义，就像主机地址一样。 在这种情况\n下，网络被认为只包含由整数标识的单个地址，因此网络前缀包括整个网络地址: |  |\n|  | >>> ipaddress.ip_network(3221225984)\nIPv4Network('192.0.2.0/32')\n>>> ipaddress.ip_network(42540766411282592856903984951653826560)\nIPv6Network('2001:db8::/128') |  |\n|  | 与地址一样，可以通过直接调用类构造函数而不是使用工厂函数来强制创建特定类型的网络。\n主机接口\n如上所述，如果您需要描述特定网络上的地址，则地址和网络类都不够。 像 192.0.2.1/24 这样的\n表示法通常被网络工程师和为防火墙和路由器编写工具的人用作“ 192.0.2.0/24 网络上的主机\n192.0.2.1 ”的简写。因此，ipaddress 提供了一组将地址与特定网络相关联的混合类。用于创建的\n接口与用于定义网络对象的接口相同，除了地址部分不限于是网络地址。 |  |\n\n>>> ipaddress.ip_interface('192.0.2.1/24')\nIPv4Interface('192.0.2.1/24')\n>>> ipaddress.ip_interface('2001:db8::1/96')\nIPv6Interface('2001:db8::1/96')\n接受整数输入（与网络一样），并且可以通过直接调用相关构造函数来强制使用特定IP版本。\n审查 Address/Network/Interface 对象\n你已经遇到了创建IPv(4|6)(Address|Network|Interface) 对象的麻烦，因此你可能希望获得有关它的信\n息。 ipaddress 试图让这个过程变得简单直观。\n提取 IP 版本:\n>>> addr4 = ipaddress.ip_address('192.0.2.1')\n>>> addr6 = ipaddress.ip_address('2001:db8::1')\n>>> addr6.version\n6\n>>> addr4.version\n4\n从接口获取网络:\n>>> host4 = ipaddress.ip_interface('192.0.2.1/24')\n>>> host4.network\nIPv4Network('192.0.2.0/24')\n>>> host6 = ipaddress.ip_interface('2001:db8::1/96')\n>>> host6.network\nIPv6Network('2001:db8::/96')\n找出网络中有多少独立地址:\n>>> net4 = ipaddress.ip_network('192.0.2.0/24')\n>>> net4.num_addresses\n256\n>>> net6 = ipaddress.ip_network('2001:db8::0/96')\n>>> net6.num_addresses\n4294967296\n迭代网络上的“可用”地址:\n>>> net4 = ipaddress.ip_network('192.0.2.0/24')\n>>> for x in net4.hosts():\n... print(x)\n192.0.2.1\n192.0.2.2\n192.0.2.3\n192.0.2.4\n...\n192.0.2.252\n192.0.2.253\n192.0.2.254\n获取网络掩码（即对应于网络前缀的设置位）或主机掩码（不属于网络掩码的任何位）：\n\n|  | >>> ipaddress.ip_interface('192.0.2.1/24')\nIPv4Interface('192.0.2.1/24')\n>>> ipaddress.ip_interface('2001:db8::1/96')\nIPv6Interface('2001:db8::1/96') |  |\n| --- | --- | --- |\n|  | 接受整数输入（与网络一样），并且可以通过直接调用相关构造函数来强制使用特定IP版本。\n审查 Address/Network/Interface 对象\n你已经遇到了创建IPv(4|6)(Address|Network|Interface) 对象的麻烦，因此你可能希望获得有关它的信\n息。 ipaddress 试图让这个过程变得简单直观。\n提取 IP 版本: |  |\n|  | >>> addr4 = ipaddress.ip_address('192.0.2.1')\n>>> addr6 = ipaddress.ip_address('2001:db8::1')\n>>> addr6.version\n6\n>>> addr4.version\n4 |  |\n|  | 从接口获取网络: |  |\n|  | >>> host4 = ipaddress.ip_interface('192.0.2.1/24')\n>>> host4.network\nIPv4Network('192.0.2.0/24')\n>>> host6 = ipaddress.ip_interface('2001:db8::1/96')\n>>> host6.network\nIPv6Network('2001:db8::/96') |  |\n|  | 找出网络中有多少独立地址: |  |\n|  | >>> net4 = ipaddress.ip_network('192.0.2.0/24')\n>>> net4.num_addresses\n256\n>>> net6 = ipaddress.ip_network('2001:db8::0/96')\n>>> net6.num_addresses\n4294967296 |  |\n|  | 迭代网络上的“可用”地址: |  |\n|  | >>> net4 = ipaddress.ip_network('192.0.2.0/24')\n>>> for x in net4.hosts():\n... print(x)\n192.0.2.1\n192.0.2.2\n192.0.2.3\n192.0.2.4\n...\n192.0.2.252\n192.0.2.253\n192.0.2.254 |  |\n|  | 获取网络掩码（即对应于网络前缀的设置位）或主机掩码（不属于网络掩码的任何位）： |  |\n\n>>> net4 = ipaddress.ip_network('192.0.2.0/24')\n>>> net4.netmask\nIPv4Address('255.255.255.0')\n>>> net4.hostmask\nIPv4Address('0.0.0.255')\n>>> net6 = ipaddress.ip_network('2001:db8::0/96')\n>>> net6.netmask\nIPv6Address('ffff:ffff:ffff:ffff:ffff:ffff::')\n>>> net6.hostmask\nIPv6Address('::ffff:ffff')\n展开或压缩地址:\n>>> addr6.exploded\n'2001:0db8:0000:0000:0000:0000:0000:0001'\n>>> addr6.compressed\n'2001:db8::1'\n>>> net6.exploded\n'2001:0db8:0000:0000:0000:0000:0000:0000/96'\n>>> net6.compressed\n'2001:db8::/96'\n虽然IPv4不支持展开或压缩，但关联对象仍提供相关属性，因此版本中性代码可以轻松确保最简洁或\n最详细的形式用于IPv6地址，同时仍能正确处理IPv4地址。\nNetwork 作为 Address 列表\n将网络视为列表有时很有用。 这意味着它可以像这样索引它们:\n>>> net4[1]\nIPv4Address('192.0.2.1')\n>>> net4[-1]\nIPv4Address('192.0.2.255')\n>>> net6[1]\nIPv6Address('2001:db8::1')\n>>> net6[-1]\nIPv6Address('2001:db8::ffff:ffff')\n它还意味着网络对象可以使用像这样的列表成员测试语法:\nif address in network:\n# 执行某种操作\n根据网络前缀有效地完成包含性测试:\n>>> addr4 = ipaddress.ip_address('192.0.2.1')\n>>> addr4 in ipaddress.ip_network('192.0.2.0/24')\nTrue\n>>> addr4 in ipaddress.ip_network('192.0.3.0/24')\nFalse\n比较运算\n\n|  | >>> net4 = ipaddress.ip_network('192.0.2.0/24')\n>>> net4.netmask\nIPv4Address('255.255.255.0')\n>>> net4.hostmask\nIPv4Address('0.0.0.255')\n>>> net6 = ipaddress.ip_network('2001:db8::0/96')\n>>> net6.netmask\nIPv6Address('ffff:ffff:ffff:ffff:ffff:ffff::')\n>>> net6.hostmask\nIPv6Address('::ffff:ffff') |  |\n| --- | --- | --- |\n|  | 展开或压缩地址: |  |\n|  | >>> addr6.exploded\n'2001:0db8:0000:0000:0000:0000:0000:0001'\n>>> addr6.compressed\n'2001:db8::1'\n>>> net6.exploded\n'2001:0db8:0000:0000:0000:0000:0000:0000/96'\n>>> net6.compressed\n'2001:db8::/96' |  |\n|  | 虽然IPv4不支持展开或压缩，但关联对象仍提供相关属性，因此版本中性代码可以轻松确保最简洁或\n最详细的形式用于IPv6地址，同时仍能正确处理IPv4地址。\nNetwork 作为 Address 列表\n将网络视为列表有时很有用。 这意味着它可以像这样索引它们: |  |\n|  | >>> net4[1]\nIPv4Address('192.0.2.1')\n>>> net4[-1]\nIPv4Address('192.0.2.255')\n>>> net6[1]\nIPv6Address('2001:db8::1')\n>>> net6[-1]\nIPv6Address('2001:db8::ffff:ffff') |  |\n|  | 它还意味着网络对象可以使用像这样的列表成员测试语法: |  |\n|  | if address in network:\n# 执行某种操作 |  |\n|  | 根据网络前缀有效地完成包含性测试: |  |\n|  | >>> addr4 = ipaddress.ip_address('192.0.2.1')\n>>> addr4 in ipaddress.ip_network('192.0.2.0/24')\nTrue\n>>> addr4 in ipaddress.ip_network('192.0.3.0/24')\nFalse |  |\n|  | 比较运算 |  |\n\nipaddress 有意义地提供了一些简单、希望直观的比较对象的方法:\n>>> ipaddress.ip_address('192.0.2.1') < ipaddress.ip_address('192.0.2.2')\nTrue\n如果你尝试比较不同版本或不同类型的对象，则会引发 TypeError 异常。\n将IP地址与其他模块一起使用\n其他使用IP地址的模块（例如 socket ）通常不会直接接受来自该模块的对象。 相反，它们必须被\n强制转换为另一个模块可接受的整数或字符串:\n>>> addr4 = ipaddress.ip_address('192.0.2.1')\n>>> str(addr4)\n'192.0.2.1'\n>>> int(addr4)\n3221225985\n实例创建失败时获取更多详细信息\n使用与版本无关的工厂函数创建 address/network/interface 对象时，任何错误都将报告为\nValueError ，带有一般错误消息，只是说传入的值未被识别为该类型的对象。 缺少特定错误是因\n为有必要知道该值是*假设*是IPv4还是IPv6，以便提供有关其被拒绝原因的更多详细信息。\n为了支持访问这些额外细节的用例，各个类构造函数实际上引发了 ValueError 子类\nipaddress.AddressValueError 和 ipaddress.NetmaskValueError 以准确指示定义的哪一部分无\n法正确解析。\n直接使用类构造函数时，错误消息更加详细。 例如:\n>>> ipaddress.ip_address(\"192.168.0.256\")\nTraceback (most recent call last):\n...\nValueError: '192.168.0.256' does not appear to be an IPv4 or IPv6 address\n>>> ipaddress.IPv4Address(\"192.168.0.256\")\nTraceback (most recent call last):\n...\nipaddress.AddressValueError: Octet 256 (> 255) not permitted in '192.168.0.256'\n>>> ipaddress.ip_network(\"192.168.0.1/64\")\nTraceback (most recent call last):\n...\nValueError: '192.168.0.1/64' does not appear to be an IPv4 or IPv6 network\n>>> ipaddress.IPv4Network(\"192.168.0.1/64\")\nTraceback (most recent call last):\n...\nipaddress.NetmaskValueError: '64' is not a valid netmask\n但是，两个模块特定的异常都有 ValueError 作为它们的父类，所以如果你不关心特定类型的错\n误，你仍然可以编写如下代码:\n\n|  | ipaddress 有意义地提供了一些简单、希望直观的比较对象的方法: |  |\n| --- | --- | --- |\n|  | >>> ipaddress.ip_address('192.0.2.1') < ipaddress.ip_address('192.0.2.2')\nTrue |  |\n|  | 如果你尝试比较不同版本或不同类型的对象，则会引发 TypeError 异常。\n将IP地址与其他模块一起使用\n其他使用IP地址的模块（例如 socket ）通常不会直接接受来自该模块的对象。 相反，它们必须被\n强制转换为另一个模块可接受的整数或字符串: |  |\n|  | >>> addr4 = ipaddress.ip_address('192.0.2.1')\n>>> str(addr4)\n'192.0.2.1'\n>>> int(addr4)\n3221225985 |  |\n|  | 实例创建失败时获取更多详细信息\n使用与版本无关的工厂函数创建 address/network/interface 对象时，任何错误都将报告为\nValueError ，带有一般错误消息，只是说传入的值未被识别为该类型的对象。 缺少特定错误是因\n为有必要知道该值是*假设*是IPv4还是IPv6，以便提供有关其被拒绝原因的更多详细信息。\n为了支持访问这些额外细节的用例，各个类构造函数实际上引发了 ValueError 子类\nipaddress.AddressValueError 和 ipaddress.NetmaskValueError 以准确指示定义的哪一部分无\n法正确解析。\n直接使用类构造函数时，错误消息更加详细。 例如: |  |\n|  | >>> ipaddress.ip_address(\"192.168.0.256\")\nTraceback (most recent call last):\n...\nValueError: '192.168.0.256' does not appear to be an IPv4 or IPv6 address\n>>> ipaddress.IPv4Address(\"192.168.0.256\")\nTraceback (most recent call last):\n...\nipaddress.AddressValueError: Octet 256 (> 255) not permitted in '192.168.0.256'\n>>> ipaddress.ip_network(\"192.168.0.1/64\")\nTraceback (most recent call last):\n...\nValueError: '192.168.0.1/64' does not appear to be an IPv4 or IPv6 network\n>>> ipaddress.IPv4Network(\"192.168.0.1/64\")\nTraceback (most recent call last):\n...\nipaddress.NetmaskValueError: '64' is not a valid netmask |  |\n|  | 但是，两个模块特定的异常都有 ValueError 作为它们的父类，所以如果你不关心特定类型的错\n误，你仍然可以编写如下代码: |  |\n\ntry:\nnetwork = ipaddress.IPv4Network(address)\nexcept ValueError:\nprint('address/netmask is invalid for IPv4:', address)\n\n| try:\nnetwork = ipaddress.IPv4Network(address)\nexcept ValueError:\nprint('address/netmask is invalid for IPv4:', address) |\n| --- |\n|  |", "metadata": {"title": "07_ipaddress模块介绍", "source": "md_docs\\python_howto_md\\07_ipaddress模块介绍.md", "doc_type": "指南", "language": "中文", "doc_id": "05482666"}}
{"doc_id": "11679574", "content": "日志指南\n作者: Vinay Sajip <vinay_sajip at red-dove dot com>\n本页面包含教学信息。 要获取参考信息和日志记录指导书的链接，请查看 其他资源。\n日志基础教程\n日志是对软件执行时所发生事件的一种追踪方式。软件开发人员对他们的代码添加日志调用，借此来指示某事件的发生。一个事件通\n过一些包含变量数据的描述信息来描述（比如：每个事件发生时的数据都是不同的）。开发者还会区分事件的重要性，重要性也被称\n为 等级 或 严重性。\n什么时候使用日志\n你可以通过执行 logger = getLogger(__name__) 创建一个日志记录器然后调用日志记录器的 debug(), info(), warning(),\nerror() 和 critical() 方法来使用日志记录功能。 要确定何时使用日志记录，以及确定要使用哪个日志记录器方法，请参阅下\n表。 它针对一组常见任务中的每一个都列出了最适合该任务的工具。\n你想要执行的任务 此任务最好的工具\n对于命令行或程序的应用，结果显示在控制台。 print()\n在对程序的普通操作发生时提交事件报告(比如：状 日志记录器的 info() (或者对于诊断目的需要非常详细的输出时则使用\n态监控和错误调查) debug() 方法)\nwarnings.warn() 位于代码库中，该事件是可以避免的，需要修改客户端\n应用以消除告警\n提出一个警告信息基于一个特殊的运行时事件\n对于客户端应用无法干预，但事件仍然需要被关注的场合则使用日志记录\n器的 warning() 方法\n对一个特殊的运行时事件报告错误 引发异常\n报告错误而不引发异常(如在长时间运行中的服务端 日志记录器的 error(), exception() 或 critical() 方法分别适用于特\n进程的错误处理) 定的错误及应用领域\n日志记录器方法以它们所追踪的事件级别或严重程度来命名。 标准的级别及其适用性如下所述（严重程序从低至高）：\n级别 何时使用\nDEBUG 细节信息，仅当诊断问题时适用。\nINFO 确认程序按预期运行。\nWARNING 表明有已经或即将发生的意外（例如：磁盘空间不足）。程序仍按预期进行。\nERROR 由于严重的问题，程序的某些功能已经不能正常执行\nCRITICAL 严重的错误，表明程序已不能继续执行\n默认的级别是 WARNING，意味着只会追踪该严重程度及以上的事件，除非 logging 包另有其他配置。\n所追踪事件可以以不同形式处理。最简单的方式是输出到控制台。另一种常用的方式是写入磁盘文件。\n一个简单的例子\n一个非常简单的例子:\nimport logging\nlogging.warning('Watch out!') # 将打印一条消息到控制台\nlogging.info('I told you so') # 将不打印任何消息\n\n| 日志指南\n作者: Vinay Sajip <vinay_sajip at red-dove dot com>\n本页面包含教学信息。 要获取参考信息和日志记录指导书的链接，请查看 其他资源。\n日志基础教程\n日志是对软件执行时所发生事件的一种追踪方式。软件开发人员对他们的代码添加日志调用，借此来指示某事件的发生。一个事件通\n过一些包含变量数据的描述信息来描述（比如：每个事件发生时的数据都是不同的）。开发者还会区分事件的重要性，重要性也被称\n为 等级 或 严重性。\n什么时候使用日志\n你可以通过执行 logger = getLogger(__name__) 创建一个日志记录器然后调用日志记录器的 debug(), info(), warning(),\nerror() 和 critical() 方法来使用日志记录功能。 要确定何时使用日志记录，以及确定要使用哪个日志记录器方法，请参阅下\n表。 它针对一组常见任务中的每一个都列出了最适合该任务的工具。 |  |\n| --- | --- |\n| 你想要执行的任务 | 此任务最好的工具 |\n| 对于命令行或程序的应用，结果显示在控制台。 | print() |\n| 在对程序的普通操作发生时提交事件报告(比如：状\n态监控和错误调查) | 日志记录器的 info() (或者对于诊断目的需要非常详细的输出时则使用\ndebug() 方法) |\n| 提出一个警告信息基于一个特殊的运行时事件 | warnings.warn() 位于代码库中，该事件是可以避免的，需要修改客户端\n应用以消除告警\n对于客户端应用无法干预，但事件仍然需要被关注的场合则使用日志记录\n器的 warning() 方法 |\n| 对一个特殊的运行时事件报告错误 | 引发异常 |\n| 报告错误而不引发异常(如在长时间运行中的服务端\n进程的错误处理) | 日志记录器的 error(), exception() 或 critical() 方法分别适用于特\n定的错误及应用领域 |\n| 日志记录器方法以它们所追踪的事件级别或严重程度来命名。 标准的级别及其适用性如下所述（严重程序从低至高）：\n级别 何时使用\nDEBUG 细节信息，仅当诊断问题时适用。\nINFO 确认程序按预期运行。\nWARNING 表明有已经或即将发生的意外（例如：磁盘空间不足）。程序仍按预期进行。\nERROR 由于严重的问题，程序的某些功能已经不能正常执行\nCRITICAL 严重的错误，表明程序已不能继续执行\n默认的级别是 WARNING，意味着只会追踪该严重程度及以上的事件，除非 logging 包另有其他配置。\n所追踪事件可以以不同形式处理。最简单的方式是输出到控制台。另一种常用的方式是写入磁盘文件。\n一个简单的例子\n一个非常简单的例子: |  |\n| import logging\nlogging.warning('Watch out!') # 将打印一条消息到控制台\nlogging.info('I told you so') # 将不打印任何消息 |  |\n|  |  |\n\n| 级别 | 何时使用 |\n| --- | --- |\n| DEBUG | 细节信息，仅当诊断问题时适用。 |\n| INFO | 确认程序按预期运行。 |\n| WARNING | 表明有已经或即将发生的意外（例如：磁盘空间不足）。程序仍按预期进行。 |\n| ERROR | 由于严重的问题，程序的某些功能已经不能正常执行 |\n| CRITICAL | 严重的错误，表明程序已不能继续执行 |\n\n如果你在命令行中输入这些代码并运行，你将会看到：\nWARNING:root:Watch out!\n在控制台上打印出来。 INFO 消息没有出现是因为默认级别为 WARNING。 打印的消息包括在日志记录调用中提供的事件级别和描述\n信息，例如 'Watch out!'。 实际输出可以按你的需要相当灵活地格式化；格式化选项也将在后文中进行说明。\n请注意在这个例子中，我们是直接使用 logging 模块的函数，比如 logging.debug，而不是创建一个日志记录器并调用其方法。 这\n些函数作用于根日志记录器，但它们在未被调用时将会调用 basicConfig() 来发挥作用，就像在这个例子中那样。 然而在更大的程\n序中你通常会需要显式地控制日志记录的配置 —— 所以出于这样那样的理由，最好还是创建日志记录器并调用其方法。\n记录日志到文件\n一种很常见的情况是将日志事件记录到文件中，下面让我们来看这个问题。 请确认在一个新启动的 Python 解释器中尝试以下操作，\n而非在上面描述的会话中继续:\nimport logging\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(filename='example.log', encoding='utf-8', level=logging.DEBUG)\nlogger.debug('This message should go to the log file')\nlogger.info('So should this')\nlogger.warning('And this, too')\nlogger.error('And non-ASCII stuff, too, like Øresund and Malmö')\n在 3.9 版本发生变更: 增加了 encoding 参数。在更早的 Python 版本中或没有指定时，编码会用 open() 使用的默认值。尽管在\n上面的例子中没有展示，但也可以传入一个决定如何处理编码错误的 errors 参数。可使用的值和默认值，请参照 open() 的文\n档。\n现在，如果我们打开日志文件，我们应当能看到日志信息：\nDEBUG:__main__:This message should go to the log file\nINFO:__main__:So should this\nWARNING:__main__:And this, too\nERROR:__main__:And non-ASCII stuff, too, like Øresund and Malmö\n该示例同样展示了如何设置日志追踪级别的阈值。该示例中，由于我们设置的阈值是 DEBUG，所有信息都将被打印。\n如果你想从命令行设置日志级别，例如：\n--log=INFO\n并且你将 --log 命令的参数存进了变量 loglevel，你可以用：\ngetattr(logging, loglevel.upper())\n获取要通过 level 参数传给 basicConfig() 的值。可如下对用户输入值进行错误检查：\n# 假定 loglevel 绑定到从命令行参数获取的字符串值。\n# 转换为大写形式以允许用户指定 --log=DEBUG 或 --log=debug\nnumeric_level = getattr(logging, loglevel.upper(), None)\nif not isinstance(numeric_level, int):\nraise ValueError('Invalid log level: %s' % loglevel)\nlogging.basicConfig(level=numeric_level, ...)\n对 basicConfig() 的调用应当在任何对日志记录器方法的调用如 debug(), info() 等 之前 执行。 否则，日志记录事件可能无法以\n预期的方式来处理。\n如果多次运行上述脚本，则连续运行的消息将追加到文件 example.log 。 如果你希望每次运行重新开始，而不是记住先前运行的消\n息，则可以通过将上例中的调用更改为来指定 filemode 参数:\nlogging.basicConfig(filename='example.log', filemode='w', level=logging.DEBUG)\n输出将与之前相同，但不再追加进日志文件，因此早期运行的消息将丢失。\n记录变量数据\n要记录变量数据，请使用格式字符串作为事件描述消息，并附加传入变量数据作为参数。 例如:\n\n|  | 如果你在命令行中输入这些代码并运行，你将会看到： |  |\n| --- | --- | --- |\n|  | WARNING:root:Watch out! |  |\n|  | 在控制台上打印出来。 INFO 消息没有出现是因为默认级别为 WARNING。 打印的消息包括在日志记录调用中提供的事件级别和描述\n信息，例如 'Watch out!'。 实际输出可以按你的需要相当灵活地格式化；格式化选项也将在后文中进行说明。\n请注意在这个例子中，我们是直接使用 logging 模块的函数，比如 logging.debug，而不是创建一个日志记录器并调用其方法。 这\n些函数作用于根日志记录器，但它们在未被调用时将会调用 basicConfig() 来发挥作用，就像在这个例子中那样。 然而在更大的程\n序中你通常会需要显式地控制日志记录的配置 —— 所以出于这样那样的理由，最好还是创建日志记录器并调用其方法。\n记录日志到文件\n一种很常见的情况是将日志事件记录到文件中，下面让我们来看这个问题。 请确认在一个新启动的 Python 解释器中尝试以下操作，\n而非在上面描述的会话中继续: |  |\n|  | import logging\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(filename='example.log', encoding='utf-8', level=logging.DEBUG)\nlogger.debug('This message should go to the log file')\nlogger.info('So should this')\nlogger.warning('And this, too')\nlogger.error('And non-ASCII stuff, too, like Øresund and Malmö') |  |\n|  | 在 3.9 版本发生变更: 增加了 encoding 参数。在更早的 Python 版本中或没有指定时，编码会用 open() 使用的默认值。尽管在\n上面的例子中没有展示，但也可以传入一个决定如何处理编码错误的 errors 参数。可使用的值和默认值，请参照 open() 的文\n档。\n现在，如果我们打开日志文件，我们应当能看到日志信息： |  |\n|  | DEBUG:__main__:This message should go to the log file\nINFO:__main__:So should this\nWARNING:__main__:And this, too\nERROR:__main__:And non-ASCII stuff, too, like Øresund and Malmö |  |\n|  | 该示例同样展示了如何设置日志追踪级别的阈值。该示例中，由于我们设置的阈值是 DEBUG，所有信息都将被打印。\n如果你想从命令行设置日志级别，例如： |  |\n|  | --log=INFO |  |\n|  | 并且你将 --log 命令的参数存进了变量 loglevel，你可以用： |  |\n|  | getattr(logging, loglevel.upper()) |  |\n|  | 获取要通过 level 参数传给 basicConfig() 的值。可如下对用户输入值进行错误检查： |  |\n|  | # 假定 loglevel 绑定到从命令行参数获取的字符串值。\n# 转换为大写形式以允许用户指定 --log=DEBUG 或 --log=debug\nnumeric_level = getattr(logging, loglevel.upper(), None)\nif not isinstance(numeric_level, int):\nraise ValueError('Invalid log level: %s' % loglevel)\nlogging.basicConfig(level=numeric_level, ...) |  |\n|  | 对 basicConfig() 的调用应当在任何对日志记录器方法的调用如 debug(), info() 等 之前 执行。 否则，日志记录事件可能无法以\n预期的方式来处理。\n如果多次运行上述脚本，则连续运行的消息将追加到文件 example.log 。 如果你希望每次运行重新开始，而不是记住先前运行的消\n息，则可以通过将上例中的调用更改为来指定 filemode 参数: |  |\n|  | logging.basicConfig(filename='example.log', filemode='w', level=logging.DEBUG) |  |\n|  | 输出将与之前相同，但不再追加进日志文件，因此早期运行的消息将丢失。\n记录变量数据\n要记录变量数据，请使用格式字符串作为事件描述消息，并附加传入变量数据作为参数。 例如: |  |\n\nimport logging\nlogging.warning('%s before you %s', 'Look', 'leap!')\n将显示：\nWARNING:root:Look before you leap!\n如你所见，将可变数据合并到事件描述消息中使用旧的 %-s形式的字符串格式化。 这是为了向后兼容：logging 包的出现时间早于较\n新的格式化选项例如 str.format() 和 string.Template。 这些较新格式化选项 是 受支持的，但探索它们超出了本教程的范围：\n有关详细信息，请参阅 生效于整个应用程序的格式化样式。\n更改显示消息的格式\n要更改用于显示消息的格式，你需要指定要使用的格式:\nimport logging\nlogging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)\nlogging.debug('This message should appear on the console')\nlogging.info('So should this')\nlogging.warning('And this, too')\n这将输出：\nDEBUG:This message should appear on the console\nINFO:So should this\nWARNING:And this, too\n注意在前面例子中出现的 “root” 已消失。文档 LogRecord 属性 列出了可在格式字符串中出现的所有内容，但在简单的使用场景中，\n你只需要 levelname （严重性）、message （事件描述，包含可变的数据）或许再加上事件发生的时间。 这将在下一节中介绍。\n在消息中显示日期/时间\n要显示事件的日期和时间，你可以在格式字符串中放置 '%(asctime)s'\nimport logging\nlogging.basicConfig(format='%(asctime)s %(message)s')\nlogging.warning('is when this event was logged.')\n应该打印这样的东西：\n2010-12-12 11:41:42,612 is when this event was logged.\n日期/时间显示的默认格式（如上所示）类似于 ISO8601 或 RFC 3339 。 如果你需要更多地控制日期/时间的格式，请为\nbasicConfig 提供 datefmt 参数，如下例所示:\nimport logging\nlogging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')\nlogging.warning('is when this event was logged.')\n这会显示如下内容：\n12/12/2010 11:46:36 AM is when this event was logged.\ndatefmt 参数的格式与 time.strftime() 支持的格式相同。\n后续步骤\n基本教程到此结束。 它应该足以让你启动并运行日志记录。 logging 包提供了更多功能，但为了充分利用它，你需要花更多的时间\n来阅读以下部分。 如果你准备好了，可以拿一些你最喜欢的饮料然后继续。\n如果你的日志记录需求较为简单，那么可以使用上述示例将日志功能集成到你自己的脚本中。如果在操作过程中遇到问题或对某些内\n容不理解，你可以在 Python 讨论论坛 的“帮助”分类下发布问题，通常很快就会得到帮助。\n还不够？ 你可以继续阅读接下来的几个部分，这些部分提供了比上面基本部分更高级或深入的教程。 之后，你可以看一下 日志专题\n手册 。\n\n|  | import logging\nlogging.warning('%s before you %s', 'Look', 'leap!') |  |\n| --- | --- | --- |\n|  | 将显示： |  |\n|  | WARNING:root:Look before you leap! |  |\n|  | 如你所见，将可变数据合并到事件描述消息中使用旧的 %-s形式的字符串格式化。 这是为了向后兼容：logging 包的出现时间早于较\n新的格式化选项例如 str.format() 和 string.Template。 这些较新格式化选项 是 受支持的，但探索它们超出了本教程的范围：\n有关详细信息，请参阅 生效于整个应用程序的格式化样式。\n更改显示消息的格式\n要更改用于显示消息的格式，你需要指定要使用的格式: |  |\n|  | import logging\nlogging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)\nlogging.debug('This message should appear on the console')\nlogging.info('So should this')\nlogging.warning('And this, too') |  |\n|  | 这将输出： |  |\n|  | DEBUG:This message should appear on the console\nINFO:So should this\nWARNING:And this, too |  |\n|  | 注意在前面例子中出现的 “root” 已消失。文档 LogRecord 属性 列出了可在格式字符串中出现的所有内容，但在简单的使用场景中，\n你只需要 levelname （严重性）、message （事件描述，包含可变的数据）或许再加上事件发生的时间。 这将在下一节中介绍。\n在消息中显示日期/时间\n要显示事件的日期和时间，你可以在格式字符串中放置 '%(asctime)s' |  |\n|  | import logging\nlogging.basicConfig(format='%(asctime)s %(message)s')\nlogging.warning('is when this event was logged.') |  |\n|  | 应该打印这样的东西： |  |\n|  | 2010-12-12 11:41:42,612 is when this event was logged. |  |\n|  | 日期/时间显示的默认格式（如上所示）类似于 ISO8601 或 RFC 3339 。 如果你需要更多地控制日期/时间的格式，请为\nbasicConfig 提供 datefmt 参数，如下例所示: |  |\n|  | import logging\nlogging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')\nlogging.warning('is when this event was logged.') |  |\n|  | 这会显示如下内容： |  |\n|  | 12/12/2010 11:46:36 AM is when this event was logged. |  |\n|  | datefmt 参数的格式与 time.strftime() 支持的格式相同。\n后续步骤\n基本教程到此结束。 它应该足以让你启动并运行日志记录。 logging 包提供了更多功能，但为了充分利用它，你需要花更多的时间\n来阅读以下部分。 如果你准备好了，可以拿一些你最喜欢的饮料然后继续。\n如果你的日志记录需求较为简单，那么可以使用上述示例将日志功能集成到你自己的脚本中。如果在操作过程中遇到问题或对某些内\n容不理解，你可以在 Python 讨论论坛 的“帮助”分类下发布问题，通常很快就会得到帮助。\n还不够？ 你可以继续阅读接下来的几个部分，这些部分提供了比上面基本部分更高级或深入的教程。 之后，你可以看一下 日志专题\n手册 。 |  |\n\n进阶日志教程\n日志库采用模块化方法，并提供几类组件：记录器、处理器、过滤器和格式器。\n记录器暴露了应用程序代码直接使用的接口。\n处理器将日志记录（由记录器创建）发送到适当的目标。\n过滤器提供了更细粒度的功能，用于确定要输出的日志记录。\n格式器指定最终输出中日志记录的样式。\n日志事件信息在 LogRecord 实例中的记录器、处理器、过滤器和格式器之间传递。\n通过调用 Logger 类（以下称为 loggers ， 记录器）的实例来执行日志记录。 每个实例都有一个名称，它们在概念上以点（句点）作\n为分隔符排列在命名空间的层次结构中。 例如，名为 'scan' 的记录器是记录器 'scan.text' ，'scan.html' 和 'scan.pdf' 的父级。 记录器\n名称可以是你想要的任何名称，并指示记录消息源自的应用程序区域。\n在命名记录器时使用的一个好习惯是在每个使用日志记录的模块中使用模块级记录器，命名如下:\nlogger = logging.getLogger(__name__)\n这意味着记录器名称跟踪包或模块的层次结构，并且直观地从记录器名称显示记录事件的位置。\n记录器层次结构的根称为根记录器。 这是函数 debug() 、 info() 、 warning() 、 error() 和 critical() 使用的记录器，它们\n就是调用了根记录器的同名方法。 函数和方法具有相同的签名。 根记录器的名称在输出中打印为 'root' 。\n当然，可以将消息记录到不同的地方。 软件包中的支持包含，用于将日志消息写入文件、 HTTP GET/POST 位置、通过 SMTP 发送电\n子邮件、通用套接字、队列或特定于操作系统的日志记录机制（如 syslog 或 Windows NT 事件日志）。 目标由 handler 类提供。 如\n果你有任何内置处理器类未满足的特殊要求，则可以创建自己的日志目标类。\n默认情况下，没有为任何日志消息设置目标。 你可以使用 basicConfig() 指定目标（例如控制台或文件），如教程示例中所示。 如\n果你调用函数 debug() 、 info() 、 warning() 、 error() 和 critical() ，它们将检查是否有设置目标；如果没有设置，将在委\n托给根记录器进行实际的消息输出之前设置目标为控制台（ sys.stderr ）并设置显示消息的默认格式。\n由 basicConfig() 设置的消息默认格式为：\n严重等级:日志记录器名称:消息\n你可以通过使用 format 参数将格式字符串传递给 basicConfig() 来更改此设置。有关如何构造格式字符串的所有选项，请参阅 格\n式器对象 。\n记录流程\n记录器和处理器中的日志事件信息流程如下图所示。\n\n|  | 进阶日志教程\n日志库采用模块化方法，并提供几类组件：记录器、处理器、过滤器和格式器。\n记录器暴露了应用程序代码直接使用的接口。\n处理器将日志记录（由记录器创建）发送到适当的目标。\n过滤器提供了更细粒度的功能，用于确定要输出的日志记录。\n格式器指定最终输出中日志记录的样式。\n日志事件信息在 LogRecord 实例中的记录器、处理器、过滤器和格式器之间传递。\n通过调用 Logger 类（以下称为 loggers ， 记录器）的实例来执行日志记录。 每个实例都有一个名称，它们在概念上以点（句点）作\n为分隔符排列在命名空间的层次结构中。 例如，名为 'scan' 的记录器是记录器 'scan.text' ，'scan.html' 和 'scan.pdf' 的父级。 记录器\n名称可以是你想要的任何名称，并指示记录消息源自的应用程序区域。\n在命名记录器时使用的一个好习惯是在每个使用日志记录的模块中使用模块级记录器，命名如下: |  |\n| --- | --- | --- |\n|  | logger = logging.getLogger(__name__) |  |\n|  | 这意味着记录器名称跟踪包或模块的层次结构，并且直观地从记录器名称显示记录事件的位置。\n记录器层次结构的根称为根记录器。 这是函数 debug() 、 info() 、 warning() 、 error() 和 critical() 使用的记录器，它们\n就是调用了根记录器的同名方法。 函数和方法具有相同的签名。 根记录器的名称在输出中打印为 'root' 。\n当然，可以将消息记录到不同的地方。 软件包中的支持包含，用于将日志消息写入文件、 HTTP GET/POST 位置、通过 SMTP 发送电\n子邮件、通用套接字、队列或特定于操作系统的日志记录机制（如 syslog 或 Windows NT 事件日志）。 目标由 handler 类提供。 如\n果你有任何内置处理器类未满足的特殊要求，则可以创建自己的日志目标类。\n默认情况下，没有为任何日志消息设置目标。 你可以使用 basicConfig() 指定目标（例如控制台或文件），如教程示例中所示。 如\n果你调用函数 debug() 、 info() 、 warning() 、 error() 和 critical() ，它们将检查是否有设置目标；如果没有设置，将在委\n托给根记录器进行实际的消息输出之前设置目标为控制台（ sys.stderr ）并设置显示消息的默认格式。\n由 basicConfig() 设置的消息默认格式为： |  |\n|  | 严重等级:日志记录器名称:消息 |  |\n|  | 你可以通过使用 format 参数将格式字符串传递给 basicConfig() 来更改此设置。有关如何构造格式字符串的所有选项，请参阅 格\n式器对象 。\n记录流程\n记录器和处理器中的日志事件信息流程如下图所示。 |  |\n\nLogging call in user\nLogger flow code, e.g. Handler flow Record passed\nlogger.info(...) to handler\nLogger enabled for No Stop Handler enabled for No Stop\nlevel of call? level of record?\nYes Yes\nCreate\nLogRecord\nDoes a filter attached Yes\nto handler reject the\nrecord?\nNo\nDoes a filter attached Yes\nto logger reject the Emit (includes formatting)\nrecord?\nNo\nPass record to\nhandlers of At least one handler Yes\ncurrent logger in hierarchy?\nSet current\nlogger to parent No\nUse lastResort\nhandler\nIs propagate true for No\ncurrent logger?\nYes\nYes No\nIs there a parent\nlogger?\n记录器\nLogger 对象有三重任务。首先，它们向应用程序代码公开了几种方法，以便应用程序可以在运行时记录消息。其次，记录器对象根\n据严重性（默认过滤工具）或过滤器对象确定要处理的日志消息。第三，记录器对象将相关的日志消息传递给所有感兴趣的日志处理\n器。\n记录器对象上使用最广泛的方法分为两类：配置和消息发送。\n这些是最常见的配置方法：\nLogger.setLevel() 指定记录器将处理的最低严重性日志消息，其中 debug 是最低内置严重性级别， critical 是最高内置严重性\n级别。 例如，如果严重性级别为 INFO ，则记录器将仅处理 INFO 、 WARNING 、 ERROR 和 CRITICAL 消息，并将忽略 DEBUG 消\n息。\nLogger.addHandler() 和 Logger.removeHandler() 从记录器对象中添加和删除处理器对象。处理器在以下内容中有更详细的介\n绍 处理器 。\nLogger.addFilter() 和 Logger.removeFilter() 可以添加或移除记录器对象中的过滤器。 过滤器对象 包含更多的过滤器细\n节。\n你不需要总是在你创建的每个记录器上都调用这些方法。 请参阅本节的最后两段。\n\n|  | Logging call in user\nLogger flow code, e.g. Handler flow R\nlogger.info(...)\nLogger enabled for No Stop Handler enable\nlevel of call? level of recor\nYes Yes\nCreate\nLogRecord\nDoes a filter atta\nto handler rejec\nrecord?\nNo\nDoes a filter attached Yes\nto logger reject the Emit (includes for\nrecord?\nNo\nPass record to\nhandlers of At least one handler Y\ncurrent logger in hierarchy?\nSet current\nlogger to parent No\nUse lastRe\nhandl\nIs propagate true for No\ncurrent logger?\nYes\nYes No\nIs there a parent\nlogger?\n记录器\nLogger 对象有三重任务。首先，它们向应用程序代码公开了几种方法，以便应用程序可以在运行时记录\n据严重性（默认过滤工具）或过滤器对象确定要处理的日志消息。第三，记录器对象将相关的日志消息\n器。\n记录器对象上使用最广泛的方法分为两类：配置和消息发送。\n这些是最常见的配置方法：\nLogger.setLevel() 指定记录器将处理的最低严重性日志消息，其中 debug 是最低内置严重性级别\n级别。 例如，如果严重性级别为 INFO ，则记录器将仅处理 INFO 、 WARNING 、 ERROR 和 CRITICA\n息。\nLogger.addHandler() 和 Logger.removeHandler() 从记录器对象中添加和删除处理器对象。处理\n绍 处理器 。\nLogger.addFilter() 和 Logger.removeFilter() 可以添加或移除记录器对象中的过滤器。 过滤器\n节。\n你不需要总是在你创建的每个记录器上都调用这些方法。 请参阅本节的最后两段。 |\n| --- | --- |\n\n配置记录器对象后，以下方法将创建日志消息：\nLogger.debug() 、 Logger.info() 、 Logger.warning() 、 Logger.error() 和 Logger.critical() 都创建日志记录，包含\n消息和与其各自方法名称对应的级别。该消息实际上是一个格式化字符串，它可能包含标题字符串替换语法 %s 、 %d 、 %f 等\n等。其余参数是与消息中的替换字段对应的对象列表。关于 **kwargs ，日志记录方法只关注 exc_info 的关键字，并用它来确定\n是否记录异常信息。\nLogger.exception() 创建与 Logger.error() 相似的日志信息。 不同之处是， Logger.exception() 同时还记录当前的堆栈追\n踪。仅从异常处理程序调用此方法。\nLogger.log() 将日志级别作为显式参数。对于记录消息而言，这比使用上面列出的日志级别便利方法更加冗长，但这是使用自定\n义日志级别的方法。\ngetLogger() 返回对具有指定名称的记录器实例的引用（如果已提供），或者如果没有则返回 root 。名称是以句点分隔的层次结\n构。多次调用 getLogger() 具有相同的名称将返回对同一记录器对象的引用。在分层列表中较低的记录器是列表中较高的记录器的\n子项。例如，给定一个名为 foo 的记录器，名称为 foo.bar 、 foo.bar.baz 和 foo.bam 的记录器都是 foo 子项。\n记录器具有 有效等级 的概念。如果未在记录器上显式设置级别，则使用其父记录器的级别作为其有效级别。如果父记录器没有明确\n的级别设置，则检查 其 父级。依此类推，搜索所有上级元素，直到找到明确设置的级别。根记录器始终具有明确的级别配置（默认\n情况下为 WARNING ）。在决定是否处理事件时，记录器的有效级别用于确定事件是否传递给记录器相关的处理器。\n子记录器将消息传播到与其父级记录器关联的处理器。因此，不必为应用程序使用的所有记录器定义和配置处理器。一般为顶级记录\n器配置处理器，再根据需要创建子记录器就足够了。（但是，你可以通过将记录器的 propagate 属性设置为 False 来关闭传播。）\n处理器\nHandler 对象负责将适当的日志消息（基于日志消息的严重性）分派给处理器的指定目标。 Logger 对象可以使用 addHandler() 方\n法向自己添加零个或多个处理器对象。作为示例场景，应用程序可能希望将所有日志消息发送到日志文件，将错误或更高的所有日志\n消息发送到标准输出，以及将所有关键消息发送至一个邮件地址。 此方案需要三个单独的处理器，其中每个处理器负责将特定严重\n性的消息发送到特定位置。\n标准库包含很多处理器类型（参见 有用的处理器 ）；教程主要使用 StreamHandler 和 FileHandler 。\n处理器中很少有方法可供应用程序开发人员使用。使用内置处理器对象（即不创建自定义处理器）的应用程序开发人员能用到的仅有\n以下配置方法：\nsetLevel() 方法，就像在日志记录器对象中一样，指定将被分派到适当目标的最低严重性。 为什么有两个 setLevel() 方法？\n在日志记录器中设置的级别确定要传递给其处理器的消息的严重性。 每个处理器中设置的级别则确定该处理器将发送哪些消息。\nsetFormatter() 选择一个该处理器使用的 Formatter 对象。\naddFilter() 和 removeFilter() 分别在处理器上配置和取消配置过滤器对象。\n应用程序代码不应直接实例化并使用 Handler 的实例。 相反， Handler 类是一个基类，它定义了所有处理器应该具有的接口，并建\n立了子类可以使用（或覆盖）的一些默认行为。\n格式器\n格式化器对象配置日志消息的最终顺序、结构和内容。 与 logging.Handler 类不同，应用程序代码可以实例化格式器类，但如果应\n用程序需要特殊行为，则可能会对格式化器进行子类化定制。构造函数有三个可选参数 —— 消息格式字符串、日期格式字符串和样\n式指示符。\nlogging.Formatter.__init__(fmt=None, datefmt=None, style='%')\n如果没有消息格式字符串，则默认使用原始消息。如果没有日期格式字符串，则默认日期格式为：\n%Y-%m-%d %H:%M:%S\n在末尾加上毫秒数。 style 是 '%', '{' 或 '{TX-PL-LABEL}#x27; 之一。 如果未指定其中之一，则将使用 '%'。\n如果 style 为 '%'，则消息格式字符串将使用 %(<dictionary key>)s 样式的字符串替换；可用的键值记录在 LogRecord 属性 中。\n如果样式为 '{'，则将假定消息格式字符串与 str.format() 兼容（使用关键字参数），而如果样式为 '{TX-PL-LABEL}#x27; 则消\n息格式字符串应当符合 string.Template.substitute() 的预期。\n在 3.2 版本发生变更: 添加 style 形参。\n以下消息格式字符串将以人类可读的格式记录时间、消息的严重性以及消息的内容，按此顺序:\n\n|  | 配置记录器对象后，以下方法将创建日志消息：\nLogger.debug() 、 Logger.info() 、 Logger.warning() 、 Logger.error() 和 Logger.critical() 都创建日志记录，包含\n消息和与其各自方法名称对应的级别。该消息实际上是一个格式化字符串，它可能包含标题字符串替换语法 %s 、 %d 、 %f 等\n等。其余参数是与消息中的替换字段对应的对象列表。关于 **kwargs ，日志记录方法只关注 exc_info 的关键字，并用它来确定\n是否记录异常信息。\nLogger.exception() 创建与 Logger.error() 相似的日志信息。 不同之处是， Logger.exception() 同时还记录当前的堆栈追\n踪。仅从异常处理程序调用此方法。\nLogger.log() 将日志级别作为显式参数。对于记录消息而言，这比使用上面列出的日志级别便利方法更加冗长，但这是使用自定\n义日志级别的方法。\ngetLogger() 返回对具有指定名称的记录器实例的引用（如果已提供），或者如果没有则返回 root 。名称是以句点分隔的层次结\n构。多次调用 getLogger() 具有相同的名称将返回对同一记录器对象的引用。在分层列表中较低的记录器是列表中较高的记录器的\n子项。例如，给定一个名为 foo 的记录器，名称为 foo.bar 、 foo.bar.baz 和 foo.bam 的记录器都是 foo 子项。\n记录器具有 有效等级 的概念。如果未在记录器上显式设置级别，则使用其父记录器的级别作为其有效级别。如果父记录器没有明确\n的级别设置，则检查 其 父级。依此类推，搜索所有上级元素，直到找到明确设置的级别。根记录器始终具有明确的级别配置（默认\n情况下为 WARNING ）。在决定是否处理事件时，记录器的有效级别用于确定事件是否传递给记录器相关的处理器。\n子记录器将消息传播到与其父级记录器关联的处理器。因此，不必为应用程序使用的所有记录器定义和配置处理器。一般为顶级记录\n器配置处理器，再根据需要创建子记录器就足够了。（但是，你可以通过将记录器的 propagate 属性设置为 False 来关闭传播。）\n处理器\nHandler 对象负责将适当的日志消息（基于日志消息的严重性）分派给处理器的指定目标。 Logger 对象可以使用 addHandler() 方\n法向自己添加零个或多个处理器对象。作为示例场景，应用程序可能希望将所有日志消息发送到日志文件，将错误或更高的所有日志\n消息发送到标准输出，以及将所有关键消息发送至一个邮件地址。 此方案需要三个单独的处理器，其中每个处理器负责将特定严重\n性的消息发送到特定位置。\n标准库包含很多处理器类型（参见 有用的处理器 ）；教程主要使用 StreamHandler 和 FileHandler 。\n处理器中很少有方法可供应用程序开发人员使用。使用内置处理器对象（即不创建自定义处理器）的应用程序开发人员能用到的仅有\n以下配置方法：\nsetLevel() 方法，就像在日志记录器对象中一样，指定将被分派到适当目标的最低严重性。 为什么有两个 setLevel() 方法？\n在日志记录器中设置的级别确定要传递给其处理器的消息的严重性。 每个处理器中设置的级别则确定该处理器将发送哪些消息。\nsetFormatter() 选择一个该处理器使用的 Formatter 对象。\naddFilter() 和 removeFilter() 分别在处理器上配置和取消配置过滤器对象。\n应用程序代码不应直接实例化并使用 Handler 的实例。 相反， Handler 类是一个基类，它定义了所有处理器应该具有的接口，并建\n立了子类可以使用（或覆盖）的一些默认行为。\n格式器\n格式化器对象配置日志消息的最终顺序、结构和内容。 与 logging.Handler 类不同，应用程序代码可以实例化格式器类，但如果应\n用程序需要特殊行为，则可能会对格式化器进行子类化定制。构造函数有三个可选参数 —— 消息格式字符串、日期格式字符串和样\n式指示符。\nlogging.Formatter.__init__(fmt=None, datefmt=None, style='%')\n如果没有消息格式字符串，则默认使用原始消息。如果没有日期格式字符串，则默认日期格式为： |  |\n| --- | --- | --- |\n|  | %Y-%m-%d %H:%M:%S |  |\n|  | 在末尾加上毫秒数。 style 是 '%', '{' 或 '{TX-PL-LABEL}#x27; 之一。 如果未指定其中之一，则将使用 '%'。\n如果 style 为 '%'，则消息格式字符串将使用 %(<dictionary key>)s 样式的字符串替换；可用的键值记录在 LogRecord 属性 中。\n如果样式为 '{'，则将假定消息格式字符串与 str.format() 兼容（使用关键字参数），而如果样式为 '{TX-PL-LABEL}#x27; 则消\n息格式字符串应当符合 string.Template.substitute() 的预期。\n在 3.2 版本发生变更: 添加 style 形参。\n以下消息格式字符串将以人类可读的格式记录时间、消息的严重性以及消息的内容，按此顺序: |  |\n\n'%(asctime)s - %(levelname)s - %(message)s'\n格式器通过用户可配置的函数将记录的创建时间转换为元组。 默认情况下，使用 time.localtime() ；要为特定格式器实例更改此\n项，请将实例的 converter 属性设置为与 time.localtime() 或 time.gmtime() 具有相同签名的函数。 要为所有格式器更改它，\n例如，如果你希望所有记录时间都以 GMT 显示，请在格式器类中设置 converter 属性（对于 GMT 显示，设置为 time.gmtime\n）。\n配置日志记录\n开发者可以通过三种方式配置日志记录：\n1. 使用调用上面列出的配置方法的 Python 代码显式创建记录器、处理器和格式器。\n2. 创建日志配置文件并使用 fileConfig() 函数读取它。\n3. 创建配置信息字典并将其传递给 dictConfig() 函数。\n有关最后两个选项的参考文档，请参阅 配置函数 。 以下示例使用 Python 代码配置一个非常简单的记录器、一个控制台处理器和一\n个简单的格式器:\nimport logging\n# 创建日志记录器 logger\nlogger = logging.getLogger('simple_example')\nlogger.setLevel(logging.DEBUG)\n# 创建控制台处理器 ch 并将等级设为 debug\nch = logging.StreamHandler()\nch.setLevel(logging.DEBUG)\n# 创建格式化器 formatter\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n# 将 formatter 添加到 ch\nch.setFormatter(formatter)\n# 将 ch 添加到 logger\nlogger.addHandler(ch)\n# '应用程序' 代码\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warn message')\nlogger.error('error message')\nlogger.critical('critical message')\n从命令行运行此模块将生成以下输出：\n$ python simple_logging_module.py\n2005-03-19 15:10:26,618 - simple_example - DEBUG - debug message\n2005-03-19 15:10:26,620 - simple_example - INFO - info message\n2005-03-19 15:10:26,695 - simple_example - WARNING - warn message\n2005-03-19 15:10:26,697 - simple_example - ERROR - error message\n2005-03-19 15:10:26,773 - simple_example - CRITICAL - critical message\n以下 Python 模块创建的记录器、处理器和格式器几乎与上面列出的示例中的相同，唯一的区别是对象的名称:\nimport logging\nimport logging.config\nlogging.config.fileConfig('logging.conf')\n# 创建日志记录器 logger\nlogger = logging.getLogger('simpleExample')\n# '应用程序' 代码\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warn message')\nlogger.error('error message')\nlogger.critical('critical message')\n这是 logging.conf 文件：\n\n|  | '%(asctime)s - %(levelname)s - %(message)s' |  |\n| --- | --- | --- |\n|  | 格式器通过用户可配置的函数将记录的创建时间转换为元组。 默认情况下，使用 time.localtime() ；要为特定格式器实例更改此\n项，请将实例的 converter 属性设置为与 time.localtime() 或 time.gmtime() 具有相同签名的函数。 要为所有格式器更改它，\n例如，如果你希望所有记录时间都以 GMT 显示，请在格式器类中设置 converter 属性（对于 GMT 显示，设置为 time.gmtime\n）。\n配置日志记录\n开发者可以通过三种方式配置日志记录：\n1. 使用调用上面列出的配置方法的 Python 代码显式创建记录器、处理器和格式器。\n2. 创建日志配置文件并使用 fileConfig() 函数读取它。\n3. 创建配置信息字典并将其传递给 dictConfig() 函数。\n有关最后两个选项的参考文档，请参阅 配置函数 。 以下示例使用 Python 代码配置一个非常简单的记录器、一个控制台处理器和一\n个简单的格式器: |  |\n|  | import logging\n# 创建日志记录器 logger\nlogger = logging.getLogger('simple_example')\nlogger.setLevel(logging.DEBUG)\n# 创建控制台处理器 ch 并将等级设为 debug\nch = logging.StreamHandler()\nch.setLevel(logging.DEBUG)\n# 创建格式化器 formatter\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n# 将 formatter 添加到 ch\nch.setFormatter(formatter)\n# 将 ch 添加到 logger\nlogger.addHandler(ch)\n# '应用程序' 代码\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warn message')\nlogger.error('error message')\nlogger.critical('critical message') |  |\n|  | 从命令行运行此模块将生成以下输出： |  |\n|  | $ python simple_logging_module.py\n2005-03-19 15:10:26,618 - simple_example - DEBUG - debug message\n2005-03-19 15:10:26,620 - simple_example - INFO - info message\n2005-03-19 15:10:26,695 - simple_example - WARNING - warn message\n2005-03-19 15:10:26,697 - simple_example - ERROR - error message\n2005-03-19 15:10:26,773 - simple_example - CRITICAL - critical message |  |\n|  | 以下 Python 模块创建的记录器、处理器和格式器几乎与上面列出的示例中的相同，唯一的区别是对象的名称: |  |\n|  | import logging\nimport logging.config\nlogging.config.fileConfig('logging.conf')\n# 创建日志记录器 logger\nlogger = logging.getLogger('simpleExample')\n# '应用程序' 代码\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warn message')\nlogger.error('error message')\nlogger.critical('critical message') |  |\n|  | 这是 logging.conf 文件： |  |\n\n[loggers]\nkeys=root,simpleExample\n[handlers]\nkeys=consoleHandler\n[formatters]\nkeys=simpleFormatter\n[logger_root]\nlevel=DEBUG\nhandlers=consoleHandler\n[logger_simpleExample]\nlevel=DEBUG\nhandlers=consoleHandler\nqualname=simpleExample\npropagate=0\n[handler_consoleHandler]\nclass=StreamHandler\nlevel=DEBUG\nformatter=simpleFormatter\nargs=(sys.stdout,)\n[formatter_simpleFormatter]\nformat=%(asctime)s - %(name)s - %(levelname)s - %(message)s\n其输出与不基于配置文件的示例几乎相同：\n$ python simple_logging_config.py\n2005-03-19 15:38:55,977 - simpleExample - DEBUG - debug message\n2005-03-19 15:38:55,979 - simpleExample - INFO - info message\n2005-03-19 15:38:56,054 - simpleExample - WARNING - warn message\n2005-03-19 15:38:56,055 - simpleExample - ERROR - error message\n2005-03-19 15:38:56,130 - simpleExample - CRITICAL - critical message\n你可以看到配置文件方法相较于 Python 代码方法有一些优势，主要是配置和代码的分离以及非开发者轻松修改日志记录属性的能\n力。\n警告: fileConfig() 函数接受一个默认参数 disable_existing_loggers ，出于向后兼容的原因，默认为 True 。这可能与您\n的期望不同，因为除非在配置中明确命名它们（或其父级），否则它将导致在 fileConfig() 调用之前存在的任何非 root 记录器\n被禁用。有关更多信息，请参阅参考文档，如果需要，请将此参数指定为 False 。\n传递给 dictConfig() 的字典也可以用键 disable_existing_loggers 指定一个布尔值，如果没有在字典中明确指定，也默认被\n解释为 True 。这会导致上面描述的记录器禁用行为，这可能与你的期望不同——在这种情况下，请明确地为其提供 False 值。\n请注意，配置文件中引用的类名称需要相对于日志记录模块，或者可以使用常规导入机制解析的绝对值。因此，你可以使用\nWatchedFileHandler （相对于日志记录模块）或 mypackage.mymodule.MyHandler （对于在 mypackage 包中定义的类和模块\nmymodule ，其中 mypackage 在 Python 导入路径上可用）。\n在 Python 3.2 中，引入了一种新的配置日志记录的方法，使用字典来保存配置信息。 这提供了上述基于配置文件方法的功能的超\n集，并且是新应用程序和部署的推荐配置方法。 因为 Python 字典用于保存配置信息，并且由于你可以使用不同的方式填充该字典，\n因此你有更多的配置选项。 例如，你可以使用 JSON 格式的配置文件，或者如果你有权访问 YAML 处理功能，则可以使用 YAML 格\n式的文件来填充配置字典。当然，你可以在 Python 代码中构造字典，通过套接字以 pickle 形式接收它，或者使用对你的应用程序合\n理的任何方法。\n以下是与上述相同配置的示例，采用 YAML 格式，用于新的基于字典的方法：\nversion: 1\nformatters:\nsimple:\nformat: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\nhandlers:\nconsole:\nclass: logging.StreamHandler\nlevel: DEBUG\nformatter: simple\nstream: ext://sys.stdout\nloggers:\n\n|  | [loggers]\nkeys=root,simpleExample\n[handlers]\nkeys=consoleHandler\n[formatters]\nkeys=simpleFormatter\n[logger_root]\nlevel=DEBUG\nhandlers=consoleHandler\n[logger_simpleExample]\nlevel=DEBUG\nhandlers=consoleHandler\nqualname=simpleExample\npropagate=0\n[handler_consoleHandler]\nclass=StreamHandler\nlevel=DEBUG\nformatter=simpleFormatter\nargs=(sys.stdout,)\n[formatter_simpleFormatter]\nformat=%(asctime)s - %(name)s - %(levelname)s - %(message)s |  |\n| --- | --- | --- |\n|  | 其输出与不基于配置文件的示例几乎相同： |  |\n|  | $ python simple_logging_config.py\n2005-03-19 15:38:55,977 - simpleExample - DEBUG - debug message\n2005-03-19 15:38:55,979 - simpleExample - INFO - info message\n2005-03-19 15:38:56,054 - simpleExample - WARNING - warn message\n2005-03-19 15:38:56,055 - simpleExample - ERROR - error message\n2005-03-19 15:38:56,130 - simpleExample - CRITICAL - critical message |  |\n|  | 你可以看到配置文件方法相较于 Python 代码方法有一些优势，主要是配置和代码的分离以及非开发者轻松修改日志记录属性的能\n力。 |  |\n|  | 警告: fileConfig() 函数接受一个默认参数 disable_existing_loggers ，出于向后兼容的原因，默认为 True 。这可能与您\n的期望不同，因为除非在配置中明确命名它们（或其父级），否则它将导致在 fileConfig() 调用之前存在的任何非 root 记录器\n被禁用。有关更多信息，请参阅参考文档，如果需要，请将此参数指定为 False 。\n传递给 dictConfig() 的字典也可以用键 disable_existing_loggers 指定一个布尔值，如果没有在字典中明确指定，也默认被\n解释为 True 。这会导致上面描述的记录器禁用行为，这可能与你的期望不同——在这种情况下，请明确地为其提供 False 值。 |  |\n|  | 请注意，配置文件中引用的类名称需要相对于日志记录模块，或者可以使用常规导入机制解析的绝对值。因此，你可以使用\nWatchedFileHandler （相对于日志记录模块）或 mypackage.mymodule.MyHandler （对于在 mypackage 包中定义的类和模块\nmymodule ，其中 mypackage 在 Python 导入路径上可用）。\n在 Python 3.2 中，引入了一种新的配置日志记录的方法，使用字典来保存配置信息。 这提供了上述基于配置文件方法的功能的超\n集，并且是新应用程序和部署的推荐配置方法。 因为 Python 字典用于保存配置信息，并且由于你可以使用不同的方式填充该字典，\n因此你有更多的配置选项。 例如，你可以使用 JSON 格式的配置文件，或者如果你有权访问 YAML 处理功能，则可以使用 YAML 格\n式的文件来填充配置字典。当然，你可以在 Python 代码中构造字典，通过套接字以 pickle 形式接收它，或者使用对你的应用程序合\n理的任何方法。\n以下是与上述相同配置的示例，采用 YAML 格式，用于新的基于字典的方法： |  |\n|  | version: 1\nformatters:\nsimple:\nformat: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\nhandlers:\nconsole:\nclass: logging.StreamHandler\nlevel: DEBUG\nformatter: simple\nstream: ext://sys.stdout\nloggers: |  |\n\nsimpleExample:\nlevel: DEBUG\nhandlers: [console]\npropagate: no\nroot:\nlevel: DEBUG\nhandlers: [console]\n有关使用字典进行日志记录的更多信息，请参阅 配置函数。\n如果没有提供配置会发生什么\n如果未提供日志记录配置，则可能出现需要输出日志记录事件，但无法找到输出事件的处理器的情况。\n事件将使用‘最后的处理器’来输出，它存储在 lastResort 中。 这个内部处理器与任何日志记录器都没有关联，它的作用类似于\nStreamHandler，它将事件描述消息写入到 sys.stderr 的当前值（因此会遵循任何已生效的重定向）。 没有对消息进行任何格式\n化 —— 只打印简单的事件描述消息。 该处理器的级别被设为 WARNING，因此将输出严重性在此级别以上的所有事件。\n在 3.2 版本发生变更: 对于 3.2 之前的 Python 版本，行为如下：\n如果 raiseExceptions 为 False (生产模式)，则该事件会被静默地丢弃。\n如果 raiseExceptions 为 True (开发模式)，则会打印一条消息 'No handlers could be found for logger X.Y.Z'。\n要获得 3.2 之前的行为，可以将 lastResort 设为 None。\n为库配置日志\n在开发带日志的库时，你应该在文档中详细说明，你的库会如何使用日志——例如，使用的记录器的名称。还需要考虑其日志配置。\n如果使用库的应用程序不使用日志，且库代码调用日志进行记录，那么（如上一节所述）严重性为 WARNING 和更高级别的事件将被\n打印到 sys.stderr。这被认为是最好的默认行为。\n如果由于某种原因，你 不 希望在没有任何日志记录配置的情况下打印这些消息，则可以将无操作处理器附加到库的顶级记录器。这\n样可以避免打印消息，因为将始终为库的事件找到处理器：它不会产生任何输出。如果库用户配置应用程序使用的日志记录，可能是\n配置将添加一些处理器，如果级别已适当配置，则在库代码中进行的日志记录调用将正常地将输出发送给这些处理器。\n日志包中包含一个不做任何事情的处理器： NullHandler （自 Python 3.1 起）。可以将此处理器的实例添加到库使用的日志记录命\n名空间的顶级记录器中（ 如果 你希望在没有日志记录配置的情况下阻止库的记录事件输出到 sys.stderr ）。如果库 foo 的所有日\n志记录都是使用名称匹配 'foo.x' ， 'foo.x.y' 等的记录器完成的，那么代码:\nimport logging\nlogging.getLogger('foo').addHandler(logging.NullHandler())\n应该有预计的效果。如果一个组织生成了许多库，则指定的记录器名称可以是 “orgname.foo” 而不仅仅是 “foo” 。\n备注: 强烈建议在你的库中 不要将日志记录到根记录器，而为你的库的最高层级包或模块使用一个具有唯一的易识别的名称——\n例如，__name__——的记录器。将日志记录到根记录器，会使应用程序开发人员按照他们的意愿配置你的库的日志的详细程度或\n处理器变得困难，或者完全不可能。\n备注: 强烈建议你 不要将 NullHandler 以外的任何处理器添加到库的记录器中 。这是因为处理器的配置是使用你的库的应用程\n序开发人员的权利。应用程序开发人员了解他们的目标受众以及哪些处理器最适合他们的应用程序：如果你在“底层”添加处理器，\n则可能会干扰他们执行单元测试和提供符合其要求的日志的能力。\n日志级别\n日志记录级别的数值在下表中给出。如果你想要定义自己的级别，并且需要它们具有相对于预定义级别的特定值，那么这你可能对以\n下内容感兴趣。如果你定义具有相同数值的级别，它将覆盖预定义的值；预定义的名称将失效。\n级别 数值\nCRITICAL 50\nERROR 40\nWARNING 30\n\n|  | simpleExample:\nlevel: DEBUG\nhandlers: [console]\npropagate: no\nroot:\nlevel: DEBUG\nhandlers: [console] |  |\n| --- | --- | --- |\n|  | 有关使用字典进行日志记录的更多信息，请参阅 配置函数。\n如果没有提供配置会发生什么\n如果未提供日志记录配置，则可能出现需要输出日志记录事件，但无法找到输出事件的处理器的情况。\n事件将使用‘最后的处理器’来输出，它存储在 lastResort 中。 这个内部处理器与任何日志记录器都没有关联，它的作用类似于\nStreamHandler，它将事件描述消息写入到 sys.stderr 的当前值（因此会遵循任何已生效的重定向）。 没有对消息进行任何格式\n化 —— 只打印简单的事件描述消息。 该处理器的级别被设为 WARNING，因此将输出严重性在此级别以上的所有事件。\n在 3.2 版本发生变更: 对于 3.2 之前的 Python 版本，行为如下：\n如果 raiseExceptions 为 False (生产模式)，则该事件会被静默地丢弃。\n如果 raiseExceptions 为 True (开发模式)，则会打印一条消息 'No handlers could be found for logger X.Y.Z'。\n要获得 3.2 之前的行为，可以将 lastResort 设为 None。\n为库配置日志\n在开发带日志的库时，你应该在文档中详细说明，你的库会如何使用日志——例如，使用的记录器的名称。还需要考虑其日志配置。\n如果使用库的应用程序不使用日志，且库代码调用日志进行记录，那么（如上一节所述）严重性为 WARNING 和更高级别的事件将被\n打印到 sys.stderr。这被认为是最好的默认行为。\n如果由于某种原因，你 不 希望在没有任何日志记录配置的情况下打印这些消息，则可以将无操作处理器附加到库的顶级记录器。这\n样可以避免打印消息，因为将始终为库的事件找到处理器：它不会产生任何输出。如果库用户配置应用程序使用的日志记录，可能是\n配置将添加一些处理器，如果级别已适当配置，则在库代码中进行的日志记录调用将正常地将输出发送给这些处理器。\n日志包中包含一个不做任何事情的处理器： NullHandler （自 Python 3.1 起）。可以将此处理器的实例添加到库使用的日志记录命\n名空间的顶级记录器中（ 如果 你希望在没有日志记录配置的情况下阻止库的记录事件输出到 sys.stderr ）。如果库 foo 的所有日\n志记录都是使用名称匹配 'foo.x' ， 'foo.x.y' 等的记录器完成的，那么代码: |  |\n|  | import logging\nlogging.getLogger('foo').addHandler(logging.NullHandler()) |  |\n|  | 应该有预计的效果。如果一个组织生成了许多库，则指定的记录器名称可以是 “orgname.foo” 而不仅仅是 “foo” 。 |  |\n|  | 备注: 强烈建议在你的库中 不要将日志记录到根记录器，而为你的库的最高层级包或模块使用一个具有唯一的易识别的名称——\n例如，__name__——的记录器。将日志记录到根记录器，会使应用程序开发人员按照他们的意愿配置你的库的日志的详细程度或\n处理器变得困难，或者完全不可能。 |  |\n|  |  |  |\n|  | 备注: 强烈建议你 不要将 NullHandler 以外的任何处理器添加到库的记录器中 。这是因为处理器的配置是使用你的库的应用程\n序开发人员的权利。应用程序开发人员了解他们的目标受众以及哪些处理器最适合他们的应用程序：如果你在“底层”添加处理器，\n则可能会干扰他们执行单元测试和提供符合其要求的日志的能力。 |  |\n|  | 日志级别\n日志记录级别的数值在下表中给出。如果你想要定义自己的级别，并且需要它们具有相对于预定义级别的特定值，那么这你可能对以\n下内容感兴趣。如果你定义具有相同数值的级别，它将覆盖预定义的值；预定义的名称将失效。\n级别 数值\nCRITICAL 50\nERROR 40\nWARNING 30 |  |\n\n| 级别 | 数值 |\n| --- | --- |\n| CRITICAL | 50 |\n| ERROR | 40 |\n| WARNING | 30 |\n\n级别 数值\nINFO 20\nDEBUG 10\nNOTSET 0\n级别也可以与记录器关联，可以由开发人员设置，也可以通过加载保存的日志配置来设置。在记录器上调用记录方法时，记录器会将\n自己的级别与调用的方法的级别进行比较。如果记录器的级别高于调用的方法的级别，则实际上不会生成任何记录消息。这是控制日\n志记录输出详细程度的基本机制。\n日志消息被编码为 LogRecord 类的实例。当记录器决定实际记录一个事件时，将从记录消息创建一个 LogRecord 实例。\n使用 Handler 类的子例的实例 handlers，可以为日志消息建立分派机制。处理器负责确保记录的消息（以 LogRecord 的形式）最终\n到达对该消息的目标受众（如最终用户、技术支持员工、系统管理员或开发人员）有用的一个或多个位置上。想要去到特定目标的\nLogRecord 实例会被传给相应的处理器。每个记录器可以有零、一或多个与之相关联的处理器（通过 Logger 的 addHandler() 方\n法）。除了与记录器直接关联的所有处理器之外，还会将消息分派给 记录器的所有祖先关联的各个处理器*（除非某个记录器的\n*propagate 旗标被设为假值，这将使向祖先的传递在其处终止）。\n就像记录器一样，处理器可以具有与它们相关联的级别。处理器的级别作为过滤器，其方式与记录器级别相同。如果处理器决定调度\n一个事件，则使用 emit() 方法将消息发送到其目标。大多数用户定义的 Handler 子类都需要重写 emit()。\n自定义级别\n定义你自己的级别是可能的，但不一定是必要的，因为现有级别是根据实践经验选择的。但是，如果你确信需要自定义级别，那么在\n执行此操作时应特别小心，如果你正在开发库，则 定义自定义级别可能是一个非常糟糕的主意 。 这是因为如果多个库作者都定义了\n他们自己的自定义级别，那么使用开发人员很难控制和解释这些多个库的日志记录输出，因为给定的数值对于不同的库可能意味着不\n同的东西。\n有用的处理器\n作为 Handler 基类的补充，提供了很多有用的子类：\n1. StreamHandler 实例发送消息到流（类似文件对象）。\n2. FileHandler 实例将消息发送到硬盘文件。\n3. BaseRotatingHandler 是轮换日志文件的处理器的基类。它并不应该直接实例化。而应该使用 RotatingFileHandler 或\nTimedRotatingFileHandler 代替它。\n4. RotatingFileHandler 实例将消息发送到硬盘文件，支持最大日志文件大小和日志文件轮换。\n5. TimedRotatingFileHandler 实例将消息发送到硬盘文件，以特定的时间间隔轮换日志文件。\n6. SocketHandler 实例将消息发送到 TCP/IP 套接字。从 3.4 开始，也支持 Unix 域套接字。\n7. DatagramHandler 实例将消息发送到 UDP 套接字。从 3.4 开始，也支持 Unix 域套接字。\n8. SMTPHandler 实例将消息发送到指定的电子邮件地址。\n9. SysLogHandler 实例将消息发送到 Unix syslog 守护程序，可能在远程计算机上。\n10. NTEventLogHandler 实例将消息发送到 Windows NT/2000/XP 事件日志。\n11. MemoryHandler 实例将消息发送到内存中的缓冲区，只要满足特定条件，缓冲区就会刷新。\n12. HTTPHandler 实例使用 GET 或 POST 方法将消息发送到 HTTP 服务器。\n13. WatchedFileHandler 实例会监视他们要写入日志的文件。如果文件发生更改，则会关闭该文件并使用文件名重新打开。此处\n理器仅在类 Unix 系统上有用； Windows 不支持依赖的基础机制。\n14. QueueHandler 实例将消息发送到队列，例如在 queue 或 multiprocessing 模块中实现的队列。\n15. NullHandler 实例不对错误消息执行任何操作。 如果库开发者希望使用日志记录，但又希望避免出现“找不到日志记录器 XXX\n的处理器”消息则可以使用它们。 更多信息请参阅 为库配置日志。\nAdded in version 3.1: NullHandler 类。\nAdded in version 3.2: QueueHandler 类。\nThe NullHandler 、 StreamHandler 和 FileHandler 类在核心日志包中定义。其他处理器定义在 logging.handlers 中。（还有\n另一个子模块 logging.config ，用于配置功能）\n记录的消息通过 Formatter 类的实例进行格式化后呈现。 它们使用能与 ％ 运算符一起使用的格式字符串和字典进行初始化。\n\n|  | 级别 数值\nINFO 20\nDEBUG 10\nNOTSET 0\n级别也可以与记录器关联，可以由开发人员设置，也可以通过加载保存的日志配置来设置。在记录器上调用记录方法时，记录器会将\n自己的级别与调用的方法的级别进行比较。如果记录器的级别高于调用的方法的级别，则实际上不会生成任何记录消息。这是控制日\n志记录输出详细程度的基本机制。\n日志消息被编码为 LogRecord 类的实例。当记录器决定实际记录一个事件时，将从记录消息创建一个 LogRecord 实例。\n使用 Handler 类的子例的实例 handlers，可以为日志消息建立分派机制。处理器负责确保记录的消息（以 LogRecord 的形式）最终\n到达对该消息的目标受众（如最终用户、技术支持员工、系统管理员或开发人员）有用的一个或多个位置上。想要去到特定目标的\nLogRecord 实例会被传给相应的处理器。每个记录器可以有零、一或多个与之相关联的处理器（通过 Logger 的 addHandler() 方\n法）。除了与记录器直接关联的所有处理器之外，还会将消息分派给 记录器的所有祖先关联的各个处理器*（除非某个记录器的\n*propagate 旗标被设为假值，这将使向祖先的传递在其处终止）。\n就像记录器一样，处理器可以具有与它们相关联的级别。处理器的级别作为过滤器，其方式与记录器级别相同。如果处理器决定调度\n一个事件，则使用 emit() 方法将消息发送到其目标。大多数用户定义的 Handler 子类都需要重写 emit()。\n自定义级别\n定义你自己的级别是可能的，但不一定是必要的，因为现有级别是根据实践经验选择的。但是，如果你确信需要自定义级别，那么在\n执行此操作时应特别小心，如果你正在开发库，则 定义自定义级别可能是一个非常糟糕的主意 。 这是因为如果多个库作者都定义了\n他们自己的自定义级别，那么使用开发人员很难控制和解释这些多个库的日志记录输出，因为给定的数值对于不同的库可能意味着不\n同的东西。\n有用的处理器\n作为 Handler 基类的补充，提供了很多有用的子类：\n1. StreamHandler 实例发送消息到流（类似文件对象）。\n2. FileHandler 实例将消息发送到硬盘文件。\n3. BaseRotatingHandler 是轮换日志文件的处理器的基类。它并不应该直接实例化。而应该使用 RotatingFileHandler 或\nTimedRotatingFileHandler 代替它。\n4. RotatingFileHandler 实例将消息发送到硬盘文件，支持最大日志文件大小和日志文件轮换。\n5. TimedRotatingFileHandler 实例将消息发送到硬盘文件，以特定的时间间隔轮换日志文件。\n6. SocketHandler 实例将消息发送到 TCP/IP 套接字。从 3.4 开始，也支持 Unix 域套接字。\n7. DatagramHandler 实例将消息发送到 UDP 套接字。从 3.4 开始，也支持 Unix 域套接字。\n8. SMTPHandler 实例将消息发送到指定的电子邮件地址。\n9. SysLogHandler 实例将消息发送到 Unix syslog 守护程序，可能在远程计算机上。\n10. NTEventLogHandler 实例将消息发送到 Windows NT/2000/XP 事件日志。\n11. MemoryHandler 实例将消息发送到内存中的缓冲区，只要满足特定条件，缓冲区就会刷新。\n12. HTTPHandler 实例使用 GET 或 POST 方法将消息发送到 HTTP 服务器。\n13. WatchedFileHandler 实例会监视他们要写入日志的文件。如果文件发生更改，则会关闭该文件并使用文件名重新打开。此处\n理器仅在类 Unix 系统上有用； Windows 不支持依赖的基础机制。\n14. QueueHandler 实例将消息发送到队列，例如在 queue 或 multiprocessing 模块中实现的队列。\n15. NullHandler 实例不对错误消息执行任何操作。 如果库开发者希望使用日志记录，但又希望避免出现“找不到日志记录器 XXX\n的处理器”消息则可以使用它们。 更多信息请参阅 为库配置日志。\nAdded in version 3.1: NullHandler 类。\nAdded in version 3.2: QueueHandler 类。\nThe NullHandler 、 StreamHandler 和 FileHandler 类在核心日志包中定义。其他处理器定义在 logging.handlers 中。（还有\n另一个子模块 logging.config ，用于配置功能）\n记录的消息通过 Formatter 类的实例进行格式化后呈现。 它们使用能与 ％ 运算符一起使用的格式字符串和字典进行初始化。 |  |\n| --- | --- | --- |\n\n| 级别 | 数值 |\n| --- | --- |\n| INFO | 20 |\n| DEBUG | 10 |\n| NOTSET | 0 |\n\n要批量格式化多条消息，可以使用 BufferingFormatter 的实例。 除了格式字符串（它将应用于批次中的每条消息）以外，还提供\n了标头和尾部格式字符串。\n当基于记录器级别和处理器级别的过滤不够时，可以将 Filter 的实例添加到 Logger 和 Handler 实例（通过它们的 addFilter()\n方法）。在决定进一步处理消息之前，记录器和处理器都会查询其所有过滤器以获得许可。如果任何过滤器返回 false 值，则不会进\n一步处理该消息。\n基本 Filter 的功能允许按特定的记录器名称进行过滤。如果使用此功能，则允许通过过滤器发送到指定记录器及其子项的消息，并\n丢弃其他所有消息。\n记录日志时引发的异常\nlogging 包被设计为，当在生产环境下使用时，忽略记录日志时发生的异常。这样，处理与日志相关的事件时发生的错误（例如日志\n配置错误、网络或其它类似错误）不会导致使用日志的应用程序终止。\nSystemExit 和 KeyboardInterrupt 异常永远不会被忽略。在 Handler 的子类的 emit() 方法中发生的其它异常将被传递给其\nhandleError() 方法。\nHandler 中的 handleError() 的默认实现是检查是否设置了模块级变量 raiseExceptions。如有设置，则会将回溯打印到\nsys.stderr。如果未设置，则忽略异常。\n备注: raiseExceptions 的默认值是 True。这是因为在开发期间，你通常想要在发生异常时收到通知。建议你将\nraiseExceptions 设为 False 供生产环境下使用。\n使用任意对象作为消息\n在前面的部分和示例中，都假设记录事件时传递的消息是字符串。 但是，这不是唯一的可能性。你可以将任意对象作为消息传递，\n并且当日志记录系统需要将其转换为字符串表示时，将调用其 __ str__() 方法。实际上，如果你愿意，你可以完全避免计算字符串\n表示。例如， SocketHandler 用 pickle 处理事件后，通过网络发送。\n优化\n消息参数的格式化将被推迟，直到无法避免。但是，计算传递给日志记录方法的参数也可能很消耗资源，如果记录器只是丢弃你的事\n件，你可能希望避免这样做。要决定做什么，可以调用 isEnabledFor() 方法，该方法接受一个 level 参数，如果记录器为该级别的\n调用创建了该事件，则返回 true 。 你可以写这样的代码:\nif logger.isEnabledFor(logging.DEBUG):\nlogger.debug('Message with %s, %s', expensive_func1(),\nexpensive_func2())\n因此如果日志记录器的阈值设置高于 DEBUG，则永远不会调用 expensive_func1 和 expensive_func2。\n备注: 在某些情况下， isEnabledFor() 本身可能比你想要的更消耗资源（例如，对于深度嵌套的记录器，其中仅在记录器层次\n结构中设置了显式级别）。在这种情况下（或者如果你想避免在紧密循环中调用方法），你可以在本地或实例变量中将调用的结果\n缓存到 isEnabledFor() ，并使用它而不是每次调用方法。在日志记录配置在应用程序运行时动态更改（这不常见）时，只需要\n重新计算这样的缓存值即可。\n对于需要对收集的日志信息进行更精确控制的特定应用程序，还可以进行其他优化。以下列出了在日志记录过程中您可以避免的非必\n须处理操作：\n你不想收集的内容 如何避免收集它\n将 logging._srcfile 设置为 None 。这避免了调用 sys._getframe() ，如果 PyPy 支持\n有关调用来源的信息 Python 3.x ，这可能有助于加速 PyPy （无法加速使用 sys._getframe() 的代码）等环境中\n的代码。\n线程信息 将 logging.logThreads 设为 False。\n当前进程 ID (os.getpid()) 将 logging.logProcesses 设为 False。\n\n|  | 要批量格式化多条消息，可以使用 BufferingFormatter 的实例。 除了格式字符串（它将应用于批次中的每条消息）以外，还提供\n了标头和尾部格式字符串。\n当基于记录器级别和处理器级别的过滤不够时，可以将 Filter 的实例添加到 Logger 和 Handler 实例（通过它们的 addFilter()\n方法）。在决定进一步处理消息之前，记录器和处理器都会查询其所有过滤器以获得许可。如果任何过滤器返回 false 值，则不会进\n一步处理该消息。\n基本 Filter 的功能允许按特定的记录器名称进行过滤。如果使用此功能，则允许通过过滤器发送到指定记录器及其子项的消息，并\n丢弃其他所有消息。\n记录日志时引发的异常\nlogging 包被设计为，当在生产环境下使用时，忽略记录日志时发生的异常。这样，处理与日志相关的事件时发生的错误（例如日志\n配置错误、网络或其它类似错误）不会导致使用日志的应用程序终止。\nSystemExit 和 KeyboardInterrupt 异常永远不会被忽略。在 Handler 的子类的 emit() 方法中发生的其它异常将被传递给其\nhandleError() 方法。\nHandler 中的 handleError() 的默认实现是检查是否设置了模块级变量 raiseExceptions。如有设置，则会将回溯打印到\nsys.stderr。如果未设置，则忽略异常。 |  |  |\n| --- | --- | --- | --- |\n|  | 备注: raiseExceptions 的默认值是 True。这是因为在开发期间，你通常想要在发生异常时收到通知。建议你将\nraiseExceptions 设为 False 供生产环境下使用。 |  |  |\n|  | 使用任意对象作为消息\n在前面的部分和示例中，都假设记录事件时传递的消息是字符串。 但是，这不是唯一的可能性。你可以将任意对象作为消息传递，\n并且当日志记录系统需要将其转换为字符串表示时，将调用其 __ str__() 方法。实际上，如果你愿意，你可以完全避免计算字符串\n表示。例如， SocketHandler 用 pickle 处理事件后，通过网络发送。\n优化\n消息参数的格式化将被推迟，直到无法避免。但是，计算传递给日志记录方法的参数也可能很消耗资源，如果记录器只是丢弃你的事\n件，你可能希望避免这样做。要决定做什么，可以调用 isEnabledFor() 方法，该方法接受一个 level 参数，如果记录器为该级别的\n调用创建了该事件，则返回 true 。 你可以写这样的代码: |  |  |\n|  | if logger.isEnabledFor(logging.DEBUG):\nlogger.debug('Message with %s, %s', expensive_func1(),\nexpensive_func2()) |  |  |\n|  | 因此如果日志记录器的阈值设置高于 DEBUG，则永远不会调用 expensive_func1 和 expensive_func2。 |  |  |\n|  | 备注: 在某些情况下， isEnabledFor() 本身可能比你想要的更消耗资源（例如，对于深度嵌套的记录器，其中仅在记录器层次\n结构中设置了显式级别）。在这种情况下（或者如果你想避免在紧密循环中调用方法），你可以在本地或实例变量中将调用的结果\n缓存到 isEnabledFor() ，并使用它而不是每次调用方法。在日志记录配置在应用程序运行时动态更改（这不常见）时，只需要\n重新计算这样的缓存值即可。 |  |  |\n|  | 对于需要对收集的日志信息进行更精确控制的特定应用程序，还可以进行其他优化。以下列出了在日志记录过程中您可以避免的非必\n须处理操作： |  |  |\n|  | 你不想收集的内容 | 如何避免收集它 |  |\n|  | 有关调用来源的信息 | 将 logging._srcfile 设置为 None 。这避免了调用 sys._getframe() ，如果 PyPy 支持\nPython 3.x ，这可能有助于加速 PyPy （无法加速使用 sys._getframe() 的代码）等环境中\n的代码。 |  |\n|  | 线程信息 | 将 logging.logThreads 设为 False。 |  |\n|  | 当前进程 ID (os.getpid()) | 将 logging.logProcesses 设为 False。 |  |\n|  |  |  |  |\n\n你不想收集的内容 如何避免收集它\n当使用 multiprocessing 来管理\n将 logging.logMultiprocessing 设为 False。\n多个进程时的当前进程名称。\n在使用 asyncio 时的当前\n将 logging.logAsyncioTasks 设为 False。\nasyncio.Task。\n另请注意，核心日志记录模块仅包含基本处理器。如果你不导入 logging.handlers 和 logging.config ，它们将不会占用任何内\n存。\n其他资源\n参见:\n模块 logging\n日志记录模块的 API 参考。\nlogging.config 模块\n日志记录模块的配置 API 。\nlogging.handlers 模块\n日志记录模块附带的有用处理器。\n日志操作手册\n\n| 你不想收集的内容 | 如何避免收集它 |\n| --- | --- |\n| 当使用 multiprocessing 来管理\n多个进程时的当前进程名称。 | 将 logging.logMultiprocessing 设为 False。 |\n| 在使用 asyncio 时的当前\nasyncio.Task。 | 将 logging.logAsyncioTasks 设为 False。 |\n| 另请注意，核心日志记录模块仅包含基本处理器。如果你不导入 logging.handlers 和 logging.config ，它们将不会占用任何内\n存。\n其他资源 |  |\n| 参见:\n模块 logging\n日志记录模块的 API 参考。\nlogging.config 模块\n日志记录模块的配置 API 。\nlogging.handlers 模块\n日志记录模块附带的有用处理器。\n日志操作手册 |  |", "metadata": {"title": "08_日志指南", "source": "md_docs\\python_howto_md\\08_日志指南.md", "doc_type": "指南", "language": "中文", "doc_id": "11679574"}}
{"doc_id": "e72209fa", "content": "日志专题手册\n作者: Vinay Sajip <vinay_sajip at red-dove dot com>\n本页面包含多个与日志相关的专题，历史证明它们是很有用的。教程和参考信息的链接另见 其他资\n源。\n在多模块中使用日志\n无论对 logging.getLogger('someLogger') 进行多少次调用，都会返回同一个 logger 对象的引\n用。不仅在同一个模块内如此，只要是在同一个 Python 解释器进程中，跨模块调用也是一样。同样\n是引用同一个对象，应用程序也可以在一个模块中定义和配置一个父 logger，而在另一个单独的模\n块中创建（但不配置）子 logger，对于子 logger 的所有调用都会传给父 logger。以下是主模块：\nimport logging\nimport auxiliary_module\n# 创建 'spam_application' 日志记录器\nlogger = logging.getLogger('spam_application')\nlogger.setLevel(logging.DEBUG)\n# 创建可记录调试消息的文件处理器\nfh = logging.FileHandler('spam.log')\nfh.setLevel(logging.DEBUG)\n# 创建具有更高日志层级的控制台处理器\nch = logging.StreamHandler()\nch.setLevel(logging.ERROR)\n# 创建格式化器并将其添加到处理器\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)\nfh.setFormatter(formatter)\nch.setFormatter(formatter)\n# 将处理器添加到日志记录器\nlogger.addHandler(fh)\nlogger.addHandler(ch)\nlogger.info('creating an instance of auxiliary_module.Auxiliary')\na = auxiliary_module.Auxiliary()\nlogger.info('created an instance of auxiliary_module.Auxiliary')\nlogger.info('calling auxiliary_module.Auxiliary.do_something')\na.do_something()\nlogger.info('finished auxiliary_module.Auxiliary.do_something')\nlogger.info('calling auxiliary_module.some_function()')\nauxiliary_module.some_function()\nlogger.info('done with auxiliary_module.some_function()')\n以下是辅助模块：\nimport logging\n# 创建日志记录器\nmodule_logger = logging.getLogger('spam_application.auxiliary')\n\n| 日志专题手册\n作者: Vinay Sajip <vinay_sajip at red-dove dot com>\n本页面包含多个与日志相关的专题，历史证明它们是很有用的。教程和参考信息的链接另见 其他资\n源。\n在多模块中使用日志\n无论对 logging.getLogger('someLogger') 进行多少次调用，都会返回同一个 logger 对象的引\n用。不仅在同一个模块内如此，只要是在同一个 Python 解释器进程中，跨模块调用也是一样。同样\n是引用同一个对象，应用程序也可以在一个模块中定义和配置一个父 logger，而在另一个单独的模\n块中创建（但不配置）子 logger，对于子 logger 的所有调用都会传给父 logger。以下是主模块：\nimport logging\nimport auxiliary_module\n# 创建 'spam_application' 日志记录器\nlogger = logging.getLogger('spam_application')\nlogger.setLevel(logging.DEBUG)\n# 创建可记录调试消息的文件处理器\nfh = logging.FileHandler('spam.log')\nfh.setLevel(logging.DEBUG)\n# 创建具有更高日志层级的控制台处理器\nch = logging.StreamHandler()\nch.setLevel(logging.ERROR)\n# 创建格式化器并将其添加到处理器\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)\nfh.setFormatter(formatter)\nch.setFormatter(formatter)\n# 将处理器添加到日志记录器\nlogger.addHandler(fh)\nlogger.addHandler(ch)\nlogger.info('creating an instance of auxiliary_module.Auxiliary')\na = auxiliary_module.Auxiliary()\nlogger.info('created an instance of auxiliary_module.Auxiliary')\nlogger.info('calling auxiliary_module.Auxiliary.do_something')\na.do_something()\nlogger.info('finished auxiliary_module.Auxiliary.do_something')\nlogger.info('calling auxiliary_module.some_function()')\nauxiliary_module.some_function()\nlogger.info('done with auxiliary_module.some_function()')\n以下是辅助模块：\nimport logging\n# 创建日志记录器\nmodule_logger = logging.getLogger('spam_application.auxiliary') |  |  |  |\n| --- | --- | --- | --- |\n|  | 日志专题手册\n作者: Vinay Sajip <vinay_sajip at red-dove dot com>\n本页面包含多个与日志相关的专题，历史证明它们是很有用的。教程和参考信息的链接另见 其他资\n源。\n在多模块中使用日志\n无论对 logging.getLogger('someLogger') 进行多少次调用，都会返回同一个 logger 对象的引\n用。不仅在同一个模块内如此，只要是在同一个 Python 解释器进程中，跨模块调用也是一样。同样\n是引用同一个对象，应用程序也可以在一个模块中定义和配置一个父 logger，而在另一个单独的模\n块中创建（但不配置）子 logger，对于子 logger 的所有调用都会传给父 logger。以下是主模块： |  |  |\n|  | import logging\nimport auxiliary_module\n# 创建 'spam_application' 日志记录器\nlogger = logging.getLogger('spam_application')\nlogger.setLevel(logging.DEBUG)\n# 创建可记录调试消息的文件处理器\nfh = logging.FileHandler('spam.log')\nfh.setLevel(logging.DEBUG)\n# 创建具有更高日志层级的控制台处理器\nch = logging.StreamHandler()\nch.setLevel(logging.ERROR)\n# 创建格式化器并将其添加到处理器\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)\nfh.setFormatter(formatter)\nch.setFormatter(formatter)\n# 将处理器添加到日志记录器\nlogger.addHandler(fh)\nlogger.addHandler(ch)\nlogger.info('creating an instance of auxiliary_module.Auxiliary')\na = auxiliary_module.Auxiliary()\nlogger.info('created an instance of auxiliary_module.Auxiliary')\nlogger.info('calling auxiliary_module.Auxiliary.do_something')\na.do_something()\nlogger.info('finished auxiliary_module.Auxiliary.do_something')\nlogger.info('calling auxiliary_module.some_function()')\nauxiliary_module.some_function()\nlogger.info('done with auxiliary_module.some_function()') |  |  |\n|  | 以下是辅助模块： |  |  |\n|  | import logging\n# 创建日志记录器\nmodule_logger = logging.getLogger('spam_application.auxiliary') |  |  |\n\nclass Auxiliary:\ndef __init__(self):\nself.logger = logging.getLogger('spam_application.auxiliary.Auxiliary')\nself.logger.info('creating an instance of Auxiliary')\ndef do_something(self):\nself.logger.info('doing something')\na = 1 + 1\nself.logger.info('done doing something')\ndef some_function():\nmodule_logger.info('received a call to \"some_function\"')\n输出结果会像这样:\n2005-03-23 23:47:11,663 - spam_application - INFO -\ncreating an instance of auxiliary_module.Auxiliary\n2005-03-23 23:47:11,665 - spam_application.auxiliary.Auxiliary - INFO -\ncreating an instance of Auxiliary\n2005-03-23 23:47:11,665 - spam_application - INFO -\ncreated an instance of auxiliary_module.Auxiliary\n2005-03-23 23:47:11,668 - spam_application - INFO -\ncalling auxiliary_module.Auxiliary.do_something\n2005-03-23 23:47:11,668 - spam_application.auxiliary.Auxiliary - INFO -\ndoing something\n2005-03-23 23:47:11,669 - spam_application.auxiliary.Auxiliary - INFO -\ndone doing something\n2005-03-23 23:47:11,670 - spam_application - INFO -\nfinished auxiliary_module.Auxiliary.do_something\n2005-03-23 23:47:11,671 - spam_application - INFO -\ncalling auxiliary_module.some_function()\n2005-03-23 23:47:11,672 - spam_application.auxiliary - INFO -\nreceived a call to 'some_function'\n2005-03-23 23:47:11,673 - spam_application - INFO -\ndone with auxiliary_module.some_function()\n在多个线程中记录日志\n多线程记录日志并不需要特殊处理，以下示例演示了在主线程（起始线程）和其他线程中记录日志\n的过程：\nimport logging\nimport threading\nimport time\ndef worker(arg):\nwhile not arg['stop']:\nlogging.debug('Hi from myfunc')\ntime.sleep(0.5)\ndef main():\nlogging.basicConfig(level=logging.DEBUG, format='%(relativeCreated)6d %(thread\ninfo = {'stop': False}\nthread = threading.Thread(target=worker, args=(info,))\nthread.start()\nwhile True:\n\n|  | class Auxiliary:\ndef __init__(self):\nself.logger = logging.getLogger('spam_application.auxiliary.Auxiliary')\nself.logger.info('creating an instance of Auxiliary')\ndef do_something(self):\nself.logger.info('doing something')\na = 1 + 1\nself.logger.info('done doing something')\ndef some_function():\nmodule_logger.info('received a call to \"some_function\"') |  |\n| --- | --- | --- |\n|  | 输出结果会像这样: |  |\n|  | 2005-03-23 23:47:11,663 - spam_application - INFO -\ncreating an instance of auxiliary_module.Auxiliary\n2005-03-23 23:47:11,665 - spam_application.auxiliary.Auxiliary - INFO -\ncreating an instance of Auxiliary\n2005-03-23 23:47:11,665 - spam_application - INFO -\ncreated an instance of auxiliary_module.Auxiliary\n2005-03-23 23:47:11,668 - spam_application - INFO -\ncalling auxiliary_module.Auxiliary.do_something\n2005-03-23 23:47:11,668 - spam_application.auxiliary.Auxiliary - INFO -\ndoing something\n2005-03-23 23:47:11,669 - spam_application.auxiliary.Auxiliary - INFO -\ndone doing something\n2005-03-23 23:47:11,670 - spam_application - INFO -\nfinished auxiliary_module.Auxiliary.do_something\n2005-03-23 23:47:11,671 - spam_application - INFO -\ncalling auxiliary_module.some_function()\n2005-03-23 23:47:11,672 - spam_application.auxiliary - INFO -\nreceived a call to 'some_function'\n2005-03-23 23:47:11,673 - spam_application - INFO -\ndone with auxiliary_module.some_function() |  |\n|  | 在多个线程中记录日志\n多线程记录日志并不需要特殊处理，以下示例演示了在主线程（起始线程）和其他线程中记录日志\n的过程： |  |\n|  | import logging\nimport threading\nimport time\ndef worker(arg):\nwhile not arg['stop']:\nlogging.debug('Hi from myfunc')\ntime.sleep(0.5)\ndef main():\nlogging.basicConfig(level=logging.DEBUG, format='%(relativeCreated)6d %(thread\ninfo = {'stop': False}\nthread = threading.Thread(target=worker, args=(info,))\nthread.start()\nwhile True: |  |\n\ntry:\nlogging.debug('Hello from main')\ntime.sleep(0.75)\nexcept KeyboardInterrupt:\ninfo['stop'] = True\nbreak\nthread.join()\nif __name__ == '__main__':\nmain()\n脚本会运行输出类似下面的内容:\n0 Thread-1 Hi from myfunc\n3 MainThread Hello from main\n505 Thread-1 Hi from myfunc\n755 MainThread Hello from main\n1007 Thread-1 Hi from myfunc\n1507 MainThread Hello from main\n1508 Thread-1 Hi from myfunc\n2010 Thread-1 Hi from myfunc\n2258 MainThread Hello from main\n2512 Thread-1 Hi from myfunc\n3009 MainThread Hello from main\n3013 Thread-1 Hi from myfunc\n3515 Thread-1 Hi from myfunc\n3761 MainThread Hello from main\n4017 Thread-1 Hi from myfunc\n4513 MainThread Hello from main\n4518 Thread-1 Hi from myfunc\n以上如期显示了不同线程的日志是交替输出的。当然更多的线程也会如此。\n多个 handler 和多种 formatter\n日志是个普通的 Python 对象。 addHandler() 方法可加入不限数量的日志 handler。有时候，应用\n程序需把严重错误信息记入文本文件，而将一般错误或其他级别的信息输出到控制台。若要进行这\n样的设定，只需多配置几个日志 handler 即可，应用程序的日志调用代码可以保持不变。下面对之\n前的分模块日志示例略做修改：\nimport logging\nlogger = logging.getLogger('simple_example')\nlogger.setLevel(logging.DEBUG)\n# 创建可记录调试消息的文件处理器\nfh = logging.FileHandler('spam.log')\nfh.setLevel(logging.DEBUG)\n# 创建具有更高日志层级的控制台处理器\nch = logging.StreamHandler()\nch.setLevel(logging.ERROR)\n# 创建格式化器并将其添加到处理器\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)\nch.setFormatter(formatter)\nfh.setFormatter(formatter)\n# 将处理器添加到日志记录器\nlogger.addHandler(ch)\n\n|  | try:\nlogging.debug('Hello from main')\ntime.sleep(0.75)\nexcept KeyboardInterrupt:\ninfo['stop'] = True\nbreak\nthread.join()\nif __name__ == '__main__':\nmain() |  |  |\n| --- | --- | --- | --- |\n|  | 脚本会运行输出类似下面的内容: |  |  |\n|  | 0 Thread-1 Hi from myfunc\n3 MainThread Hello from main\n505 Thread-1 Hi from myfunc\n755 MainThread Hello from main\n1007 Thread-1 Hi from myfunc\n1507 MainThread Hello from main\n1508 Thread-1 Hi from myfunc\n2010 Thread-1 Hi from myfunc\n2258 MainThread Hello from main\n2512 Thread-1 Hi from myfunc\n3009 MainThread Hello from main\n3013 Thread-1 Hi from myfunc\n3515 Thread-1 Hi from myfunc |  |  |\n|  | 3761 MainThread Hello from main\n4017 Thread-1 Hi from myfunc\n4513 MainThread Hello from main\n4518 Thread-1 Hi from myfunc |  |  |\n|  | 以上如期显示了不同线程的日志是交替输出的。当然更多的线程也会如此。\n多个 handler 和多种 formatter\n日志是个普通的 Python 对象。 addHandler() 方法可加入不限数量的日志 handler。有时候，应用\n程序需把严重错误信息记入文本文件，而将一般错误或其他级别的信息输出到控制台。若要进行这\n样的设定，只需多配置几个日志 handler 即可，应用程序的日志调用代码可以保持不变。下面对之\n前的分模块日志示例略做修改： |  |  |\n|  | import logging\nlogger = logging.getLogger('simple_example')\nlogger.setLevel(logging.DEBUG)\n# 创建可记录调试消息的文件处理器\nfh = logging.FileHandler('spam.log')\nfh.setLevel(logging.DEBUG)\n# 创建具有更高日志层级的控制台处理器\nch = logging.StreamHandler()\nch.setLevel(logging.ERROR)\n# 创建格式化器并将其添加到处理器\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)\nch.setFormatter(formatter)\nfh.setFormatter(formatter)\n# 将处理器添加到日志记录器\nlogger.addHandler(ch) |  |  |\n\nlogger.addHandler(fh)\n# '应用程序' 代码\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warn message')\nlogger.error('error message')\nlogger.critical('critical message')\n需要注意的是，“应用程序”内的代码并不关心是否存在多个日志 handler。示例中所做的改变，只是\n新加入并配置了一个名为 fh 的 handler。\n在编写和测试应用程序时，若能创建日志 handler 对不同严重级别的日志信息进行过滤，这将十分\n有用。调试时无需用多条 print 语句，而是采用 logger.debug ：print 语句以后还得注释或删掉，\n而 logger.debug 语句可以原样留在源码中保持静默。当需要再次调试时，只要改变日志对象或\nhandler 的严重级别即可。\n在多个地方记录日志\n假定要根据不同的情况将日志以不同的格式写入控制台和文件。比如把 DEBUG 以上级别的日志信息\n写于文件，并且把 INFO 以上的日志信息输出到控制台。再假设日志文件需要包含时间戳，控制台信\n息则不需要。以下演示了做法：\nimport logging\n# 设置日志记录到文件 —— 参阅前一节了解详情\nlogging.basicConfig(level=logging.DEBUG,\nformat='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\ndatefmt='%m-%d %H:%M',\nfilename='/tmp/myapp.log',\nfilemode='w')\n# 定义一个将 INFO 或更高层级消息写到 sys.stderr 的处理器\nconsole = logging.StreamHandler()\nconsole.setLevel(logging.INFO)\n# 设置一个适用于控制台的更简单格式\nformatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')\n# 告诉处理器使用此格式\nconsole.setFormatter(formatter)\n# 将处理器添加到根日志记录器\nlogging.getLogger('').addHandler(console)\n# 现在我们可以写入根记录器或任何其他记录器。 首先是根记录器...\nlogging.info('Jackdaws love my big sphinx of quartz.')\n# 现在，定义几个可以代表你的应用程序中不同组成部分的\n# 其他日志记录器\nlogger1 = logging.getLogger('myapp.area1')\nlogger2 = logging.getLogger('myapp.area2')\nlogger1.debug('Quick zephyrs blow, vexing daft Jim.')\nlogger1.info('How quickly daft jumping zebras vex.')\nlogger2.warning('Jail zesty vixen who grabbed pay from quack.')\nlogger2.error('The five boxing wizards jump quickly.')\n\n|  | logger.addHandler(fh)\n# '应用程序' 代码\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warn message')\nlogger.error('error message')\nlogger.critical('critical message') |  |  |\n| --- | --- | --- | --- |\n|  | 需要注意的是，“应用程序”内的代码并不关心是否存在多个日志 handler。示例中所做的改变，只是\n新加入并配置了一个名为 fh 的 handler。\n在编写和测试应用程序时，若能创建日志 handler 对不同严重级别的日志信息进行过滤，这将十分\n有用。调试时无需用多条 print 语句，而是采用 logger.debug ：print 语句以后还得注释或删掉，\n而 logger.debug 语句可以原样留在源码中保持静默。当需要再次调试时，只要改变日志对象或\nhandler 的严重级别即可。\n在多个地方记录日志\n假定要根据不同的情况将日志以不同的格式写入控制台和文件。比如把 DEBUG 以上级别的日志信息\n写于文件，并且把 INFO 以上的日志信息输出到控制台。再假设日志文件需要包含时间戳，控制台信\n息则不需要。以下演示了做法： |  |  |\n|  |  |  |  |\n|  | import logging\n# 设置日志记录到文件 —— 参阅前一节了解详情\nlogging.basicConfig(level=logging.DEBUG,\nformat='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\ndatefmt='%m-%d %H:%M',\nfilename='/tmp/myapp.log',\nfilemode='w')\n# 定义一个将 INFO 或更高层级消息写到 sys.stderr 的处理器\nconsole = logging.StreamHandler()\nconsole.setLevel(logging.INFO)\n# 设置一个适用于控制台的更简单格式\nformatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')\n# 告诉处理器使用此格式\nconsole.setFormatter(formatter)\n# 将处理器添加到根日志记录器\nlogging.getLogger('').addHandler(console)\n# 现在我们可以写入根记录器或任何其他记录器。 首先是根记录器...\nlogging.info('Jackdaws love my big sphinx of quartz.')\n# 现在，定义几个可以代表你的应用程序中不同组成部分的\n# 其他日志记录器\nlogger1 = logging.getLogger('myapp.area1')\nlogger2 = logging.getLogger('myapp.area2')\nlogger1.debug('Quick zephyrs blow, vexing daft Jim.')\nlogger1.info('How quickly daft jumping zebras vex.')\nlogger2.warning('Jail zesty vixen who grabbed pay from quack.')\nlogger2.error('The five boxing wizards jump quickly.') |  |  |\n|  |  |  |  |\n\n当运行后，你会看到控制台如下所示\nroot : INFO Jackdaws love my big sphinx of quartz.\nmyapp.area1 : INFO How quickly daft jumping zebras vex.\nmyapp.area2 : WARNING Jail zesty vixen who grabbed pay from quack.\nmyapp.area2 : ERROR The five boxing wizards jump quickly.\n而日志文件将如下所示：\n10-22 22:19 root INFO Jackdaws love my big sphinx of quartz.\n10-22 22:19 myapp.area1 DEBUG Quick zephyrs blow, vexing daft Jim.\n10-22 22:19 myapp.area1 INFO How quickly daft jumping zebras vex.\n10-22 22:19 myapp.area2 WARNING Jail zesty vixen who grabbed pay from quack.\n10-22 22:19 myapp.area2 ERROR The five boxing wizards jump quickly.\n如您所见，DEBUG 级别的日志信息只出现在了文件中，而其他信息则两个地方都会输出。\n上述示例只用到了控制台和文件 handler，当然还可以自由组合任意数量的日志 handler。\n请注意上面选择的日志文件名 /tmp/myapp.log 表示在 POSIX 系统上使用临时文件的标准位置。 在\nWindows 上，你可能需要为日志选择不同的目录名称 —— 只要确保该目录存在并且你有在其中创\n建和更新文件的权限。\n自定义处理级别\n有时，你想要做的可能略微不同于处理器中标准的级别处理方式，即某个界限以上的所有级别都会\n被处理器所处理。 要做到这一点，你需要使用过滤器。 让我们来看一个假设你想要执行如下安排的\n场景:\n将严重级别为 INFO 和 WARNING 的消息发送到 sys.stdout\n将严重级别为 ERROR 及以上的消息发送到 sys.stderr\n将严重级别为 DEBUG 及以上的消息发送到文件 app.log\n假定你使用以下 JSON 来配置日志记录:\n{\n\"version\": 1,\n\"disable_existing_loggers\": false,\n\"formatters\": {\n\"simple\": {\n\"format\": \"%(levelname)-8s - %(message)s\"\n}\n},\n\"handlers\": {\n\"stdout\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"INFO\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stdout\"\n},\n\"stderr\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"ERROR\",\n\n|  | 当运行后，你会看到控制台如下所示 |  |\n| --- | --- | --- |\n|  | root : INFO Jackdaws love my big sphinx of quartz.\nmyapp.area1 : INFO How quickly daft jumping zebras vex.\nmyapp.area2 : WARNING Jail zesty vixen who grabbed pay from quack.\nmyapp.area2 : ERROR The five boxing wizards jump quickly. |  |\n|  | 而日志文件将如下所示： |  |\n|  | 10-22 22:19 root INFO Jackdaws love my big sphinx of quartz.\n10-22 22:19 myapp.area1 DEBUG Quick zephyrs blow, vexing daft Jim.\n10-22 22:19 myapp.area1 INFO How quickly daft jumping zebras vex.\n10-22 22:19 myapp.area2 WARNING Jail zesty vixen who grabbed pay from quack.\n10-22 22:19 myapp.area2 ERROR The five boxing wizards jump quickly. |  |\n|  | 如您所见，DEBUG 级别的日志信息只出现在了文件中，而其他信息则两个地方都会输出。\n上述示例只用到了控制台和文件 handler，当然还可以自由组合任意数量的日志 handler。\n请注意上面选择的日志文件名 /tmp/myapp.log 表示在 POSIX 系统上使用临时文件的标准位置。 在\nWindows 上，你可能需要为日志选择不同的目录名称 —— 只要确保该目录存在并且你有在其中创\n建和更新文件的权限。\n自定义处理级别\n有时，你想要做的可能略微不同于处理器中标准的级别处理方式，即某个界限以上的所有级别都会\n被处理器所处理。 要做到这一点，你需要使用过滤器。 让我们来看一个假设你想要执行如下安排的\n场景:\n将严重级别为 INFO 和 WARNING 的消息发送到 sys.stdout\n将严重级别为 ERROR 及以上的消息发送到 sys.stderr\n将严重级别为 DEBUG 及以上的消息发送到文件 app.log\n假定你使用以下 JSON 来配置日志记录: |  |\n|  | {\n\"version\": 1,\n\"disable_existing_loggers\": false,\n\"formatters\": {\n\"simple\": {\n\"format\": \"%(levelname)-8s - %(message)s\"\n}\n},\n\"handlers\": {\n\"stdout\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"INFO\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stdout\"\n},\n\"stderr\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"ERROR\", |  |\n\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stderr\"\n},\n\"file\": {\n\"class\": \"logging.FileHandler\",\n\"formatter\": \"simple\",\n\"filename\": \"app.log\",\n\"mode\": \"w\"\n}\n},\n\"root\": {\n\"level\": \"DEBUG\",\n\"handlers\": [\n\"stderr\",\n\"stdout\",\n\"file\"\n]\n}\n}\n这个配置 几乎 能做到我们想要的，但是除了 sys.stdout 在 INFO 和 WARNING 消息之外会只显示严\n重程度 ERROR 及以上的消息。 为了防止这种情况，我们可以设置一个排除掉这些消息的过滤器并将\n其添加到相应的处理器中。 这可以通过添加一个平行于 formatters 和 handlers 的 filters 节来\n配置：\n{\n\"filters\": {\n\"warnings_and_below\": {\n\"()\" : \"__main__.filter_maker\",\n\"level\": \"WARNING\"\n}\n}\n}\n并修改 stdout 处理器上的节来添加它:\n{\n\"stdout\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"INFO\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stdout\",\n\"filters\": [\"warnings_and_below\"]\n}\n}\n过滤器就是一个函数，因此我们可以定义 filter_maker (工厂函数) 如下:\ndef filter_maker(level):\nlevel = getattr(logging, level)\ndef filter(record):\nreturn record.levelno <= level\nreturn filter\n\n|  | \"formatter\": \"simple\",\n\"stream\": \"ext://sys.stderr\"\n},\n\"file\": {\n\"class\": \"logging.FileHandler\",\n\"formatter\": \"simple\",\n\"filename\": \"app.log\",\n\"mode\": \"w\"\n}\n},\n\"root\": {\n\"level\": \"DEBUG\",\n\"handlers\": [\n\"stderr\",\n\"stdout\",\n\"file\"\n]\n}\n} |  |\n| --- | --- | --- |\n|  | 这个配置 几乎 能做到我们想要的，但是除了 sys.stdout 在 INFO 和 WARNING 消息之外会只显示严\n重程度 ERROR 及以上的消息。 为了防止这种情况，我们可以设置一个排除掉这些消息的过滤器并将\n其添加到相应的处理器中。 这可以通过添加一个平行于 formatters 和 handlers 的 filters 节来\n配置： |  |\n|  | {\n\"filters\": {\n\"warnings_and_below\": {\n\"()\" : \"__main__.filter_maker\",\n\"level\": \"WARNING\"\n}\n}\n} |  |\n|  | 并修改 stdout 处理器上的节来添加它: |  |\n|  | {\n\"stdout\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"INFO\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stdout\",\n\"filters\": [\"warnings_and_below\"]\n}\n} |  |\n|  | 过滤器就是一个函数，因此我们可以定义 filter_maker (工厂函数) 如下: |  |\n|  | def filter_maker(level):\nlevel = getattr(logging, level)\ndef filter(record):\nreturn record.levelno <= level\nreturn filter |  |\n|  |  |  |\n\n此函数将传入的字符串参数转换为数字级别，并返回一个仅在传入等于或低于指定数字级别的级别\n时返回 True 的函数。 请注意在这个示例中我是将 filter_maker 定义在一个从命令行运行的测试\n脚本 main.py 中，因此其所属模块将为 __main__ —— 即在过滤器配置中写作\n__main__.filter_maker。 如果你在不同的模块中定义它则需要加以修改。\n在添加该过滤器后，我们就可以运行 main.py，完整代码如下:\nimport json\nimport logging\nimport logging.config\nCONFIG = '''\n{\n\"version\": 1,\n\"disable_existing_loggers\": false,\n\"formatters\": {\n\"simple\": {\n\"format\": \"%(levelname)-8s - %(message)s\"\n}\n},\n\"filters\": {\n\"warnings_and_below\": {\n\"()\" : \"__main__.filter_maker\",\n\"level\": \"WARNING\"\n}\n},\n\"handlers\": {\n\"stdout\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"INFO\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stdout\",\n\"filters\": [\"warnings_and_below\"]\n},\n\"stderr\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"ERROR\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stderr\"\n},\n\"file\": {\n\"class\": \"logging.FileHandler\",\n\"formatter\": \"simple\",\n\"filename\": \"app.log\",\n\"mode\": \"w\"\n}\n},\n\"root\": {\n\"level\": \"DEBUG\",\n\"handlers\": [\n\"stderr\",\n\"stdout\",\n\"file\"\n]\n}\n}\n'''\n\n|  | 此函数将传入的字符串参数转换为数字级别，并返回一个仅在传入等于或低于指定数字级别的级别\n时返回 True 的函数。 请注意在这个示例中我是将 filter_maker 定义在一个从命令行运行的测试\n脚本 main.py 中，因此其所属模块将为 __main__ —— 即在过滤器配置中写作\n__main__.filter_maker。 如果你在不同的模块中定义它则需要加以修改。\n在添加该过滤器后，我们就可以运行 main.py，完整代码如下: |  |\n| --- | --- | --- |\n|  | import json\nimport logging\nimport logging.config\nCONFIG = '''\n{\n\"version\": 1,\n\"disable_existing_loggers\": false,\n\"formatters\": {\n\"simple\": {\n\"format\": \"%(levelname)-8s - %(message)s\"\n}\n},\n\"filters\": {\n\"warnings_and_below\": {\n\"()\" : \"__main__.filter_maker\",\n\"level\": \"WARNING\"\n}\n},\n\"handlers\": {\n\"stdout\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"INFO\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stdout\",\n\"filters\": [\"warnings_and_below\"]\n},\n\"stderr\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"ERROR\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stderr\"\n},\n\"file\": {\n\"class\": \"logging.FileHandler\",\n\"formatter\": \"simple\",\n\"filename\": \"app.log\",\n\"mode\": \"w\"\n}\n},\n\"root\": {\n\"level\": \"DEBUG\",\n\"handlers\": [\n\"stderr\",\n\"stdout\",\n\"file\"\n]\n}\n}\n''' |  |\n\ndef filter_maker(level):\nlevel = getattr(logging, level)\ndef filter(record):\nreturn record.levelno <= level\nreturn filter\nlogging.config.dictConfig(json.loads(CONFIG))\nlogging.debug('A DEBUG message')\nlogging.info('An INFO message')\nlogging.warning('A WARNING message')\nlogging.error('An ERROR message')\nlogging.critical('A CRITICAL message')\n使用这样的命令运行它之后:\npython main.py 2>stderr.log >stdout.log\n我们可以看到结果是符合预期的:\n$ more *.log\n::::::::::::::\napp.log\n::::::::::::::\nDEBUG - A DEBUG message\nINFO - An INFO message\nWARNING - A WARNING message\nERROR - An ERROR message\nCRITICAL - A CRITICAL message\n::::::::::::::\nstderr.log\n::::::::::::::\nERROR - An ERROR message\nCRITICAL - A CRITICAL message\n::::::::::::::\nstdout.log\n::::::::::::::\nINFO - An INFO message\nWARNING - A WARNING message\n日志配置服务器示例\n以下是一个用到了日志配置服务器的模块示例：\nimport logging\nimport logging.config\nimport time\nimport os\n# 读取初始配置文件\nlogging.config.fileConfig('logging.conf')\n# 在 9999 端口上创建并启动监听器\nt = logging.config.listen(9999)\nt.start()\n\n|  | def filter_maker(level):\nlevel = getattr(logging, level)\ndef filter(record):\nreturn record.levelno <= level\nreturn filter\nlogging.config.dictConfig(json.loads(CONFIG))\nlogging.debug('A DEBUG message')\nlogging.info('An INFO message')\nlogging.warning('A WARNING message')\nlogging.error('An ERROR message')\nlogging.critical('A CRITICAL message') |  |\n| --- | --- | --- |\n|  | 使用这样的命令运行它之后: |  |\n|  | python main.py 2>stderr.log >stdout.log |  |\n|  | 我们可以看到结果是符合预期的: |  |\n|  | $ more *.log\n::::::::::::::\napp.log\n::::::::::::::\nDEBUG - A DEBUG message\nINFO - An INFO message\nWARNING - A WARNING message\nERROR - An ERROR message\nCRITICAL - A CRITICAL message\n::::::::::::::\nstderr.log\n::::::::::::::\nERROR - An ERROR message\nCRITICAL - A CRITICAL message\n::::::::::::::\nstdout.log\n::::::::::::::\nINFO - An INFO message\nWARNING - A WARNING message |  |\n|  | 日志配置服务器示例\n以下是一个用到了日志配置服务器的模块示例： |  |\n|  | import logging\nimport logging.config\nimport time\nimport os\n# 读取初始配置文件\nlogging.config.fileConfig('logging.conf')\n# 在 9999 端口上创建并启动监听器\nt = logging.config.listen(9999)\nt.start() |  |\n\nlogger = logging.getLogger('simpleExample')\ntry:\n# 循环遍历日志记录调用以查看\n# 新配置进行的修改，直到按下 Ctrl+C\nwhile True:\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warn message')\nlogger.error('error message')\nlogger.critical('critical message')\ntime.sleep(5)\nexcept KeyboardInterrupt:\n# 清理\nlogging.config.stopListening()\nt.join()\n以下脚本将接受文件名作为参数，然后将此文件发送到服务器，前面加上文件的二进制编码长度，\n做为新的日志配置：\n#!/usr/bin/env python\nimport socket, sys, struct\nwith open(sys.argv[1], 'rb') as f:\ndata_to_send = f.read()\nHOST = 'localhost'\nPORT = 9999\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nprint('connecting...')\ns.connect((HOST, PORT))\nprint('sending config...')\ns.send(struct.pack('>L', len(data_to_send)))\ns.send(data_to_send)\ns.close()\nprint('complete')\n处理日志 handler 的阻塞\n有时你必须让日志记录处理程序的运行不会阻塞你要记录日志的线程。 这在 Web 应用程序中是很常\n见，当然在其他场景中也可能发生。\n有一种原因往往会让程序表现迟钝，这就是 SMTPHandler：由于很多因素是开发人员无法控制的\n（例如邮件或网络基础设施的性能不佳），发送电子邮件可能需要很长时间。不过几乎所有网络\nhandler 都可能会发生阻塞：即使是 SocketHandler 操作也可能在后台执行 DNS 查询，而这种查询\n实在太慢了（并且 DNS 查询还可能在很底层的套接字库代码中，位于 Python 层之下，超出了可控\n范围）。\n有一种解决方案是分成两部分实现。第一部分，针对那些对性能有要求的关键线程，只为日志对象\n连接一个 QueueHandler。日志对象只需简单地写入队列即可，可为队列设置足够大的容量，或者可\n以在初始化时不设置容量上限。尽管为以防万一，可能需要在代码中捕获 queue.Full 异常,不过队\n列写入操作通常会很快得以处理。如果要开发库代码，包含性能要求较高的线程，为了让使用该库\n的开发人员受益，请务必在开发文档中进行标明（包括建议仅连接 QueueHandlers ）。\n\n|  | logger = logging.getLogger('simpleExample')\ntry:\n# 循环遍历日志记录调用以查看\n# 新配置进行的修改，直到按下 Ctrl+C\nwhile True:\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warn message')\nlogger.error('error message')\nlogger.critical('critical message')\ntime.sleep(5)\nexcept KeyboardInterrupt:\n# 清理\nlogging.config.stopListening()\nt.join() |  |\n| --- | --- | --- |\n|  | 以下脚本将接受文件名作为参数，然后将此文件发送到服务器，前面加上文件的二进制编码长度，\n做为新的日志配置： |  |\n|  | #!/usr/bin/env python\nimport socket, sys, struct\nwith open(sys.argv[1], 'rb') as f:\ndata_to_send = f.read()\nHOST = 'localhost'\nPORT = 9999\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nprint('connecting...')\ns.connect((HOST, PORT))\nprint('sending config...')\ns.send(struct.pack('>L', len(data_to_send)))\ns.send(data_to_send)\ns.close()\nprint('complete') |  |\n|  | 处理日志 handler 的阻塞\n有时你必须让日志记录处理程序的运行不会阻塞你要记录日志的线程。 这在 Web 应用程序中是很常\n见，当然在其他场景中也可能发生。\n有一种原因往往会让程序表现迟钝，这就是 SMTPHandler：由于很多因素是开发人员无法控制的\n（例如邮件或网络基础设施的性能不佳），发送电子邮件可能需要很长时间。不过几乎所有网络\nhandler 都可能会发生阻塞：即使是 SocketHandler 操作也可能在后台执行 DNS 查询，而这种查询\n实在太慢了（并且 DNS 查询还可能在很底层的套接字库代码中，位于 Python 层之下，超出了可控\n范围）。\n有一种解决方案是分成两部分实现。第一部分，针对那些对性能有要求的关键线程，只为日志对象\n连接一个 QueueHandler。日志对象只需简单地写入队列即可，可为队列设置足够大的容量，或者可\n以在初始化时不设置容量上限。尽管为以防万一，可能需要在代码中捕获 queue.Full 异常,不过队\n列写入操作通常会很快得以处理。如果要开发库代码，包含性能要求较高的线程，为了让使用该库\n的开发人员受益，请务必在开发文档中进行标明（包括建议仅连接 QueueHandlers ）。 |  |\n\n解决方案的另一部分就是 QueueListener，它被设计为 QueueHandler 的对应部分。\nQueueListener 非常简单：传入一个队列和一些 handler，并启动一个内部线程，用于侦听\nQueueHandlers （或其他 LogRecords 源）发送的 LogRecord 队列。LogRecords 会从队列中移除\n并传给 handler 处理。\nQueueListener 作为单独的类，好处就是可以用同一个实例为多个 QueueHandlers 服务。这比把\n现有 handler 类线程化更加资源友好，后者会每个 handler 会占用一个线程，却没有特别的好处。\n以下是这两个类的运用示例（省略了 import 语句）：\nque = queue.Queue(-1) # 对大小没有限制\nqueue_handler = QueueHandler(que)\nhandler = logging.StreamHandler()\nlistener = QueueListener(que, handler)\nroot = logging.getLogger()\nroot.addHandler(queue_handler)\nformatter = logging.Formatter('%(threadName)s: %(message)s')\nhandler.setFormatter(formatter)\nlistener.start()\n# 日志输出将显示生成事件的线程（主线程）\n# 而不是监控内部队列的内部线程。这也正是\n# 你所希望的。\nroot.warning('Look out!')\nlistener.stop()\n在运行后会产生:\nMainThread: Look out!\n备注: 虽然前面的讨论没有专门提及异步代码，但需要注意当在异步代码中记录日志时，网络甚\n至文件处理器都可能会导致问题（阻塞事件循环）因为某些日志记录是在 asyncio 内部完成的。\n如果在应用程序中使用了任何异步代码，最好的做法是使用上面的日志记录方式，这样任何阻塞\n式代码都将只在 QueueListener 线程中运行。\n在 3.5 版本发生变更: 在 Python 3.5 之前，QueueListener 总会把由队列接收到的每条信息都\n传递给已初始化的每个处理程序。（因为这里假定级别过滤操作已在写入队列时完成了。）从\n3.5 版开始，可以修改这种处理方式，只要将关键字参数 respect_handler_level=True 传给\n侦听器的构造函数即可。这样侦听器将会把每条信息的级别与 handler 的级别进行比较，只在\n适配时才会将信息传给 handler 。\n在 3.14 版本发生变更: QueueListener 可通过 with 语句来启动（和停止）。 例如：\nwith QueueListener(que, handler) as listener:\n# 该队列监听器将会在进入\n# 'with' 代码块时自动启动。\npass\n# 该队列监听器将在退出\n# 'with' 代码块时自动停止。\n通过网络收发日志事件\n\n|  | 解决方案的另一部分就是 QueueListener，它被设计为 QueueHandler 的对应部分。\nQueueListener 非常简单：传入一个队列和一些 handler，并启动一个内部线程，用于侦听\nQueueHandlers （或其他 LogRecords 源）发送的 LogRecord 队列。LogRecords 会从队列中移除\n并传给 handler 处理。\nQueueListener 作为单独的类，好处就是可以用同一个实例为多个 QueueHandlers 服务。这比把\n现有 handler 类线程化更加资源友好，后者会每个 handler 会占用一个线程，却没有特别的好处。\n以下是这两个类的运用示例（省略了 import 语句）： |  |\n| --- | --- | --- |\n|  | que = queue.Queue(-1) # 对大小没有限制\nqueue_handler = QueueHandler(que)\nhandler = logging.StreamHandler()\nlistener = QueueListener(que, handler)\nroot = logging.getLogger()\nroot.addHandler(queue_handler)\nformatter = logging.Formatter('%(threadName)s: %(message)s')\nhandler.setFormatter(formatter)\nlistener.start()\n# 日志输出将显示生成事件的线程（主线程）\n# 而不是监控内部队列的内部线程。这也正是\n# 你所希望的。\nroot.warning('Look out!')\nlistener.stop() |  |\n|  | 在运行后会产生: |  |\n|  | MainThread: Look out! |  |\n|  |  |  |\n|  | 备注: 虽然前面的讨论没有专门提及异步代码，但需要注意当在异步代码中记录日志时，网络甚\n至文件处理器都可能会导致问题（阻塞事件循环）因为某些日志记录是在 asyncio 内部完成的。\n如果在应用程序中使用了任何异步代码，最好的做法是使用上面的日志记录方式，这样任何阻塞\n式代码都将只在 QueueListener 线程中运行。 |  |\n|  | 在 3.5 版本发生变更: 在 Python 3.5 之前，QueueListener 总会把由队列接收到的每条信息都\n传递给已初始化的每个处理程序。（因为这里假定级别过滤操作已在写入队列时完成了。）从\n3.5 版开始，可以修改这种处理方式，只要将关键字参数 respect_handler_level=True 传给\n侦听器的构造函数即可。这样侦听器将会把每条信息的级别与 handler 的级别进行比较，只在\n适配时才会将信息传给 handler 。\n在 3.14 版本发生变更: QueueListener 可通过 with 语句来启动（和停止）。 例如：\nwith QueueListener(que, handler) as listener:\n# 该队列监听器将会在进入\n# 'with' 代码块时自动启动。\npass\n# 该队列监听器将在退出\n# 'with' 代码块时自动停止。\n通过网络收发日志事件 |  |\n\n假定现在要通过网络发送日志事件，并在接收端进行处理。有一种简单的方案，就是在发送端的根\n日志对象连接一个 SocketHandler 实例：\nimport logging, logging.handlers\nrootLogger = logging.getLogger('')\nrootLogger.setLevel(logging.DEBUG)\nsocketHandler = logging.handlers.SocketHandler('localhost',\nlogging.handlers.DEFAULT_TCP_LOGGING_PORT)\n# 不必设置格式化器，因为套接字处理器会将事件以未格式化的\n# pickle 形式发送\nrootLogger.addHandler(socketHandler)\n# 现在我们可以写入根记录器或任何其他记录器。 首先是根记录器...\nlogging.info('Jackdaws love my big sphinx of quartz.')\n# 现在定义几个可以代表你的应用程序中不同组成部分的\n# 其他日志记录器：\nlogger1 = logging.getLogger('myapp.area1')\nlogger2 = logging.getLogger('myapp.area2')\nlogger1.debug('Quick zephyrs blow, vexing daft Jim.')\nlogger1.info('How quickly daft jumping zebras vex.')\nlogger2.warning('Jail zesty vixen who grabbed pay from quack.')\nlogger2.error('The five boxing wizards jump quickly.')\n在接收端，可以用 socketserver 模块设置一个接收器。简要示例如下：\nimport pickle\nimport logging\nimport logging.handlers\nimport socketserver\nimport struct\nclass LogRecordStreamHandler(socketserver.StreamRequestHandler):\n\"\"\"Handler for a streaming logging request.\nThis basically logs the record using whatever logging policy is\nconfigured locally.\n\"\"\"\ndef handle(self):\n\"\"\"\nHandle multiple requests - each expected to be a 4-byte length,\nfollowed by the LogRecord in pickle format. Logs the record\naccording to whatever policy is configured locally.\n\"\"\"\nwhile True:\nchunk = self.connection.recv(4)\nif len(chunk) < 4:\nbreak\nslen = struct.unpack('>L', chunk)[0]\nchunk = self.connection.recv(slen)\nwhile len(chunk) < slen:\nchunk = chunk + self.connection.recv(slen - len(chunk))\nobj = self.unPickle(chunk)\n\n|  | 假定现在要通过网络发送日志事件，并在接收端进行处理。有一种简单的方案，就是在发送端的根\n日志对象连接一个 SocketHandler 实例： |  |\n| --- | --- | --- |\n|  | import logging, logging.handlers\nrootLogger = logging.getLogger('')\nrootLogger.setLevel(logging.DEBUG)\nsocketHandler = logging.handlers.SocketHandler('localhost',\nlogging.handlers.DEFAULT_TCP_LOGGING_PORT)\n# 不必设置格式化器，因为套接字处理器会将事件以未格式化的\n# pickle 形式发送\nrootLogger.addHandler(socketHandler)\n# 现在我们可以写入根记录器或任何其他记录器。 首先是根记录器...\nlogging.info('Jackdaws love my big sphinx of quartz.')\n# 现在定义几个可以代表你的应用程序中不同组成部分的\n# 其他日志记录器：\nlogger1 = logging.getLogger('myapp.area1')\nlogger2 = logging.getLogger('myapp.area2')\nlogger1.debug('Quick zephyrs blow, vexing daft Jim.')\nlogger1.info('How quickly daft jumping zebras vex.')\nlogger2.warning('Jail zesty vixen who grabbed pay from quack.')\nlogger2.error('The five boxing wizards jump quickly.') |  |\n|  | 在接收端，可以用 socketserver 模块设置一个接收器。简要示例如下： |  |\n|  | import pickle\nimport logging\nimport logging.handlers\nimport socketserver\nimport struct\nclass LogRecordStreamHandler(socketserver.StreamRequestHandler):\n\"\"\"Handler for a streaming logging request.\nThis basically logs the record using whatever logging policy is\nconfigured locally.\n\"\"\"\ndef handle(self):\n\"\"\"\nHandle multiple requests - each expected to be a 4-byte length,\nfollowed by the LogRecord in pickle format. Logs the record\naccording to whatever policy is configured locally.\n\"\"\"\nwhile True:\nchunk = self.connection.recv(4)\nif len(chunk) < 4:\nbreak\nslen = struct.unpack('>L', chunk)[0]\nchunk = self.connection.recv(slen)\nwhile len(chunk) < slen:\nchunk = chunk + self.connection.recv(slen - len(chunk))\nobj = self.unPickle(chunk) |  |\n\nrecord = logging.makeLogRecord(obj)\nself.handleLogRecord(record)\ndef unPickle(self, data):\nreturn pickle.loads(data)\ndef handleLogRecord(self, record):\n# 如果指定了名称，我们将使用指定的记录器而不是\n# record 原本使用的。\nif self.server.logname is not None:\nname = self.server.logname\nelse:\nname = record.name\nlogger = logging.getLogger(name)\n# 注意每条记录都会被写入。 这是因为 Logger.handle\n# 通常会在记录器层级过滤之后被调用。 如果你希望\n# 进行过滤，请在客户端结束时进行以避免浪费循环\n# 并节省网络带宽！\nlogger.handle(record)\nclass LogRecordSocketReceiver(socketserver.ThreadingTCPServer):\n\"\"\"\nSimple TCP socket-based logging receiver suitable for testing.\n\"\"\"\nallow_reuse_address = True\ndef __init__(self, host='localhost',\nport=logging.handlers.DEFAULT_TCP_LOGGING_PORT,\nhandler=LogRecordStreamHandler):\nsocketserver.ThreadingTCPServer.__init__(self, (host, port), handler)\nself.abort = 0\nself.timeout = 1\nself.logname = None\ndef serve_until_stopped(self):\nimport select\nabort = 0\nwhile not abort:\nrd, wr, ex = select.select([self.socket.fileno()],\n[], [],\nself.timeout)\nif rd:\nself.handle_request()\nabort = self.abort\ndef main():\nlogging.basicConfig(\nformat='%(relativeCreated)5d %(name)-15s %(levelname)-8s %(message)s')\ntcpserver = LogRecordSocketReceiver()\nprint('About to start TCP server...')\ntcpserver.serve_until_stopped()\nif __name__ == '__main__':\nmain()\n先运行服务端，再运行客户端。客户端控制台不会显示什么信息；在服务端应该会看到如下内容：\n\n|  | record = logging.makeLogRecord(obj)\nself.handleLogRecord(record)\ndef unPickle(self, data):\nreturn pickle.loads(data)\ndef handleLogRecord(self, record):\n# 如果指定了名称，我们将使用指定的记录器而不是\n# record 原本使用的。\nif self.server.logname is not None:\nname = self.server.logname\nelse:\nname = record.name\nlogger = logging.getLogger(name)\n# 注意每条记录都会被写入。 这是因为 Logger.handle\n# 通常会在记录器层级过滤之后被调用。 如果你希望\n# 进行过滤，请在客户端结束时进行以避免浪费循环\n# 并节省网络带宽！\nlogger.handle(record)\nclass LogRecordSocketReceiver(socketserver.ThreadingTCPServer):\n\"\"\"\nSimple TCP socket-based logging receiver suitable for testing.\n\"\"\"\nallow_reuse_address = True\ndef __init__(self, host='localhost',\nport=logging.handlers.DEFAULT_TCP_LOGGING_PORT,\nhandler=LogRecordStreamHandler):\nsocketserver.ThreadingTCPServer.__init__(self, (host, port), handler)\nself.abort = 0\nself.timeout = 1\nself.logname = None\ndef serve_until_stopped(self):\nimport select\nabort = 0\nwhile not abort:\nrd, wr, ex = select.select([self.socket.fileno()],\n[], [],\nself.timeout)\nif rd:\nself.handle_request()\nabort = self.abort\ndef main():\nlogging.basicConfig(\nformat='%(relativeCreated)5d %(name)-15s %(levelname)-8s %(message)s')\ntcpserver = LogRecordSocketReceiver()\nprint('About to start TCP server...')\ntcpserver.serve_until_stopped()\nif __name__ == '__main__':\nmain() |  |\n| --- | --- | --- |\n|  | 先运行服务端，再运行客户端。客户端控制台不会显示什么信息；在服务端应该会看到如下内容： |  |\n\nAbout to start TCP server...\n59 root INFO Jackdaws love my big sphinx of quartz.\n59 myapp.area1 DEBUG Quick zephyrs blow, vexing daft Jim.\n69 myapp.area1 INFO How quickly daft jumping zebras vex.\n69 myapp.area2 WARNING Jail zesty vixen who grabbed pay from quack.\n69 myapp.area2 ERROR The five boxing wizards jump quickly.\n请注意在某些情况下 pickle 会存在一些安全问题。 如果这些问题对你有影响，你可以换用自己的替\n代序列化方案，只要重写 makePickle() 方法并在其中实现你的替代方案，并调整上述脚本以使用\n这个替代方案。\n在生产中运行日志套接字侦听器\n要在生产环境中运行日志记录监听器，你可能需要使用一个进程管理工具如 Supervisor。 这个 Gist\n提供了使用 Supervisor 来运行上述功能的基本框架文件。 它由以下文件组成:\n文件 目的\nprepare.sh 用于准备针对测试的环境的 Bash 脚本\nsupervisor.conf Supervisor 配置文件，其中有用于侦听器和多进程 Web 应用程序的条目\nensure_app.sh 用于确保 Supervisor 在使用上述配置运行的 Bash 脚本\nlog_listener.py 接收日志事件并将其记录到文件中的套接字监听器\nmain.py 一个通过连接到监听器的套接字来执行日志记录的简单 Web 应用程序\nwebapp.json 一个针对 Web 应用程序的 JSON 配置文件\nclient.py 使用 Web 应用程序的 Python 脚本\n该 Web 应用程序使用了 Gunicorn，这个流行的 Web 应用服务器可启动多个工作进程来处理请求。\n这个示例设置演示了多个工作进程是如何写入相同的日志文件而不会相互冲突的 --- 它们都通过套接\n字监听器进程操作。\n要测试这些文件，请在 POSIX 环境中执行以下操作:\n1. 使用 Download ZIP 按钮将 此 Gist 下载为 ZIP 归档文件。\n2. 将上述文件从归档解压缩到一个初始目录中。\n3. 在初始目录中，运行 bash prepare.sh 完成准备工作。 这将创建一个 run 子目录来包含\nSupervisor 相关文件和日志文件，以及一个 venv 子目录来包含安装了 bottle, gunicorn 和\nsupervisor 的虚拟环境。\n4. 运行 bash ensure_app.sh 以确保 Supervisor 正在使用上述配置运行。\n5. 运行 venv/bin/python client.py 来使用 Web 应用程序，这将使得记录被写入到日志中。\n6. 检查 run 子目录中的日志文件。 你应当看到匹配模式为 app.log* 的文件中最新的日志记录\n行。 它们不会有任何特定的顺序，因为它们是由不同的工作进程以不确定的方式并发地处理\n的。\n\n|  | About to start TCP server...\n59 root INFO Jackdaws love my big sphinx of quartz.\n59 myapp.area1 DEBUG Quick zephyrs blow, vexing daft Jim.\n69 myapp.area1 INFO How quickly daft jumping zebras vex.\n69 myapp.area2 WARNING Jail zesty vixen who grabbed pay from quack.\n69 myapp.area2 ERROR The five boxing wizards jump quickly. |  |\n| --- | --- | --- |\n|  | 请注意在某些情况下 pickle 会存在一些安全问题。 如果这些问题对你有影响，你可以换用自己的替\n代序列化方案，只要重写 makePickle() 方法并在其中实现你的替代方案，并调整上述脚本以使用\n这个替代方案。\n在生产中运行日志套接字侦听器\n要在生产环境中运行日志记录监听器，你可能需要使用一个进程管理工具如 Supervisor。 这个 Gist\n提供了使用 Supervisor 来运行上述功能的基本框架文件。 它由以下文件组成:\n文件 目的\nprepare.sh 用于准备针对测试的环境的 Bash 脚本\nsupervisor.conf Supervisor 配置文件，其中有用于侦听器和多进程 Web 应用程序的条目\nensure_app.sh 用于确保 Supervisor 在使用上述配置运行的 Bash 脚本\nlog_listener.py 接收日志事件并将其记录到文件中的套接字监听器\nmain.py 一个通过连接到监听器的套接字来执行日志记录的简单 Web 应用程序\nwebapp.json 一个针对 Web 应用程序的 JSON 配置文件\nclient.py 使用 Web 应用程序的 Python 脚本\n该 Web 应用程序使用了 Gunicorn，这个流行的 Web 应用服务器可启动多个工作进程来处理请求。\n这个示例设置演示了多个工作进程是如何写入相同的日志文件而不会相互冲突的 --- 它们都通过套接\n字监听器进程操作。\n要测试这些文件，请在 POSIX 环境中执行以下操作:\n1. 使用 Download ZIP 按钮将 此 Gist 下载为 ZIP 归档文件。\n2. 将上述文件从归档解压缩到一个初始目录中。\n3. 在初始目录中，运行 bash prepare.sh 完成准备工作。 这将创建一个 run 子目录来包含\nSupervisor 相关文件和日志文件，以及一个 venv 子目录来包含安装了 bottle, gunicorn 和\nsupervisor 的虚拟环境。\n4. 运行 bash ensure_app.sh 以确保 Supervisor 正在使用上述配置运行。\n5. 运行 venv/bin/python client.py 来使用 Web 应用程序，这将使得记录被写入到日志中。\n6. 检查 run 子目录中的日志文件。 你应当看到匹配模式为 app.log* 的文件中最新的日志记录\n行。 它们不会有任何特定的顺序，因为它们是由不同的工作进程以不确定的方式并发地处理\n的。 |  |\n\n| 文件 | 目的 |\n| --- | --- |\n| prepare.sh | 用于准备针对测试的环境的 Bash 脚本 |\n| supervisor.conf | Supervisor 配置文件，其中有用于侦听器和多进程 Web 应用程序的条目 |\n| ensure_app.sh | 用于确保 Supervisor 在使用上述配置运行的 Bash 脚本 |\n| log_listener.py | 接收日志事件并将其记录到文件中的套接字监听器 |\n| main.py | 一个通过连接到监听器的套接字来执行日志记录的简单 Web 应用程序 |\n| webapp.json | 一个针对 Web 应用程序的 JSON 配置文件 |\n| client.py | 使用 Web 应用程序的 Python 脚本 |\n\n7. 你可以通过运行 venv/bin/supervisorctl -c supervisor.conf shutdown 来关闭监听器\n和 Web 应用程序。\n你可能需要在配置的端口与你的测试环境中其他程序发生意外冲突的情况下调整配置文件。\n默认配置使用一个 9020 端口上的 TCP 套接字。 你可以通过以下方式改用 Unix 域套接字代替 TCP\n套接字：\n1. 在 listener.json 中，添加一个 socket 键并设为你想使用的域套接字路径。 如果存在该\n键，监听器就将监听相应的域套接字而不是 TCP 套接字 (port 键将被忽略)。\n2. 在 webapp.json 中，修改套接字处理器配置字典以使 host 值为该域套接字的路径，并将\nport 值设为 null。\n在自己的输出日志中添加上下文信息\n有时，除了调用日志对象时传入的参数之外，还希望日志输出中能包含上下文信息。 比如在网络应\n用程序中，可能需要在日志中记录某客户端的信息（如远程客户端的用户名或 IP 地址）。 这虽然可\n以用 extra 参数实现，但传递起来并不总是很方便。 虽然为每个网络连接都创建 Logger 实例貌似不\n错，但并不是个好主意，因为这些实例不会被垃圾回收。 虽然在实践中不是问题，但当 Logger 实\n例的数量取决于应用程序要采用的日志粒度时，如果 Logger 实例的数量实际上是无限的，则有可\n能难以管理。\n利用 LoggerAdapter 传递上下文信息\n要传递上下文信息和日志事件信息，有一种简单方案是利用 LoggerAdapter 类。这个类设计得类似\nLogger，所以可以直接调用 debug()、info()、 warning()、 error()、exception()、\ncritical() 和 log()。这些方法的签名与 Logger 对应的方法相同，所以这两类实例可以交换使\n用。\n当你创建一个 LoggerAdapter 的实例时，你会传入一个 Logger 的实例和一个包含了上下文信息的\n字典对象。当你调用一个 LoggerAdapter 实例的方法时，它会把调用委托给内部的 Logger 的实\n例，并为其整理相关的上下文信息。这是 LoggerAdapter 的一个代码片段:\ndef debug(self, msg, /, *args, **kwargs):\n\"\"\"\n在添加来自这个适配器实例的上下文信息之后，\n将调试调用委托给下层的日志记录器。\n\"\"\"\nmsg, kwargs = self.process(msg, kwargs)\nself.logger.debug(msg, *args, **kwargs)\nLoggerAdapter 的 process() 方法是将上下文信息添加到日志的输出中。 它传入日志消息和日志\n调用的关键字参数，并传回（隐式的）这些修改后的内容去调用底层的日志记录器。此方法的默认\n参数只是一个消息字段，但留有一个 'extra' 的字段作为关键字参数传给构造器。当然，如果你在调\n用适配器时传入了一个 'extra' 字段的参数，它会被静默覆盖。\n使用 'extra' 的优点是这些键值对会被传入 LogRecord 实例的 __dict__ 中，让你通过 Formatter 的\n实例直接使用定制的字符串，实例能找到这个字典类对象的键。 如果你需要一个其他的方法，比如\n\n|  | 7. 你可以通过运行 venv/bin/supervisorctl -c supervisor.conf shutdown 来关闭监听器\n和 Web 应用程序。\n你可能需要在配置的端口与你的测试环境中其他程序发生意外冲突的情况下调整配置文件。\n默认配置使用一个 9020 端口上的 TCP 套接字。 你可以通过以下方式改用 Unix 域套接字代替 TCP\n套接字：\n1. 在 listener.json 中，添加一个 socket 键并设为你想使用的域套接字路径。 如果存在该\n键，监听器就将监听相应的域套接字而不是 TCP 套接字 (port 键将被忽略)。\n2. 在 webapp.json 中，修改套接字处理器配置字典以使 host 值为该域套接字的路径，并将\nport 值设为 null。\n在自己的输出日志中添加上下文信息\n有时，除了调用日志对象时传入的参数之外，还希望日志输出中能包含上下文信息。 比如在网络应\n用程序中，可能需要在日志中记录某客户端的信息（如远程客户端的用户名或 IP 地址）。 这虽然可\n以用 extra 参数实现，但传递起来并不总是很方便。 虽然为每个网络连接都创建 Logger 实例貌似不\n错，但并不是个好主意，因为这些实例不会被垃圾回收。 虽然在实践中不是问题，但当 Logger 实\n例的数量取决于应用程序要采用的日志粒度时，如果 Logger 实例的数量实际上是无限的，则有可\n能难以管理。\n利用 LoggerAdapter 传递上下文信息\n要传递上下文信息和日志事件信息，有一种简单方案是利用 LoggerAdapter 类。这个类设计得类似\nLogger，所以可以直接调用 debug()、info()、 warning()、 error()、exception()、\ncritical() 和 log()。这些方法的签名与 Logger 对应的方法相同，所以这两类实例可以交换使\n用。\n当你创建一个 LoggerAdapter 的实例时，你会传入一个 Logger 的实例和一个包含了上下文信息的\n字典对象。当你调用一个 LoggerAdapter 实例的方法时，它会把调用委托给内部的 Logger 的实\n例，并为其整理相关的上下文信息。这是 LoggerAdapter 的一个代码片段: |  |\n| --- | --- | --- |\n|  | def debug(self, msg, /, *args, **kwargs):\n\"\"\"\n在添加来自这个适配器实例的上下文信息之后，\n将调试调用委托给下层的日志记录器。\n\"\"\"\nmsg, kwargs = self.process(msg, kwargs)\nself.logger.debug(msg, *args, **kwargs) |  |\n|  | LoggerAdapter 的 process() 方法是将上下文信息添加到日志的输出中。 它传入日志消息和日志\n调用的关键字参数，并传回（隐式的）这些修改后的内容去调用底层的日志记录器。此方法的默认\n参数只是一个消息字段，但留有一个 'extra' 的字段作为关键字参数传给构造器。当然，如果你在调\n用适配器时传入了一个 'extra' 字段的参数，它会被静默覆盖。\n使用 'extra' 的优点是这些键值对会被传入 LogRecord 实例的 __dict__ 中，让你通过 Formatter 的\n实例直接使用定制的字符串，实例能找到这个字典类对象的键。 如果你需要一个其他的方法，比如 |  |\n\n说，想要在消息字符串前后增加上下文信息，你只需要创建一个 LoggerAdapter 的子类，并覆盖它\n的 process() 方法来做你想做的事情，以下是一个简单的示例:\nclass CustomAdapter(logging.LoggerAdapter):\n\"\"\"\nThis example adapter expects the passed in dict-like object to have a\n'connid' key, whose value in brackets is prepended to the log message.\n\"\"\"\ndef process(self, msg, kwargs):\nreturn '[%s] %s' % (self.extra['connid'], msg), kwargs\n你可以这样使用:\nlogger = logging.getLogger(__name__)\nadapter = CustomAdapter(logger, {'connid': some_conn_id})\n然后，你记录在适配器中的任何事件消息前将添加 some_conn_id 的值。\n使用除字典之外的其它对象传递上下文信息\n你不需要将一个实际的字典传递给 LoggerAdapter-你可以传入一个实现了 __getitem__ 和\n__iter__ 的类的实例，这样它就像是一个字典。这对于你想动态生成值（而字典中的值往往是常\n量）将很有帮助。\n使用过滤器传递上下文信息\n你也可以使用一个用户定义的类 Filter 在日志输出中添加上下文信息。Filter 的实例是被允许修\n改传入的 LogRecords，包括添加其他的属性，然后可以使用合适的格式化字符串输出，或者可以使\n用一个自定义的类 Formatter。\n例如，在一个web应用程序中，正在处理的请求（或者至少是请求的一部分），可以存储在一个线程\n本地 (threading.local) 变量中，然后从 Filter 中去访问。请求中的信息，如IP地址和用户名将\n被存储在 LogRecord 中，使用上例 LoggerAdapter 中的 'ip' 和 'user' 属性名。在这种情况下，可以\n使用相同的格式化字符串来得到上例中类似的输出结果。这是一段示例代码:\nimport logging\nfrom random import choice\nclass ContextFilter(logging.Filter):\n\"\"\"\nThis is a filter which injects contextual information into the log.\nRather than use actual contextual information, we just use random\ndata in this demo.\n\"\"\"\nUSERS = ['jim', 'fred', 'sheila']\nIPS = ['123.231.231.123', '127.0.0.1', '192.168.0.1']\ndef filter(self, record):\nrecord.ip = choice(ContextFilter.IPS)\nrecord.user = choice(ContextFilter.USERS)\n\n|  | 说，想要在消息字符串前后增加上下文信息，你只需要创建一个 LoggerAdapter 的子类，并覆盖它\n的 process() 方法来做你想做的事情，以下是一个简单的示例: |  |\n| --- | --- | --- |\n|  | class CustomAdapter(logging.LoggerAdapter):\n\"\"\"\nThis example adapter expects the passed in dict-like object to have a\n'connid' key, whose value in brackets is prepended to the log message.\n\"\"\"\ndef process(self, msg, kwargs):\nreturn '[%s] %s' % (self.extra['connid'], msg), kwargs |  |\n|  | 你可以这样使用: |  |\n|  | logger = logging.getLogger(__name__)\nadapter = CustomAdapter(logger, {'connid': some_conn_id}) |  |\n|  | 然后，你记录在适配器中的任何事件消息前将添加 some_conn_id 的值。\n使用除字典之外的其它对象传递上下文信息\n你不需要将一个实际的字典传递给 LoggerAdapter-你可以传入一个实现了 __getitem__ 和\n__iter__ 的类的实例，这样它就像是一个字典。这对于你想动态生成值（而字典中的值往往是常\n量）将很有帮助。\n使用过滤器传递上下文信息\n你也可以使用一个用户定义的类 Filter 在日志输出中添加上下文信息。Filter 的实例是被允许修\n改传入的 LogRecords，包括添加其他的属性，然后可以使用合适的格式化字符串输出，或者可以使\n用一个自定义的类 Formatter。\n例如，在一个web应用程序中，正在处理的请求（或者至少是请求的一部分），可以存储在一个线程\n本地 (threading.local) 变量中，然后从 Filter 中去访问。请求中的信息，如IP地址和用户名将\n被存储在 LogRecord 中，使用上例 LoggerAdapter 中的 'ip' 和 'user' 属性名。在这种情况下，可以\n使用相同的格式化字符串来得到上例中类似的输出结果。这是一段示例代码: |  |\n|  | import logging\nfrom random import choice\nclass ContextFilter(logging.Filter):\n\"\"\"\nThis is a filter which injects contextual information into the log.\nRather than use actual contextual information, we just use random\ndata in this demo.\n\"\"\"\nUSERS = ['jim', 'fred', 'sheila']\nIPS = ['123.231.231.123', '127.0.0.1', '192.168.0.1']\ndef filter(self, record):\nrecord.ip = choice(ContextFilter.IPS)\nrecord.user = choice(ContextFilter.USERS) |  |\n\nreturn True\nif __name__ == '__main__':\nlevels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging\nlogging.basicConfig(level=logging.DEBUG,\nformat='%(asctime)-15s %(name)-5s %(levelname)-8s IP: %(ip\na1 = logging.getLogger('a.b.c')\na2 = logging.getLogger('d.e.f')\nf = ContextFilter()\na1.addFilter(f)\na2.addFilter(f)\na1.debug('A debug message')\na1.info('An info message with %s', 'some parameters')\nfor x in range(10):\nlvl = choice(levels)\nlvlname = logging.getLevelName(lvl)\na2.log(lvl, 'A message at %s level with %d %s', lvlname, 2, 'parameters')\n在运行时，产生如下内容:\n2010-09-06 22:38:15,292 a.b.c DEBUG IP: 123.231.231.123 User: fred A debug\n2010-09-06 22:38:15,300 a.b.c INFO IP: 192.168.0.1 User: sheila An info\n2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1 User: sheila A messag\n2010-09-06 22:38:15,300 d.e.f ERROR IP: 127.0.0.1 User: jim A messag\n2010-09-06 22:38:15,300 d.e.f DEBUG IP: 127.0.0.1 User: sheila A messag\n2010-09-06 22:38:15,300 d.e.f ERROR IP: 123.231.231.123 User: fred A messag\n2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 192.168.0.1 User: jim A messag\n2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1 User: sheila A messag\n2010-09-06 22:38:15,300 d.e.f DEBUG IP: 192.168.0.1 User: jim A messag\n2010-09-06 22:38:15,301 d.e.f ERROR IP: 127.0.0.1 User: sheila A messag\n2010-09-06 22:38:15,301 d.e.f DEBUG IP: 123.231.231.123 User: fred A messag\n2010-09-06 22:38:15,301 d.e.f INFO IP: 123.231.231.123 User: fred A messag\ncontextvars 的使用\n自 Python 3.7 起，contextvars 模块提供了同时适用于 threading 和 asyncio 处理需求的上下文\n本地存储。 因此这种存储类型通常要比线程本地存储更好。 下面的例子演示了在多线程环境中日志\n如何用上下文信息来填充内容，例如 Web 应用程序所处理的请求属性。\n出于说明的目的，比方说你有几个不同的 Web 应用程序，彼此都保持独立状态但运行在同一个\nPython 进程中并且它们共同使用了某个库。 这些应用程序要如何拥有各自的日志记录，其中来自这\n个库的日志消息（以及其他请求处理代码）会发到对应的应用程序的日志文件，同时在日志中包括\n额外的上下文信息如客户端 IP、HTTP 请求方法和客户端用户名呢？\n让我们假定这个库可以通过以下代码来模拟:\n# webapplib.py\nimport logging\nimport time\nlogger = logging.getLogger(__name__)\ndef useful():\n# 一条从库中记录的代表性事件\n\n|  | return True\nif __name__ == '__main__':\nlevels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging\nlogging.basicConfig(level=logging.DEBUG,\nformat='%(asctime)-15s %(name)-5s %(levelname)-8s IP: %(ip\na1 = logging.getLogger('a.b.c')\na2 = logging.getLogger('d.e.f')\nf = ContextFilter()\na1.addFilter(f)\na2.addFilter(f)\na1.debug('A debug message')\na1.info('An info message with %s', 'some parameters')\nfor x in range(10):\nlvl = choice(levels)\nlvlname = logging.getLevelName(lvl)\na2.log(lvl, 'A message at %s level with %d %s', lvlname, 2, 'parameters') |  |  |\n| --- | --- | --- | --- |\n|  | 在运行时，产生如下内容: |  |  |\n|  | 2010-09-06 22:38:15,292 a.b.c DEBUG IP: 123.231.231.123 User: fred A debug\n2010-09-06 22:38:15,300 a.b.c INFO IP: 192.168.0.1 User: sheila An info\n2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1 User: sheila A messag\n2010-09-06 22:38:15,300 d.e.f ERROR IP: 127.0.0.1 User: jim A messag\n2010-09-06 22:38:15,300 d.e.f DEBUG IP: 127.0.0.1 User: sheila A messag\n2010-09-06 22:38:15,300 d.e.f ERROR IP: 123.231.231.123 User: fred A messag\n2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 192.168.0.1 User: jim A messag\n2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1 User: sheila A messag\n2010-09-06 22:38:15,300 d.e.f DEBUG IP: 192.168.0.1 User: jim A messag\n2010-09-06 22:38:15,301 d.e.f ERROR IP: 127.0.0.1 User: sheila A messag\n2010-09-06 22:38:15,301 d.e.f DEBUG IP: 123.231.231.123 User: fred A messag\n2010-09-06 22:38:15,301 d.e.f INFO IP: 123.231.231.123 User: fred A messag |  |  |\n|  | contextvars 的使用 |  |  |\n|  | 自 Python 3.7 起，contextvars 模块提供了同时适用于 threading 和 asyncio 处理需求的上下文\n本地存储。 因此这种存储类型通常要比线程本地存储更好。 下面的例子演示了在多线程环境中日志\n如何用上下文信息来填充内容，例如 Web 应用程序所处理的请求属性。\n出于说明的目的，比方说你有几个不同的 Web 应用程序，彼此都保持独立状态但运行在同一个\nPython 进程中并且它们共同使用了某个库。 这些应用程序要如何拥有各自的日志记录，其中来自这\n个库的日志消息（以及其他请求处理代码）会发到对应的应用程序的日志文件，同时在日志中包括\n额外的上下文信息如客户端 IP、HTTP 请求方法和客户端用户名呢？\n让我们假定这个库可以通过以下代码来模拟: |  |  |\n|  | # webapplib.py\nimport logging\nimport time\nlogger = logging.getLogger(__name__)\ndef useful():\n# 一条从库中记录的代表性事件 |  |  |\n\nlogger.debug('Hello from webapplib!')\n# 休眠一下以便其他线程能够运行\ntime.sleep(0.01)\n我们可以通过两个简单的类 Request 和 WebApp 来模拟多个 Web 应用程序。 它们模拟了真正的多\n线程 Web 应用程序是如何工作的 —— 每个请求均由单独的线程来处理:\n# main.py\nimport argparse\nfrom contextvars import ContextVar\nimport logging\nimport os\nfrom random import choice\nimport threading\nimport webapplib\nlogger = logging.getLogger(__name__)\nroot = logging.getLogger()\nroot.setLevel(logging.DEBUG)\nclass Request:\n\"\"\"\nA simple dummy request class which just holds dummy HTTP request method,\nclient IP address and client username\n\"\"\"\ndef __init__(self, method, ip, user):\nself.method = method\nself.ip = ip\nself.user = user\n# 将在模拟中使用的一组假请求 —— 我们将从这个列表随机选取。\n# 请注意所有 GET 请求都来自 192.168.2.XXX 地址，\n# 而 POST 请求都来自 192.16.3.XXX 地址。\n# 在这些样例请求中有三个用户。\nREQUESTS = [\nRequest('GET', '192.168.2.20', 'jim'),\nRequest('POST', '192.168.3.20', 'fred'),\nRequest('GET', '192.168.2.21', 'sheila'),\nRequest('POST', '192.168.3.21', 'jim'),\nRequest('GET', '192.168.2.22', 'fred'),\nRequest('POST', '192.168.3.22', 'sheila'),\n]\n# 请注意格式字符串包括了对请求上下文信息的引用\n# 如 HTTP 方法，客户端 IP 和用户名\nformatter = logging.Formatter('%(threadName)-11s %(appName)s %(name)-9s %(user)-6s\n# 创建我们的上下文变量。 它们将在开始处理请求时被填充，\n# 并将在处理时发生的日志记录中被使用。\nctx_request = ContextVar('request')\nctx_appname = ContextVar('appname')\nclass InjectingFilter(logging.Filter):\n\"\"\"\nA filter which injects context-specific information into logs and ensures\n\n|  | logger.debug('Hello from webapplib!')\n# 休眠一下以便其他线程能够运行\ntime.sleep(0.01) |  |\n| --- | --- | --- |\n|  | 我们可以通过两个简单的类 Request 和 WebApp 来模拟多个 Web 应用程序。 它们模拟了真正的多\n线程 Web 应用程序是如何工作的 —— 每个请求均由单独的线程来处理: |  |\n|  | # main.py\nimport argparse\nfrom contextvars import ContextVar\nimport logging\nimport os\nfrom random import choice\nimport threading\nimport webapplib\nlogger = logging.getLogger(__name__)\nroot = logging.getLogger()\nroot.setLevel(logging.DEBUG)\nclass Request:\n\"\"\"\nA simple dummy request class which just holds dummy HTTP request method,\nclient IP address and client username\n\"\"\"\ndef __init__(self, method, ip, user):\nself.method = method\nself.ip = ip\nself.user = user\n# 将在模拟中使用的一组假请求 —— 我们将从这个列表随机选取。\n# 请注意所有 GET 请求都来自 192.168.2.XXX 地址，\n# 而 POST 请求都来自 192.16.3.XXX 地址。\n# 在这些样例请求中有三个用户。\nREQUESTS = [\nRequest('GET', '192.168.2.20', 'jim'),\nRequest('POST', '192.168.3.20', 'fred'),\nRequest('GET', '192.168.2.21', 'sheila'),\nRequest('POST', '192.168.3.21', 'jim'),\nRequest('GET', '192.168.2.22', 'fred'),\nRequest('POST', '192.168.3.22', 'sheila'),\n]\n# 请注意格式字符串包括了对请求上下文信息的引用\n# 如 HTTP 方法，客户端 IP 和用户名\nformatter = logging.Formatter('%(threadName)-11s %(appName)s %(name)-9s %(user)-6s\n# 创建我们的上下文变量。 它们将在开始处理请求时被填充，\n# 并将在处理时发生的日志记录中被使用。\nctx_request = ContextVar('request')\nctx_appname = ContextVar('appname')\nclass InjectingFilter(logging.Filter):\n\"\"\"\nA filter which injects context-specific information into logs and ensures |  |\n\nthat only information for a specific webapp is included in its log\n\"\"\"\ndef __init__(self, app):\nself.app = app\ndef filter(self, record):\nrequest = ctx_request.get()\nrecord.method = request.method\nrecord.ip = request.ip\nrecord.user = request.user\nrecord.appName = appName = ctx_appname.get()\nreturn appName == self.app.name\nclass WebApp:\n\"\"\"\nA dummy web application class which has its own handler and filter for a\nwebapp-specific log.\n\"\"\"\ndef __init__(self, name):\nself.name = name\nhandler = logging.FileHandler(name + '.log', 'w')\nf = InjectingFilter(self)\nhandler.setFormatter(formatter)\nhandler.addFilter(f)\nroot.addHandler(handler)\nself.num_requests = 0\ndef process_request(self, request):\n\"\"\"\nThis is the dummy method for processing a request. It's called on a\ndifferent thread for every request. We store the context information into\nthe context vars before doing anything else.\n\"\"\"\nctx_request.set(request)\nctx_appname.set(self.name)\nself.num_requests += 1\nlogger.debug('Request processing started')\nwebapplib.useful()\nlogger.debug('Request processing finished')\ndef main():\nfn = os.path.splitext(os.path.basename(__file__))[0]\nadhf = argparse.ArgumentDefaultsHelpFormatter\nap = argparse.ArgumentParser(formatter_class=adhf, prog=fn,\ndescription='Simulate a couple of web '\n'applications handling some '\n'requests, showing how request '\n'context can be used to '\n'populate logs')\naa = ap.add_argument\naa('--count', '-c', type=int, default=100, help='How many requests to simulate\noptions = ap.parse_args()\n# 创建假 Web 应用并将其放在列表中以便我们\n# 用于随机选取\napp1 = WebApp('app1')\napp2 = WebApp('app2')\napps = [app1, app2]\nthreads = []\n# 添加一个将捕获所有事件的通用处理器\n\n|  | that only information for a specific webapp is included in its log\n\"\"\"\ndef __init__(self, app):\nself.app = app\ndef filter(self, record):\nrequest = ctx_request.get()\nrecord.method = request.method\nrecord.ip = request.ip\nrecord.user = request.user\nrecord.appName = appName = ctx_appname.get()\nreturn appName == self.app.name\nclass WebApp:\n\"\"\"\nA dummy web application class which has its own handler and filter for a\nwebapp-specific log.\n\"\"\"\ndef __init__(self, name):\nself.name = name\nhandler = logging.FileHandler(name + '.log', 'w')\nf = InjectingFilter(self)\nhandler.setFormatter(formatter)\nhandler.addFilter(f)\nroot.addHandler(handler)\nself.num_requests = 0\ndef process_request(self, request):\n\"\"\"\nThis is the dummy method for processing a request. It's called on a\ndifferent thread for every request. We store the context information into\nthe context vars before doing anything else.\n\"\"\"\nctx_request.set(request)\nctx_appname.set(self.name)\nself.num_requests += 1\nlogger.debug('Request processing started')\nwebapplib.useful()\nlogger.debug('Request processing finished')\ndef main():\nfn = os.path.splitext(os.path.basename(__file__))[0]\nadhf = argparse.ArgumentDefaultsHelpFormatter\nap = argparse.ArgumentParser(formatter_class=adhf, prog=fn,\ndescription='Simulate a couple of web '\n'applications handling some '\n'requests, showing how request '\n'context can be used to '\n'populate logs')\naa = ap.add_argument\naa('--count', '-c', type=int, default=100, help='How many requests to simulate\noptions = ap.parse_args()\n# 创建假 Web 应用并将其放在列表中以便我们\n# 用于随机选取\napp1 = WebApp('app1')\napp2 = WebApp('app2')\napps = [app1, app2]\nthreads = []\n# 添加一个将捕获所有事件的通用处理器 |  |\n| --- | --- | --- |\n\nhandler = logging.FileHandler('app.log', 'w')\nhandler.setFormatter(formatter)\nroot.addHandler(handler)\n# 生成调用来处理请求\nfor i in range(options.count):\ntry:\n# Pick an app at random and a request for it to process\napp = choice(apps)\nrequest = choice(REQUESTS)\n# Process the request in its own thread\nt = threading.Thread(target=app.process_request, args=(request,))\nthreads.append(t)\nt.start()\nexcept KeyboardInterrupt:\nbreak\n# 等待线程终结\nfor t in threads:\nt.join()\nfor app in apps:\nprint('%s processed %s requests' % (app.name, app.num_requests))\nif __name__ == '__main__':\nmain()\n如果你运行上面的代码，你将会发现约有半数请求是发给 app1.log 而其余的则是发给 app2.log，\n并且所有请求都会被记录至 app.log。 每个 Web 应用专属的日志将只包含该 Web 应用的日志条\n目，请求信息也将以一致的方式显示在日志里（即每个模拟请求中的信息将总是在一个日志行中一\n起显示）。 如下面的 shell 输出所示:\n~/logging-contextual-webapp$ python main.py\napp1 processed 51 requests\napp2 processed 49 requests\n~/logging-contextual-webapp$ wc -l *.log\n153 app1.log\n147 app2.log\n300 app.log\n600 total\n~/logging-contextual-webapp$ head -3 app1.log\nThread-3 (process_request) app1 __main__ jim 192.168.3.21 POST Request process\nThread-3 (process_request) app1 webapplib jim 192.168.3.21 POST Hello from weba\nThread-5 (process_request) app1 __main__ jim 192.168.3.21 POST Request process\n~/logging-contextual-webapp$ head -3 app2.log\nThread-1 (process_request) app2 __main__ sheila 192.168.2.21 GET Request process\nThread-1 (process_request) app2 webapplib sheila 192.168.2.21 GET Hello from weba\nThread-2 (process_request) app2 __main__ jim 192.168.2.20 GET Request process\n~/logging-contextual-webapp$ head app.log\nThread-1 (process_request) app2 __main__ sheila 192.168.2.21 GET Request process\nThread-1 (process_request) app2 webapplib sheila 192.168.2.21 GET Hello from weba\nThread-2 (process_request) app2 __main__ jim 192.168.2.20 GET Request process\nThread-3 (process_request) app1 __main__ jim 192.168.3.21 POST Request process\nThread-2 (process_request) app2 webapplib jim 192.168.2.20 GET Hello from weba\nThread-3 (process_request) app1 webapplib jim 192.168.3.21 POST Hello from weba\nThread-4 (process_request) app2 __main__ fred 192.168.2.22 GET Request process\nThread-5 (process_request) app1 __main__ jim 192.168.3.21 POST Request process\nThread-4 (process_request) app2 webapplib fred 192.168.2.22 GET Hello from weba\n\n|  | handler = logging.FileHandler('app.log', 'w')\nhandler.setFormatter(formatter)\nroot.addHandler(handler)\n# 生成调用来处理请求\nfor i in range(options.count):\ntry:\n# Pick an app at random and a request for it to process\napp = choice(apps)\nrequest = choice(REQUESTS)\n# Process the request in its own thread\nt = threading.Thread(target=app.process_request, args=(request,))\nthreads.append(t)\nt.start()\nexcept KeyboardInterrupt:\nbreak\n# 等待线程终结\nfor t in threads:\nt.join()\nfor app in apps:\nprint('%s processed %s requests' % (app.name, app.num_requests))\nif __name__ == '__main__':\nmain() |  |  |\n| --- | --- | --- | --- |\n|  | 如果你运行上面的代码，你将会发现约有半数请求是发给 app1.log 而其余的则是发给 app2.log，\n并且所有请求都会被记录至 app.log。 每个 Web 应用专属的日志将只包含该 Web 应用的日志条\n目，请求信息也将以一致的方式显示在日志里（即每个模拟请求中的信息将总是在一个日志行中一\n起显示）。 如下面的 shell 输出所示: |  |  |\n|  | ~/logging-contextual-webapp$ python main.py\napp1 processed 51 requests\napp2 processed 49 requests\n~/logging-contextual-webapp$ wc -l *.log\n153 app1.log\n147 app2.log\n300 app.log\n600 total\n~/logging-contextual-webapp$ head -3 app1.log\nThread-3 (process_request) app1 __main__ jim 192.168.3.21 POST Request process\nThread-3 (process_request) app1 webapplib jim 192.168.3.21 POST Hello from weba\nThread-5 (process_request) app1 __main__ jim 192.168.3.21 POST Request process\n~/logging-contextual-webapp$ head -3 app2.log\nThread-1 (process_request) app2 __main__ sheila 192.168.2.21 GET Request process\nThread-1 (process_request) app2 webapplib sheila 192.168.2.21 GET Hello from weba\nThread-2 (process_request) app2 __main__ jim 192.168.2.20 GET Request process\n~/logging-contextual-webapp$ head app.log\nThread-1 (process_request) app2 __main__ sheila 192.168.2.21 GET Request process\nThread-1 (process_request) app2 webapplib sheila 192.168.2.21 GET Hello from weba\nThread-2 (process_request) app2 __main__ jim 192.168.2.20 GET Request process\nThread-3 (process_request) app1 __main__ jim 192.168.3.21 POST Request process\nThread-2 (process_request) app2 webapplib jim 192.168.2.20 GET Hello from weba\nThread-3 (process_request) app1 webapplib jim 192.168.3.21 POST Hello from weba\nThread-4 (process_request) app2 __main__ fred 192.168.2.22 GET Request process\nThread-5 (process_request) app1 __main__ jim 192.168.3.21 POST Request process\nThread-4 (process_request) app2 webapplib fred 192.168.2.22 GET Hello from weba |  |  |\n\nThread-6 (process_request) app1 __main__ jim 192.168.3.21 POST Request process\n~/logging-contextual-webapp$ grep app1 app1.log | wc -l\n153\n~/logging-contextual-webapp$ grep app2 app2.log | wc -l\n147\n~/logging-contextual-webapp$ grep app1 app.log | wc -l\n153\n~/logging-contextual-webapp$ grep app2 app.log | wc -l\n147\n在处理器中传递上下文信息\n每个 Handler 都有自己的过滤器链。 如果你想向一个 LogRecord 添加上下文信息而不使其泄露给\n其它处理器，你可以使用一个返回新 LogRecord 而不是原地修改它的过滤器，如下面的脚本所示:\nimport copy\nimport logging\ndef filter(record: logging.LogRecord):\nrecord = copy.copy(record)\nrecord.user = 'jim'\nreturn record\nif __name__ == '__main__':\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\nhandler = logging.StreamHandler()\nformatter = logging.Formatter('%(message)s from %(user)-8s')\nhandler.setFormatter(formatter)\nhandler.addFilter(filter)\nlogger.addHandler(handler)\nlogger.info('A log message')\n从多个进程记录至单个文件\n尽管 logging 是线程安全的，将单个进程中的多个线程日志记录至单个文件也 是 受支持的，但将 多\n个进程 中的日志记录至单个文件则 不是 受支持的，因为在 Python 中并没有在多个进程中实现对单\n个文件访问的序列化的标准方案。 如果你需要将多个进程中的日志记录至单个文件，有一个方案是\n让所有进程都将日志记录至一个 SocketHandler，然后用一个实现了套接字服务器的单独进程一边\n从套接字中读取一边将日志记录至文件。 （如果愿意的话，你可以在一个现有进程中专门开一个线\n程来执行此项功能。） 这一部分 文档对此方式有更详细的介绍，并包含一个可用的套接字接收器，\n你自己的应用可以在此基础上进行适配。\n你也可以编写你自己的处理器，让其使用 multiprocessing 模块中的 Lock 类来顺序访问你的多个\n进程中的文件。 标准库的 FileHandler 及其子类均未使用 multiprocessing。\n或者，你也可以使用 Queue 和 QueueHandler 将所有的日志事件发送至你的多进程应用的一个进程\n中。 以下示例脚本演示了如何执行此操作。 在示例中，一个单独的监听进程负责监听其他进程的日\n志事件，并根据自己的配置记录。 尽管示例只演示了这种方法（例如你可能希望使用单独的监听线\n\n|  | Thread-6 (process_request) app1 __main__ jim 192.168.3.21 POST Request process\n~/logging-contextual-webapp$ grep app1 app1.log | wc -l\n153\n~/logging-contextual-webapp$ grep app2 app2.log | wc -l\n147\n~/logging-contextual-webapp$ grep app1 app.log | wc -l\n153\n~/logging-contextual-webapp$ grep app2 app.log | wc -l\n147 |  |  |\n| --- | --- | --- | --- |\n|  | 在处理器中传递上下文信息\n每个 Handler 都有自己的过滤器链。 如果你想向一个 LogRecord 添加上下文信息而不使其泄露给\n其它处理器，你可以使用一个返回新 LogRecord 而不是原地修改它的过滤器，如下面的脚本所示: |  |  |\n|  | import copy\nimport logging\ndef filter(record: logging.LogRecord):\nrecord = copy.copy(record)\nrecord.user = 'jim'\nreturn record\nif __name__ == '__main__':\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\nhandler = logging.StreamHandler()\nformatter = logging.Formatter('%(message)s from %(user)-8s')\nhandler.setFormatter(formatter)\nhandler.addFilter(filter)\nlogger.addHandler(handler)\nlogger.info('A log message') |  |  |\n|  |  |  |  |\n|  | 从多个进程记录至单个文件\n尽管 logging 是线程安全的，将单个进程中的多个线程日志记录至单个文件也 是 受支持的，但将 多\n个进程 中的日志记录至单个文件则 不是 受支持的，因为在 Python 中并没有在多个进程中实现对单\n个文件访问的序列化的标准方案。 如果你需要将多个进程中的日志记录至单个文件，有一个方案是\n让所有进程都将日志记录至一个 SocketHandler，然后用一个实现了套接字服务器的单独进程一边\n从套接字中读取一边将日志记录至文件。 （如果愿意的话，你可以在一个现有进程中专门开一个线\n程来执行此项功能。） 这一部分 文档对此方式有更详细的介绍，并包含一个可用的套接字接收器，\n你自己的应用可以在此基础上进行适配。\n你也可以编写你自己的处理器，让其使用 multiprocessing 模块中的 Lock 类来顺序访问你的多个\n进程中的文件。 标准库的 FileHandler 及其子类均未使用 multiprocessing。\n或者，你也可以使用 Queue 和 QueueHandler 将所有的日志事件发送至你的多进程应用的一个进程\n中。 以下示例脚本演示了如何执行此操作。 在示例中，一个单独的监听进程负责监听其他进程的日\n志事件，并根据自己的配置记录。 尽管示例只演示了这种方法（例如你可能希望使用单独的监听线 |  |  |\n\n程而非监听进程 —— 它们的实现是类似的），但你也可以在应用程序的监听进程和其他进程使用不\n同的配置，它可以作为满足你特定需求的一个基础:\n# 你将在自己的代码中需要这些导入\nimport logging\nimport logging.handlers\nimport multiprocessing\n# 以下两行导入仅针对本演示\nfrom random import choice, random\nimport time\n#\n# 因为你会希望为监听进程和工作进程定义日志记录配置，\n# 这些进程函数将接受一个可调用对象作为 configurer 形参\n# 用于为进程配置日志记录。 这些函数还将接受一个队列，\n# 供它们在通信中使用。\n#\n# 实际上，你可以根据你的需要任意配置监听进程，但请注意在\n# 该简单示例中监听进程没有对收到的记录应用层级或过滤逻辑。\n# 在实践中，你可能会希望在工作进程中执行此逻辑，以避免发送\n# 将会在进程间被过滤掉的事件。\n#\n# 轮转文件的尺寸被设置为很小以便你能方便地查看结果。\ndef listener_configurer():\nroot = logging.getLogger()\nh = logging.handlers.RotatingFileHandler('mptest.log', 'a', 300, 10)\nf = logging.Formatter('%(asctime)s %(processName)-10s %(name)s %(levelname)-8s\nh.setFormatter(f)\nroot.addHandler(h)\n# 这是监听进程的最高层级循环：等待队列中的日志记录事件\n# (LogRecords) 并处理它们，当在接受 LogRecord 时收到 None\n# 则退出。\ndef listener_process(queue, configurer):\nconfigurer()\nwhile True:\ntry:\nrecord = queue.get()\nif record is None: # 我们发送该值以通知监听进程退出。\nbreak\nlogger = logging.getLogger(record.name)\nlogger.handle(record) # 未应用层级或过滤逻辑 —— 直接做！ except\nimport sys, traceback\nprint('Whoops! Problem:', file=sys.stderr)\ntraceback.print_exc(file=sys.stderr)\n# 用于在本演示中随机选取的数组\nLEVELS = [logging.DEBUG, logging.INFO, logging.WARNING,\nlogging.ERROR, logging.CRITICAL]\nLOGGERS = ['a.b.c', 'd.e.f']\nMESSAGES = [\n'Random message #1',\n'Random message #2',\n'Random message #3',\n]\n\n|  | 程而非监听进程 —— 它们的实现是类似的），但你也可以在应用程序的监听进程和其他进程使用不\n同的配置，它可以作为满足你特定需求的一个基础: |  |\n| --- | --- | --- |\n|  | # 你将在自己的代码中需要这些导入\nimport logging\nimport logging.handlers\nimport multiprocessing\n# 以下两行导入仅针对本演示\nfrom random import choice, random\nimport time\n#\n# 因为你会希望为监听进程和工作进程定义日志记录配置，\n# 这些进程函数将接受一个可调用对象作为 configurer 形参\n# 用于为进程配置日志记录。 这些函数还将接受一个队列，\n# 供它们在通信中使用。\n#\n# 实际上，你可以根据你的需要任意配置监听进程，但请注意在\n# 该简单示例中监听进程没有对收到的记录应用层级或过滤逻辑。\n# 在实践中，你可能会希望在工作进程中执行此逻辑，以避免发送\n# 将会在进程间被过滤掉的事件。\n#\n# 轮转文件的尺寸被设置为很小以便你能方便地查看结果。\ndef listener_configurer():\nroot = logging.getLogger()\nh = logging.handlers.RotatingFileHandler('mptest.log', 'a', 300, 10)\nf = logging.Formatter('%(asctime)s %(processName)-10s %(name)s %(levelname)-8s\nh.setFormatter(f)\nroot.addHandler(h)\n# 这是监听进程的最高层级循环：等待队列中的日志记录事件\n# (LogRecords) 并处理它们，当在接受 LogRecord 时收到 None\n# 则退出。\ndef listener_process(queue, configurer):\nconfigurer()\nwhile True:\ntry:\nrecord = queue.get()\nif record is None: # 我们发送该值以通知监听进程退出。\nbreak\nlogger = logging.getLogger(record.name)\nlogger.handle(record) # 未应用层级或过滤逻辑 —— 直接做！ except\nimport sys, traceback\nprint('Whoops! Problem:', file=sys.stderr)\ntraceback.print_exc(file=sys.stderr)\n# 用于在本演示中随机选取的数组\nLEVELS = [logging.DEBUG, logging.INFO, logging.WARNING,\nlogging.ERROR, logging.CRITICAL]\nLOGGERS = ['a.b.c', 'd.e.f']\nMESSAGES = [\n'Random message #1',\n'Random message #2',\n'Random message #3',\n] |  |\n\n# 工作进程配置在工作进程开始运行时完成。\n# 请注意在 Windows 上不能依赖 fork 语义，因此每个进程\n# 将在启动时运行日志记录配置代码。\ndef worker_configurer(queue):\nh = logging.handlers.QueueHandler(queue) # 只需要一个处理器\nroot = logging.getLogger()\nroot.addHandler(h)\n# 发送所有消息，用于演示；未应用其他层级或过滤逻辑。\nroot.setLevel(logging.DEBUG)\n# 这是工作进程的最高层级循环，它将在结束前以随机间隔\n# 记录十个事件。\n# 打印消息只是让你知道它正在做一些事情！\ndef worker_process(queue, configurer):\nconfigurer(queue)\nname = multiprocessing.current_process().name\nprint('Worker started: %s' % name)\nfor i in range(10):\ntime.sleep(random())\nlogger = logging.getLogger(choice(LOGGERS))\nlevel = choice(LEVELS)\nmessage = choice(MESSAGES)\nlogger.log(level, message)\nprint('Worker finished: %s' % name)\n# 以下是演示整合各个组件的地方。 创建队列，创建并启动\n# 监听进程，创建十个工作进程并启动它们，等待它们结束，\n# 然后向队列发送 None 以通知监听进程退出。\ndef main():\nqueue = multiprocessing.Queue(-1)\nlistener = multiprocessing.Process(target=listener_process,\nargs=(queue, listener_configurer))\nlistener.start()\nworkers = []\nfor i in range(10):\nworker = multiprocessing.Process(target=worker_process,\nargs=(queue, worker_configurer))\nworkers.append(worker)\nworker.start()\nfor w in workers:\nw.join()\nqueue.put_nowait(None)\nlistener.join()\nif __name__ == '__main__':\nmain()\n上面脚本的一个变种，仍然在主进程中记录日志，但使用一个单独的线程:\nimport logging\nimport logging.config\nimport logging.handlers\nfrom multiprocessing import Process, Queue\nimport random\nimport threading\nimport time\ndef logger_thread(q):\n\n|  | # 工作进程配置在工作进程开始运行时完成。\n# 请注意在 Windows 上不能依赖 fork 语义，因此每个进程\n# 将在启动时运行日志记录配置代码。\ndef worker_configurer(queue):\nh = logging.handlers.QueueHandler(queue) # 只需要一个处理器\nroot = logging.getLogger()\nroot.addHandler(h)\n# 发送所有消息，用于演示；未应用其他层级或过滤逻辑。\nroot.setLevel(logging.DEBUG)\n# 这是工作进程的最高层级循环，它将在结束前以随机间隔\n# 记录十个事件。\n# 打印消息只是让你知道它正在做一些事情！\ndef worker_process(queue, configurer):\nconfigurer(queue)\nname = multiprocessing.current_process().name\nprint('Worker started: %s' % name)\nfor i in range(10):\ntime.sleep(random())\nlogger = logging.getLogger(choice(LOGGERS))\nlevel = choice(LEVELS)\nmessage = choice(MESSAGES)\nlogger.log(level, message)\nprint('Worker finished: %s' % name)\n# 以下是演示整合各个组件的地方。 创建队列，创建并启动\n# 监听进程，创建十个工作进程并启动它们，等待它们结束，\n# 然后向队列发送 None 以通知监听进程退出。\ndef main():\nqueue = multiprocessing.Queue(-1)\nlistener = multiprocessing.Process(target=listener_process,\nargs=(queue, listener_configurer))\nlistener.start()\nworkers = []\nfor i in range(10):\nworker = multiprocessing.Process(target=worker_process,\nargs=(queue, worker_configurer))\nworkers.append(worker)\nworker.start()\nfor w in workers:\nw.join()\nqueue.put_nowait(None)\nlistener.join()\nif __name__ == '__main__':\nmain() |  |  |\n| --- | --- | --- | --- |\n|  | 上面脚本的一个变种，仍然在主进程中记录日志，但使用一个单独的线程: |  |  |\n|  | import logging\nimport logging.config\nimport logging.handlers\nfrom multiprocessing import Process, Queue\nimport random\nimport threading\nimport time\ndef logger_thread(q): |  |  |\n\nwhile True:\nrecord = q.get()\nif record is None:\nbreak\nlogger = logging.getLogger(record.name)\nlogger.handle(record)\ndef worker_process(q):\nqh = logging.handlers.QueueHandler(q)\nroot = logging.getLogger()\nroot.setLevel(logging.DEBUG)\nroot.addHandler(qh)\nlevels = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL]\nloggers = ['foo', 'foo.bar', 'foo.bar.baz',\n'spam', 'spam.ham', 'spam.ham.eggs']\nfor i in range(100):\nlvl = random.choice(levels)\nlogger = logging.getLogger(random.choice(loggers))\nlogger.log(lvl, 'Message no. %d', i)\nif __name__ == '__main__':\nq = Queue()\nd = {\n'version': 1,\n'formatters': {\n'detailed': {\n'class': 'logging.Formatter',\n'format': '%(asctime)s %(name)-15s %(levelname)-8s %(processName)-\n}\n},\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'level': 'INFO',\n},\n'file': {\n'class': 'logging.FileHandler',\n'filename': 'mplog.log',\n'mode': 'w',\n'formatter': 'detailed',\n},\n'foofile': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-foo.log',\n'mode': 'w',\n'formatter': 'detailed',\n},\n'errors': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-errors.log',\n'mode': 'w',\n'level': 'ERROR',\n'formatter': 'detailed',\n},\n},\n'loggers': {\n'foo': {\n'handlers': ['foofile']\n\n|  | while True:\nrecord = q.get()\nif record is None:\nbreak\nlogger = logging.getLogger(record.name)\nlogger.handle(record)\ndef worker_process(q):\nqh = logging.handlers.QueueHandler(q)\nroot = logging.getLogger()\nroot.setLevel(logging.DEBUG)\nroot.addHandler(qh)\nlevels = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL]\nloggers = ['foo', 'foo.bar', 'foo.bar.baz',\n'spam', 'spam.ham', 'spam.ham.eggs']\nfor i in range(100):\nlvl = random.choice(levels)\nlogger = logging.getLogger(random.choice(loggers))\nlogger.log(lvl, 'Message no. %d', i)\nif __name__ == '__main__':\nq = Queue()\nd = {\n'version': 1,\n'formatters': {\n'detailed': {\n'class': 'logging.Formatter',\n'format': '%(asctime)s %(name)-15s %(levelname)-8s %(processName)-\n}\n},\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'level': 'INFO',\n},\n'file': {\n'class': 'logging.FileHandler',\n'filename': 'mplog.log',\n'mode': 'w',\n'formatter': 'detailed',\n},\n'foofile': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-foo.log',\n'mode': 'w',\n'formatter': 'detailed',\n},\n'errors': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-errors.log',\n'mode': 'w',\n'level': 'ERROR',\n'formatter': 'detailed',\n},\n},\n'loggers': {\n'foo': {\n'handlers': ['foofile'] |  |\n| --- | --- | --- |\n\n}\n},\n'root': {\n'level': 'DEBUG',\n'handlers': ['console', 'file', 'errors']\n},\n}\nworkers = []\nfor i in range(5):\nwp = Process(target=worker_process, name='worker %d' % (i + 1), args=(q,))\nworkers.append(wp)\nwp.start()\nlogging.config.dictConfig(d)\nlp = threading.Thread(target=logger_thread, args=(q,))\nlp.start()\n# 在这里，主进程可以执行某些对它自己有用的工作\n# 当其完成后，即可等待工作进程终结...\nfor wp in workers:\nwp.join()\n# 现在再通知日志记录线程结束\nq.put(None)\nlp.join()\n这段变种的代码展示了如何使用特定的日志记录配置 - 例如 foo 记录器使用了特殊的处理程序，将\nfoo 子系统中所有的事件记录至一个文件 mplog-foo.log 。在主进程（即使是在工作进程中产生的\n日志事件）的日志记录机制中将直接使用恰当的配置。\nconcurrent.futures.ProcessPoolExecutor 的用法\n若要利用 concurrent.futures.ProcessPoolExecutor 启动工作进程，创建队列的方式应稍有不\n同。不能是：\nqueue = multiprocessing.Queue(-1)\n而应是：\nqueue = multiprocessing.Manager().Queue(-1) # 同样适用于上面的例子\n然后就可以将以下工作进程的创建过程：\nworkers = []\nfor i in range(10):\nworker = multiprocessing.Process(target=worker_process,\nargs=(queue, worker_configurer))\nworkers.append(worker)\nworker.start()\nfor w in workers:\nw.join()\n改为 (记得要先导入 concurrent.futures):\nwith concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\nfor i in range(10):\nexecutor.submit(worker_process, queue, worker_configurer)\n\n|  | }\n},\n'root': {\n'level': 'DEBUG',\n'handlers': ['console', 'file', 'errors']\n},\n}\nworkers = []\nfor i in range(5):\nwp = Process(target=worker_process, name='worker %d' % (i + 1), args=(q,))\nworkers.append(wp)\nwp.start()\nlogging.config.dictConfig(d)\nlp = threading.Thread(target=logger_thread, args=(q,))\nlp.start()\n# 在这里，主进程可以执行某些对它自己有用的工作\n# 当其完成后，即可等待工作进程终结...\nfor wp in workers:\nwp.join()\n# 现在再通知日志记录线程结束\nq.put(None)\nlp.join() |  |\n| --- | --- | --- |\n|  | 这段变种的代码展示了如何使用特定的日志记录配置 - 例如 foo 记录器使用了特殊的处理程序，将\nfoo 子系统中所有的事件记录至一个文件 mplog-foo.log 。在主进程（即使是在工作进程中产生的\n日志事件）的日志记录机制中将直接使用恰当的配置。\nconcurrent.futures.ProcessPoolExecutor 的用法\n若要利用 concurrent.futures.ProcessPoolExecutor 启动工作进程，创建队列的方式应稍有不\n同。不能是： |  |\n|  | queue = multiprocessing.Queue(-1) |  |\n|  | 而应是： |  |\n|  | queue = multiprocessing.Manager().Queue(-1) # 同样适用于上面的例子 |  |\n|  | 然后就可以将以下工作进程的创建过程： |  |\n|  | workers = []\nfor i in range(10):\nworker = multiprocessing.Process(target=worker_process,\nargs=(queue, worker_configurer))\nworkers.append(worker)\nworker.start()\nfor w in workers:\nw.join() |  |\n|  | 改为 (记得要先导入 concurrent.futures): |  |\n|  | with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\nfor i in range(10):\nexecutor.submit(worker_process, queue, worker_configurer) |  |\n\n使用 Gunicorn 和 uWSGI 来部署 Web 应用程序\n当使用 Gunicorn 或 uWSGI (或其他类似工具) 来部署 Web 应用时，会创建多个工作进程来处理客户\n端请求。 在这种环境下，要避免在你的 Web 应用中直接创建基于文件的处理器。 而应改为使用一\n个 SocketHandler 将来自 Web 应用的日志发送到在单独进程中运行的监听器。 这可以通过使用一\n个进程管理工具例如 Supervisor 来进行设置 —— 请参阅 Running a logging socket listener in\nproduction 了解详情。\n轮换日志文件\n有时您会希望让日志文件增长到一定大小，然后打开一个新的接着记录日志。 您可能希望只保留一\n定数量的日志文件，当创建文件达到指定数量后将会轮换文件，从而使文件数量和文件大小都保持\n在一定范围之内。 对于这种使用模式，日志包提供了一个 RotatingFileHandler:\nimport glob\nimport logging\nimport logging.handlers\nLOG_FILENAME = 'logging_rotatingfile_example.out'\n# 使用我们想要的输出层级设置特定的日志记录器\nmy_logger = logging.getLogger('MyLogger')\nmy_logger.setLevel(logging.DEBUG)\n# 将日志消息处理器添加到日志记录器\nhandler = logging.handlers.RotatingFileHandler(\nLOG_FILENAME, maxBytes=20, backupCount=5)\nmy_logger.addHandler(handler)\n# 记录一些消息\nfor i in range(20):\nmy_logger.debug('i = %d' % i)\n# 查看创建了哪些文件\nlogfiles = glob.glob('%s*' % LOG_FILENAME)\nfor filename in logfiles:\nprint(filename)\n结果应该是6个单独的文件，每个文件都包含了应用程序的部分历史日志:\nlogging_rotatingfile_example.out\nlogging_rotatingfile_example.out.1\nlogging_rotatingfile_example.out.2\nlogging_rotatingfile_example.out.3\nlogging_rotatingfile_example.out.4\nlogging_rotatingfile_example.out.5\n最新的文件始终是 logging_rotatingfile_example.out，每次到达大小限制时，都会使用后缀\n.1 重命名。每个现有的备份文件都会被重命名并增加其后缀（例如 .1 变为 .2 ），而 .6 文件会被\n删除掉。\n\n|  | 使用 Gunicorn 和 uWSGI 来部署 Web 应用程序\n当使用 Gunicorn 或 uWSGI (或其他类似工具) 来部署 Web 应用时，会创建多个工作进程来处理客户\n端请求。 在这种环境下，要避免在你的 Web 应用中直接创建基于文件的处理器。 而应改为使用一\n个 SocketHandler 将来自 Web 应用的日志发送到在单独进程中运行的监听器。 这可以通过使用一\n个进程管理工具例如 Supervisor 来进行设置 —— 请参阅 Running a logging socket listener in\nproduction 了解详情。\n轮换日志文件\n有时您会希望让日志文件增长到一定大小，然后打开一个新的接着记录日志。 您可能希望只保留一\n定数量的日志文件，当创建文件达到指定数量后将会轮换文件，从而使文件数量和文件大小都保持\n在一定范围之内。 对于这种使用模式，日志包提供了一个 RotatingFileHandler: |  |\n| --- | --- | --- |\n|  | import glob\nimport logging\nimport logging.handlers\nLOG_FILENAME = 'logging_rotatingfile_example.out'\n# 使用我们想要的输出层级设置特定的日志记录器\nmy_logger = logging.getLogger('MyLogger')\nmy_logger.setLevel(logging.DEBUG)\n# 将日志消息处理器添加到日志记录器\nhandler = logging.handlers.RotatingFileHandler(\nLOG_FILENAME, maxBytes=20, backupCount=5)\nmy_logger.addHandler(handler)\n# 记录一些消息\nfor i in range(20):\nmy_logger.debug('i = %d' % i)\n# 查看创建了哪些文件\nlogfiles = glob.glob('%s*' % LOG_FILENAME)\nfor filename in logfiles:\nprint(filename) |  |\n|  | 结果应该是6个单独的文件，每个文件都包含了应用程序的部分历史日志: |  |\n|  | logging_rotatingfile_example.out\nlogging_rotatingfile_example.out.1\nlogging_rotatingfile_example.out.2\nlogging_rotatingfile_example.out.3\nlogging_rotatingfile_example.out.4\nlogging_rotatingfile_example.out.5 |  |\n|  | 最新的文件始终是 logging_rotatingfile_example.out，每次到达大小限制时，都会使用后缀\n.1 重命名。每个现有的备份文件都会被重命名并增加其后缀（例如 .1 变为 .2 ），而 .6 文件会被\n删除掉。 |  |\n\n显然，这个例子将日志长度设置得太小，这是一个极端的例子。 你可能希望将 maxBytes 设置为一\n个合适的值。\n使用其他日志格式化方式\n当日志模块被添加至 Python 标准库时，只有一种格式化消息内容的方法即 %-formatting。 在那之\n后，Python 又增加了两种格式化方法: string.Template (在 Python 2.4 中新增) 和 str.format()\n(在 Python 2.6 中新增)。\n日志（从 3.2 开始）为这两种格式化方式提供了更多支持。Formatter 类可以添加一个额外的可选\n关键字参数 style。它的默认值是 '%'，其他的值 '{' 和 '$' 也支持，对应了其他两种格式化样\n式。其保持了向后兼容（如您所愿），但通过显示指定样式参数，你可以指定格式化字符串的方式\n是使用 str.format() 或 string.Template。 这里是一个控制台会话的示例，展示了这些方式：\n>>> import logging\n>>> root = logging.getLogger()\n>>> root.setLevel(logging.DEBUG)\n>>> handler = logging.StreamHandler()\n>>> bf = logging.Formatter('{asctime} {name} {levelname:8s} {message}',\n... style='{')\n>>> handler.setFormatter(bf)\n>>> root.addHandler(handler)\n>>> logger = logging.getLogger('foo.bar')\n>>> logger.debug('This is a DEBUG message')\n2010-10-28 15:11:55,341 foo.bar DEBUG This is a DEBUG message\n>>> logger.critical('This is a CRITICAL message')\n2010-10-28 15:12:11,526 foo.bar CRITICAL This is a CRITICAL message\n>>> df = logging.Formatter('$asctime $name ${levelname} $message',\n... style='$')\n>>> handler.setFormatter(df)\n>>> logger.debug('This is a DEBUG message')\n2010-10-28 15:13:06,924 foo.bar DEBUG This is a DEBUG message\n>>> logger.critical('This is a CRITICAL message')\n2010-10-28 15:13:11,494 foo.bar CRITICAL This is a CRITICAL message\n>>>\n请注意最终输出到日志的消息格式完全独立于单条日志消息的构造方式。 它仍然可以使用 %-\nformatting，如下所示:\n>>> logger.error('This is an%s %s %s', 'other,', 'ERROR,', 'message')\n2010-10-28 15:19:29,833 foo.bar ERROR This is another, ERROR, message\n>>>\n日志调用（logger.debug() 、logger.info() 等）接受的位置参数只会用于日志信息本身，而关\n键字参数仅用于日志调用的可选处理参数（如关键字参数 exc_info 表示应记录跟踪信息， extra\n则标识了需要加入日志的额外上下文信息）。所以不能直接用 str.format() 或 string.Template\n语法进行日志调用，因为日志包在内部使用 %-f 格式来合并格式串和参数变量。在保持向下兼容性\n时，这一点不会改变，因为已有代码中的所有日志调用都会使用%-f 格式串。\n还有一种方法可以构建自己的日志信息，就是利用 {}- 和 $- 格式。回想一下，任意对象都可用为日\n志信息的格式串，日志包将会调用该对象的 str() 方法，以获取最终的格式串。不妨看下一下两个\n\n|  | 显然，这个例子将日志长度设置得太小，这是一个极端的例子。 你可能希望将 maxBytes 设置为一\n个合适的值。\n使用其他日志格式化方式\n当日志模块被添加至 Python 标准库时，只有一种格式化消息内容的方法即 %-formatting。 在那之\n后，Python 又增加了两种格式化方法: string.Template (在 Python 2.4 中新增) 和 str.format()\n(在 Python 2.6 中新增)。\n日志（从 3.2 开始）为这两种格式化方式提供了更多支持。Formatter 类可以添加一个额外的可选\n关键字参数 style。它的默认值是 '%'，其他的值 '{' 和 '$' 也支持，对应了其他两种格式化样\n式。其保持了向后兼容（如您所愿），但通过显示指定样式参数，你可以指定格式化字符串的方式\n是使用 str.format() 或 string.Template。 这里是一个控制台会话的示例，展示了这些方式： |  |\n| --- | --- | --- |\n|  | >>> import logging\n>>> root = logging.getLogger()\n>>> root.setLevel(logging.DEBUG)\n>>> handler = logging.StreamHandler()\n>>> bf = logging.Formatter('{asctime} {name} {levelname:8s} {message}',\n... style='{')\n>>> handler.setFormatter(bf)\n>>> root.addHandler(handler)\n>>> logger = logging.getLogger('foo.bar')\n>>> logger.debug('This is a DEBUG message')\n2010-10-28 15:11:55,341 foo.bar DEBUG This is a DEBUG message\n>>> logger.critical('This is a CRITICAL message')\n2010-10-28 15:12:11,526 foo.bar CRITICAL This is a CRITICAL message\n>>> df = logging.Formatter('$asctime $name ${levelname} $message',\n... style='$')\n>>> handler.setFormatter(df)\n>>> logger.debug('This is a DEBUG message')\n2010-10-28 15:13:06,924 foo.bar DEBUG This is a DEBUG message\n>>> logger.critical('This is a CRITICAL message')\n2010-10-28 15:13:11,494 foo.bar CRITICAL This is a CRITICAL message\n>>> |  |\n|  | 请注意最终输出到日志的消息格式完全独立于单条日志消息的构造方式。 它仍然可以使用 %-\nformatting，如下所示: |  |\n|  | >>> logger.error('This is an%s %s %s', 'other,', 'ERROR,', 'message')\n2010-10-28 15:19:29,833 foo.bar ERROR This is another, ERROR, message\n>>> |  |\n|  | 日志调用（logger.debug() 、logger.info() 等）接受的位置参数只会用于日志信息本身，而关\n键字参数仅用于日志调用的可选处理参数（如关键字参数 exc_info 表示应记录跟踪信息， extra\n则标识了需要加入日志的额外上下文信息）。所以不能直接用 str.format() 或 string.Template\n语法进行日志调用，因为日志包在内部使用 %-f 格式来合并格式串和参数变量。在保持向下兼容性\n时，这一点不会改变，因为已有代码中的所有日志调用都会使用%-f 格式串。\n还有一种方法可以构建自己的日志信息，就是利用 {}- 和 $- 格式。回想一下，任意对象都可用为日\n志信息的格式串，日志包将会调用该对象的 str() 方法，以获取最终的格式串。不妨看下一下两个 |  |\n\n类：\nclass BraceMessage:\ndef __init__(self, fmt, /, *args, **kwargs):\nself.fmt = fmt\nself.args = args\nself.kwargs = kwargs\ndef __str__(self):\nreturn self.fmt.format(*self.args, **self.kwargs)\nclass DollarMessage:\ndef __init__(self, fmt, /, **kwargs):\nself.fmt = fmt\nself.kwargs = kwargs\ndef __str__(self):\nfrom string import Template\nreturn Template(self.fmt).substitute(**self.kwargs)\n上述两个类均可代替格式串，使得能用 {}- 或 $-formatting 构建最终的“日志信息”部分，这些信息将\n出现在格式化后的日志输出中，替换 %(message)s 或“{message}”或“$message”。每次写入日志时都\n要使用类名，有点不大实用，但如果用上 __ 之类的别名就相当合适了（双下划线 --- 不要与 _ 混\n淆，单下划线用作 gettext.gettext() 或相关函数的同义词/别名 ）。\nPython 并没有上述两个类，当然复制粘贴到自己的代码中也很容易。用法可如下所示（假定在名为\nwherever 的模块中声明）：\n>>> from wherever import BraceMessage as __\n>>> print(__('Message with {0} {name}', 2, name='placeholders'))\nMessage with 2 placeholders\n>>> class Point: pass\n...\n>>> p = Point()\n>>> p.x = 0.5\n>>> p.y = 0.5\n>>> print(__('Message with coordinates: ({point.x:.2f}, {point.y:.2f})',\n... point=p))\nMessage with coordinates: (0.50, 0.50)\n>>> from wherever import DollarMessage as __\n>>> print(__('Message with $num $what', num=2, what='placeholders'))\nMessage with 2 placeholders\n>>>\n上述示例用了 print() 演示格式化输出的过程，实际记录日志时当然会用类似 logger.debug() 的\n方法来应用。\n需要注意的是使用这种方式不会对性能造成明显影响：实际的格式化工作不是在日志记录调用时发\n生的，而是在（如果）处理器即将把日志消息输出到日志时发生的。 因此，唯一可能令人困惑的不\n寻常之处在于包裹在格式字符串和参数外面的圆括号，而不仅仅是格式字符串。 这是因为 __ 标记只\n是对 XXXMessage 类的构造器的调用的语法糖。\n只要愿意，上述类似的效果即可用 LoggerAdapter 实现，如下例所示：\n\n|  | 类： |  |\n| --- | --- | --- |\n|  | class BraceMessage:\ndef __init__(self, fmt, /, *args, **kwargs):\nself.fmt = fmt\nself.args = args\nself.kwargs = kwargs\ndef __str__(self):\nreturn self.fmt.format(*self.args, **self.kwargs)\nclass DollarMessage:\ndef __init__(self, fmt, /, **kwargs):\nself.fmt = fmt\nself.kwargs = kwargs\ndef __str__(self):\nfrom string import Template\nreturn Template(self.fmt).substitute(**self.kwargs) |  |\n|  | 上述两个类均可代替格式串，使得能用 {}- 或 $-formatting 构建最终的“日志信息”部分，这些信息将\n出现在格式化后的日志输出中，替换 %(message)s 或“{message}”或“$message”。每次写入日志时都\n要使用类名，有点不大实用，但如果用上 __ 之类的别名就相当合适了（双下划线 --- 不要与 _ 混\n淆，单下划线用作 gettext.gettext() 或相关函数的同义词/别名 ）。\nPython 并没有上述两个类，当然复制粘贴到自己的代码中也很容易。用法可如下所示（假定在名为\nwherever 的模块中声明）： |  |\n|  | >>> from wherever import BraceMessage as __\n>>> print(__('Message with {0} {name}', 2, name='placeholders'))\nMessage with 2 placeholders\n>>> class Point: pass\n...\n>>> p = Point()\n>>> p.x = 0.5\n>>> p.y = 0.5\n>>> print(__('Message with coordinates: ({point.x:.2f}, {point.y:.2f})',\n... point=p))\nMessage with coordinates: (0.50, 0.50)\n>>> from wherever import DollarMessage as __\n>>> print(__('Message with $num $what', num=2, what='placeholders'))\nMessage with 2 placeholders\n>>> |  |\n|  | 上述示例用了 print() 演示格式化输出的过程，实际记录日志时当然会用类似 logger.debug() 的\n方法来应用。\n需要注意的是使用这种方式不会对性能造成明显影响：实际的格式化工作不是在日志记录调用时发\n生的，而是在（如果）处理器即将把日志消息输出到日志时发生的。 因此，唯一可能令人困惑的不\n寻常之处在于包裹在格式字符串和参数外面的圆括号，而不仅仅是格式字符串。 这是因为 __ 标记只\n是对 XXXMessage 类的构造器的调用的语法糖。\n只要愿意，上述类似的效果即可用 LoggerAdapter 实现，如下例所示： |  |\n\nimport logging\nclass Message:\ndef __init__(self, fmt, args):\nself.fmt = fmt\nself.args = args\ndef __str__(self):\nreturn self.fmt.format(*self.args)\nclass StyleAdapter(logging.LoggerAdapter):\ndef log(self, level, msg, /, *args, stacklevel=1, **kwargs):\nif self.isEnabledFor(level):\nmsg, kwargs = self.process(msg, kwargs)\nself.logger.log(level, Message(msg, args), **kwargs,\nstacklevel=stacklevel+1)\nlogger = StyleAdapter(logging.getLogger(__name__))\ndef main():\nlogger.debug('Hello, {}', 'world!')\nif __name__ == '__main__':\nlogging.basicConfig(level=logging.DEBUG)\nmain()\n在用 Python 3.8 以上版本运行时上述脚本应该会将消息 Hello, world! 写入日志。\n自定义 LogRecord\n每条日志事件都由一个 LogRecord 实例表示。当某事件要记入日志并且没有被某级别过滤掉时，就\n会创建一个 LogRecord 对象，并将有关事件的信息填入，传给该日志对象的 handler（及其祖先，\n直至对象禁止向上传播为止）。在 Python 3.2 之前，只有两个地方会进行事件的创建：\nLogger.makeRecord()，在事件正常记入日志的过程中调用。这会直接调用 LogRecord 来创建一\n个实例。\nmakeLogRecord()，调用时会带上一个字典参数，其中存放着要加入 LogRecord 的属性。这通常\n在通过网络接收到合适的字典时调用（如通过 SocketHandler 以 pickle 形式，或通过\nHTTPHandler 以 JSON 形式）。\n于是这意味着若要对 LogRecord 进行定制，必须进行下述某种操作。\n创建 Logger 自定义子类，重写 Logger.makeRecord()，并在实例化所需日志对象之前用\nsetLoggerClass() 进行设置。\n为日志对象添加 Filter 或 handler，当其 filter() 方法被调用时，会执行必要的定制操作。\n比如说在有多个不同库要完成不同操作的场景下，第一种方式会有点笨拙。 每次都要尝试设置自己\n的 Logger 子类，而起作用的是最后一次尝试。\n第二种方式在多数情况下效果都比较良好，但不允许你使用特殊化的 LogRecord 子类。 库开发者可\n以为他们的日志记录器设置合适的过滤器，但他们应当要记得每次引入新的日志记录器时都需如此\n（他们只需通过添加新的包或模块并执行以下操作即可）:\n\n|  | import logging\nclass Message:\ndef __init__(self, fmt, args):\nself.fmt = fmt\nself.args = args\ndef __str__(self):\nreturn self.fmt.format(*self.args)\nclass StyleAdapter(logging.LoggerAdapter):\ndef log(self, level, msg, /, *args, stacklevel=1, **kwargs):\nif self.isEnabledFor(level):\nmsg, kwargs = self.process(msg, kwargs)\nself.logger.log(level, Message(msg, args), **kwargs,\nstacklevel=stacklevel+1)\nlogger = StyleAdapter(logging.getLogger(__name__))\ndef main():\nlogger.debug('Hello, {}', 'world!')\nif __name__ == '__main__':\nlogging.basicConfig(level=logging.DEBUG)\nmain() |  |\n| --- | --- | --- |\n|  | 在用 Python 3.8 以上版本运行时上述脚本应该会将消息 Hello, world! 写入日志。\n自定义 LogRecord\n每条日志事件都由一个 LogRecord 实例表示。当某事件要记入日志并且没有被某级别过滤掉时，就\n会创建一个 LogRecord 对象，并将有关事件的信息填入，传给该日志对象的 handler（及其祖先，\n直至对象禁止向上传播为止）。在 Python 3.2 之前，只有两个地方会进行事件的创建：\nLogger.makeRecord()，在事件正常记入日志的过程中调用。这会直接调用 LogRecord 来创建一\n个实例。\nmakeLogRecord()，调用时会带上一个字典参数，其中存放着要加入 LogRecord 的属性。这通常\n在通过网络接收到合适的字典时调用（如通过 SocketHandler 以 pickle 形式，或通过\nHTTPHandler 以 JSON 形式）。\n于是这意味着若要对 LogRecord 进行定制，必须进行下述某种操作。\n创建 Logger 自定义子类，重写 Logger.makeRecord()，并在实例化所需日志对象之前用\nsetLoggerClass() 进行设置。\n为日志对象添加 Filter 或 handler，当其 filter() 方法被调用时，会执行必要的定制操作。\n比如说在有多个不同库要完成不同操作的场景下，第一种方式会有点笨拙。 每次都要尝试设置自己\n的 Logger 子类，而起作用的是最后一次尝试。\n第二种方式在多数情况下效果都比较良好，但不允许你使用特殊化的 LogRecord 子类。 库开发者可\n以为他们的日志记录器设置合适的过滤器，但他们应当要记得每次引入新的日志记录器时都需如此\n（他们只需通过添加新的包或模块并执行以下操作即可）: |  |\n\nlogger = logging.getLogger(__name__)\n或许这样要顾及太多事情。开发人员还可以将过滤器附加到其顶级日志对象的 NullHandler 中，但\n如果应用程序开发人员将 handler 附加到较底层库的日志对象，则不会调用该过滤器 --- 所以\nhandler 输出的内容不会符合库开发人员的预期。\n在 Python 3.2 以上版本中，LogRecord 的创建是通过工厂对象完成的，工厂对象可以指定。工厂对\n象只是一个可调用对象，可以用 setLogRecordFactory() 进行设置，并用\ngetLogRecordFactory() 进行查询。工厂对象的调用参数与 LogRecord 的构造函数相同，因为\nLogRecord 是工厂对象的默认设置。\n这种方式可以让自定义工厂对象完全控制 LogRecord 的创建过程。比如可以返回一个子类，或者在\n创建的日志对象中加入一些额外的属性，使用方式如下所示：\nold_factory = logging.getLogRecordFactory()\ndef record_factory(*args, **kwargs):\nrecord = old_factory(*args, **kwargs)\nrecord.custom_attribute = 0xdecafbad\nreturn record\nlogging.setLogRecordFactory(record_factory)\n这种模式允许不同的库将多个工厂对象链在一起，只要不会覆盖彼此的属性或标准属性，就不会出\n现意外。但应记住，工厂链中的每个节点都会增加日志操作的运行开销，本技术仅在采用 Filter\n无法达到目标时才应使用。\n子类化 QueueHandler 和 QueueListener - ZeroMQ 示例\n子类 QueueHandler\n你可以使用 QueueHandler 子类将消息发送给其他类型的队列 ，比如 ZeroMQ 'publish' 套接字。 在\n以下示例中，套接字将单独创建并传给处理器 (作为它的 'queue'):\nimport zmq # 使用 pyzmq，这是 ZeroMQ 的 Python 绑定\nimport json # 用于可移植地对记录进行序列化\nctx = zmq.Context()\nsock = zmq.Socket(ctx, zmq.PUB) # 或 zmq.PUSH，或其他适当的值\nsock.bind('tcp://*:5556') # 或任何值\nclass ZeroMQSocketHandler(QueueHandler):\ndef enqueue(self, record):\nself.queue.send_json(record.__dict__)\nhandler = ZeroMQSocketHandler(sock)\n当然还有其他方案，比如通过 hander 传入所需数据，以创建 socket：\nclass ZeroMQSocketHandler(QueueHandler):\ndef __init__(self, uri, socktype=zmq.PUB, ctx=None):\n\n|  | logger = logging.getLogger(__name__) |  |\n| --- | --- | --- |\n|  | 或许这样要顾及太多事情。开发人员还可以将过滤器附加到其顶级日志对象的 NullHandler 中，但\n如果应用程序开发人员将 handler 附加到较底层库的日志对象，则不会调用该过滤器 --- 所以\nhandler 输出的内容不会符合库开发人员的预期。\n在 Python 3.2 以上版本中，LogRecord 的创建是通过工厂对象完成的，工厂对象可以指定。工厂对\n象只是一个可调用对象，可以用 setLogRecordFactory() 进行设置，并用\ngetLogRecordFactory() 进行查询。工厂对象的调用参数与 LogRecord 的构造函数相同，因为\nLogRecord 是工厂对象的默认设置。\n这种方式可以让自定义工厂对象完全控制 LogRecord 的创建过程。比如可以返回一个子类，或者在\n创建的日志对象中加入一些额外的属性，使用方式如下所示： |  |\n|  | old_factory = logging.getLogRecordFactory()\ndef record_factory(*args, **kwargs):\nrecord = old_factory(*args, **kwargs)\nrecord.custom_attribute = 0xdecafbad\nreturn record\nlogging.setLogRecordFactory(record_factory) |  |\n|  | 这种模式允许不同的库将多个工厂对象链在一起，只要不会覆盖彼此的属性或标准属性，就不会出\n现意外。但应记住，工厂链中的每个节点都会增加日志操作的运行开销，本技术仅在采用 Filter\n无法达到目标时才应使用。\n子类化 QueueHandler 和 QueueListener - ZeroMQ 示例\n子类 QueueHandler\n你可以使用 QueueHandler 子类将消息发送给其他类型的队列 ，比如 ZeroMQ 'publish' 套接字。 在\n以下示例中，套接字将单独创建并传给处理器 (作为它的 'queue'): |  |\n|  | import zmq # 使用 pyzmq，这是 ZeroMQ 的 Python 绑定\nimport json # 用于可移植地对记录进行序列化\nctx = zmq.Context()\nsock = zmq.Socket(ctx, zmq.PUB) # 或 zmq.PUSH，或其他适当的值\nsock.bind('tcp://*:5556') # 或任何值\nclass ZeroMQSocketHandler(QueueHandler):\ndef enqueue(self, record):\nself.queue.send_json(record.__dict__)\nhandler = ZeroMQSocketHandler(sock) |  |\n|  | 当然还有其他方案，比如通过 hander 传入所需数据，以创建 socket： |  |\n|  | class ZeroMQSocketHandler(QueueHandler):\ndef __init__(self, uri, socktype=zmq.PUB, ctx=None): |  |\n\nself.ctx = ctx or zmq.Context()\nsocket = zmq.Socket(self.ctx, socktype)\nsocket.bind(uri)\nsuper().__init__(socket)\ndef enqueue(self, record):\nself.queue.send_json(record.__dict__)\ndef close(self):\nself.queue.close()\n子类 QueueListener\n你还可以子类化 QueueListener 来从其他类型的队列中获取消息，比如从 ZeroMQ 'subscribe' 套接\n字。 下面是一个例子:\nclass ZeroMQSocketListener(QueueListener):\ndef __init__(self, uri, /, *handlers, **kwargs):\nself.ctx = kwargs.get('ctx') or zmq.Context()\nsocket = zmq.Socket(self.ctx, zmq.SUB)\nsocket.setsockopt_string(zmq.SUBSCRIBE, '') # 全部预订\nsocket.connect(uri)\nsuper().__init__(socket, *handlers, **kwargs)\ndef dequeue(self):\nmsg = self.queue.recv_json()\nreturn logging.makeLogRecord(msg)\n子类化 QueueHandler 和 QueueListener - pynng 示例\n通过与上一节类似的方式，我们可以使用 pynng 来实现监听器和处理器，这个包是针对 NNG 的\nPython 绑定，它被确定为 ZeroMQ 的精神后继者。 以下代码片段被用作演示 -- 你可以在安装了\npynng 的环境中测试它们。 为增加变化，我们先编写监听器。\n子类 QueueListener\n# listener.py\nimport json\nimport logging\nimport logging.handlers\nimport pynng\nDEFAULT_ADDR = \"tcp://localhost:13232\"\ninterrupted = False\nclass NNGSocketListener(logging.handlers.QueueListener):\ndef __init__(self, uri, /, *handlers, **kwargs):\n# 设置超时以允许中断，并打开一个\n# 订阅方套接字\nsocket = pynng.Sub0(listen=uri, recv_timeout=500)\n# b'' 订阅将匹配所有主题\ntopics = kwargs.pop('topics', None) or b''\nsocket.subscribe(topics)\n\n|  | self.ctx = ctx or zmq.Context()\nsocket = zmq.Socket(self.ctx, socktype)\nsocket.bind(uri)\nsuper().__init__(socket)\ndef enqueue(self, record):\nself.queue.send_json(record.__dict__)\ndef close(self):\nself.queue.close() |  |\n| --- | --- | --- |\n|  | 子类 QueueListener\n你还可以子类化 QueueListener 来从其他类型的队列中获取消息，比如从 ZeroMQ 'subscribe' 套接\n字。 下面是一个例子: |  |\n|  | class ZeroMQSocketListener(QueueListener):\ndef __init__(self, uri, /, *handlers, **kwargs):\nself.ctx = kwargs.get('ctx') or zmq.Context()\nsocket = zmq.Socket(self.ctx, zmq.SUB)\nsocket.setsockopt_string(zmq.SUBSCRIBE, '') # 全部预订\nsocket.connect(uri)\nsuper().__init__(socket, *handlers, **kwargs)\ndef dequeue(self):\nmsg = self.queue.recv_json()\nreturn logging.makeLogRecord(msg) |  |\n|  | 子类化 QueueHandler 和 QueueListener - pynng 示例\n通过与上一节类似的方式，我们可以使用 pynng 来实现监听器和处理器，这个包是针对 NNG 的\nPython 绑定，它被确定为 ZeroMQ 的精神后继者。 以下代码片段被用作演示 -- 你可以在安装了\npynng 的环境中测试它们。 为增加变化，我们先编写监听器。\n子类 QueueListener |  |\n|  | # listener.py\nimport json\nimport logging\nimport logging.handlers\nimport pynng\nDEFAULT_ADDR = \"tcp://localhost:13232\"\ninterrupted = False\nclass NNGSocketListener(logging.handlers.QueueListener):\ndef __init__(self, uri, /, *handlers, **kwargs):\n# 设置超时以允许中断，并打开一个\n# 订阅方套接字\nsocket = pynng.Sub0(listen=uri, recv_timeout=500)\n# b'' 订阅将匹配所有主题\ntopics = kwargs.pop('topics', None) or b''\nsocket.subscribe(topics) |  |\n\n# 我们将套接字视为一个队列\nsuper().__init__(socket, *handlers, **kwargs)\ndef dequeue(self, block):\ndata = None\n# 在未被打断且未从套接字接收数据时\n# 保持循环\nwhile not interrupted:\ntry:\ndata = self.queue.recv(block=block)\nbreak\nexcept pynng.Timeout:\npass\nexcept pynng.Closed: # 会在你按下 Ctrl-C 时发生\nbreak\nif data is None:\nreturn None\n# 获取从发布方发送的日志记录事件\nevent = json.loads(data.decode('utf-8'))\nreturn logging.makeLogRecord(event)\ndef enqueue_sentinel(self):\n# 在本实现中未被使用，因为套接字并不是\n# 真正的队列\npass\nlogging.getLogger('pynng').propagate = False\nlistener = NNGSocketListener(DEFAULT_ADDR, logging.StreamHandler(), topics=b'')\nlistener.start()\nprint('Press Ctrl-C to stop.')\ntry:\nwhile True:\npass\nexcept KeyboardInterrupt:\ninterrupted = True\nfinally:\nlistener.stop()\n子类 QueueHandler\n# sender.py\nimport json\nimport logging\nimport logging.handlers\nimport time\nimport random\nimport pynng\nDEFAULT_ADDR = \"tcp://localhost:13232\"\nclass NNGSocketHandler(logging.handlers.QueueHandler):\ndef __init__(self, uri):\nsocket = pynng.Pub0(dial=uri, send_timeout=500)\nsuper().__init__(socket)\ndef enqueue(self, record):\n# Send the record as UTF-8 encoded JSON\n\n|  | # 我们将套接字视为一个队列\nsuper().__init__(socket, *handlers, **kwargs)\ndef dequeue(self, block):\ndata = None\n# 在未被打断且未从套接字接收数据时\n# 保持循环\nwhile not interrupted:\ntry:\ndata = self.queue.recv(block=block)\nbreak\nexcept pynng.Timeout:\npass\nexcept pynng.Closed: # 会在你按下 Ctrl-C 时发生\nbreak\nif data is None:\nreturn None\n# 获取从发布方发送的日志记录事件\nevent = json.loads(data.decode('utf-8'))\nreturn logging.makeLogRecord(event)\ndef enqueue_sentinel(self):\n# 在本实现中未被使用，因为套接字并不是\n# 真正的队列\npass\nlogging.getLogger('pynng').propagate = False\nlistener = NNGSocketListener(DEFAULT_ADDR, logging.StreamHandler(), topics=b'')\nlistener.start()\nprint('Press Ctrl-C to stop.')\ntry:\nwhile True:\npass\nexcept KeyboardInterrupt:\ninterrupted = True\nfinally:\nlistener.stop() |  |\n| --- | --- | --- |\n|  | 子类 QueueHandler |  |\n|  | # sender.py\nimport json\nimport logging\nimport logging.handlers\nimport time\nimport random\nimport pynng\nDEFAULT_ADDR = \"tcp://localhost:13232\"\nclass NNGSocketHandler(logging.handlers.QueueHandler):\ndef __init__(self, uri):\nsocket = pynng.Pub0(dial=uri, send_timeout=500)\nsuper().__init__(socket)\ndef enqueue(self, record):\n# Send the record as UTF-8 encoded JSON |  |\n\nd = dict(record.__dict__)\ndata = json.dumps(d)\nself.queue.send(data.encode('utf-8'))\ndef close(self):\nself.queue.close()\nlogging.getLogger('pynng').propagate = False\nhandler = NNGSocketHandler(DEFAULT_ADDR)\n# 确保进程 ID 在输出内容中\nlogging.basicConfig(level=logging.DEBUG,\nhandlers=[logging.StreamHandler(), handler],\nformat='%(levelname)-8s %(name)10s %(process)6s %(message)s')\nlevels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL)\nlogger_names = ('myapp', 'myapp.lib1', 'myapp.lib2')\nmsgno = 1\nwhile True:\n# 随机地选择日志记录器和层级并记录日志\nlevel = random.choice(levels)\nlogger = logging.getLogger(random.choice(logger_names))\nlogger.log(level, 'Message no. %5d' % msgno)\nmsgno += 1\ndelay = random.random() * 2 + 0.5\ntime.sleep(delay)\n你可以在不同的命令行 shell 中运行上面两个代码片段。 如果我们在一个 shell 中运行监听器并在两\n个不同的 shell 中运行发送器，我们将看到如下的结果。 在第一个发送器 shell 中：\n$ python sender.py\nDEBUG myapp 613 Message no. 1\nWARNING myapp.lib2 613 Message no. 2\nCRITICAL myapp.lib2 613 Message no. 3\nWARNING myapp.lib2 613 Message no. 4\nCRITICAL myapp.lib1 613 Message no. 5\nDEBUG myapp 613 Message no. 6\nCRITICAL myapp.lib1 613 Message no. 7\nINFO myapp.lib1 613 Message no. 8\n(下略)\n在第二个发送器 shell 中：\n$ python sender.py\nINFO myapp.lib2 657 Message no. 1\nCRITICAL myapp.lib2 657 Message no. 2\nCRITICAL myapp 657 Message no. 3\nCRITICAL myapp.lib1 657 Message no. 4\nINFO myapp.lib1 657 Message no. 5\nWARNING myapp.lib2 657 Message no. 6\nCRITICAL myapp 657 Message no. 7\nDEBUG myapp.lib1 657 Message no. 8\n(下略)\n在监听器 shell 中：\n$ python listener.py\nPress Ctrl-C to stop.\n\n|  | d = dict(record.__dict__)\ndata = json.dumps(d)\nself.queue.send(data.encode('utf-8'))\ndef close(self):\nself.queue.close()\nlogging.getLogger('pynng').propagate = False\nhandler = NNGSocketHandler(DEFAULT_ADDR)\n# 确保进程 ID 在输出内容中\nlogging.basicConfig(level=logging.DEBUG,\nhandlers=[logging.StreamHandler(), handler],\nformat='%(levelname)-8s %(name)10s %(process)6s %(message)s')\nlevels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL)\nlogger_names = ('myapp', 'myapp.lib1', 'myapp.lib2')\nmsgno = 1\nwhile True:\n# 随机地选择日志记录器和层级并记录日志\nlevel = random.choice(levels)\nlogger = logging.getLogger(random.choice(logger_names))\nlogger.log(level, 'Message no. %5d' % msgno)\nmsgno += 1\ndelay = random.random() * 2 + 0.5\ntime.sleep(delay) |  |\n| --- | --- | --- |\n|  | 你可以在不同的命令行 shell 中运行上面两个代码片段。 如果我们在一个 shell 中运行监听器并在两\n个不同的 shell 中运行发送器，我们将看到如下的结果。 在第一个发送器 shell 中： |  |\n|  | $ python sender.py\nDEBUG myapp 613 Message no. 1\nWARNING myapp.lib2 613 Message no. 2\nCRITICAL myapp.lib2 613 Message no. 3\nWARNING myapp.lib2 613 Message no. 4\nCRITICAL myapp.lib1 613 Message no. 5\nDEBUG myapp 613 Message no. 6\nCRITICAL myapp.lib1 613 Message no. 7\nINFO myapp.lib1 613 Message no. 8\n(下略) |  |\n|  | 在第二个发送器 shell 中： |  |\n|  | $ python sender.py\nINFO myapp.lib2 657 Message no. 1\nCRITICAL myapp.lib2 657 Message no. 2\nCRITICAL myapp 657 Message no. 3\nCRITICAL myapp.lib1 657 Message no. 4\nINFO myapp.lib1 657 Message no. 5\nWARNING myapp.lib2 657 Message no. 6\nCRITICAL myapp 657 Message no. 7\nDEBUG myapp.lib1 657 Message no. 8\n(下略) |  |\n|  | 在监听器 shell 中： |  |\n|  | $ python listener.py\nPress Ctrl-C to stop. |  |\n\nDEBUG myapp 613 Message no. 1\nWARNING myapp.lib2 613 Message no. 2\nINFO myapp.lib2 657 Message no. 1\nCRITICAL myapp.lib2 613 Message no. 3\nCRITICAL myapp.lib2 657 Message no. 2\nCRITICAL myapp 657 Message no. 3\nWARNING myapp.lib2 613 Message no. 4\nCRITICAL myapp.lib1 613 Message no. 5\nCRITICAL myapp.lib1 657 Message no. 4\nINFO myapp.lib1 657 Message no. 5\nDEBUG myapp 613 Message no. 6\nWARNING myapp.lib2 657 Message no. 6\nCRITICAL myapp 657 Message no. 7\nCRITICAL myapp.lib1 613 Message no. 7\nINFO myapp.lib1 613 Message no. 8\nDEBUG myapp.lib1 657 Message no. 8\n(下略)\n如你所见，来自两个发送器进程的日志记录会在监听器的输出中交错出现。\n基于字典进行日志配置的示例\n以下是日志配置字典的一个示例——它取自 Django 项目的`文档\n<https://docs.djangoproject.com/en/stable/topics/logging/#configuring-logging>`_。此字典将被\n传给 dictConfig() 以使配置生效:\nLOGGING = {\n'version': 1,\n'disable_existing_loggers': False,\n'formatters': {\n'verbose': {\n'format': '{levelname} {asctime} {module} {process:d} {thread:d} {mess\n'style': '{',\n},\n'simple': {\n'format': '{levelname} {message}',\n'style': '{',\n},\n},\n'filters': {\n'special': {\n'()': 'project.logging.SpecialFilter',\n'foo': 'bar',\n},\n},\n'handlers': {\n'console': {\n'level': 'INFO',\n'class': 'logging.StreamHandler',\n'formatter': 'simple',\n},\n'mail_admins': {\n'level': 'ERROR',\n'class': 'django.utils.log.AdminEmailHandler',\n'filters': ['special']\n}\n},\n\n|  | DEBUG myapp 613 Message no. 1\nWARNING myapp.lib2 613 Message no. 2\nINFO myapp.lib2 657 Message no. 1\nCRITICAL myapp.lib2 613 Message no. 3\nCRITICAL myapp.lib2 657 Message no. 2\nCRITICAL myapp 657 Message no. 3\nWARNING myapp.lib2 613 Message no. 4\nCRITICAL myapp.lib1 613 Message no. 5\nCRITICAL myapp.lib1 657 Message no. 4\nINFO myapp.lib1 657 Message no. 5\nDEBUG myapp 613 Message no. 6\nWARNING myapp.lib2 657 Message no. 6\nCRITICAL myapp 657 Message no. 7\nCRITICAL myapp.lib1 613 Message no. 7\nINFO myapp.lib1 613 Message no. 8\nDEBUG myapp.lib1 657 Message no. 8\n(下略) |  |\n| --- | --- | --- |\n|  | 如你所见，来自两个发送器进程的日志记录会在监听器的输出中交错出现。\n基于字典进行日志配置的示例\n以下是日志配置字典的一个示例——它取自 Django 项目的`文档\n<https://docs.djangoproject.com/en/stable/topics/logging/#configuring-logging>`_。此字典将被\n传给 dictConfig() 以使配置生效: |  |\n|  | LOGGING = {\n'version': 1,\n'disable_existing_loggers': False,\n'formatters': {\n'verbose': {\n'format': '{levelname} {asctime} {module} {process:d} {thread:d} {mess\n'style': '{',\n},\n'simple': {\n'format': '{levelname} {message}',\n'style': '{',\n},\n},\n'filters': {\n'special': {\n'()': 'project.logging.SpecialFilter',\n'foo': 'bar',\n},\n},\n'handlers': {\n'console': {\n'level': 'INFO',\n'class': 'logging.StreamHandler',\n'formatter': 'simple',\n},\n'mail_admins': {\n'level': 'ERROR',\n'class': 'django.utils.log.AdminEmailHandler',\n'filters': ['special']\n}\n}, |  |\n\n'loggers': {\n'django': {\n'handlers': ['console'],\n'propagate': True,\n},\n'django.request': {\n'handlers': ['mail_admins'],\n'level': 'ERROR',\n'propagate': False,\n},\n'myproject.custom': {\n'handlers': ['console', 'mail_admins'],\n'level': 'INFO',\n'filters': ['special']\n}\n}\n}\n有关本配置的更多信息，请参阅 Django 文档的 有关章节 。\n利用 rotator 和 namer 自定义日志轮换操作\n下面的可运行代码给出了你可以怎样定义命名器和轮换器的例子，其中演示了日志文件的 gzip 压缩\n过程:\nimport gzip\nimport logging\nimport logging.handlers\nimport os\nimport shutil\ndef namer(name):\nreturn name + \".gz\"\ndef rotator(source, dest):\nwith open(source, 'rb') as f_in:\nwith gzip.open(dest, 'wb') as f_out:\nshutil.copyfileobj(f_in, f_out)\nos.remove(source)\nrh = logging.handlers.RotatingFileHandler('rotated.log', maxBytes=128, backupCount\nrh.rotator = rotator\nrh.namer = namer\nroot = logging.getLogger()\nroot.setLevel(logging.INFO)\nroot.addHandler(rh)\nf = logging.Formatter('%(asctime)s %(message)s')\nrh.setFormatter(f)\nfor i in range(1000):\nroot.info(f'Message no. {i + 1}')\n运行此脚本后，你将看到六个新文件，其中五个是已压缩的:\n$ ls rotated.log*\nrotated.log rotated.log.2.gz rotated.log.4.gz\n\n|  | 'loggers': {\n'django': {\n'handlers': ['console'],\n'propagate': True,\n},\n'django.request': {\n'handlers': ['mail_admins'],\n'level': 'ERROR',\n'propagate': False,\n},\n'myproject.custom': {\n'handlers': ['console', 'mail_admins'],\n'level': 'INFO',\n'filters': ['special']\n}\n}\n} |  |  |\n| --- | --- | --- | --- |\n|  | 有关本配置的更多信息，请参阅 Django 文档的 有关章节 。\n利用 rotator 和 namer 自定义日志轮换操作\n下面的可运行代码给出了你可以怎样定义命名器和轮换器的例子，其中演示了日志文件的 gzip 压缩\n过程: |  |  |\n|  | import gzip\nimport logging\nimport logging.handlers\nimport os\nimport shutil\ndef namer(name):\nreturn name + \".gz\"\ndef rotator(source, dest):\nwith open(source, 'rb') as f_in:\nwith gzip.open(dest, 'wb') as f_out:\nshutil.copyfileobj(f_in, f_out)\nos.remove(source)\nrh = logging.handlers.RotatingFileHandler('rotated.log', maxBytes=128, backupCount\nrh.rotator = rotator\nrh.namer = namer\nroot = logging.getLogger()\nroot.setLevel(logging.INFO)\nroot.addHandler(rh) |  |  |\n|  | f = logging.Formatter('%(asctime)s %(message)s')\nrh.setFormatter(f)\nfor i in range(1000):\nroot.info(f'Message no. {i + 1}') |  |  |\n|  | 运行此脚本后，你将看到六个新文件，其中五个是已压缩的: |  |  |\n|  | $ ls rotated.log*\nrotated.log rotated.log.2.gz rotated.log.4.gz |  |  |\n\nrotated.log.1.gz rotated.log.3.gz rotated.log.5.gz\n$ zcat rotated.log.1.gz\n2023-01-20 02:28:17,767 Message no. 996\n2023-01-20 02:28:17,767 Message no. 997\n2023-01-20 02:28:17,767 Message no. 998\n更加详细的多道处理示例\n以下可运行的示例显示了如何利用配置文件在多进程中应用日志。这些配置相当简单，但足以说明\n如何在真实的多进程场景中实现较为复杂的配置。\n上述示例中，主进程产生一个侦听器进程和一些工作进程。每个主进程、侦听器进程和工作进程都\n有三种独立的日志配置（工作进程共享同一套配置）。大家可以看到主进程的日志记录过程、工作\n线程向 QueueHandler 写入日志的过程，以及侦听器实现 QueueListener 和较为复杂的日志配置，\n如何将由队列接收到的事件分发给配置指定的 handler。请注意，这些配置纯粹用于演示，但应该能\n调整代码以适用于自己的场景。\n以下是代码——但愿文档字符串和注释能有助于理解其工作原理：\nimport logging\nimport logging.config\nimport logging.handlers\nfrom multiprocessing import Process, Queue, Event, current_process\nimport os\nimport random\nimport time\nclass MyHandler:\n\"\"\"\nA simple handler for logging events. It runs in the listener process and\ndispatches events to loggers based on the name in the received record,\nwhich then get dispatched, by the logging system, to the handlers\nconfigured for those loggers.\n\"\"\"\ndef handle(self, record):\nif record.name == \"root\":\nlogger = logging.getLogger()\nelse:\nlogger = logging.getLogger(record.name)\nif logger.isEnabledFor(record.levelno):\n# 进程名称经过变换以演示是由监听器来执行\n# 记录日志到文件和控制台\nrecord.processName = '%s (for %s)' % (current_process().name, record.p\nlogger.handle(record)\ndef listener_process(q, stop_event, config):\n\"\"\"\nThis could be done in the main process, but is just done in a separate\nprocess for illustrative purposes.\nThis initialises logging according to the specified configuration,\nstarts the listener and waits for the main process to signal completion\nvia the event. The listener is then stopped, and the process exits.\n\"\"\"\n\n|  | rotated.log.1.gz rotated.log.3.gz rotated.log.5.gz\n$ zcat rotated.log.1.gz\n2023-01-20 02:28:17,767 Message no. 996\n2023-01-20 02:28:17,767 Message no. 997\n2023-01-20 02:28:17,767 Message no. 998 |  |\n| --- | --- | --- |\n|  | 更加详细的多道处理示例\n以下可运行的示例显示了如何利用配置文件在多进程中应用日志。这些配置相当简单，但足以说明\n如何在真实的多进程场景中实现较为复杂的配置。\n上述示例中，主进程产生一个侦听器进程和一些工作进程。每个主进程、侦听器进程和工作进程都\n有三种独立的日志配置（工作进程共享同一套配置）。大家可以看到主进程的日志记录过程、工作\n线程向 QueueHandler 写入日志的过程，以及侦听器实现 QueueListener 和较为复杂的日志配置，\n如何将由队列接收到的事件分发给配置指定的 handler。请注意，这些配置纯粹用于演示，但应该能\n调整代码以适用于自己的场景。\n以下是代码——但愿文档字符串和注释能有助于理解其工作原理： |  |\n|  | import logging\nimport logging.config\nimport logging.handlers\nfrom multiprocessing import Process, Queue, Event, current_process\nimport os\nimport random\nimport time\nclass MyHandler:\n\"\"\"\nA simple handler for logging events. It runs in the listener process and\ndispatches events to loggers based on the name in the received record,\nwhich then get dispatched, by the logging system, to the handlers\nconfigured for those loggers.\n\"\"\"\ndef handle(self, record):\nif record.name == \"root\":\nlogger = logging.getLogger()\nelse:\nlogger = logging.getLogger(record.name)\nif logger.isEnabledFor(record.levelno):\n# 进程名称经过变换以演示是由监听器来执行\n# 记录日志到文件和控制台\nrecord.processName = '%s (for %s)' % (current_process().name, record.p\nlogger.handle(record)\ndef listener_process(q, stop_event, config):\n\"\"\"\nThis could be done in the main process, but is just done in a separate\nprocess for illustrative purposes.\nThis initialises logging according to the specified configuration,\nstarts the listener and waits for the main process to signal completion\nvia the event. The listener is then stopped, and the process exits.\n\"\"\" |  |\n\nlogging.config.dictConfig(config)\nlistener = logging.handlers.QueueListener(q, MyHandler())\nlistener.start()\nif os.name == 'posix':\n# 在 POSIX 系统上，setup 日志记录器将会在\n# 父进程中完成配置，但应当在 dictConfig 调用\n# 之后即已被禁用。\n# 在 Windows 上，由于不会使用 fork，setup 日志记录器\n# 将不会在子进程中退出，因此它将被创建并且显示消息\n# —— 对应 \"if posix\" 子句。\nlogger = logging.getLogger('setup')\nlogger.critical('Should not appear, because of disabled logger ...')\nstop_event.wait()\nlistener.stop()\ndef worker_process(config):\n\"\"\"\nA number of these are spawned for the purpose of illustration. In\npractice, they could be a heterogeneous bunch of processes rather than\nones which are identical to each other.\nThis initialises logging according to the specified configuration,\nand logs a hundred messages with random levels to randomly selected\nloggers.\nA small sleep is added to allow other processes a chance to run. This\nis not strictly needed, but it mixes the output from the different\nprocesses a bit more than if it's left out.\n\"\"\"\nlogging.config.dictConfig(config)\nlevels = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL]\nloggers = ['foo', 'foo.bar', 'foo.bar.baz',\n'spam', 'spam.ham', 'spam.ham.eggs']\nif os.name == 'posix':\n# 在 POSIX 系统上，setup 日志记录器将会在\n# 父进程中完成配置，但应当在 dictConfig 调用\n# 之后已被禁用。\n# 在 Windows 上，由于不会使用 fork，setup 日志记录器\n# 将不会在子进程中退出，因此它将被创建并且显示消息\n# —— 对应 \"if posix\" 子句。\nlogger = logging.getLogger('setup')\nlogger.critical('Should not appear, because of disabled logger ...')\nfor i in range(100):\nlvl = random.choice(levels)\nlogger = logging.getLogger(random.choice(loggers))\nlogger.log(lvl, 'Message no. %d', i)\ntime.sleep(0.01)\ndef main():\nq = Queue()\n# 主进程将获得一个打印到控制台的简单配置。\nconfig_initial = {\n'version': 1,\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'level': 'INFO'\n}\n},\n\n|  | logging.config.dictConfig(config)\nlistener = logging.handlers.QueueListener(q, MyHandler())\nlistener.start()\nif os.name == 'posix':\n# 在 POSIX 系统上，setup 日志记录器将会在\n# 父进程中完成配置，但应当在 dictConfig 调用\n# 之后即已被禁用。\n# 在 Windows 上，由于不会使用 fork，setup 日志记录器\n# 将不会在子进程中退出，因此它将被创建并且显示消息\n# —— 对应 \"if posix\" 子句。\nlogger = logging.getLogger('setup')\nlogger.critical('Should not appear, because of disabled logger ...')\nstop_event.wait()\nlistener.stop()\ndef worker_process(config):\n\"\"\"\nA number of these are spawned for the purpose of illustration. In\npractice, they could be a heterogeneous bunch of processes rather than\nones which are identical to each other.\nThis initialises logging according to the specified configuration,\nand logs a hundred messages with random levels to randomly selected\nloggers.\nA small sleep is added to allow other processes a chance to run. This\nis not strictly needed, but it mixes the output from the different\nprocesses a bit more than if it's left out.\n\"\"\"\nlogging.config.dictConfig(config)\nlevels = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL]\nloggers = ['foo', 'foo.bar', 'foo.bar.baz',\n'spam', 'spam.ham', 'spam.ham.eggs']\nif os.name == 'posix':\n# 在 POSIX 系统上，setup 日志记录器将会在\n# 父进程中完成配置，但应当在 dictConfig 调用\n# 之后已被禁用。\n# 在 Windows 上，由于不会使用 fork，setup 日志记录器\n# 将不会在子进程中退出，因此它将被创建并且显示消息\n# —— 对应 \"if posix\" 子句。\nlogger = logging.getLogger('setup')\nlogger.critical('Should not appear, because of disabled logger ...')\nfor i in range(100):\nlvl = random.choice(levels)\nlogger = logging.getLogger(random.choice(loggers))\nlogger.log(lvl, 'Message no. %d', i)\ntime.sleep(0.01)\ndef main():\nq = Queue()\n# 主进程将获得一个打印到控制台的简单配置。\nconfig_initial = {\n'version': 1,\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'level': 'INFO'\n}\n}, |  |\n| --- | --- | --- |\n\n'root': {\n'handlers': ['console'],\n'level': 'DEBUG'\n}\n}\n# 工作进程配置就是一个附加到根日志记录器的 QueueHandler，\n# 它允许所有消息被发送至队列 。\n# 我们禁用现有的日志记录器以禁用在父进程中使用的 \"setup\"\n# 日志记录器。 这在 POSIX 中是必需的因为日志记录器将会在\n# fork() 之后出现在子进程中。\nconfig_worker = {\n'version': 1,\n'disable_existing_loggers': True,\n'handlers': {\n'queue': {\n'class': 'logging.handlers.QueueHandler',\n'queue': q\n}\n},\n'root': {\n'handlers': ['queue'],\n'level': 'DEBUG'\n}\n}\n# 监听器进程配置显示可以使用日志记录配置的\n# 完整适应性以便以你希望的方式将事件分发给\n# 处理器。\n# 我们禁用现有的日志记录器以禁用在父进程中使用的\n# \"setup\" 日志记录器。 这在 POSIX 中是必需的因为\n# 日志记录器将会在 fork() 之后出现在子进程中。\nconfig_listener = {\n'version': 1,\n'disable_existing_loggers': True,\n'formatters': {\n'detailed': {\n'class': 'logging.Formatter',\n'format': '%(asctime)s %(name)-15s %(levelname)-8s %(processName)-\n},\n'simple': {\n'class': 'logging.Formatter',\n'format': '%(name)-15s %(levelname)-8s %(processName)-10s %(messag\n}\n},\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'formatter': 'simple',\n'level': 'INFO'\n},\n'file': {\n'class': 'logging.FileHandler',\n'filename': 'mplog.log',\n'mode': 'w',\n'formatter': 'detailed'\n},\n'foofile': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-foo.log',\n'mode': 'w',\n'formatter': 'detailed'\n\n|  | 'root': {\n'handlers': ['console'],\n'level': 'DEBUG'\n}\n}\n# 工作进程配置就是一个附加到根日志记录器的 QueueHandler，\n# 它允许所有消息被发送至队列 。\n# 我们禁用现有的日志记录器以禁用在父进程中使用的 \"setup\"\n# 日志记录器。 这在 POSIX 中是必需的因为日志记录器将会在\n# fork() 之后出现在子进程中。\nconfig_worker = {\n'version': 1,\n'disable_existing_loggers': True,\n'handlers': {\n'queue': {\n'class': 'logging.handlers.QueueHandler',\n'queue': q\n}\n},\n'root': {\n'handlers': ['queue'],\n'level': 'DEBUG'\n}\n}\n# 监听器进程配置显示可以使用日志记录配置的\n# 完整适应性以便以你希望的方式将事件分发给\n# 处理器。\n# 我们禁用现有的日志记录器以禁用在父进程中使用的\n# \"setup\" 日志记录器。 这在 POSIX 中是必需的因为\n# 日志记录器将会在 fork() 之后出现在子进程中。\nconfig_listener = {\n'version': 1,\n'disable_existing_loggers': True,\n'formatters': {\n'detailed': {\n'class': 'logging.Formatter',\n'format': '%(asctime)s %(name)-15s %(levelname)-8s %(processName)-\n},\n'simple': {\n'class': 'logging.Formatter',\n'format': '%(name)-15s %(levelname)-8s %(processName)-10s %(messag\n}\n},\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'formatter': 'simple',\n'level': 'INFO'\n},\n'file': {\n'class': 'logging.FileHandler',\n'filename': 'mplog.log',\n'mode': 'w',\n'formatter': 'detailed'\n},\n'foofile': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-foo.log',\n'mode': 'w',\n'formatter': 'detailed' |  |\n| --- | --- | --- |\n\n},\n'errors': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-errors.log',\n'mode': 'w',\n'formatter': 'detailed',\n'level': 'ERROR'\n}\n},\n'loggers': {\n'foo': {\n'handlers': ['foofile']\n}\n},\n'root': {\n'handlers': ['console', 'file', 'errors'],\n'level': 'DEBUG'\n}\n}\n# 记录一些初始事件，以便显示父进程中的日志记录\n# 工作正常。\nlogging.config.dictConfig(config_initial)\nlogger = logging.getLogger('setup')\nlogger.info('About to create workers ...')\nworkers = []\nfor i in range(5):\nwp = Process(target=worker_process, name='worker %d' % (i + 1),\nargs=(config_worker,))\nworkers.append(wp)\nwp.start()\nlogger.info('Started worker: %s', wp.name)\nlogger.info('About to create listener ...')\nstop_event = Event()\nlp = Process(target=listener_process, name='listener',\nargs=(q, stop_event, config_listener))\nlp.start()\nlogger.info('Started listener')\n# 我们现在要等待工作进程完成其工作。\nfor wp in workers:\nwp.join()\n# 工作进程全部结束，现在可以停止监听。\n# 父进程中的日志记录仍然正常进行。\nlogger.info('Telling listener to stop ...')\nstop_event.set()\nlp.join()\nlogger.info('All done.')\nif __name__ == '__main__':\nmain()\n在发送给 SysLogHandler 的信息中插入一个 BOM。\nRFC 5424 要求，Unicode 信息应采用字节流形式发送到系统 syslog 守护程序，字节流结构如下所\n示：可选的纯 ASCII部分，后跟 UTF-8 字节序标记（BOM），然后是采用 UTF-8 编码的 Unicode。\n（参见 相关规范 。）\n\n|  | },\n'errors': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-errors.log',\n'mode': 'w',\n'formatter': 'detailed',\n'level': 'ERROR'\n}\n},\n'loggers': {\n'foo': {\n'handlers': ['foofile']\n}\n},\n'root': {\n'handlers': ['console', 'file', 'errors'],\n'level': 'DEBUG'\n}\n}\n# 记录一些初始事件，以便显示父进程中的日志记录\n# 工作正常。\nlogging.config.dictConfig(config_initial)\nlogger = logging.getLogger('setup')\nlogger.info('About to create workers ...')\nworkers = []\nfor i in range(5):\nwp = Process(target=worker_process, name='worker %d' % (i + 1),\nargs=(config_worker,))\nworkers.append(wp)\nwp.start()\nlogger.info('Started worker: %s', wp.name)\nlogger.info('About to create listener ...')\nstop_event = Event()\nlp = Process(target=listener_process, name='listener',\nargs=(q, stop_event, config_listener))\nlp.start()\nlogger.info('Started listener')\n# 我们现在要等待工作进程完成其工作。\nfor wp in workers:\nwp.join()\n# 工作进程全部结束，现在可以停止监听。\n# 父进程中的日志记录仍然正常进行。\nlogger.info('Telling listener to stop ...')\nstop_event.set()\nlp.join()\nlogger.info('All done.')\nif __name__ == '__main__':\nmain() |  |\n| --- | --- | --- |\n|  | 在发送给 SysLogHandler 的信息中插入一个 BOM。\nRFC 5424 要求，Unicode 信息应采用字节流形式发送到系统 syslog 守护程序，字节流结构如下所\n示：可选的纯 ASCII部分，后跟 UTF-8 字节序标记（BOM），然后是采用 UTF-8 编码的 Unicode。\n（参见 相关规范 。） |  |\n\n在 Python 3.1 的 SysLogHandler 中，已加入了在日志信息中插入 BOM 的代码，但不幸的是，代码\n并不正确，BOM 出现在了日志信息的开头，因此在它之前就不允许出现纯 ASCII 内容了。\n由于无法正常工作， Python 3.2.4 以上版本已删除了出错的插入 BOM 代码。但已有版本的代码不会\n被替换，若要生成与 RFC 5424 兼容的日志信息，包括一个 BOM 符，前面有可选的纯 ASCII 字节\n流，后面为 UTF-8 编码的任意 Unicode，那么 需要执行以下操作：\n1. 为 SysLogHandler 实例串上一个 Formatter 实例，格式串可如下：\n'ASCII section\\ufeffUnicode section'\n用 UTF-8 编码时，Unicode 码位 U+FEFF 将会编码为 UTF-8 BOM——字节串\nb'\\xef\\xbb\\xbf' 。\n2. 用任意占位符替换 ASCII 部分，但要保证替换之后的数据一定是 ASCII 码（这样在 UTF-8 编码\n后就会维持不变）。\n3. 用任意占位符替换 Unicode 部分；如果替换后的数据包含超出 ASCII 范围的字符，没问题\n——他们将用 UTF-8 进行编码。\nSysLogHandler 将 对格式化后的日志信息进行 UTF-8 编码。如果遵循上述规则，应能生成符合 RFC\n5424 的日志信息。否则，日志记录过程可能不会有什么反馈，但日志信息将不与 RFC 5424 兼容，\nsyslog 守护程序可能会有出错反应。\n结构化日志的实现代码\n大多数日志信息是供人阅读的，所以机器解析起来并不容易，但某些时候可能希望以结构化的格式\n输出，以 能够 被程序解析（无需用到复杂的正则表达式）。这可以直接用 logging 包实现。实现方\n式有很多，以下是一种比较简单的方案，利用 JSON 以机器可解析的方式对事件信息进行序列化：\nimport json\nimport logging\nclass StructuredMessage:\ndef __init__(self, message, /, **kwargs):\nself.message = message\nself.kwargs = kwargs\ndef __str__(self):\nreturn '%s >>> %s' % (self.message, json.dumps(self.kwargs))\n_ = StructuredMessage # 可选项，用于提升可读性\nlogging.basicConfig(level=logging.INFO, format='%(message)s')\nlogging.info(_('message 1', foo='bar', bar='baz', num=123, fnum=123.456))\n上述代码运行后的结果是：\nmessage 1 >>> {\"fnum\": 123.456, \"num\": 123, \"bar\": \"baz\", \"foo\": \"bar\"}\n请注意，根据 Python 版本的不同，各项数据的输出顺序可能会不一样。\n\n|  | 在 Python 3.1 的 SysLogHandler 中，已加入了在日志信息中插入 BOM 的代码，但不幸的是，代码\n并不正确，BOM 出现在了日志信息的开头，因此在它之前就不允许出现纯 ASCII 内容了。\n由于无法正常工作， Python 3.2.4 以上版本已删除了出错的插入 BOM 代码。但已有版本的代码不会\n被替换，若要生成与 RFC 5424 兼容的日志信息，包括一个 BOM 符，前面有可选的纯 ASCII 字节\n流，后面为 UTF-8 编码的任意 Unicode，那么 需要执行以下操作：\n1. 为 SysLogHandler 实例串上一个 Formatter 实例，格式串可如下：\n'ASCII section\\ufeffUnicode section'\n用 UTF-8 编码时，Unicode 码位 U+FEFF 将会编码为 UTF-8 BOM——字节串\nb'\\xef\\xbb\\xbf' 。\n2. 用任意占位符替换 ASCII 部分，但要保证替换之后的数据一定是 ASCII 码（这样在 UTF-8 编码\n后就会维持不变）。\n3. 用任意占位符替换 Unicode 部分；如果替换后的数据包含超出 ASCII 范围的字符，没问题\n——他们将用 UTF-8 进行编码。\nSysLogHandler 将 对格式化后的日志信息进行 UTF-8 编码。如果遵循上述规则，应能生成符合 RFC\n5424 的日志信息。否则，日志记录过程可能不会有什么反馈，但日志信息将不与 RFC 5424 兼容，\nsyslog 守护程序可能会有出错反应。\n结构化日志的实现代码\n大多数日志信息是供人阅读的，所以机器解析起来并不容易，但某些时候可能希望以结构化的格式\n输出，以 能够 被程序解析（无需用到复杂的正则表达式）。这可以直接用 logging 包实现。实现方\n式有很多，以下是一种比较简单的方案，利用 JSON 以机器可解析的方式对事件信息进行序列化： |  |\n| --- | --- | --- |\n|  | import json\nimport logging\nclass StructuredMessage:\ndef __init__(self, message, /, **kwargs):\nself.message = message\nself.kwargs = kwargs\ndef __str__(self):\nreturn '%s >>> %s' % (self.message, json.dumps(self.kwargs))\n_ = StructuredMessage # 可选项，用于提升可读性\nlogging.basicConfig(level=logging.INFO, format='%(message)s')\nlogging.info(_('message 1', foo='bar', bar='baz', num=123, fnum=123.456)) |  |\n|  | 上述代码运行后的结果是： |  |\n|  | message 1 >>> {\"fnum\": 123.456, \"num\": 123, \"bar\": \"baz\", \"foo\": \"bar\"} |  |\n|  | 请注意，根据 Python 版本的不同，各项数据的输出顺序可能会不一样。 |  |\n\n若需进行更为定制化的处理，可以使用自定义 JSON 编码对象，下面给出完整示例：\nimport json\nimport logging\nclass Encoder(json.JSONEncoder):\ndef default(self, o):\nif isinstance(o, set):\nreturn tuple(o)\nelif isinstance(o, str):\nreturn o.encode('unicode_escape').decode('ascii')\nreturn super().default(o)\nclass StructuredMessage:\ndef __init__(self, message, /, **kwargs):\nself.message = message\nself.kwargs = kwargs\ndef __str__(self):\ns = Encoder().encode(self.kwargs)\nreturn '%s >>> %s' % (self.message, s)\n_ = StructuredMessage # 可选项，用于提升可读性\ndef main():\nlogging.basicConfig(level=logging.INFO, format='%(message)s')\nlogging.info(_('message 1', set_value={1, 2, 3}, snowman='\\u2603'))\nif __name__ == '__main__':\nmain()\n上述代码运行后的结果是：\nmessage 1 >>> {\"snowman\": \"\\u2603\", \"set_value\": [1, 2, 3]}\n请注意，根据 Python 版本的不同，各项数据的输出顺序可能会不一样。\n利用 dictConfig() 自定义 handler\n有时需要以特定方式自定义日志 handler，如果采用 dictConfig()，可能无需生成子类就可以做\n到。比如要设置日志文件的所有权。在 POSIX 上，可以利用 shutil.chown() 轻松完成，但 stdlib\n中的文件 handler 并不提供内置支持。于是可以用普通函数自定义 handler 的创建，例如：\ndef owned_file_handler(filename, mode='a', encoding=None, owner=None):\nif owner:\nif not os.path.exists(filename):\nopen(filename, 'a').close()\nshutil.chown(filename, *owner)\nreturn logging.FileHandler(filename, mode, encoding)\n然后，你可以在传给 dictConfig() 的日志配置中指定通过调用此函数来创建日志处理程序:\nLOGGING = {\n'version': 1,\n\n|  | 若需进行更为定制化的处理，可以使用自定义 JSON 编码对象，下面给出完整示例： |  |\n| --- | --- | --- |\n|  | import json\nimport logging\nclass Encoder(json.JSONEncoder):\ndef default(self, o):\nif isinstance(o, set):\nreturn tuple(o)\nelif isinstance(o, str):\nreturn o.encode('unicode_escape').decode('ascii')\nreturn super().default(o)\nclass StructuredMessage:\ndef __init__(self, message, /, **kwargs):\nself.message = message\nself.kwargs = kwargs\ndef __str__(self):\ns = Encoder().encode(self.kwargs)\nreturn '%s >>> %s' % (self.message, s)\n_ = StructuredMessage # 可选项，用于提升可读性\ndef main():\nlogging.basicConfig(level=logging.INFO, format='%(message)s')\nlogging.info(_('message 1', set_value={1, 2, 3}, snowman='\\u2603'))\nif __name__ == '__main__':\nmain() |  |\n|  | 上述代码运行后的结果是： |  |\n|  | message 1 >>> {\"snowman\": \"\\u2603\", \"set_value\": [1, 2, 3]} |  |\n|  | 请注意，根据 Python 版本的不同，各项数据的输出顺序可能会不一样。\n利用 dictConfig() 自定义 handler\n有时需要以特定方式自定义日志 handler，如果采用 dictConfig()，可能无需生成子类就可以做\n到。比如要设置日志文件的所有权。在 POSIX 上，可以利用 shutil.chown() 轻松完成，但 stdlib\n中的文件 handler 并不提供内置支持。于是可以用普通函数自定义 handler 的创建，例如： |  |\n|  | def owned_file_handler(filename, mode='a', encoding=None, owner=None):\nif owner:\nif not os.path.exists(filename):\nopen(filename, 'a').close()\nshutil.chown(filename, *owner)\nreturn logging.FileHandler(filename, mode, encoding) |  |\n|  | 然后，你可以在传给 dictConfig() 的日志配置中指定通过调用此函数来创建日志处理程序: |  |\n|  | LOGGING = {\n'version': 1, |  |\n\n'disable_existing_loggers': False,\n'formatters': {\n'default': {\n'format': '%(asctime)s %(levelname)s %(name)s %(message)s'\n},\n},\n'handlers': {\n'file':{\n# 下面的值将从该字典中弹出并被用来\n# 创建处理器，设置处理器的层级及其\n# 格式化器：\n'()': owned_file_handler,\n'level':'DEBUG',\n'formatter': 'default',\n# 下面的值将以关键字参数形式传给\n# 处理器调用方的可调用对象。\n'owner': ['pulse', 'pulse'],\n'filename': 'chowntest.log',\n'mode': 'w',\n'encoding': 'utf-8',\n},\n},\n'root': {\n'handlers': ['file'],\n'level': 'DEBUG',\n},\n}\n出于演示目的，以下示例设置用户和用户组为 pulse。代码置于一个可运行的脚本文件\nchowntest.py 中：\nimport logging, logging.config, os, shutil\ndef owned_file_handler(filename, mode='a', encoding=None, owner=None):\nif owner:\nif not os.path.exists(filename):\nopen(filename, 'a').close()\nshutil.chown(filename, *owner)\nreturn logging.FileHandler(filename, mode, encoding)\nLOGGING = {\n'version': 1,\n'disable_existing_loggers': False,\n'formatters': {\n'default': {\n'format': '%(asctime)s %(levelname)s %(name)s %(message)s'\n},\n},\n'handlers': {\n'file':{\n# 下面的值将从此字典中被弹出并被用来\n# 创建处理器、设置处理器的层级\n# 及其格式化器。\n'()': owned_file_handler,\n'level':'DEBUG',\n'formatter': 'default',\n# 下面的值将以关键字参数形式传给处理器的\n# 创建方可调用对象。\n\n|  | 'disable_existing_loggers': False,\n'formatters': {\n'default': {\n'format': '%(asctime)s %(levelname)s %(name)s %(message)s'\n},\n},\n'handlers': {\n'file':{\n# 下面的值将从该字典中弹出并被用来\n# 创建处理器，设置处理器的层级及其\n# 格式化器：\n'()': owned_file_handler,\n'level':'DEBUG',\n'formatter': 'default',\n# 下面的值将以关键字参数形式传给\n# 处理器调用方的可调用对象。\n'owner': ['pulse', 'pulse'],\n'filename': 'chowntest.log',\n'mode': 'w',\n'encoding': 'utf-8',\n},\n},\n'root': {\n'handlers': ['file'],\n'level': 'DEBUG',\n},\n} |  |\n| --- | --- | --- |\n|  | 出于演示目的，以下示例设置用户和用户组为 pulse。代码置于一个可运行的脚本文件\nchowntest.py 中： |  |\n|  | import logging, logging.config, os, shutil\ndef owned_file_handler(filename, mode='a', encoding=None, owner=None):\nif owner:\nif not os.path.exists(filename):\nopen(filename, 'a').close()\nshutil.chown(filename, *owner)\nreturn logging.FileHandler(filename, mode, encoding)\nLOGGING = {\n'version': 1,\n'disable_existing_loggers': False,\n'formatters': {\n'default': {\n'format': '%(asctime)s %(levelname)s %(name)s %(message)s'\n},\n},\n'handlers': {\n'file':{\n# 下面的值将从此字典中被弹出并被用来\n# 创建处理器、设置处理器的层级\n# 及其格式化器。\n'()': owned_file_handler,\n'level':'DEBUG',\n'formatter': 'default',\n# 下面的值将以关键字参数形式传给处理器的\n# 创建方可调用对象。 |  |\n\n'owner': ['pulse', 'pulse'],\n'filename': 'chowntest.log',\n'mode': 'w',\n'encoding': 'utf-8',\n},\n},\n'root': {\n'handlers': ['file'],\n'level': 'DEBUG',\n},\n}\nlogging.config.dictConfig(LOGGING)\nlogger = logging.getLogger('mylogger')\nlogger.debug('A debug message')\n可能需要 root 权限才能运行：\n$ sudo python3.3 chowntest.py\n$ cat chowntest.log\n2013-11-05 09:34:51,128 DEBUG mylogger A debug message\n$ ls -l chowntest.log\n-rw-r--r-- 1 pulse pulse 55 2013-11-05 09:34 chowntest.log\n请注意此示例用的是 Python 3.3，因为 shutil.chown() 是从此版本开始出现的。 此方式应当适用\n于任何支持 dictConfig() 的 Python 版本 —— 例如 Python 2.7, 3.2 或更新的版本。 对于 3.3 之前\n的版本，你应当使用 os.chown() 之类的函数来实现实际的所有权修改。\n实际应用中，handler 的创建函数可能位于项目的工具模块中。以下配置：\n'()': owned_file_handler,\n应使用：\n'()': 'ext://project.util.owned_file_handler',\n这里的 project.util 可以换成函数所在包的实际名称。 在上述的可用脚本中，应该可以使用\n'ext://__main__.owned_file_handler'。 在这里，实际的可调用对象是由 dictConfig() 从\next:// 说明中解析出来的。\n上述示例还指明了其他的文件修改类型的实现方案 —— 比如同样利用 os.chmod() 设置 POSIX 访问\n权限位。\n当然，以上做法也可以扩展到 FileHandler 之外的其他类型的 handler ——比如某个轮换文件\nhandler，或类型完全不同的其他 handler。\n生效于整个应用程序的格式化样式\n在 Python 3.2 中，Formatter 增加了一个 style 关键字形参，它默认为 % 以便向下兼容，但是允\n许采用 { 或 $ 来支持 str.format() 和 string.Template 所支持的格式化方式。 请注意此形参控\n制着用用于最终输出到日志的日志消息格式，并且与单独日志消息的构造方式完全无关。\n\n|  | 'owner': ['pulse', 'pulse'],\n'filename': 'chowntest.log',\n'mode': 'w',\n'encoding': 'utf-8',\n},\n},\n'root': {\n'handlers': ['file'],\n'level': 'DEBUG',\n},\n}\nlogging.config.dictConfig(LOGGING)\nlogger = logging.getLogger('mylogger')\nlogger.debug('A debug message') |  |\n| --- | --- | --- |\n|  | 可能需要 root 权限才能运行： |  |\n|  | $ sudo python3.3 chowntest.py\n$ cat chowntest.log\n2013-11-05 09:34:51,128 DEBUG mylogger A debug message\n$ ls -l chowntest.log\n-rw-r--r-- 1 pulse pulse 55 2013-11-05 09:34 chowntest.log |  |\n|  | 请注意此示例用的是 Python 3.3，因为 shutil.chown() 是从此版本开始出现的。 此方式应当适用\n于任何支持 dictConfig() 的 Python 版本 —— 例如 Python 2.7, 3.2 或更新的版本。 对于 3.3 之前\n的版本，你应当使用 os.chown() 之类的函数来实现实际的所有权修改。\n实际应用中，handler 的创建函数可能位于项目的工具模块中。以下配置： |  |\n|  | '()': owned_file_handler, |  |\n|  | 应使用： |  |\n|  | '()': 'ext://project.util.owned_file_handler', |  |\n|  | 这里的 project.util 可以换成函数所在包的实际名称。 在上述的可用脚本中，应该可以使用\n'ext://__main__.owned_file_handler'。 在这里，实际的可调用对象是由 dictConfig() 从\next:// 说明中解析出来的。\n上述示例还指明了其他的文件修改类型的实现方案 —— 比如同样利用 os.chmod() 设置 POSIX 访问\n权限位。\n当然，以上做法也可以扩展到 FileHandler 之外的其他类型的 handler ——比如某个轮换文件\nhandler，或类型完全不同的其他 handler。\n生效于整个应用程序的格式化样式\n在 Python 3.2 中，Formatter 增加了一个 style 关键字形参，它默认为 % 以便向下兼容，但是允\n许采用 { 或 $ 来支持 str.format() 和 string.Template 所支持的格式化方式。 请注意此形参控\n制着用用于最终输出到日志的日志消息格式，并且与单独日志消息的构造方式完全无关。 |  |\n\n日志调用 (debug(), info() 等) 只接受包含实际日志消息自身的位置参数，而关键字参数仅用于确\n定如何处理日志调用的选项 (例如 exc_info 关键字参数表示应将回溯信息记入日志，而 extra 关键\n字参数则指定要添加到日志的额外上下文信息)。 所以你不能直接使用 str.format() 或\nstring.Template 语法来直接执行日志调用，因为 logging 包在内部是使用 % 格式符来合并格式字\n符串和可变参数的。 这一点不应被改变以保持向下兼容性，因为现有代码中所有的日志调用都将使\n用 % 格式化字符串。\n有人建议将格式化样式与特定的日志对象进行关联，但其实也会遇到向下兼容的问题，因为已有代\n码可能用到了某日志对象并采用了 %-f 格式串。\n为了让第三方库和自编代码都能够交互使用日志功能，需要决定在单次日志记录调用级别采用什么\n格式。于是就出现了其他几种格式化样式方案。\nLogRecord 工厂的用法\n在 Python 3.2 中，伴随着 Formatter 的上述变化，logging 包增加了允许用户使用\nsetLogRecordFactory() 函数来。设置自己的 LogRecord 子类的功能。 你可以使用此功能来设置\n自己的 LogRecord 子类，它会通过重写 getMessage() 方法来完成适当的操作。 msg % args 格式\n化是在此方法的基类实现中进行的，你可以在那里用你自己的格式化操作来替换；但是，你应当注\n意要支持全部的格式化样式并允许将 %-formatting 作为默认样式，以确保与其他代码进行配合。 还\n应当注意调用 str(self.msg)，正如基类实现所做的一样。\n更多信息请参阅 setLogRecordFactory() 和 LogRecord 的参考文档。\n自定义信息对象的使用\n另一种方案可能更为简单，可以利用 {}- 和 $- 格式构建自己的日志消息。大家或许还记得（来自 使\n用任意对象作为消息），可以用任意对象作为日志信息的格式串，日志包将调用该对象上 str() 获\n取实际的格式串。看下以下两个类：\nclass BraceMessage:\ndef __init__(self, fmt, /, *args, **kwargs):\nself.fmt = fmt\nself.args = args\nself.kwargs = kwargs\ndef __str__(self):\nreturn self.fmt.format(*self.args, **self.kwargs)\nclass DollarMessage:\ndef __init__(self, fmt, /, **kwargs):\nself.fmt = fmt\nself.kwargs = kwargs\ndef __str__(self):\nfrom string import Template\nreturn Template(self.fmt).substitute(**self.kwargs)\n以上两个类均都可用于替代格式串，以便用 {}- 或 $-formatting 构建实际的“日志信息”部分，此部分\n将出现在格式化后的日志输出中，替换 %(message)s 、“{message}”或“$message”。每次要写入日志\n\n|  | 日志调用 (debug(), info() 等) 只接受包含实际日志消息自身的位置参数，而关键字参数仅用于确\n定如何处理日志调用的选项 (例如 exc_info 关键字参数表示应将回溯信息记入日志，而 extra 关键\n字参数则指定要添加到日志的额外上下文信息)。 所以你不能直接使用 str.format() 或\nstring.Template 语法来直接执行日志调用，因为 logging 包在内部是使用 % 格式符来合并格式字\n符串和可变参数的。 这一点不应被改变以保持向下兼容性，因为现有代码中所有的日志调用都将使\n用 % 格式化字符串。\n有人建议将格式化样式与特定的日志对象进行关联，但其实也会遇到向下兼容的问题，因为已有代\n码可能用到了某日志对象并采用了 %-f 格式串。\n为了让第三方库和自编代码都能够交互使用日志功能，需要决定在单次日志记录调用级别采用什么\n格式。于是就出现了其他几种格式化样式方案。\nLogRecord 工厂的用法\n在 Python 3.2 中，伴随着 Formatter 的上述变化，logging 包增加了允许用户使用\nsetLogRecordFactory() 函数来。设置自己的 LogRecord 子类的功能。 你可以使用此功能来设置\n自己的 LogRecord 子类，它会通过重写 getMessage() 方法来完成适当的操作。 msg % args 格式\n化是在此方法的基类实现中进行的，你可以在那里用你自己的格式化操作来替换；但是，你应当注\n意要支持全部的格式化样式并允许将 %-formatting 作为默认样式，以确保与其他代码进行配合。 还\n应当注意调用 str(self.msg)，正如基类实现所做的一样。\n更多信息请参阅 setLogRecordFactory() 和 LogRecord 的参考文档。\n自定义信息对象的使用\n另一种方案可能更为简单，可以利用 {}- 和 $- 格式构建自己的日志消息。大家或许还记得（来自 使\n用任意对象作为消息），可以用任意对象作为日志信息的格式串，日志包将调用该对象上 str() 获\n取实际的格式串。看下以下两个类： |  |\n| --- | --- | --- |\n|  | class BraceMessage:\ndef __init__(self, fmt, /, *args, **kwargs):\nself.fmt = fmt\nself.args = args\nself.kwargs = kwargs\ndef __str__(self):\nreturn self.fmt.format(*self.args, **self.kwargs)\nclass DollarMessage:\ndef __init__(self, fmt, /, **kwargs):\nself.fmt = fmt\nself.kwargs = kwargs\ndef __str__(self):\nfrom string import Template\nreturn Template(self.fmt).substitute(**self.kwargs) |  |\n|  | 以上两个类均都可用于替代格式串，以便用 {}- 或 $-formatting 构建实际的“日志信息”部分，此部分\n将出现在格式化后的日志输出中，替换 %(message)s 、“{message}”或“$message”。每次要写入日志 |  |\n\n时都使用类名，如果觉得使用不便，可以采用 M 或 _ 之类的别名（如果将 _ 用于本地化操作，则可\n用 __）。\n下面给出示例。 首先用 str.format() 进行格式化：\n>>> __ = BraceMessage\n>>> print(__('Message with {0} {1}', 2, 'placeholders'))\nMessage with 2 placeholders\n>>> class Point: pass\n...\n>>> p = Point()\n>>> p.x = 0.5\n>>> p.y = 0.5\n>>> print(__('Message with coordinates: ({point.x:.2f}, {point.y:.2f})', point=p))\nMessage with coordinates: (0.50, 0.50)\n然后，用 string.Template 格式化：\n>>> __ = DollarMessage\n>>> print(__('Message with $num $what', num=2, what='placeholders'))\nMessage with 2 placeholders\n>>>\n需要注意的是使用这种方式不会对性能造成明显影响：实际的格式化工作不是在日志记录调用时发\n生的，而是在（如果）处理器即将把日志消息输出到日志时发生的。 因此，唯一可能令人困惑的不\n寻常之处在于包裹在格式字符串和参数外面的圆括号，而不仅仅是格式字符串。 这是因为 __ 符号只\n是对上面显示的 XXXMessage 类的构造器的调用的语法糖。\n利用 dictConfig() 定义过滤器\n用 dictConfig() 可以 对日志过滤器进行设置，尽管乍一看做法并不明显（所以才需要本秘籍）。\n由于 Filter 是标准库中唯一的日志过滤器类，不太可能满足众多的要求（它只是作为基类存\n在），通常需要定义自己的 Filter 子类，并重写 filter() 方法。为此，请在过滤器的配置字典中\n设置 () 键，指定要用于创建过滤器的可调用对象（最明显可用的就是给出一个类，但也可以提供任\n何一个可调用对象，只要能返回 Filter 实例即可）。下面是一个完整的例子：\nimport logging\nimport logging.config\nimport sys\nclass MyFilter(logging.Filter):\ndef __init__(self, param=None):\nself.param = param\ndef filter(self, record):\nif self.param is None:\nallow = True\nelse:\nallow = self.param not in record.msg\nif allow:\nrecord.msg = 'changed: ' + record.msg\nreturn allow\n\n|  | 时都使用类名，如果觉得使用不便，可以采用 M 或 _ 之类的别名（如果将 _ 用于本地化操作，则可\n用 __）。\n下面给出示例。 首先用 str.format() 进行格式化： |  |\n| --- | --- | --- |\n|  | >>> __ = BraceMessage\n>>> print(__('Message with {0} {1}', 2, 'placeholders'))\nMessage with 2 placeholders\n>>> class Point: pass\n...\n>>> p = Point()\n>>> p.x = 0.5\n>>> p.y = 0.5\n>>> print(__('Message with coordinates: ({point.x:.2f}, {point.y:.2f})', point=p))\nMessage with coordinates: (0.50, 0.50) |  |\n|  | 然后，用 string.Template 格式化： |  |\n|  | >>> __ = DollarMessage\n>>> print(__('Message with $num $what', num=2, what='placeholders'))\nMessage with 2 placeholders\n>>> |  |\n|  | 需要注意的是使用这种方式不会对性能造成明显影响：实际的格式化工作不是在日志记录调用时发\n生的，而是在（如果）处理器即将把日志消息输出到日志时发生的。 因此，唯一可能令人困惑的不\n寻常之处在于包裹在格式字符串和参数外面的圆括号，而不仅仅是格式字符串。 这是因为 __ 符号只\n是对上面显示的 XXXMessage 类的构造器的调用的语法糖。\n利用 dictConfig() 定义过滤器\n用 dictConfig() 可以 对日志过滤器进行设置，尽管乍一看做法并不明显（所以才需要本秘籍）。\n由于 Filter 是标准库中唯一的日志过滤器类，不太可能满足众多的要求（它只是作为基类存\n在），通常需要定义自己的 Filter 子类，并重写 filter() 方法。为此，请在过滤器的配置字典中\n设置 () 键，指定要用于创建过滤器的可调用对象（最明显可用的就是给出一个类，但也可以提供任\n何一个可调用对象，只要能返回 Filter 实例即可）。下面是一个完整的例子： |  |\n|  | import logging\nimport logging.config\nimport sys\nclass MyFilter(logging.Filter):\ndef __init__(self, param=None):\nself.param = param\ndef filter(self, record):\nif self.param is None:\nallow = True\nelse:\nallow = self.param not in record.msg\nif allow:\nrecord.msg = 'changed: ' + record.msg\nreturn allow |  |\n\nLOGGING = {\n'version': 1,\n'filters': {\n'myfilter': {\n'()': MyFilter,\n'param': 'noshow',\n}\n},\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'filters': ['myfilter']\n}\n},\n'root': {\n'level': 'DEBUG',\n'handlers': ['console']\n},\n}\nif __name__ == '__main__':\nlogging.config.dictConfig(LOGGING)\nlogging.debug('hello')\nlogging.debug('hello - noshow')\n以上示例展示了将配置数据传给构造实例的可调用对象，形式是关键字参数。运行后将会输出：\nchanged: hello\n这说明过滤器按照配置的参数生效了。\n需要额外注意的地方：\n如果在配置中无法直接引用可调用对象（比如位于不同的模块中，并且不能在配置字典所在的位\n置直接导入），则可以采用 ext://... 的形式，正如 访问外部对象 所述。例如，在上述示例中\n可以使用文本 'ext://__main__.MyFilter' 而不是 MyFilter 对象。\n与过滤器一样，上述技术还可用于配置自定义 handler 和格式化对象。有关如何在日志配置中使\n用用户自定义对象的更多信息，请参阅 用户定义对象，以及上述 利用 dictConfig() 自定义\nhandler 的其他指南。\n异常信息的自定义格式化\n有时可能需要设置自定义的异常信息格式——考虑到会用到参数，假定要让每条日志事件只占一\n行，即便存在异常信息也一样。这可以用自定义格式化类来实现，如下所示：\nimport logging\nclass OneLineExceptionFormatter(logging.Formatter):\ndef formatException(self, exc_info):\n\"\"\"\nFormat an exception so that it prints on a single line.\n\"\"\"\nresult = super().formatException(exc_info)\nreturn repr(result) # 或格式化为任何你想要的单行内容\n\n|  | LOGGING = {\n'version': 1,\n'filters': {\n'myfilter': {\n'()': MyFilter,\n'param': 'noshow',\n}\n},\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'filters': ['myfilter']\n}\n},\n'root': {\n'level': 'DEBUG',\n'handlers': ['console']\n},\n}\nif __name__ == '__main__':\nlogging.config.dictConfig(LOGGING)\nlogging.debug('hello')\nlogging.debug('hello - noshow') |  |\n| --- | --- | --- |\n|  | 以上示例展示了将配置数据传给构造实例的可调用对象，形式是关键字参数。运行后将会输出： |  |\n|  | changed: hello |  |\n|  | 这说明过滤器按照配置的参数生效了。\n需要额外注意的地方：\n如果在配置中无法直接引用可调用对象（比如位于不同的模块中，并且不能在配置字典所在的位\n置直接导入），则可以采用 ext://... 的形式，正如 访问外部对象 所述。例如，在上述示例中\n可以使用文本 'ext://__main__.MyFilter' 而不是 MyFilter 对象。\n与过滤器一样，上述技术还可用于配置自定义 handler 和格式化对象。有关如何在日志配置中使\n用用户自定义对象的更多信息，请参阅 用户定义对象，以及上述 利用 dictConfig() 自定义\nhandler 的其他指南。\n异常信息的自定义格式化\n有时可能需要设置自定义的异常信息格式——考虑到会用到参数，假定要让每条日志事件只占一\n行，即便存在异常信息也一样。这可以用自定义格式化类来实现，如下所示： |  |\n|  | import logging\nclass OneLineExceptionFormatter(logging.Formatter):\ndef formatException(self, exc_info):\n\"\"\"\nFormat an exception so that it prints on a single line.\n\"\"\"\nresult = super().formatException(exc_info)\nreturn repr(result) # 或格式化为任何你想要的单行内容 |  |\n\ndef format(self, record):\ns = super().format(record)\nif record.exc_text:\ns = s.replace('\\n', '') + '|'\nreturn s\ndef configure_logging():\nfh = logging.FileHandler('output.txt', 'w')\nf = OneLineExceptionFormatter('%(asctime)s|%(levelname)s|%(message)s|',\n'%d/%m/%Y %H:%M:%S')\nfh.setFormatter(f)\nroot = logging.getLogger()\nroot.setLevel(logging.DEBUG)\nroot.addHandler(fh)\ndef main():\nconfigure_logging()\nlogging.info('Sample message')\ntry:\nx = 1 / 0\nexcept ZeroDivisionError as e:\nlogging.exception('ZeroDivisionError: %s', e)\nif __name__ == '__main__':\nmain()\n运行后将会生成只有两行信息的文件：\n28/01/2015 07:21:23|INFO|Sample message|\n28/01/2015 07:21:23|ERROR|ZeroDivisionError: division by zero|'Traceback (most rec\n虽然上述处理方式很简单，但也给出了根据喜好对异常信息进行格式化输出的方案。或许\ntraceback 模块能满足更专门的需求。\n语音播报日志信息\n有时可能需要以声音的形式呈现日志消息。如果系统自带了文本转语音 （TTS）功能，即便没与\nPython 关联也很容易做到。大多数 TTS 系统都有一个可运行的命令行程序，在 handler 中可以用\nsubprocess 进行调用。这里假定 TTS 命令行程序不会与用户交互，或需要很长时间才会执行完毕，\n写入日志的信息也不会多到影响用户查看，并且可以接受每次播报一条信息，以下示例实现了等一\n条信息播完再处理下一条，可能会导致其他 handler 的等待。这个简短示例仅供演示，假定 espeak\nTTS 包已就绪：\nimport logging\nimport subprocess\nimport sys\nclass TTSHandler(logging.Handler):\ndef emit(self, record):\nmsg = self.format(record)\n# 以女性的英语语音慢速地说话\ncmd = ['espeak', '-s150', '-ven+f3', msg]\np = subprocess.Popen(cmd, stdout=subprocess.PIPE,\nstderr=subprocess.STDOUT)\n\n|  | def format(self, record):\ns = super().format(record)\nif record.exc_text:\ns = s.replace('\\n', '') + '|'\nreturn s\ndef configure_logging():\nfh = logging.FileHandler('output.txt', 'w')\nf = OneLineExceptionFormatter('%(asctime)s|%(levelname)s|%(message)s|',\n'%d/%m/%Y %H:%M:%S')\nfh.setFormatter(f)\nroot = logging.getLogger()\nroot.setLevel(logging.DEBUG)\nroot.addHandler(fh)\ndef main():\nconfigure_logging()\nlogging.info('Sample message')\ntry:\nx = 1 / 0\nexcept ZeroDivisionError as e:\nlogging.exception('ZeroDivisionError: %s', e)\nif __name__ == '__main__':\nmain() |  |  |\n| --- | --- | --- | --- |\n|  | 运行后将会生成只有两行信息的文件： |  |  |\n|  | 28/01/2015 07:21:23|INFO|Sample message|\n28/01/2015 07:21:23|ERROR|ZeroDivisionError: division by zero|'Traceback (most rec |  |  |\n|  | 虽然上述处理方式很简单，但也给出了根据喜好对异常信息进行格式化输出的方案。或许\ntraceback 模块能满足更专门的需求。\n语音播报日志信息\n有时可能需要以声音的形式呈现日志消息。如果系统自带了文本转语音 （TTS）功能，即便没与\nPython 关联也很容易做到。大多数 TTS 系统都有一个可运行的命令行程序，在 handler 中可以用\nsubprocess 进行调用。这里假定 TTS 命令行程序不会与用户交互，或需要很长时间才会执行完毕，\n写入日志的信息也不会多到影响用户查看，并且可以接受每次播报一条信息，以下示例实现了等一\n条信息播完再处理下一条，可能会导致其他 handler 的等待。这个简短示例仅供演示，假定 espeak\nTTS 包已就绪： |  |  |\n|  | import logging\nimport subprocess\nimport sys\nclass TTSHandler(logging.Handler):\ndef emit(self, record):\nmsg = self.format(record)\n# 以女性的英语语音慢速地说话\ncmd = ['espeak', '-s150', '-ven+f3', msg]\np = subprocess.Popen(cmd, stdout=subprocess.PIPE,\nstderr=subprocess.STDOUT) |  |  |\n\n# 等待程序结束\np.communicate()\ndef configure_logging():\nh = TTSHandler()\nroot = logging.getLogger()\nroot.addHandler(h)\n# 默认格式化器简单地返回消息\nroot.setLevel(logging.DEBUG)\ndef main():\nlogging.info('Hello')\nlogging.debug('Goodbye')\nif __name__ == '__main__':\nconfigure_logging()\nsys.exit(main())\n运行后将会以女声播报“Hello”和“Goodbye”。\n当然，上述方案也适用于其他 TTS 系统，甚至可以通过利用命令行运行的外部程序来处理消息。\n缓冲日志消息并有条件地输出它们\n在某些情况下，你可能希望在临时区域中记录日志消息，并且只在发生某种特定的情况下才输出它\n们。 例如，你可能希望起始在函数中记录调试事件，如果函数执行完成且没有错误，你不希望输出\n收集的调试信息以避免造成日志混乱，但如果出现错误，那么你希望所有调试以及错误消息被输\n出。\n下面是一个示例，展示如何在你的日志记录函数上使用装饰器以实现这一功能。该示例使用\nlogging.handlers.MemoryHandler ，它允许缓冲已记录的事件直到某些条件发生，缓冲的事件才\n会被刷新（flushed） - 传递给另一个处理程序（ target handler）进行处理。 默认情况下，\nMemoryHandler 在其缓冲区被填满时被刷新，或者看到一个级别大于或等于指定阈值的事件。 如果\n想要自定义刷新行为，你可以通过更专业的 MemoryHandler 子类来使用这个秘诀。\n这个示例脚本有一个简单的函数 foo ，它只是在所有的日志级别中循环运行，写到 sys.stderr ，\n说明它要记录在哪个级别上，然后在这个级别上实际记录一个消息。你可以给 foo 传递一个参数，\n如果为 true ，它将在ERROR和CRITICAL级别记录，否则，它只在DEBUG、INFO和WARNING级别记\n录。\n脚本只是使用了一个装饰器来装饰 foo，这个装饰器将记录执行所需的条件。装饰器使用一个记录\n器作为参数，并在调用被装饰的函数期间附加一个内存处理程序。装饰器可以使用目标处理程序、\n记录级别和缓冲区的容量（缓冲记录的数量）来附加参数。这些参数分别默认为写入 sys.stderr\n的 StreamHandler ， logging.ERROR 和 100。\n以下是脚本：\nimport logging\nfrom logging.handlers import MemoryHandler\nimport sys\nlogger = logging.getLogger(__name__)\n\n|  | # 等待程序结束\np.communicate()\ndef configure_logging():\nh = TTSHandler()\nroot = logging.getLogger()\nroot.addHandler(h)\n# 默认格式化器简单地返回消息\nroot.setLevel(logging.DEBUG)\ndef main():\nlogging.info('Hello')\nlogging.debug('Goodbye')\nif __name__ == '__main__':\nconfigure_logging()\nsys.exit(main()) |  |\n| --- | --- | --- |\n|  | 运行后将会以女声播报“Hello”和“Goodbye”。\n当然，上述方案也适用于其他 TTS 系统，甚至可以通过利用命令行运行的外部程序来处理消息。\n缓冲日志消息并有条件地输出它们\n在某些情况下，你可能希望在临时区域中记录日志消息，并且只在发生某种特定的情况下才输出它\n们。 例如，你可能希望起始在函数中记录调试事件，如果函数执行完成且没有错误，你不希望输出\n收集的调试信息以避免造成日志混乱，但如果出现错误，那么你希望所有调试以及错误消息被输\n出。\n下面是一个示例，展示如何在你的日志记录函数上使用装饰器以实现这一功能。该示例使用\nlogging.handlers.MemoryHandler ，它允许缓冲已记录的事件直到某些条件发生，缓冲的事件才\n会被刷新（flushed） - 传递给另一个处理程序（ target handler）进行处理。 默认情况下，\nMemoryHandler 在其缓冲区被填满时被刷新，或者看到一个级别大于或等于指定阈值的事件。 如果\n想要自定义刷新行为，你可以通过更专业的 MemoryHandler 子类来使用这个秘诀。\n这个示例脚本有一个简单的函数 foo ，它只是在所有的日志级别中循环运行，写到 sys.stderr ，\n说明它要记录在哪个级别上，然后在这个级别上实际记录一个消息。你可以给 foo 传递一个参数，\n如果为 true ，它将在ERROR和CRITICAL级别记录，否则，它只在DEBUG、INFO和WARNING级别记\n录。\n脚本只是使用了一个装饰器来装饰 foo，这个装饰器将记录执行所需的条件。装饰器使用一个记录\n器作为参数，并在调用被装饰的函数期间附加一个内存处理程序。装饰器可以使用目标处理程序、\n记录级别和缓冲区的容量（缓冲记录的数量）来附加参数。这些参数分别默认为写入 sys.stderr\n的 StreamHandler ， logging.ERROR 和 100。\n以下是脚本： |  |\n|  | import logging\nfrom logging.handlers import MemoryHandler\nimport sys\nlogger = logging.getLogger(__name__) |  |\n\nlogger.addHandler(logging.NullHandler())\ndef log_if_errors(logger, target_handler=None, flush_level=None, capacity=None):\nif target_handler is None:\ntarget_handler = logging.StreamHandler()\nif flush_level is None:\nflush_level = logging.ERROR\nif capacity is None:\ncapacity = 100\nhandler = MemoryHandler(capacity, flushLevel=flush_level, target=target_handle\ndef decorator(fn):\ndef wrapper(*args, **kwargs):\nlogger.addHandler(handler)\ntry:\nreturn fn(*args, **kwargs)\nexcept Exception:\nlogger.exception('call failed')\nraise\nfinally:\nsuper(MemoryHandler, handler).flush()\nlogger.removeHandler(handler)\nreturn wrapper\nreturn decorator\ndef write_line(s):\nsys.stderr.write('%s\\n' % s)\ndef foo(fail=False):\nwrite_line('about to log at DEBUG ...')\nlogger.debug('Actually logged at DEBUG')\nwrite_line('about to log at INFO ...')\nlogger.info('Actually logged at INFO')\nwrite_line('about to log at WARNING ...')\nlogger.warning('Actually logged at WARNING')\nif fail:\nwrite_line('about to log at ERROR ...')\nlogger.error('Actually logged at ERROR')\nwrite_line('about to log at CRITICAL ...')\nlogger.critical('Actually logged at CRITICAL')\nreturn fail\ndecorated_foo = log_if_errors(logger)(foo)\nif __name__ == '__main__':\nlogger.setLevel(logging.DEBUG)\nwrite_line('Calling undecorated foo with False')\nassert not foo(False)\nwrite_line('Calling undecorated foo with True')\nassert foo(True)\nwrite_line('Calling decorated foo with False')\nassert not decorated_foo(False)\nwrite_line('Calling decorated foo with True')\nassert decorated_foo(True)\n运行此脚本时，应看到以下输出：\n\n|  | logger.addHandler(logging.NullHandler())\ndef log_if_errors(logger, target_handler=None, flush_level=None, capacity=None):\nif target_handler is None:\ntarget_handler = logging.StreamHandler()\nif flush_level is None:\nflush_level = logging.ERROR\nif capacity is None:\ncapacity = 100\nhandler = MemoryHandler(capacity, flushLevel=flush_level, target=target_handle\ndef decorator(fn):\ndef wrapper(*args, **kwargs):\nlogger.addHandler(handler)\ntry:\nreturn fn(*args, **kwargs)\nexcept Exception:\nlogger.exception('call failed')\nraise\nfinally:\nsuper(MemoryHandler, handler).flush()\nlogger.removeHandler(handler)\nreturn wrapper\nreturn decorator\ndef write_line(s):\nsys.stderr.write('%s\\n' % s)\ndef foo(fail=False):\nwrite_line('about to log at DEBUG ...')\nlogger.debug('Actually logged at DEBUG')\nwrite_line('about to log at INFO ...')\nlogger.info('Actually logged at INFO')\nwrite_line('about to log at WARNING ...')\nlogger.warning('Actually logged at WARNING')\nif fail:\nwrite_line('about to log at ERROR ...')\nlogger.error('Actually logged at ERROR')\nwrite_line('about to log at CRITICAL ...')\nlogger.critical('Actually logged at CRITICAL')\nreturn fail\ndecorated_foo = log_if_errors(logger)(foo)\nif __name__ == '__main__':\nlogger.setLevel(logging.DEBUG)\nwrite_line('Calling undecorated foo with False')\nassert not foo(False)\nwrite_line('Calling undecorated foo with True')\nassert foo(True)\nwrite_line('Calling decorated foo with False')\nassert not decorated_foo(False)\nwrite_line('Calling decorated foo with True')\nassert decorated_foo(True) |  |\n| --- | --- | --- |\n|  | 运行此脚本时，应看到以下输出： |  |\n\nCalling undecorated foo with False\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nCalling undecorated foo with True\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nabout to log at ERROR ...\nabout to log at CRITICAL ...\nCalling decorated foo with False\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nCalling decorated foo with True\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nabout to log at ERROR ...\nActually logged at DEBUG\nActually logged at INFO\nActually logged at WARNING\nActually logged at ERROR\nabout to log at CRITICAL ...\nActually logged at CRITICAL\n如你所见，实际日志记录输出仅在消息等级为ERROR或更高的事件时发生，但在这种情况下，任何\n之前较低消息等级的事件还会被记录。\n你当然可以使用传统的装饰方法:\n@log_if_errors(logger)\ndef foo(fail=False):\n...\n将日志消息发送至电子邮件，附带缓存支持\n为演示如何通过电子邮件发送日志消息，让每封电子邮件发送指定数量的日志消息，你可以子类化\nBufferingHandler。 对于下面的例子，你可以继续调整以适合你自己的特定需求，它提供了简单\n的测试代码来允许你附带命令行参数运行该脚本来指定你需要通过 SMTP 发送的内容。 （请附带 -h\n参数运行已下载的脚本来查看必须的和可选的参数。）\nimport logging\nimport logging.handlers\nimport smtplib\nclass BufferingSMTPHandler(logging.handlers.BufferingHandler):\ndef __init__(self, mailhost, port, username, password, fromaddr, toaddrs,\nsubject, capacity):\nlogging.handlers.BufferingHandler.__init__(self, capacity)\nself.mailhost = mailhost\nself.mailport = port\nself.username = username\nself.password = password\nself.fromaddr = fromaddr\n\n|  | Calling undecorated foo with False\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nCalling undecorated foo with True\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nabout to log at ERROR ...\nabout to log at CRITICAL ...\nCalling decorated foo with False\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nCalling decorated foo with True\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nabout to log at ERROR ...\nActually logged at DEBUG\nActually logged at INFO\nActually logged at WARNING\nActually logged at ERROR\nabout to log at CRITICAL ...\nActually logged at CRITICAL |  |\n| --- | --- | --- |\n|  | 如你所见，实际日志记录输出仅在消息等级为ERROR或更高的事件时发生，但在这种情况下，任何\n之前较低消息等级的事件还会被记录。\n你当然可以使用传统的装饰方法: |  |\n|  | @log_if_errors(logger)\ndef foo(fail=False):\n... |  |\n|  | 将日志消息发送至电子邮件，附带缓存支持\n为演示如何通过电子邮件发送日志消息，让每封电子邮件发送指定数量的日志消息，你可以子类化\nBufferingHandler。 对于下面的例子，你可以继续调整以适合你自己的特定需求，它提供了简单\n的测试代码来允许你附带命令行参数运行该脚本来指定你需要通过 SMTP 发送的内容。 （请附带 -h\n参数运行已下载的脚本来查看必须的和可选的参数。） |  |\n|  | import logging\nimport logging.handlers\nimport smtplib\nclass BufferingSMTPHandler(logging.handlers.BufferingHandler):\ndef __init__(self, mailhost, port, username, password, fromaddr, toaddrs,\nsubject, capacity):\nlogging.handlers.BufferingHandler.__init__(self, capacity)\nself.mailhost = mailhost\nself.mailport = port\nself.username = username\nself.password = password\nself.fromaddr = fromaddr |  |\n\nif isinstance(toaddrs, str):\ntoaddrs = [toaddrs]\nself.toaddrs = toaddrs\nself.subject = subject\nself.setFormatter(logging.Formatter(\"%(asctime)s %(levelname)-5s %(message\ndef flush(self):\nif len(self.buffer) > 0:\ntry:\nsmtp = smtplib.SMTP(self.mailhost, self.mailport)\nsmtp.starttls()\nsmtp.login(self.username, self.password)\nmsg = \"From: %s\\r\\nTo: %s\\r\\nSubject: %s\\r\\n\\r\\n\" % (self.fromaddr\nfor record in self.buffer:\ns = self.format(record)\nmsg = msg + s + \"\\r\\n\"\nsmtp.sendmail(self.fromaddr, self.toaddrs, msg)\nsmtp.quit()\nexcept Exception:\nif logging.raiseExceptions:\nraise\nself.buffer = []\nif __name__ == '__main__':\nimport argparse\nap = argparse.ArgumentParser()\naa = ap.add_argument\naa('host', metavar='HOST', help='SMTP server')\naa('--port', '-p', type=int, default=587, help='SMTP port')\naa('user', metavar='USER', help='SMTP username')\naa('password', metavar='PASSWORD', help='SMTP password')\naa('to', metavar='TO', help='Addressee for emails')\naa('sender', metavar='SENDER', help='Sender email address')\naa('--subject', '-s',\ndefault='Test Logging email from Python logging module (buffering)',\nhelp='Subject of email')\noptions = ap.parse_args()\nlogger = logging.getLogger()\nlogger.setLevel(logging.DEBUG)\nh = BufferingSMTPHandler(options.host, options.port, options.user,\noptions.password, options.sender,\noptions.to, options.subject, 10)\nlogger.addHandler(h)\nfor i in range(102):\nlogger.info(\"Info index = %d\", i)\nh.flush()\nh.close()\n如果你运行此脚本并且你的 SMTP 服务器已正确设置，你将发现它会向你指定的地址发出十一封电\n子邮件。 前十封邮件每封各有十条日志消息，第十一封将有两条消息。 如脚本所指定的总计为 102\n条消息。\n通过配置使用UTC (GMT) 格式化时间\n有时你会想要使用 UTC 时间格式，这可以用 UTCFormatter 这样的类来实现，如下所示:\n\n|  | if isinstance(toaddrs, str):\ntoaddrs = [toaddrs]\nself.toaddrs = toaddrs\nself.subject = subject\nself.setFormatter(logging.Formatter(\"%(asctime)s %(levelname)-5s %(message\ndef flush(self):\nif len(self.buffer) > 0:\ntry:\nsmtp = smtplib.SMTP(self.mailhost, self.mailport)\nsmtp.starttls()\nsmtp.login(self.username, self.password)\nmsg = \"From: %s\\r\\nTo: %s\\r\\nSubject: %s\\r\\n\\r\\n\" % (self.fromaddr\nfor record in self.buffer:\ns = self.format(record)\nmsg = msg + s + \"\\r\\n\"\nsmtp.sendmail(self.fromaddr, self.toaddrs, msg)\nsmtp.quit()\nexcept Exception:\nif logging.raiseExceptions:\nraise\nself.buffer = []\nif __name__ == '__main__':\nimport argparse\nap = argparse.ArgumentParser()\naa = ap.add_argument\naa('host', metavar='HOST', help='SMTP server')\naa('--port', '-p', type=int, default=587, help='SMTP port')\naa('user', metavar='USER', help='SMTP username')\naa('password', metavar='PASSWORD', help='SMTP password')\naa('to', metavar='TO', help='Addressee for emails')\naa('sender', metavar='SENDER', help='Sender email address')\naa('--subject', '-s',\ndefault='Test Logging email from Python logging module (buffering)',\nhelp='Subject of email')\noptions = ap.parse_args()\nlogger = logging.getLogger()\nlogger.setLevel(logging.DEBUG)\nh = BufferingSMTPHandler(options.host, options.port, options.user,\noptions.password, options.sender,\noptions.to, options.subject, 10)\nlogger.addHandler(h)\nfor i in range(102):\nlogger.info(\"Info index = %d\", i)\nh.flush()\nh.close() |  |\n| --- | --- | --- |\n|  | 如果你运行此脚本并且你的 SMTP 服务器已正确设置，你将发现它会向你指定的地址发出十一封电\n子邮件。 前十封邮件每封各有十条日志消息，第十一封将有两条消息。 如脚本所指定的总计为 102\n条消息。\n通过配置使用UTC (GMT) 格式化时间\n有时你会想要使用 UTC 时间格式，这可以用 UTCFormatter 这样的类来实现，如下所示: |  |\n\nimport logging\nimport time\nclass UTCFormatter(logging.Formatter):\nconverter = time.gmtime\n然后你可以在你的代码中使用 UTCFormatter，而不是 Formatter。 如果你想通过配置来实现这一\n功能，你可以使用 dictConfig() API 来完成，该方法在以下完整示例中展示:\nimport logging\nimport logging.config\nimport time\nclass UTCFormatter(logging.Formatter):\nconverter = time.gmtime\nLOGGING = {\n'version': 1,\n'disable_existing_loggers': False,\n'formatters': {\n'utc': {\n'()': UTCFormatter,\n'format': '%(asctime)s %(message)s',\n},\n'local': {\n'format': '%(asctime)s %(message)s',\n}\n},\n'handlers': {\n'console1': {\n'class': 'logging.StreamHandler',\n'formatter': 'utc',\n},\n'console2': {\n'class': 'logging.StreamHandler',\n'formatter': 'local',\n},\n},\n'root': {\n'handlers': ['console1', 'console2'],\n}\n}\nif __name__ == '__main__':\nlogging.config.dictConfig(LOGGING)\nlogging.warning('The local time is %s', time.asctime())\n脚本会运行输出类似下面的内容:\n2015-10-17 12:53:29,501 The local time is Sat Oct 17 13:53:29 2015\n2015-10-17 13:53:29,501 The local time is Sat Oct 17 13:53:29 2015\n展示了如何将时间格式化为本地时间和UTC两种形式，其中每种形式对应一个日志处理器 。\n使用上下文管理器的可选的日志记录\n\n|  | import logging\nimport time\nclass UTCFormatter(logging.Formatter):\nconverter = time.gmtime |  |\n| --- | --- | --- |\n|  | 然后你可以在你的代码中使用 UTCFormatter，而不是 Formatter。 如果你想通过配置来实现这一\n功能，你可以使用 dictConfig() API 来完成，该方法在以下完整示例中展示: |  |\n|  | import logging\nimport logging.config\nimport time\nclass UTCFormatter(logging.Formatter):\nconverter = time.gmtime\nLOGGING = {\n'version': 1,\n'disable_existing_loggers': False,\n'formatters': {\n'utc': {\n'()': UTCFormatter,\n'format': '%(asctime)s %(message)s',\n},\n'local': {\n'format': '%(asctime)s %(message)s',\n}\n},\n'handlers': {\n'console1': {\n'class': 'logging.StreamHandler',\n'formatter': 'utc',\n},\n'console2': {\n'class': 'logging.StreamHandler',\n'formatter': 'local',\n},\n},\n'root': {\n'handlers': ['console1', 'console2'],\n}\n}\nif __name__ == '__main__':\nlogging.config.dictConfig(LOGGING)\nlogging.warning('The local time is %s', time.asctime()) |  |\n|  | 脚本会运行输出类似下面的内容: |  |\n|  | 2015-10-17 12:53:29,501 The local time is Sat Oct 17 13:53:29 2015\n2015-10-17 13:53:29,501 The local time is Sat Oct 17 13:53:29 2015 |  |\n|  | 展示了如何将时间格式化为本地时间和UTC两种形式，其中每种形式对应一个日志处理器 。\n使用上下文管理器的可选的日志记录 |  |\n\n有时候，我们需要暂时更改日志配置，并在执行某些操作后将其还原。为此，上下文管理器是实现\n保存和恢复日志上下文的最明显的方式。这是一个关于上下文管理器的简单例子，它允许你在上下\n文管理器的作用域内更改日志记录等级以及增加日志处理器：\nimport logging\nimport sys\nclass LoggingContext:\ndef __init__(self, logger, level=None, handler=None, close=True):\nself.logger = logger\nself.level = level\nself.handler = handler\nself.close = close\ndef __enter__(self):\nif self.level is not None:\nself.old_level = self.logger.level\nself.logger.setLevel(self.level)\nif self.handler:\nself.logger.addHandler(self.handler)\ndef __exit__(self, et, ev, tb):\nif self.level is not None:\nself.logger.setLevel(self.old_level)\nif self.handler:\nself.logger.removeHandler(self.handler)\nif self.handler and self.close:\nself.handler.close()\n# 隐式地返回 None => 不捕获异常\n如果指定上下文管理器的日志记录等级属性，则在上下文管理器的with语句所涵盖的代码中，日志\n记录器的记录等级将临时设置为上下文管理器所配置的日志记录等级。 如果指定上下文管理的日志\n处理器属性，则该句柄在进入上下文管理器的上下文时添加到记录器中，并在退出时被删除。 如果\n你再也不需要该日志处理器时，你可以让上下文管理器在退出上下文管理器的上下文时关闭它。\n为了说明它是如何工作的，我们可以在上面添加以下代码块:\nif __name__ == '__main__':\nlogger = logging.getLogger('foo')\nlogger.addHandler(logging.StreamHandler())\nlogger.setLevel(logging.INFO)\nlogger.info('1. This should appear just once on stderr.')\nlogger.debug('2. This should not appear.')\nwith LoggingContext(logger, level=logging.DEBUG):\nlogger.debug('3. This should appear once on stderr.')\nlogger.debug('4. This should not appear.')\nh = logging.StreamHandler(sys.stdout)\nwith LoggingContext(logger, level=logging.DEBUG, handler=h, close=True):\nlogger.debug('5. This should appear twice - once on stderr and once on std\nlogger.info('6. This should appear just once on stderr.')\nlogger.debug('7. This should not appear.')\n我们最初设置日志记录器的消息等级为 INFO ，因此消息#1出现，消息#2没有出现。在接下来的\nwith 代码块中我们暂时将消息等级变更为 DEBUG ，从而消息 #3 出现。在这一代码块退出后，日志\n记录器的消息等级恢复为 INFO ，从而消息 #4 没有出现。在下一个 with 代码块中，我们再一次将\n\n|  | 有时候，我们需要暂时更改日志配置，并在执行某些操作后将其还原。为此，上下文管理器是实现\n保存和恢复日志上下文的最明显的方式。这是一个关于上下文管理器的简单例子，它允许你在上下\n文管理器的作用域内更改日志记录等级以及增加日志处理器： |  |  |\n| --- | --- | --- | --- |\n|  | import logging\nimport sys\nclass LoggingContext:\ndef __init__(self, logger, level=None, handler=None, close=True):\nself.logger = logger\nself.level = level\nself.handler = handler\nself.close = close\ndef __enter__(self):\nif self.level is not None:\nself.old_level = self.logger.level\nself.logger.setLevel(self.level)\nif self.handler:\nself.logger.addHandler(self.handler)\ndef __exit__(self, et, ev, tb):\nif self.level is not None:\nself.logger.setLevel(self.old_level)\nif self.handler:\nself.logger.removeHandler(self.handler)\nif self.handler and self.close:\nself.handler.close()\n# 隐式地返回 None => 不捕获异常 |  |  |\n|  | 如果指定上下文管理器的日志记录等级属性，则在上下文管理器的with语句所涵盖的代码中，日志\n记录器的记录等级将临时设置为上下文管理器所配置的日志记录等级。 如果指定上下文管理的日志\n处理器属性，则该句柄在进入上下文管理器的上下文时添加到记录器中，并在退出时被删除。 如果\n你再也不需要该日志处理器时，你可以让上下文管理器在退出上下文管理器的上下文时关闭它。\n为了说明它是如何工作的，我们可以在上面添加以下代码块: |  |  |\n|  | if __name__ == '__main__':\nlogger = logging.getLogger('foo')\nlogger.addHandler(logging.StreamHandler())\nlogger.setLevel(logging.INFO)\nlogger.info('1. This should appear just once on stderr.')\nlogger.debug('2. This should not appear.')\nwith LoggingContext(logger, level=logging.DEBUG):\nlogger.debug('3. This should appear once on stderr.')\nlogger.debug('4. This should not appear.')\nh = logging.StreamHandler(sys.stdout)\nwith LoggingContext(logger, level=logging.DEBUG, handler=h, close=True):\nlogger.debug('5. This should appear twice - once on stderr and once on std\nlogger.info('6. This should appear just once on stderr.')\nlogger.debug('7. This should not appear.') |  |  |\n|  | 我们最初设置日志记录器的消息等级为 INFO ，因此消息#1出现，消息#2没有出现。在接下来的\nwith 代码块中我们暂时将消息等级变更为 DEBUG ，从而消息 #3 出现。在这一代码块退出后，日志\n记录器的消息等级恢复为 INFO ，从而消息 #4 没有出现。在下一个 with 代码块中，我们再一次将 |  |  |\n\n设置消息等级设置为 DEBUG ，同时添加一个将消息写入 sys.stdout 的日志处理器。因此，消息#5\n在控制台出现两次 (分别通过 stderr 和 stdout )。在 with 语句完成后，状态与之前一样，因此消\n息 #6 出现（类似消息 #1），而消息 #7 没有出现（类似消息 #2）。\n如果我们运行生成的脚本，结果如下：\n$ python logctx.py\n1. This should appear just once on stderr.\n3. This should appear once on stderr.\n5. This should appear twice - once on stderr and once on stdout.\n5. This should appear twice - once on stderr and once on stdout.\n6. This should appear just once on stderr.\n我们将 stderr 标准错误重定向到 /dev/null ，我再次运行生成的脚步，唯一被写入 stdout 标准\n输出的消息，即我们所能看见的消息，如下：\n$ python logctx.py 2>/dev/null\n5. This should appear twice - once on stderr and once on stdout.\n再一次，将 stdout 标准输出重定向到 /dev/null，我获得如下结果：\n$ python logctx.py >/dev/null\n1. This should appear just once on stderr.\n3. This should appear once on stderr.\n5. This should appear twice - once on stderr and once on stdout.\n6. This should appear just once on stderr.\n在这种情况下，与预期一致，打印到 stdout 标准输出的消息＃5不会出现。\n当然，这里描述的方法可以被推广，例如临时附加日志记录过滤器。 请注意，上面的代码适用于\nPython 2以及Python 3。\n命令行日志应用起步\n下面的示例提供了如下功能：\n根据命令行参数确定日志级别\n在单独的文件中分发多条子命令，同一级别的子命令均以一致的方式记录。\n最简单的配置用法\n假定有一个命令行应用程序，用于停止、启动或重新启动某些服务。为了便于演示，不妨将 app.py\n作为应用程序的主代码文件，并在 start.py 、 stop.py 和 restart.py 中实现单独的命令。再假\n定要通过命令行参数控制应用程序的日志粒度，默认为 logging.INFO 。以下是 app.py 的一个示\n例：\nimport argparse\nimport importlib\nimport logging\nimport os\nimport sys\n\n|  | 设置消息等级设置为 DEBUG ，同时添加一个将消息写入 sys.stdout 的日志处理器。因此，消息#5\n在控制台出现两次 (分别通过 stderr 和 stdout )。在 with 语句完成后，状态与之前一样，因此消\n息 #6 出现（类似消息 #1），而消息 #7 没有出现（类似消息 #2）。\n如果我们运行生成的脚本，结果如下： |  |\n| --- | --- | --- |\n|  | $ python logctx.py\n1. This should appear just once on stderr.\n3. This should appear once on stderr.\n5. This should appear twice - once on stderr and once on stdout.\n5. This should appear twice - once on stderr and once on stdout.\n6. This should appear just once on stderr. |  |\n|  | 我们将 stderr 标准错误重定向到 /dev/null ，我再次运行生成的脚步，唯一被写入 stdout 标准\n输出的消息，即我们所能看见的消息，如下： |  |\n|  | $ python logctx.py 2>/dev/null\n5. This should appear twice - once on stderr and once on stdout. |  |\n|  | 再一次，将 stdout 标准输出重定向到 /dev/null，我获得如下结果： |  |\n|  | $ python logctx.py >/dev/null\n1. This should appear just once on stderr.\n3. This should appear once on stderr.\n5. This should appear twice - once on stderr and once on stdout.\n6. This should appear just once on stderr. |  |\n|  | 在这种情况下，与预期一致，打印到 stdout 标准输出的消息＃5不会出现。\n当然，这里描述的方法可以被推广，例如临时附加日志记录过滤器。 请注意，上面的代码适用于\nPython 2以及Python 3。\n命令行日志应用起步\n下面的示例提供了如下功能：\n根据命令行参数确定日志级别\n在单独的文件中分发多条子命令，同一级别的子命令均以一致的方式记录。\n最简单的配置用法\n假定有一个命令行应用程序，用于停止、启动或重新启动某些服务。为了便于演示，不妨将 app.py\n作为应用程序的主代码文件，并在 start.py 、 stop.py 和 restart.py 中实现单独的命令。再假\n定要通过命令行参数控制应用程序的日志粒度，默认为 logging.INFO 。以下是 app.py 的一个示\n例： |  |\n|  | import argparse\nimport importlib\nimport logging\nimport os\nimport sys |  |\n\ndef main(args=None):\nscriptname = os.path.basename(__file__)\nparser = argparse.ArgumentParser(scriptname)\nlevels = ('DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL')\nparser.add_argument('--log-level', default='INFO', choices=levels)\nsubparsers = parser.add_subparsers(dest='command',\nhelp='Available commands:')\nstart_cmd = subparsers.add_parser('start', help='Start a service')\nstart_cmd.add_argument('name', metavar='NAME',\nhelp='Name of service to start')\nstop_cmd = subparsers.add_parser('stop',\nhelp='Stop one or more services')\nstop_cmd.add_argument('names', metavar='NAME', nargs='+',\nhelp='Name of service to stop')\nrestart_cmd = subparsers.add_parser('restart',\nhelp='Restart one or more services')\nrestart_cmd.add_argument('names', metavar='NAME', nargs='+',\nhelp='Name of service to restart')\noptions = parser.parse_args()\n# 分发命令的代码可以全都放在此文件中。 只是出于演示目的，\n# 我们将在单独的模块中实现每个命令。\ntry:\nmod = importlib.import_module(options.command)\ncmd = getattr(mod, 'command')\nexcept (ImportError, AttributeError):\nprint('Unable to find the code for command \\'%s\\'' % options.command)\nreturn 1\n# 这里可以做得更为灵活并从文件或目录加载配置\nlogging.basicConfig(level=options.log_level,\nformat='%(levelname)s %(name)s %(message)s')\ncmd(options)\nif __name__ == '__main__':\nsys.exit(main())\nstart、stop 和 restart 命令可以在单独的模块中实现，启动命令的代码可如下：\n# start.py\nimport logging\nlogger = logging.getLogger(__name__)\ndef command(options):\nlogger.debug('About to start %s', options.name)\n# 在此进行实际的命令处理 ...\nlogger.info('Started the \\'%s\\' service.', options.name)\n然后是停止命令的代码：\n# stop.py\nimport logging\nlogger = logging.getLogger(__name__)\ndef command(options):\nn = len(options.names)\nif n == 1:\nplural = ''\n\n|  | def main(args=None):\nscriptname = os.path.basename(__file__)\nparser = argparse.ArgumentParser(scriptname)\nlevels = ('DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL')\nparser.add_argument('--log-level', default='INFO', choices=levels)\nsubparsers = parser.add_subparsers(dest='command',\nhelp='Available commands:')\nstart_cmd = subparsers.add_parser('start', help='Start a service')\nstart_cmd.add_argument('name', metavar='NAME',\nhelp='Name of service to start')\nstop_cmd = subparsers.add_parser('stop',\nhelp='Stop one or more services')\nstop_cmd.add_argument('names', metavar='NAME', nargs='+',\nhelp='Name of service to stop')\nrestart_cmd = subparsers.add_parser('restart',\nhelp='Restart one or more services')\nrestart_cmd.add_argument('names', metavar='NAME', nargs='+',\nhelp='Name of service to restart')\noptions = parser.parse_args()\n# 分发命令的代码可以全都放在此文件中。 只是出于演示目的，\n# 我们将在单独的模块中实现每个命令。\ntry:\nmod = importlib.import_module(options.command)\ncmd = getattr(mod, 'command')\nexcept (ImportError, AttributeError):\nprint('Unable to find the code for command \\'%s\\'' % options.command)\nreturn 1\n# 这里可以做得更为灵活并从文件或目录加载配置\nlogging.basicConfig(level=options.log_level,\nformat='%(levelname)s %(name)s %(message)s')\ncmd(options)\nif __name__ == '__main__':\nsys.exit(main()) |  |\n| --- | --- | --- |\n|  | start、stop 和 restart 命令可以在单独的模块中实现，启动命令的代码可如下： |  |\n|  | # start.py\nimport logging\nlogger = logging.getLogger(__name__)\ndef command(options):\nlogger.debug('About to start %s', options.name)\n# 在此进行实际的命令处理 ...\nlogger.info('Started the \\'%s\\' service.', options.name) |  |\n|  | 然后是停止命令的代码： |  |\n|  | # stop.py\nimport logging\nlogger = logging.getLogger(__name__)\ndef command(options):\nn = len(options.names)\nif n == 1:\nplural = '' |  |\n\nservices = '\\'%s\\'' % options.names[0]\nelse:\nplural = 's'\nservices = ', '.join('\\'%s\\'' % name for name in options.names)\ni = services.rfind(', ')\nservices = services[:i] + ' and ' + services[i + 2:]\nlogger.debug('About to stop %s', services)\n# 在此进行实际的命令处理 ...\nlogger.info('Stopped the %s service%s.', services, plural)\n重启命令类似：\n# restart.py\nimport logging\nlogger = logging.getLogger(__name__)\ndef command(options):\nn = len(options.names)\nif n == 1:\nplural = ''\nservices = '\\'%s\\'' % options.names[0]\nelse:\nplural = 's'\nservices = ', '.join('\\'%s\\'' % name for name in options.names)\ni = services.rfind(', ')\nservices = services[:i] + ' and ' + services[i + 2:]\nlogger.debug('About to restart %s', services)\n# 在此进行实际的命令处理 ...\nlogger.info('Restarted the %s service%s.', services, plural)\n如果以默认日志级别运行该程序，会得到以下结果：\n$ python app.py start foo\nINFO start Started the 'foo' service.\n$ python app.py stop foo bar\nINFO stop Stopped the 'foo' and 'bar' services.\n$ python app.py restart foo bar baz\nINFO restart Restarted the 'foo', 'bar' and 'baz' services.\n第一个单词是日志级别，第二个单词是日志事件所在的模块或包的名称。\n如果修改了日志级别，发送给日志的信息就能得以改变。如要显示更多信息，则可：\n$ python app.py --log-level DEBUG start foo\nDEBUG start About to start foo\nINFO start Started the 'foo' service.\n$ python app.py --log-level DEBUG stop foo bar\nDEBUG stop About to stop 'foo' and 'bar'\nINFO stop Stopped the 'foo' and 'bar' services.\n$ python app.py --log-level DEBUG restart foo bar baz\n\n|  | services = '\\'%s\\'' % options.names[0]\nelse:\nplural = 's'\nservices = ', '.join('\\'%s\\'' % name for name in options.names)\ni = services.rfind(', ')\nservices = services[:i] + ' and ' + services[i + 2:]\nlogger.debug('About to stop %s', services)\n# 在此进行实际的命令处理 ...\nlogger.info('Stopped the %s service%s.', services, plural) |  |\n| --- | --- | --- |\n|  | 重启命令类似： |  |\n|  | # restart.py\nimport logging\nlogger = logging.getLogger(__name__)\ndef command(options):\nn = len(options.names)\nif n == 1:\nplural = ''\nservices = '\\'%s\\'' % options.names[0]\nelse:\nplural = 's'\nservices = ', '.join('\\'%s\\'' % name for name in options.names)\ni = services.rfind(', ')\nservices = services[:i] + ' and ' + services[i + 2:]\nlogger.debug('About to restart %s', services)\n# 在此进行实际的命令处理 ...\nlogger.info('Restarted the %s service%s.', services, plural) |  |\n|  | 如果以默认日志级别运行该程序，会得到以下结果： |  |\n|  | $ python app.py start foo\nINFO start Started the 'foo' service.\n$ python app.py stop foo bar\nINFO stop Stopped the 'foo' and 'bar' services.\n$ python app.py restart foo bar baz\nINFO restart Restarted the 'foo', 'bar' and 'baz' services. |  |\n|  | 第一个单词是日志级别，第二个单词是日志事件所在的模块或包的名称。\n如果修改了日志级别，发送给日志的信息就能得以改变。如要显示更多信息，则可： |  |\n|  | $ python app.py --log-level DEBUG start foo\nDEBUG start About to start foo\nINFO start Started the 'foo' service.\n$ python app.py --log-level DEBUG stop foo bar\nDEBUG stop About to stop 'foo' and 'bar'\nINFO stop Stopped the 'foo' and 'bar' services.\n$ python app.py --log-level DEBUG restart foo bar baz |  |\n\nDEBUG restart About to restart 'foo', 'bar' and 'baz'\nINFO restart Restarted the 'foo', 'bar' and 'baz' services.\n若要显示的信息少一些，则：\n$ python app.py --log-level WARNING start foo\n$ python app.py --log-level WARNING stop foo bar\n$ python app.py --log-level WARNING restart foo bar baz\n这里的命令不会向控制台输出任何信息，因为没有记录 WARNING 以上级别的日志。\nQt GUI 日志示例\n一个时常被提出的问题是 GUI 应用程序要如何记录日志。 Qt 框架是一个流行的跨平台 UI 框架，它\n具有使用 PySide2 或 PyQt5 库的 Python 绑定。\n下面的例子演示了将日志写入 Qt GUI 程序的过程。这里引入了一个简单的 QtHandler 类，参数是\n一个可调用对象，其应为嵌入主线程某个“槽位”中运行的，因为GUI 的更新由主线程完成。这里还创\n建了一个工作线程，以便演示由 UI（通过人工点击日志按钮）和后台工作线程（此处只是记录级别\n和时间间隔均随机生成的日志信息）将日志写入 GUI 的过程。\n该工作线程是用 Qt 的 QThread 类实现的，而不是 threading 模块，因为某些情况下只能采用\n`QThread，它与其他 Qt 组件的集成性更好一些。\n此代码应当适用于最新的 PySide6, PyQt6, PySide2 或 PyQt5 发布版。 你也可以将此做法适配到更\n早的 Qt 版本。 请参阅代码片段中的注释来获取更详细的信息。\nimport datetime\nimport logging\nimport random\nimport sys\nimport time\n# 处理不同 Qt 包之间的微小差异\ntry:\nfrom PySide6 import QtCore, QtGui, QtWidgets\nSignal = QtCore.Signal\nSlot = QtCore.Slot\nexcept ImportError:\ntry:\nfrom PyQt6 import QtCore, QtGui, QtWidgets\nSignal = QtCore.pyqtSignal\nSlot = QtCore.pyqtSlot\nexcept ImportError:\ntry:\nfrom PySide2 import QtCore, QtGui, QtWidgets\nSignal = QtCore.Signal\nSlot = QtCore.Slot\nexcept ImportError:\nfrom PyQt5 import QtCore, QtGui, QtWidgets\nSignal = QtCore.pyqtSignal\nSlot = QtCore.pyqtSlot\nlogger = logging.getLogger(__name__)\n\n|  | DEBUG restart About to restart 'foo', 'bar' and 'baz'\nINFO restart Restarted the 'foo', 'bar' and 'baz' services. |  |\n| --- | --- | --- |\n|  | 若要显示的信息少一些，则： |  |\n|  | $ python app.py --log-level WARNING start foo\n$ python app.py --log-level WARNING stop foo bar\n$ python app.py --log-level WARNING restart foo bar baz |  |\n|  | 这里的命令不会向控制台输出任何信息，因为没有记录 WARNING 以上级别的日志。\nQt GUI 日志示例\n一个时常被提出的问题是 GUI 应用程序要如何记录日志。 Qt 框架是一个流行的跨平台 UI 框架，它\n具有使用 PySide2 或 PyQt5 库的 Python 绑定。\n下面的例子演示了将日志写入 Qt GUI 程序的过程。这里引入了一个简单的 QtHandler 类，参数是\n一个可调用对象，其应为嵌入主线程某个“槽位”中运行的，因为GUI 的更新由主线程完成。这里还创\n建了一个工作线程，以便演示由 UI（通过人工点击日志按钮）和后台工作线程（此处只是记录级别\n和时间间隔均随机生成的日志信息）将日志写入 GUI 的过程。\n该工作线程是用 Qt 的 QThread 类实现的，而不是 threading 模块，因为某些情况下只能采用\n`QThread，它与其他 Qt 组件的集成性更好一些。\n此代码应当适用于最新的 PySide6, PyQt6, PySide2 或 PyQt5 发布版。 你也可以将此做法适配到更\n早的 Qt 版本。 请参阅代码片段中的注释来获取更详细的信息。 |  |\n|  | import datetime\nimport logging\nimport random\nimport sys\nimport time\n# 处理不同 Qt 包之间的微小差异\ntry:\nfrom PySide6 import QtCore, QtGui, QtWidgets\nSignal = QtCore.Signal\nSlot = QtCore.Slot\nexcept ImportError:\ntry:\nfrom PyQt6 import QtCore, QtGui, QtWidgets\nSignal = QtCore.pyqtSignal\nSlot = QtCore.pyqtSlot\nexcept ImportError:\ntry:\nfrom PySide2 import QtCore, QtGui, QtWidgets\nSignal = QtCore.Signal\nSlot = QtCore.Slot\nexcept ImportError:\nfrom PyQt5 import QtCore, QtGui, QtWidgets\nSignal = QtCore.pyqtSignal\nSlot = QtCore.pyqtSlot\nlogger = logging.getLogger(__name__) |  |\n\n#\n# 信号需要被包含在 QObject 或其子类中以便能够正确地\n# 初始化\n#\nclass Signaller(QtCore.QObject):\nsignal = Signal(str, logging.LogRecord)\n#\n# 输出到 Qt GUI 应当仅发生在主线程中。 因此，本处理器\n# 被设计为接受一个已经设置好运行主线程的槽位函数。\n# 在本示例中，该函数接受一个已格式化的日志消息字符串\n# 参数，以及生成它的日志记录。 已格式化的字符串只是\n# 出于方便考虑 —— 你也可以在槽位函数本身以任意方式\n# 格式化字符串供输出。\n#\n# 你可以指定槽位函数执行任何你想要的 GUI 更新。 处理器\n# 并不知道或关心特定的 UI 元素。\n#\nclass QtHandler(logging.Handler):\ndef __init__(self, slotfunc, *args, **kwargs):\nsuper().__init__(*args, **kwargs)\nself.signaller = Signaller()\nself.signaller.signal.connect(slotfunc)\ndef emit(self, record):\ns = self.format(record)\nself.signaller.signal.emit(s, record)\n#\n# 本示例使用 QThreads，这意味着在 Python 层级中的线程\n# 将为像 \"Dummy-1\" 的名称。 下面的函数将获得当前线程的\n# Qt 名称。\n#\ndef ctname():\nreturn QtCore.QThread.currentThread().objectName()\n#\n# 用于生成随机的日志记录层级。\n#\nLEVELS = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL)\n#\n# 这个工作类代表在一个独立于主线程的线程中完成的工作。\n# 该线程开始执行工作的方式是通过按下一个连接到工作类中\n# 槽位的按钮。\n#\n# 因为 LogRecord 中默认的 threadName 值没有什么用处。\n# 我们增加了一个包含通过上述方式计算的 QThread 的\n# qThreadName，并在一个“额外”字典中传递该值并使用它\n# 将 LogRecord 更新为 QThread 名称。\n#\n# 这个示例工作类将顺序地输出消息，并以数秒的随机延时\n# 进行间隔。\n#\nclass Worker(QtCore.QObject):\n@Slot()\n\n|  | #\n# 信号需要被包含在 QObject 或其子类中以便能够正确地\n# 初始化\n#\nclass Signaller(QtCore.QObject):\nsignal = Signal(str, logging.LogRecord)\n#\n# 输出到 Qt GUI 应当仅发生在主线程中。 因此，本处理器\n# 被设计为接受一个已经设置好运行主线程的槽位函数。\n# 在本示例中，该函数接受一个已格式化的日志消息字符串\n# 参数，以及生成它的日志记录。 已格式化的字符串只是\n# 出于方便考虑 —— 你也可以在槽位函数本身以任意方式\n# 格式化字符串供输出。\n#\n# 你可以指定槽位函数执行任何你想要的 GUI 更新。 处理器\n# 并不知道或关心特定的 UI 元素。\n#\nclass QtHandler(logging.Handler):\ndef __init__(self, slotfunc, *args, **kwargs):\nsuper().__init__(*args, **kwargs)\nself.signaller = Signaller()\nself.signaller.signal.connect(slotfunc)\ndef emit(self, record):\ns = self.format(record)\nself.signaller.signal.emit(s, record)\n#\n# 本示例使用 QThreads，这意味着在 Python 层级中的线程\n# 将为像 \"Dummy-1\" 的名称。 下面的函数将获得当前线程的\n# Qt 名称。\n#\ndef ctname():\nreturn QtCore.QThread.currentThread().objectName()\n#\n# 用于生成随机的日志记录层级。\n#\nLEVELS = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL)\n#\n# 这个工作类代表在一个独立于主线程的线程中完成的工作。\n# 该线程开始执行工作的方式是通过按下一个连接到工作类中\n# 槽位的按钮。\n#\n# 因为 LogRecord 中默认的 threadName 值没有什么用处。\n# 我们增加了一个包含通过上述方式计算的 QThread 的\n# qThreadName，并在一个“额外”字典中传递该值并使用它\n# 将 LogRecord 更新为 QThread 名称。\n#\n# 这个示例工作类将顺序地输出消息，并以数秒的随机延时\n# 进行间隔。\n#\nclass Worker(QtCore.QObject):\n@Slot() |  |\n| --- | --- | --- |\n\ndef start(self):\nextra = {'qThreadName': ctname() }\nlogger.debug('Started work', extra=extra)\ni = 1\n# 让线程运行直到被中断。 这允许合理并且清晰的\n# 线程终结。\nwhile not QtCore.QThread.currentThread().isInterruptionRequested():\ndelay = 0.5 + random.random() * 2\ntime.sleep(delay)\ntry:\nif random.random() < 0.1:\nraise ValueError('Exception raised: %d' % i)\nelse:\nlevel = random.choice(LEVELS)\nlogger.log(level, 'Message after delay of %3.1f: %d', delay, i\nexcept ValueError as e:\nlogger.exception('Failed: %s', e, extra=extra)\ni += 1\n#\n# 为本专题指南示例实现一个简单的 UI。 其中包含：\n#\n# * 一个只读的文本编辑窗口用以显示已格式化的日志消息\n# * 一个按钮用以开始工作并在单独线程中记录日志内容\n# * 一个按钮用以以记录来自主线程的日志内容\n# * 一个按钮用以清空日志窗口\n#\nclass Window(QtWidgets.QWidget):\nCOLORS = {\nlogging.DEBUG: 'black',\nlogging.INFO: 'blue',\nlogging.WARNING: 'orange',\nlogging.ERROR: 'red',\nlogging.CRITICAL: 'purple',\n}\ndef __init__(self, app):\nsuper().__init__()\nself.app = app\nself.textedit = te = QtWidgets.QPlainTextEdit(self)\n# 设置系统平台所使用的默认等宽字体\nf = QtGui.QFont('nosuchfont')\nif hasattr(f, 'Monospace'):\nf.setStyleHint(f.Monospace)\nelse:\nf.setStyleHint(f.StyleHint.Monospace) # 针对 Qt6\nte.setFont(f)\nte.setReadOnly(True)\nPB = QtWidgets.QPushButton\nself.work_button = PB('Start background work', self)\nself.log_button = PB('Log a message at a random level', self)\nself.clear_button = PB('Clear log window', self)\nself.handler = h = QtHandler(self.update_status)\n# 记得在格式字符串中使用 qThreadName 而非 threadName。\nfs = '%(asctime)s %(qThreadName)-12s %(levelname)-8s %(message)s'\nformatter = logging.Formatter(fs)\nh.setFormatter(formatter)\nlogger.addHandler(h)\n# 设置当退出时终结 QThread\n\n|  | def start(self):\nextra = {'qThreadName': ctname() }\nlogger.debug('Started work', extra=extra)\ni = 1\n# 让线程运行直到被中断。 这允许合理并且清晰的\n# 线程终结。\nwhile not QtCore.QThread.currentThread().isInterruptionRequested():\ndelay = 0.5 + random.random() * 2\ntime.sleep(delay)\ntry:\nif random.random() < 0.1:\nraise ValueError('Exception raised: %d' % i)\nelse:\nlevel = random.choice(LEVELS)\nlogger.log(level, 'Message after delay of %3.1f: %d', delay, i\nexcept ValueError as e:\nlogger.exception('Failed: %s', e, extra=extra)\ni += 1\n#\n# 为本专题指南示例实现一个简单的 UI。 其中包含：\n#\n# * 一个只读的文本编辑窗口用以显示已格式化的日志消息\n# * 一个按钮用以开始工作并在单独线程中记录日志内容\n# * 一个按钮用以以记录来自主线程的日志内容\n# * 一个按钮用以清空日志窗口\n#\nclass Window(QtWidgets.QWidget):\nCOLORS = {\nlogging.DEBUG: 'black',\nlogging.INFO: 'blue',\nlogging.WARNING: 'orange',\nlogging.ERROR: 'red',\nlogging.CRITICAL: 'purple',\n}\ndef __init__(self, app):\nsuper().__init__()\nself.app = app\nself.textedit = te = QtWidgets.QPlainTextEdit(self)\n# 设置系统平台所使用的默认等宽字体\nf = QtGui.QFont('nosuchfont')\nif hasattr(f, 'Monospace'):\nf.setStyleHint(f.Monospace)\nelse:\nf.setStyleHint(f.StyleHint.Monospace) # 针对 Qt6\nte.setFont(f)\nte.setReadOnly(True)\nPB = QtWidgets.QPushButton\nself.work_button = PB('Start background work', self)\nself.log_button = PB('Log a message at a random level', self)\nself.clear_button = PB('Clear log window', self)\nself.handler = h = QtHandler(self.update_status)\n# 记得在格式字符串中使用 qThreadName 而非 threadName。\nfs = '%(asctime)s %(qThreadName)-12s %(levelname)-8s %(message)s'\nformatter = logging.Formatter(fs)\nh.setFormatter(formatter)\nlogger.addHandler(h)\n# 设置当退出时终结 QThread |  |\n| --- | --- | --- |\n\napp.aboutToQuit.connect(self.force_quit)\n# 对所有控件进行布局\nlayout = QtWidgets.QVBoxLayout(self)\nlayout.addWidget(te)\nlayout.addWidget(self.work_button)\nlayout.addWidget(self.log_button)\nlayout.addWidget(self.clear_button)\nself.setFixedSize(900, 400)\n# 连接非工作槽位和信号\nself.log_button.clicked.connect(self.manual_update)\nself.clear_button.clicked.connect(self.clear_display)\n# 启动一个新工作线程并为其连接槽位\nself.start_thread()\nself.work_button.clicked.connect(self.worker.start)\n# 一旦启动，该按钮应当被禁用\nself.work_button.clicked.connect(lambda : self.work_button.setEnabled(Fals\ndef start_thread(self):\nself.worker = Worker()\nself.worker_thread = QtCore.QThread()\nself.worker.setObjectName('Worker')\nself.worker_thread.setObjectName('WorkerThread') # 针对 qThreadName\nself.worker.moveToThread(self.worker_thread)\n# 这将在工作线程中启动一个事件循环\nself.worker_thread.start()\ndef kill_thread(self):\n# 告知工作线程停止运行，然后告知它退出并等待\n# 后续发生的事件\nself.worker_thread.requestInterruption()\nif self.worker_thread.isRunning():\nself.worker_thread.quit()\nself.worker_thread.wait()\nelse:\nprint('worker has already exited.')\ndef force_quit(self):\n# 当窗口被关闭时使用\nif self.worker_thread.isRunning():\nself.kill_thread()\n# 下面的函数更新 UI 并在主线程中运行因为槽位是在\n# 那里设置的\n@Slot(str, logging.LogRecord)\ndef update_status(self, status, record):\ncolor = self.COLORS.get(record.levelno, 'black')\ns = '<pre><font color=\"%s\">%s</font></pre>' % (color, status)\nself.textedit.appendHtml(s)\n@Slot()\ndef manual_update(self):\n# 此函数使用传入的已格式化消息，但也会使用来自\n# 记录的信息根据其严重程度（层级）以适当的颜色\n# 格式化消息。\nlevel = random.choice(LEVELS)\nextra = {'qThreadName': ctname() }\n\n|  | app.aboutToQuit.connect(self.force_quit)\n# 对所有控件进行布局\nlayout = QtWidgets.QVBoxLayout(self)\nlayout.addWidget(te)\nlayout.addWidget(self.work_button)\nlayout.addWidget(self.log_button)\nlayout.addWidget(self.clear_button)\nself.setFixedSize(900, 400)\n# 连接非工作槽位和信号\nself.log_button.clicked.connect(self.manual_update)\nself.clear_button.clicked.connect(self.clear_display)\n# 启动一个新工作线程并为其连接槽位\nself.start_thread()\nself.work_button.clicked.connect(self.worker.start)\n# 一旦启动，该按钮应当被禁用\nself.work_button.clicked.connect(lambda : self.work_button.setEnabled(Fals\ndef start_thread(self):\nself.worker = Worker()\nself.worker_thread = QtCore.QThread()\nself.worker.setObjectName('Worker')\nself.worker_thread.setObjectName('WorkerThread') # 针对 qThreadName\nself.worker.moveToThread(self.worker_thread)\n# 这将在工作线程中启动一个事件循环\nself.worker_thread.start()\ndef kill_thread(self):\n# 告知工作线程停止运行，然后告知它退出并等待\n# 后续发生的事件\nself.worker_thread.requestInterruption()\nif self.worker_thread.isRunning():\nself.worker_thread.quit()\nself.worker_thread.wait()\nelse:\nprint('worker has already exited.')\ndef force_quit(self):\n# 当窗口被关闭时使用\nif self.worker_thread.isRunning():\nself.kill_thread()\n# 下面的函数更新 UI 并在主线程中运行因为槽位是在\n# 那里设置的\n@Slot(str, logging.LogRecord)\ndef update_status(self, status, record):\ncolor = self.COLORS.get(record.levelno, 'black')\ns = '<pre><font color=\"%s\">%s</font></pre>' % (color, status)\nself.textedit.appendHtml(s)\n@Slot()\ndef manual_update(self):\n# 此函数使用传入的已格式化消息，但也会使用来自\n# 记录的信息根据其严重程度（层级）以适当的颜色\n# 格式化消息。\nlevel = random.choice(LEVELS)\nextra = {'qThreadName': ctname() } |  |\n| --- | --- | --- |\n\nlogger.log(level, 'Manually logged!', extra=extra)\n@Slot()\ndef clear_display(self):\nself.textedit.clear()\ndef main():\nQtCore.QThread.currentThread().setObjectName('MainThread')\nlogging.getLogger().setLevel(logging.DEBUG)\napp = QtWidgets.QApplication(sys.argv)\nexample = Window(app)\nexample.show()\nif hasattr(app, 'exec'):\nrc = app.exec()\nelse:\nrc = app.exec_()\nsys.exit(rc)\nif __name__=='__main__':\nmain()\n将日志记录到带有 RFC5424 支持的 syslog\n虽然 RFC 5424 在 2009 年就已发布，但大多数 syslog 服务器都默认被配置为使用更旧的 RFC\n3164，它发布于 2001 年。 当 logging 在 2003 年被加入 Python 时，它支持了当时（唯一存在\n的）较早版本的协议。 自从 RFC5424 发布后，因为它还未被广泛部署到 syslog 服务器上，因此\nSysLogHandler 的功能也没有被更新。\nRFC 5424 包括一些有用的特性例如对结构化数据的支持等，如果你想要能够将日志记录到带有该协\n议支持的 syslog 服务器上，你可以使用一个看起来像是这样的子类化处理器来实现:\nimport datetime\nimport logging.handlers\nimport re\nimport socket\nimport time\nclass SysLogHandler5424(logging.handlers.SysLogHandler):\ntz_offset = re.compile(r'([+-]\\d{2})(\\d{2})$')\nescaped = re.compile(r'([\\]\"\\\\])')\ndef __init__(self, *args, **kwargs):\nself.msgid = kwargs.pop('msgid', None)\nself.appname = kwargs.pop('appname', None)\nsuper().__init__(*args, **kwargs)\ndef format(self, record):\nversion = 1\nasctime = datetime.datetime.fromtimestamp(record.created).isoformat()\nm = self.tz_offset.match(time.strftime('%z'))\nhas_offset = False\nif m and time.timezone:\nhrs, mins = m.groups()\nif int(hrs) or int(mins):\nhas_offset = True\n\n|  | logger.log(level, 'Manually logged!', extra=extra)\n@Slot()\ndef clear_display(self):\nself.textedit.clear()\ndef main():\nQtCore.QThread.currentThread().setObjectName('MainThread')\nlogging.getLogger().setLevel(logging.DEBUG)\napp = QtWidgets.QApplication(sys.argv)\nexample = Window(app)\nexample.show()\nif hasattr(app, 'exec'):\nrc = app.exec()\nelse:\nrc = app.exec_()\nsys.exit(rc)\nif __name__=='__main__':\nmain() |  |  |\n| --- | --- | --- | --- |\n|  | 将日志记录到带有 RFC5424 支持的 syslog\n虽然 RFC 5424 在 2009 年就已发布，但大多数 syslog 服务器都默认被配置为使用更旧的 RFC\n3164，它发布于 2001 年。 当 logging 在 2003 年被加入 Python 时，它支持了当时（唯一存在\n的）较早版本的协议。 自从 RFC5424 发布后，因为它还未被广泛部署到 syslog 服务器上，因此\nSysLogHandler 的功能也没有被更新。\nRFC 5424 包括一些有用的特性例如对结构化数据的支持等，如果你想要能够将日志记录到带有该协\n议支持的 syslog 服务器上，你可以使用一个看起来像是这样的子类化处理器来实现: |  |  |\n|  | import datetime\nimport logging.handlers\nimport re\nimport socket\nimport time\nclass SysLogHandler5424(logging.handlers.SysLogHandler):\ntz_offset = re.compile(r'([+-]\\d{2})(\\d{2})$')\nescaped = re.compile(r'([\\]\"\\\\])')\ndef __init__(self, *args, **kwargs):\nself.msgid = kwargs.pop('msgid', None)\nself.appname = kwargs.pop('appname', None)\nsuper().__init__(*args, **kwargs)\ndef format(self, record):\nversion = 1\nasctime = datetime.datetime.fromtimestamp(record.created).isoformat()\nm = self.tz_offset.match(time.strftime('%z'))\nhas_offset = False\nif m and time.timezone:\nhrs, mins = m.groups()\nif int(hrs) or int(mins):\nhas_offset = True |  |  |\n\nif not has_offset:\nasctime += 'Z'\nelse:\nasctime += f'{hrs}:{mins}'\ntry:\nhostname = socket.gethostname()\nexcept Exception:\nhostname = '-'\nappname = self.appname or '-'\nprocid = record.process\nmsgid = '-'\nmsg = super().format(record)\nsdata = '-'\nif hasattr(record, 'structured_data'):\nsd = record.structured_data\n# 这应当是一个字典，其中的键为 SD-ID 而值则为\n# 将 PARAM-NAME 映射到 PARAM-VALUE 的字典\n# （请参阅 RFC了解其含义）\n# 这里没有错误检查 —— 它只是作为演示，你可以\n# 调整此代码以在生产环境中使用\nparts = []\ndef replacer(m):\ng = m.groups()\nreturn '\\\\' + g[0]\nfor sdid, dv in sd.items():\npart = f'[{sdid}'\nfor k, v in dv.items():\ns = str(v)\ns = self.escaped.sub(replacer, s)\npart += f' {k}=\"{s}\"'\npart += ']'\nparts.append(part)\nsdata = ''.join(parts)\nreturn f'{version} {asctime} {hostname} {appname} {procid} {msgid} {sdata}\n你需要熟悉 RFC 5424 才能完全理解上面的代码，你还可能会有稍加变化的的需求（例如你要如何将\n结构化数据记入日志）。 不管怎样，上面的代码应当根据你的特定需求来灵活调整。 通过上面的处\n理器，你可以使用类似这样的代码来传入结构化数据:\nsd = {\n'foo@12345': {'bar': 'baz', 'baz': 'bozz', 'fizz': r'buzz'},\n'foo@54321': {'rab': 'baz', 'zab': 'bozz', 'zzif': r'buzz'}\n}\nextra = {'structured_data': sd}\ni = 1\nlogger.debug('Message %d', i, extra=extra)\n如何将日志记录器作为输出流\n有时，你需要通过接口访问某个预期要写入到文件型对象第三方 API，但你希望将 API 的输出重定向\n到一个日志记录器。 你可以使用一个以文件类 API 来包装日志记录器的类。 下面是一个演示这样的\n类的简短脚本:\n\n|  | if not has_offset:\nasctime += 'Z'\nelse:\nasctime += f'{hrs}:{mins}'\ntry:\nhostname = socket.gethostname()\nexcept Exception:\nhostname = '-'\nappname = self.appname or '-'\nprocid = record.process\nmsgid = '-'\nmsg = super().format(record)\nsdata = '-'\nif hasattr(record, 'structured_data'):\nsd = record.structured_data\n# 这应当是一个字典，其中的键为 SD-ID 而值则为\n# 将 PARAM-NAME 映射到 PARAM-VALUE 的字典\n# （请参阅 RFC了解其含义）\n# 这里没有错误检查 —— 它只是作为演示，你可以\n# 调整此代码以在生产环境中使用\nparts = []\ndef replacer(m):\ng = m.groups()\nreturn '\\\\' + g[0]\nfor sdid, dv in sd.items():\npart = f'[{sdid}'\nfor k, v in dv.items():\ns = str(v)\ns = self.escaped.sub(replacer, s)\npart += f' {k}=\"{s}\"'\npart += ']'\nparts.append(part)\nsdata = ''.join(parts)\nreturn f'{version} {asctime} {hostname} {appname} {procid} {msgid} {sdata} |  |\n| --- | --- | --- |\n|  | 你需要熟悉 RFC 5424 才能完全理解上面的代码，你还可能会有稍加变化的的需求（例如你要如何将\n结构化数据记入日志）。 不管怎样，上面的代码应当根据你的特定需求来灵活调整。 通过上面的处\n理器，你可以使用类似这样的代码来传入结构化数据: |  |\n|  | sd = {\n'foo@12345': {'bar': 'baz', 'baz': 'bozz', 'fizz': r'buzz'},\n'foo@54321': {'rab': 'baz', 'zab': 'bozz', 'zzif': r'buzz'}\n}\nextra = {'structured_data': sd}\ni = 1\nlogger.debug('Message %d', i, extra=extra) |  |\n|  | 如何将日志记录器作为输出流\n有时，你需要通过接口访问某个预期要写入到文件型对象第三方 API，但你希望将 API 的输出重定向\n到一个日志记录器。 你可以使用一个以文件类 API 来包装日志记录器的类。 下面是一个演示这样的\n类的简短脚本: |  |\n\nimport logging\nclass LoggerWriter:\ndef __init__(self, logger, level):\nself.logger = logger\nself.level = level\ndef write(self, message):\nif message != '\\n': # 避免打印空白行，如果你希望如此\nself.logger.log(self.level, message)\ndef flush(self):\n# 实际上不做任何事，但对文件型对象来说应当提供\n# —— 因此根据你的情况作为可选项\npass\ndef close(self):\n# 实际上不做任何事，但对文件型对象来说应当提供\n# —— 因此根据你的情况作为可选项。 你可能会希望\n# 设置一个旗标以便后续的写入调用引发异常\npass\ndef main():\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger('demo')\ninfo_fp = LoggerWriter(logger, logging.INFO)\ndebug_fp = LoggerWriter(logger, logging.DEBUG)\nprint('An INFO message', file=info_fp)\nprint('A DEBUG message', file=debug_fp)\nif __name__ == \"__main__\":\nmain()\n当此脚本运行时，它将打印\nINFO:demo:An INFO message\nDEBUG:demo:A DEBUG message\n你还可以使用 LoggerWriter 通过下面这样的做法来重定向 sys.stdout 和 sys.stderr:\nimport sys\nsys.stdout = LoggerWriter(logger, logging.INFO)\nsys.stderr = LoggerWriter(logger, logging.WARNING)\n你应当在根据需要配置日志记录 之后 再这样做。 在上面的例子中，basicConfig() 调用执行了此\n操作（在 sys.stderr 被一个 LoggerWriter 实例覆盖 之前 使用它的值）。 然后，你将得到这样\n的结果:\n>>> print('Foo')\nINFO:demo:Foo\n>>> print('Bar', file=sys.stderr)\nWARNING:demo:Bar\n>>>\n\n|  | import logging\nclass LoggerWriter:\ndef __init__(self, logger, level):\nself.logger = logger\nself.level = level\ndef write(self, message):\nif message != '\\n': # 避免打印空白行，如果你希望如此\nself.logger.log(self.level, message)\ndef flush(self):\n# 实际上不做任何事，但对文件型对象来说应当提供\n# —— 因此根据你的情况作为可选项\npass\ndef close(self):\n# 实际上不做任何事，但对文件型对象来说应当提供\n# —— 因此根据你的情况作为可选项。 你可能会希望\n# 设置一个旗标以便后续的写入调用引发异常\npass\ndef main():\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger('demo')\ninfo_fp = LoggerWriter(logger, logging.INFO)\ndebug_fp = LoggerWriter(logger, logging.DEBUG)\nprint('An INFO message', file=info_fp)\nprint('A DEBUG message', file=debug_fp)\nif __name__ == \"__main__\":\nmain() |  |\n| --- | --- | --- |\n|  | 当此脚本运行时，它将打印 |  |\n|  | INFO:demo:An INFO message\nDEBUG:demo:A DEBUG message |  |\n|  | 你还可以使用 LoggerWriter 通过下面这样的做法来重定向 sys.stdout 和 sys.stderr: |  |\n|  | import sys\nsys.stdout = LoggerWriter(logger, logging.INFO)\nsys.stderr = LoggerWriter(logger, logging.WARNING) |  |\n|  | 你应当在根据需要配置日志记录 之后 再这样做。 在上面的例子中，basicConfig() 调用执行了此\n操作（在 sys.stderr 被一个 LoggerWriter 实例覆盖 之前 使用它的值）。 然后，你将得到这样\n的结果: |  |\n|  | >>> print('Foo')\nINFO:demo:Foo\n>>> print('Bar', file=sys.stderr)\nWARNING:demo:Bar\n>>> |  |\n|  |  |  |\n\n当然，上面的例子是按照 basicConfig() 所使用的格式来显示输出的，但你也可以在配置日志记录\n时使用其他的格式。\n请注意当使用上面的预置方案时，你将在一定程度上受到你所拦截的写入调用的缓冲和顺序的控\n制。 例如，在使用上述 LoggerWriter 的定义的情况下，如果你使用代码段\nsys.stderr = LoggerWriter(logger, logging.WARNING)\n1 / 0\n则运行该脚本的结果为\nWARNING:demo:Traceback (most recent call last):\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/test.py\", line 53, in <mod\nWARNING:demo:\nWARNING:demo:main()\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/test.py\", line 49, in main\nWARNING:demo:\nWARNING:demo:1 / 0\nWARNING:demo:ZeroDivisionError\nWARNING:demo::\nWARNING:demo:division by zero\n如你所见，这个输出并不很理想。 那是因为下层的写入 sys.stderr 的代码会执行多次写入，每次\n都将产生一条单独的日志记录行（例如，上面的最后三行）。 要避免这个问题，你需要使用缓冲并\n且只在看到换行符时才输出日志记录行。 让我们使用一个更好些的 LoggerWriter 实现：\nclass BufferingLoggerWriter(LoggerWriter):\ndef __init__(self, logger, level):\nsuper().__init__(logger, level)\nself.buffer = ''\ndef write(self, message):\nif '\\n' not in message:\nself.buffer += message\nelse:\nparts = message.split('\\n')\nif self.buffer:\ns = self.buffer + parts.pop(0)\nself.logger.log(self.level, s)\nself.buffer = parts.pop()\nfor part in parts:\nself.logger.log(self.level, part)\n这段代码对内容进行了缓冲直至遇到换行符，然后将完整的行写入日志记录。 通过这种方式，你将\n得到更好的输出:\nWARNING:demo:Traceback (most recent call last):\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/main.py\", line 55, in <mod\nWARNING:demo: main()\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/main.py\", line 52, in main\n\n|  | 当然，上面的例子是按照 basicConfig() 所使用的格式来显示输出的，但你也可以在配置日志记录\n时使用其他的格式。\n请注意当使用上面的预置方案时，你将在一定程度上受到你所拦截的写入调用的缓冲和顺序的控\n制。 例如，在使用上述 LoggerWriter 的定义的情况下，如果你使用代码段 |  |  |\n| --- | --- | --- | --- |\n|  | sys.stderr = LoggerWriter(logger, logging.WARNING)\n1 / 0 |  |  |\n|  | 则运行该脚本的结果为 |  |  |\n|  | WARNING:demo:Traceback (most recent call last):\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/test.py\", line 53, in <mod\nWARNING:demo:\nWARNING:demo:main()\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/test.py\", line 49, in main\nWARNING:demo:\nWARNING:demo:1 / 0\nWARNING:demo:ZeroDivisionError\nWARNING:demo::\nWARNING:demo:division by zero |  |  |\n|  | 如你所见，这个输出并不很理想。 那是因为下层的写入 sys.stderr 的代码会执行多次写入，每次\n都将产生一条单独的日志记录行（例如，上面的最后三行）。 要避免这个问题，你需要使用缓冲并\n且只在看到换行符时才输出日志记录行。 让我们使用一个更好些的 LoggerWriter 实现： |  |  |\n|  | class BufferingLoggerWriter(LoggerWriter):\ndef __init__(self, logger, level):\nsuper().__init__(logger, level)\nself.buffer = ''\ndef write(self, message):\nif '\\n' not in message:\nself.buffer += message\nelse:\nparts = message.split('\\n')\nif self.buffer:\ns = self.buffer + parts.pop(0)\nself.logger.log(self.level, s)\nself.buffer = parts.pop()\nfor part in parts:\nself.logger.log(self.level, part) |  |  |\n|  | 这段代码对内容进行了缓冲直至遇到换行符，然后将完整的行写入日志记录。 通过这种方式，你将\n得到更好的输出: |  |  |\n|  | WARNING:demo:Traceback (most recent call last):\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/main.py\", line 55, in <mod\nWARNING:demo: main()\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/main.py\", line 52, in main |  |  |\n\nWARNING:demo: 1/0\nWARNING:demo:ZeroDivisionError: division by zero\n如何统一地处理日志记录输出中的换行符\n通常，被记录的消息（输出到控制台或文件）是由单行文本组成的。 不过，在某些时候也会需要处\n理具有多行的消息 —— 不论是因为日志格式字符串包含换行符，还是因为被记录的数据包含换行\n符。 如果你想以统一的方式处理此类消息，使得被记录的消息中的每一行格式看起来保持一致就像\n它是被单独记录的，你可以使用处理器混入类做到这一点，如下面的代码片段所示：\n# 假定这是在一个模块的 mymixins.py 中\nimport copy\nclass MultilineMixin:\ndef emit(self, record):\ns = record.getMessage()\nif '\\n' not in s:\nsuper().emit(record)\nelse:\nlines = s.splitlines()\nrec = copy.copy(record)\nrec.args = None\nfor line in lines:\nrec.msg = line\nsuper().emit(rec)\n你可以像下面的脚本一样使用该混入类：\nimport logging\nfrom mymixins import MultilineMixin\nlogger = logging.getLogger(__name__)\nclass StreamHandler(MultilineMixin, logging.StreamHandler):\npass\nif __name__ == '__main__':\nlogging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(levelname)-9s %\nhandlers = [StreamHandler()])\nlogger.debug('Single line')\nlogger.debug('Multiple lines:\\nfool me once ...')\nlogger.debug('Another single line')\nlogger.debug('Multiple lines:\\n%s', 'fool me ...\\ncan\\'t get fooled again')\n在运行时，这个脚本将打印如下内容：\n2025-07-02 13:54:47,234 DEBUG Single line\n2025-07-02 13:54:47,234 DEBUG Multiple lines:\n2025-07-02 13:54:47,234 DEBUG fool me once ...\n2025-07-02 13:54:47,234 DEBUG Another single line\n2025-07-02 13:54:47,234 DEBUG Multiple lines:\n2025-07-02 13:54:47,234 DEBUG fool me ...\n2025-07-02 13:54:47,234 DEBUG can't get fooled again\n\n|  | WARNING:demo: 1/0\nWARNING:demo:ZeroDivisionError: division by zero |  |  |\n| --- | --- | --- | --- |\n|  | 如何统一地处理日志记录输出中的换行符\n通常，被记录的消息（输出到控制台或文件）是由单行文本组成的。 不过，在某些时候也会需要处\n理具有多行的消息 —— 不论是因为日志格式字符串包含换行符，还是因为被记录的数据包含换行 |  |  |\n|  | 符。 如果你想以统一的方式处理此类消息，使得被记录的消息中的每一行格式看起来保持一致就像\n它是被单独记录的，你可以使用处理器混入类做到这一点，如下面的代码片段所示： |  |  |\n|  | # 假定这是在一个模块的 mymixins.py 中\nimport copy\nclass MultilineMixin:\ndef emit(self, record):\ns = record.getMessage()\nif '\\n' not in s:\nsuper().emit(record)\nelse:\nlines = s.splitlines()\nrec = copy.copy(record)\nrec.args = None\nfor line in lines:\nrec.msg = line\nsuper().emit(rec) |  |  |\n|  | 你可以像下面的脚本一样使用该混入类： |  |  |\n|  | import logging\nfrom mymixins import MultilineMixin\nlogger = logging.getLogger(__name__)\nclass StreamHandler(MultilineMixin, logging.StreamHandler):\npass\nif __name__ == '__main__':\nlogging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(levelname)-9s %\nhandlers = [StreamHandler()])\nlogger.debug('Single line')\nlogger.debug('Multiple lines:\\nfool me once ...')\nlogger.debug('Another single line')\nlogger.debug('Multiple lines:\\n%s', 'fool me ...\\ncan\\'t get fooled again') |  |  |\n|  | 在运行时，这个脚本将打印如下内容： |  |  |\n|  | 2025-07-02 13:54:47,234 DEBUG Single line\n2025-07-02 13:54:47,234 DEBUG Multiple lines:\n2025-07-02 13:54:47,234 DEBUG fool me once ...\n2025-07-02 13:54:47,234 DEBUG Another single line\n2025-07-02 13:54:47,234 DEBUG Multiple lines:\n2025-07-02 13:54:47,234 DEBUG fool me ...\n2025-07-02 13:54:47,234 DEBUG can't get fooled again |  |  |\n|  |  |  |  |\n\n另一方面，如果你担心 日志注入，你可以使用对换行符进行转义的格式化器，就像下面的例子：\nimport logging\nlogger = logging.getLogger(__name__)\nclass EscapingFormatter(logging.Formatter):\ndef format(self, record):\ns = super().format(record)\nreturn s.replace('\\n', r'\\n')\nif __name__ == '__main__':\nh = logging.StreamHandler()\nh.setFormatter(EscapingFormatter('%(asctime)s %(levelname)-9s %(message)s'))\nlogging.basicConfig(level=logging.DEBUG, handlers = [h])\nlogger.debug('Single line')\nlogger.debug('Multiple lines:\\nfool me once ...')\nlogger.debug('Another single line')\nlogger.debug('Multiple lines:\\n%s', 'fool me ...\\ncan\\'t get fooled again')\n当然，你可以使用任何对你来说最合适的转义方案。 在运行时，这个脚本将会产生这样的输出：\n2025-07-09 06:47:33,783 DEBUG Single line\n2025-07-09 06:47:33,783 DEBUG Multiple lines:\\nfool me once ...\n2025-07-09 06:47:33,783 DEBUG Another single line\n2025-07-09 06:47:33,783 DEBUG Multiple lines:\\nfool me ...\\ncan't get fooled a\n转义行为不能是标准库默认设置，因为它会破坏向下兼容性。\n理应避免的用法\n前几节虽介绍了几种方案，描述了可能需要处理的操作，但值得一提的是，有些用法是 没有好处\n的，大多数情况下应该避免使用。下面几节的顺序不分先后。\n多次打开同一个日志文件\n因会导致 \"文件被其他进程占用 \"错误，所以在 Windows 中一般无法多次打开同一个文件。但在\nPOSIX 平台中，多次打开同一个文件不会报任何错误。这种操作可能是意外发生的，比如：\n多次添加指向同一文件的 handler（比如通过复制/粘贴，或忘记修改）。\n打开两个貌似不同（文件名不一样）的文件，但一个是另一个的符号链接，所以其实是同一个文\n件。\n进程 fork，然后父进程和子进程都有对同一文件的引用。 例如，这可能是通过使用\nmultiprocessing 模块实现的。\n在大多数情况下，多次打开同一个文件 貌似 一切正常，但实际会导致很多问题。\n由于多个线程或进程会尝试写入同一个文件，日志输出可能会出现乱码。尽管日志对象可以防止\n多个线程同时使用同一个 handler 实例，但如果两个不同的线程使用不同的 handler 实例同时写\n入文件，而这两个 handler 又恰好指向同一个文件，那么就失去了这种防护。\n\n|  | 另一方面，如果你担心 日志注入，你可以使用对换行符进行转义的格式化器，就像下面的例子： |  |  |\n| --- | --- | --- | --- |\n|  | import logging\nlogger = logging.getLogger(__name__)\nclass EscapingFormatter(logging.Formatter):\ndef format(self, record):\ns = super().format(record)\nreturn s.replace('\\n', r'\\n')\nif __name__ == '__main__':\nh = logging.StreamHandler()\nh.setFormatter(EscapingFormatter('%(asctime)s %(levelname)-9s %(message)s'))\nlogging.basicConfig(level=logging.DEBUG, handlers = [h])\nlogger.debug('Single line')\nlogger.debug('Multiple lines:\\nfool me once ...')\nlogger.debug('Another single line')\nlogger.debug('Multiple lines:\\n%s', 'fool me ...\\ncan\\'t get fooled again') |  |  |\n|  | 当然，你可以使用任何对你来说最合适的转义方案。 在运行时，这个脚本将会产生这样的输出： |  |  |\n|  | 2025-07-09 06:47:33,783 DEBUG Single line\n2025-07-09 06:47:33,783 DEBUG Multiple lines:\\nfool me once ...\n2025-07-09 06:47:33,783 DEBUG Another single line\n2025-07-09 06:47:33,783 DEBUG Multiple lines:\\nfool me ...\\ncan't get fooled a |  |  |\n|  | 转义行为不能是标准库默认设置，因为它会破坏向下兼容性。\n理应避免的用法\n前几节虽介绍了几种方案，描述了可能需要处理的操作，但值得一提的是，有些用法是 没有好处\n的，大多数情况下应该避免使用。下面几节的顺序不分先后。\n多次打开同一个日志文件\n因会导致 \"文件被其他进程占用 \"错误，所以在 Windows 中一般无法多次打开同一个文件。但在\nPOSIX 平台中，多次打开同一个文件不会报任何错误。这种操作可能是意外发生的，比如：\n多次添加指向同一文件的 handler（比如通过复制/粘贴，或忘记修改）。\n打开两个貌似不同（文件名不一样）的文件，但一个是另一个的符号链接，所以其实是同一个文\n件。\n进程 fork，然后父进程和子进程都有对同一文件的引用。 例如，这可能是通过使用\nmultiprocessing 模块实现的。\n在大多数情况下，多次打开同一个文件 貌似 一切正常，但实际会导致很多问题。\n由于多个线程或进程会尝试写入同一个文件，日志输出可能会出现乱码。尽管日志对象可以防止\n多个线程同时使用同一个 handler 实例，但如果两个不同的线程使用不同的 handler 实例同时写\n入文件，而这两个 handler 又恰好指向同一个文件，那么就失去了这种防护。 |  |  |\n\n尝试删除文件（例如在轮换日志文件时）会静默地失败，因为存在另一个指向它的引用。 这可能\n导致混乱并浪费调试时间 —— 日志条目会出现在意想不到的地方，或者完全丢失。 或者会有应\n当移除的文件仍然保持存在，文件还会在已经设置了基于文件大小的轮换的情况下仍然增长到预\n料之外的大小。\n请用 从多个进程记录至单个文件 中介绍的技术来避免上述问题。\n将日志对象用作属性或传递参数\n虽然特殊情况下可能有必要如此，但一般来说没有意义，因为日志是单实例对象。代码总是可以通\n过 logging.getLogger(name) 用名称访问一个已有的日志对象实例，因此将实例作为参数来传\n递，或作为属性留存，都是毫无意义的。请注意，在其他语言中，如 Java 和 C#，日志对象通常是\n静态类属性。但在 Python 中是没有意义的，因为软件拆分的单位是模块（而不是类）。\n为库中的日志记录器添加 NullHandler 以外的处理器\n通过添加 handler、formatter 和 filter 来配置日志，这是应用程序开发人员的责任，而不是库开发人\n员该做的。如果正在维护一个库，请确保不要向任何日志对象添加 NullHandler 实例以外的\nhandler。\n创建大量的日志对象\n日志是单实例对象，在代码执行过程中不会被释放，因此创建大量的日志对象会占用很多内存，而\n这些内存又不能被释放。与其为每个文件或网络连接创建一个日志，还不如利用 已有机制 将上下文\n信息传给自定义日志对象，并将创建的日志对象限制在应用程序内的指定区域（通常是模块，但偶\n尔会再精细些）使用。\n其他资源\n参见:\n模块 logging\n日志记录模块的 API 参考。\nlogging.config 模块\n日志记录模块的配置 API 。\nlogging.handlers 模块\n日志记录模块附带的有用处理器。\n基础教程\n进阶教程\n\n| 尝试删除文件（例如在轮换日志文件时）会静默地失败，因为存在另一个指向它的引用。 这可能\n导致混乱并浪费调试时间 —— 日志条目会出现在意想不到的地方，或者完全丢失。 或者会有应\n当移除的文件仍然保持存在，文件还会在已经设置了基于文件大小的轮换的情况下仍然增长到预\n料之外的大小。\n请用 从多个进程记录至单个文件 中介绍的技术来避免上述问题。\n将日志对象用作属性或传递参数\n虽然特殊情况下可能有必要如此，但一般来说没有意义，因为日志是单实例对象。代码总是可以通\n过 logging.getLogger(name) 用名称访问一个已有的日志对象实例，因此将实例作为参数来传\n递，或作为属性留存，都是毫无意义的。请注意，在其他语言中，如 Java 和 C#，日志对象通常是\n静态类属性。但在 Python 中是没有意义的，因为软件拆分的单位是模块（而不是类）。\n为库中的日志记录器添加 NullHandler 以外的处理器\n通过添加 handler、formatter 和 filter 来配置日志，这是应用程序开发人员的责任，而不是库开发人\n员该做的。如果正在维护一个库，请确保不要向任何日志对象添加 NullHandler 实例以外的\nhandler。\n创建大量的日志对象\n日志是单实例对象，在代码执行过程中不会被释放，因此创建大量的日志对象会占用很多内存，而\n这些内存又不能被释放。与其为每个文件或网络连接创建一个日志，还不如利用 已有机制 将上下文\n信息传给自定义日志对象，并将创建的日志对象限制在应用程序内的指定区域（通常是模块，但偶\n尔会再精细些）使用。\n其他资源 |\n| --- |\n| 参见:\n模块 logging\n日志记录模块的 API 参考。\nlogging.config 模块\n日志记录模块的配置 API 。\nlogging.handlers 模块\n日志记录模块附带的有用处理器。\n基础教程\n进阶教程 |", "metadata": {"title": "09_日志专题手册", "source": "md_docs\\python_howto_md\\09_日志专题手册.md", "doc_type": "指南", "language": "中文", "doc_id": "e72209fa"}}
{"doc_id": "1d9d579e", "content": "正则表达式指南\n作者: A.M. Kuchling <amk@amk.ca>\n摘要\n本文是关于在 Python 中通过 re 模块使用正则表达式的入门教程。它提供了比“标准库参考”的相\n关章节更平易的介绍。\n引言\n正则表达式（Regular expressions，也叫 REs、 regexs 或 regex patterns），本质上是嵌入 Python\n内部并通过 re 模块提供的一种微小的、高度专业化的编程语言。使用这种小语言，你可以为想要匹\n配的可能字符串编写规则；这些字符串可能是英文句子、邮箱地址、TeX 命令或任何你喜欢的内容。\n然后，你可以提出诸如“此字符串是否与表达式匹配？”、“字符串中是否存在表达式的匹配项？”之类\n的问题。你还可以用正则来修改字符串，或以各种方式将其拆分。\n正则表达式会被编译成一系列字节码，然后由 C 语言编写的匹配引擎执行。对于高级用途，可能有\n必要特别注意引擎将如何执行一个给定的正则，并以某种方式写入正则，以生成运行更快的字节\n码。本文不涉及优化问题，因为这要求你对正则引擎的匹配过程有很好的了解。\n正则表达式语言相对较小且受限，因此并非所有可能的字符串处理任务都可以使用正则表达式完\n成。有些任务尽管 可以 用正则表达式来完成，但表达式会变得非常复杂。 这些情况下，最好通过编\n写 Python 代码来进行处理。 也许 Python 代码会比精心设计的正则表达式慢，但它可能更容易理\n解。\n简单正则\n让我们从最简单的正则表达式开始吧。由于正则表达式是用来操作字符串的，我们将从最常见的任\n务开始：匹配字符。\n关于正则表达式背后的计算机科学的详细解释（确定性和非确定性有限自动机），你可以参考几乎\n所有关于编写编译器的教科书。\n匹配字符\n大多数字母和符号都会简单地匹配自身。例如，正则表达式 test 将会精确地匹配到 test 。（你可\n以启用不区分大小写模式，让这个正则也匹配 Test 或 TEST ，稍后会详细介绍。）\n但该规则有例外。有些字符是特殊的 元字符（metacharacters），并不匹配自身。事实上，它们表\n示匹配一些非常规的内容，或者通过重复它们或改变它们的含义来影响正则的其他部分。本文的大\n部分内容都致力于讨论各种元字符及其作用。\n\n| 正则表达式指南\n作者: A.M. Kuchling <amk@amk.ca> |\n| --- |\n| 摘要\n本文是关于在 Python 中通过 re 模块使用正则表达式的入门教程。它提供了比“标准库参考”的相\n关章节更平易的介绍。 |\n| 引言\n正则表达式（Regular expressions，也叫 REs、 regexs 或 regex patterns），本质上是嵌入 Python\n内部并通过 re 模块提供的一种微小的、高度专业化的编程语言。使用这种小语言，你可以为想要匹\n配的可能字符串编写规则；这些字符串可能是英文句子、邮箱地址、TeX 命令或任何你喜欢的内容。\n然后，你可以提出诸如“此字符串是否与表达式匹配？”、“字符串中是否存在表达式的匹配项？”之类\n的问题。你还可以用正则来修改字符串，或以各种方式将其拆分。\n正则表达式会被编译成一系列字节码，然后由 C 语言编写的匹配引擎执行。对于高级用途，可能有\n必要特别注意引擎将如何执行一个给定的正则，并以某种方式写入正则，以生成运行更快的字节\n码。本文不涉及优化问题，因为这要求你对正则引擎的匹配过程有很好的了解。\n正则表达式语言相对较小且受限，因此并非所有可能的字符串处理任务都可以使用正则表达式完\n成。有些任务尽管 可以 用正则表达式来完成，但表达式会变得非常复杂。 这些情况下，最好通过编\n写 Python 代码来进行处理。 也许 Python 代码会比精心设计的正则表达式慢，但它可能更容易理\n解。\n简单正则\n让我们从最简单的正则表达式开始吧。由于正则表达式是用来操作字符串的，我们将从最常见的任\n务开始：匹配字符。\n关于正则表达式背后的计算机科学的详细解释（确定性和非确定性有限自动机），你可以参考几乎\n所有关于编写编译器的教科书。\n匹配字符\n大多数字母和符号都会简单地匹配自身。例如，正则表达式 test 将会精确地匹配到 test 。（你可\n以启用不区分大小写模式，让这个正则也匹配 Test 或 TEST ，稍后会详细介绍。）\n但该规则有例外。有些字符是特殊的 元字符（metacharacters），并不匹配自身。事实上，它们表\n示匹配一些非常规的内容，或者通过重复它们或改变它们的含义来影响正则的其他部分。本文的大\n部分内容都致力于讨论各种元字符及其作用。 |\n\n这是元字符的完整列表。它们的含义将在本 HOWTO 的其余部分进行讨论。\n. ^ $ * + ? { } [ ] \\ | ( )\n首先介绍的元字符是 [ 和 ] 。这两个元字符用于指定一个字符类，也就是你希望匹配的字符的一个\n集合。这些字符可以单独地列出，也可以用字符范围来表示（给出两个字符并用 '-' 分隔）。例\n如，[abc] 将匹配 a、b、c 之中的任意一个字符；这与 [a-c] 相同，后者使用一个范围来表达相\n同的字符集合。如果只想匹配小写字母，则正则表达式将是 [a-z] 。\n元字符 (除了 \\) 在字符类中是不起作用的。 例如，[akm$] 将会匹配以下任一字符 'a', 'k', 'm' 或\n'$'；'$' 通常是一个元字符，但在一个字符类中它的特殊性被消除了。\n你可以通过对集合 取反 来匹配字符类中未列出的字符。方法是把 '^' 放在字符类的最开头。 例\n如，[^5] 将匹配除 '5' 之外的任何字符。 如果插入符出现在字符类的其他位置，则它没有特殊含\n义。 例如：[5^] 将匹配 '5' 或 '^'。\n也许最重要的元字符是反斜杠，\\ 。 与 Python 字符串字面量一样，反斜杠后面可以跟各种字符来\n表示各种特殊序列。它还用于转义元字符，以便可以在表达式中匹配元字符本身。例如，如果需要\n匹配一个 [ 或 \\ ，可以在其前面加上一个反斜杠来消除它们的特殊含义：\\[ 或 \\\\ 。\n一些以 '\\' 开头的特殊序列表示预定义的字符集合，这些字符集通常很有用，例如数字集合、字母\n集合或非空白字符集合。\n让我们举一个例子：\\w 匹配任何字母数字字符。 如果正则表达式以 bytes 类型表示，\\w 相当于字\n符类 [a-zA-Z0-9_] 。如果正则表达式是 str 类型，\\w 将匹配由 unicodedata 模块提供的 Unicode\n数据库中标记为字母的所有字符。 通过在编译正则表达式时提供 re.ASCII 标志，可以在 str 表达\n式中使用较为狭窄的 \\w 定义。\n以下为特殊序列的不完全列表。 有关 Unicode 字符串正则表达式的序列和扩展类定义的完整列表，\n参见标准库参考中 正则表达式语法 的最后一部分 。通常，Unicode 版本的字符类会匹配 Unicode\n数据库的相应类别中的任何字符。\n\\d\n匹配任何十进制数字，等价于字符类 [0-9] 。\n\\D\n匹配任何非数字字符，等价于字符类 [^0-9] 。\n\\s\n匹配任何空白字符，等价于字符类 [ \\t\\n\\r\\f\\v] 。\n\\S\n匹配任何非空白字符，等价于字符类 [^ \\t\\n\\r\\f\\v] 。\n\\w\n匹配任何字母与数字字符，等价于字符类 [a-zA-Z0-9_] 。\n\\W\n\n|  | 这是元字符的完整列表。它们的含义将在本 HOWTO 的其余部分进行讨论。 |  |\n| --- | --- | --- |\n|  | . ^ $ * + ? { } [ ] \\ | ( ) |  |\n|  | 首先介绍的元字符是 [ 和 ] 。这两个元字符用于指定一个字符类，也就是你希望匹配的字符的一个\n集合。这些字符可以单独地列出，也可以用字符范围来表示（给出两个字符并用 '-' 分隔）。例\n如，[abc] 将匹配 a、b、c 之中的任意一个字符；这与 [a-c] 相同，后者使用一个范围来表达相\n同的字符集合。如果只想匹配小写字母，则正则表达式将是 [a-z] 。\n元字符 (除了 \\) 在字符类中是不起作用的。 例如，[akm$] 将会匹配以下任一字符 'a', 'k', 'm' 或\n'$'；'$' 通常是一个元字符，但在一个字符类中它的特殊性被消除了。\n你可以通过对集合 取反 来匹配字符类中未列出的字符。方法是把 '^' 放在字符类的最开头。 例\n如，[^5] 将匹配除 '5' 之外的任何字符。 如果插入符出现在字符类的其他位置，则它没有特殊含\n义。 例如：[5^] 将匹配 '5' 或 '^'。\n也许最重要的元字符是反斜杠，\\ 。 与 Python 字符串字面量一样，反斜杠后面可以跟各种字符来\n表示各种特殊序列。它还用于转义元字符，以便可以在表达式中匹配元字符本身。例如，如果需要\n匹配一个 [ 或 \\ ，可以在其前面加上一个反斜杠来消除它们的特殊含义：\\[ 或 \\\\ 。\n一些以 '\\' 开头的特殊序列表示预定义的字符集合，这些字符集通常很有用，例如数字集合、字母\n集合或非空白字符集合。\n让我们举一个例子：\\w 匹配任何字母数字字符。 如果正则表达式以 bytes 类型表示，\\w 相当于字\n符类 [a-zA-Z0-9_] 。如果正则表达式是 str 类型，\\w 将匹配由 unicodedata 模块提供的 Unicode\n数据库中标记为字母的所有字符。 通过在编译正则表达式时提供 re.ASCII 标志，可以在 str 表达\n式中使用较为狭窄的 \\w 定义。\n以下为特殊序列的不完全列表。 有关 Unicode 字符串正则表达式的序列和扩展类定义的完整列表，\n参见标准库参考中 正则表达式语法 的最后一部分 。通常，Unicode 版本的字符类会匹配 Unicode\n数据库的相应类别中的任何字符。\n\\d\n匹配任何十进制数字，等价于字符类 [0-9] 。\n\\D\n匹配任何非数字字符，等价于字符类 [^0-9] 。\n\\s\n匹配任何空白字符，等价于字符类 [ \\t\\n\\r\\f\\v] 。\n\\S\n匹配任何非空白字符，等价于字符类 [^ \\t\\n\\r\\f\\v] 。\n\\w\n匹配任何字母与数字字符，等价于字符类 [a-zA-Z0-9_] 。\n\\W |  |\n\n匹配任何非字母与数字字符，等价于字符类 [^a-zA-Z0-9_] 。\n这些序列可以包含在字符类中。 例如，[\\s,.] 是一个匹配任何空白字符、',' 或 '.' 的字符类。\n本节的最后一个元字符是 . 。 它匹配除换行符之外的任何字符，并且有一个可选模式（ re.DOTALL\n），在该模式下它甚至可以匹配换行符。 . 通常用于你想匹配“任何字符”的场景。\n重复\n能够匹配各种各样的字符集合是正则表达式可以做到的第一件事，而这是字符串方法所不能做到\n的。但是，如果正则表达式就只有这么一个附加功能，它很难说的上有多大优势。另一个功能是，\n你可以指定正则的某部分必须重复一定的次数。\n我们先来说说重复元字符 * 。 * 并不是匹配一个字面字符 '*' 。实际上，它指定前一个字符可以匹\n配零次或更多次，而不是只匹配一次。\n例如，ca*t 将匹配 'ct' （ 0 个 'a' ）、'cat' （ 1 个 'a' ）、 'caaat' （ 3 个 'a' ）等等。\n类似 * 这样的重复是 贪婪的 。当重复正则时，匹配引擎将尝试重复尽可能多的次数。 如果表达式\n的后续部分不匹配，则匹配引擎将回退并以较少的重复次数再次尝试。\n通过一个逐步示例更容易理解这一点。让我们分析一下表达式 a[bcd]*b 。 该表达式首先匹配一个\n字母 'a' ，接着匹配字符类 [bcd] 中的零个或更多个字母，最后以一个 'b' 结尾。 现在想象一下\n用这个正则来匹配字符串 'abcbd' 。\n步骤 匹配 说明\n1 a 正则中的 a 匹配成功。\n2 abcbd 引擎尽可能多地匹配 [bcd]* ，直至字符串末尾。\n3 失败 引擎尝试匹配 b ，但是当前位置位于字符串末尾，所以匹配失败。\n4 abcb 回退，让 [bcd]* 少匹配一个字符。\n5 失败 再次尝试匹配 b ， 但是当前位置上的字符是最后一个字符 'd' 。\n6 abc 再次回退，让 [bcd]* 只匹配 bc 。\n6 abcb 再次尝试匹配 b 。 这一次当前位置的字符是 'b' ，所以它成功了。\n此时正则表达式已经到达了尽头，并且匹配到了 'abcb' 。 这个例子演示了匹配引擎一开始会尽其\n所能地进行匹配，如果没有找到匹配，它将逐步回退并重试正则的剩余部分，如此往复，直至\n[bcd]* 只匹配零次。如果随后的匹配还是失败了，那么引擎会宣告整个正则表达式与字符串匹配失\n败。\n另一个重复元字符是 + ，表示匹配一次或更多次。请注意 * 与 + 之间的差别。 * 表示匹配 零次 或\n更多次，也就是说它所重复的内容是可以完全不出现的。而 + 则要求至少出现一次。举一个类似的\n例子， ca+t 可以匹配 'cat' （ 1 个 'a' ）或 'caaat' （ 3 个 'a'），但不能匹配 'ct' 。\n\n|  | 匹配任何非字母与数字字符，等价于字符类 [^a-zA-Z0-9_] 。\n这些序列可以包含在字符类中。 例如，[\\s,.] 是一个匹配任何空白字符、',' 或 '.' 的字符类。\n本节的最后一个元字符是 . 。 它匹配除换行符之外的任何字符，并且有一个可选模式（ re.DOTALL\n），在该模式下它甚至可以匹配换行符。 . 通常用于你想匹配“任何字符”的场景。\n重复\n能够匹配各种各样的字符集合是正则表达式可以做到的第一件事，而这是字符串方法所不能做到\n的。但是，如果正则表达式就只有这么一个附加功能，它很难说的上有多大优势。另一个功能是，\n你可以指定正则的某部分必须重复一定的次数。\n我们先来说说重复元字符 * 。 * 并不是匹配一个字面字符 '*' 。实际上，它指定前一个字符可以匹\n配零次或更多次，而不是只匹配一次。\n例如，ca*t 将匹配 'ct' （ 0 个 'a' ）、'cat' （ 1 个 'a' ）、 'caaat' （ 3 个 'a' ）等等。\n类似 * 这样的重复是 贪婪的 。当重复正则时，匹配引擎将尝试重复尽可能多的次数。 如果表达式\n的后续部分不匹配，则匹配引擎将回退并以较少的重复次数再次尝试。\n通过一个逐步示例更容易理解这一点。让我们分析一下表达式 a[bcd]*b 。 该表达式首先匹配一个\n字母 'a' ，接着匹配字符类 [bcd] 中的零个或更多个字母，最后以一个 'b' 结尾。 现在想象一下\n用这个正则来匹配字符串 'abcbd' 。\n步骤 匹配 说明\n1 a 正则中的 a 匹配成功。\n2 abcbd 引擎尽可能多地匹配 [bcd]* ，直至字符串末尾。\n3 失败 引擎尝试匹配 b ，但是当前位置位于字符串末尾，所以匹配失败。\n4 abcb 回退，让 [bcd]* 少匹配一个字符。\n5 失败 再次尝试匹配 b ， 但是当前位置上的字符是最后一个字符 'd' 。\n6 abc 再次回退，让 [bcd]* 只匹配 bc 。\n6 abcb 再次尝试匹配 b 。 这一次当前位置的字符是 'b' ，所以它成功了。\n此时正则表达式已经到达了尽头，并且匹配到了 'abcb' 。 这个例子演示了匹配引擎一开始会尽其\n所能地进行匹配，如果没有找到匹配，它将逐步回退并重试正则的剩余部分，如此往复，直至\n[bcd]* 只匹配零次。如果随后的匹配还是失败了，那么引擎会宣告整个正则表达式与字符串匹配失\n败。\n另一个重复元字符是 + ，表示匹配一次或更多次。请注意 * 与 + 之间的差别。 * 表示匹配 零次 或\n更多次，也就是说它所重复的内容是可以完全不出现的。而 + 则要求至少出现一次。举一个类似的\n例子， ca+t 可以匹配 'cat' （ 1 个 'a' ）或 'caaat' （ 3 个 'a'），但不能匹配 'ct' 。 |  |\n| --- | --- | --- |\n\n| 步骤 | 匹配 | 说明 |\n| --- | --- | --- |\n| 1 | a | 正则中的 a 匹配成功。 |\n| 2 | abcbd | 引擎尽可能多地匹配 [bcd]* ，直至字符串末尾。 |\n| 3 | 失败 | 引擎尝试匹配 b ，但是当前位置位于字符串末尾，所以匹配失败。 |\n| 4 | abcb | 回退，让 [bcd]* 少匹配一个字符。 |\n| 5 | 失败 | 再次尝试匹配 b ， 但是当前位置上的字符是最后一个字符 'd' 。 |\n| 6 | abc | 再次回退，让 [bcd]* 只匹配 bc 。 |\n| 6 | abcb | 再次尝试匹配 b 。 这一次当前位置的字符是 'b' ，所以它成功了。 |\n\n此外还有两个重复操作符或限定符。 问号 ? 表示匹配一次或零次；你可以认为它把某项内容变成了\n可选的。 例如，home-?brew 可以匹配 'homebrew' 或 'home-brew'。\n最复杂的限定符是 {m,n}，其中 m 和 n 都是十进制整数。 该限定符表示必须至少重复 m 次，至多\n重复 n 次。 例如，a/{1,3}b 将匹配 'a/b', 'a//b' 和 'a///b'。 它不能匹配 'ab'，因为其中没\n有斜杠，也不能匹配 'a////b'，因为其中有四个斜杠。\nm 和 n 不是必填的，缺失的情况下会设定为默认值。缺失 m 会解释为最少重复 0 次 ，缺失 n 则解\n释为最多重复无限次。\n最简单情况 {m} 将与前一项完全匹配 m 次。 例如，a/{2}b 将只匹配 'a//b'。\n细心的读者可能会注意到另外三个限定符都可以使用此标记法来表示。 {0,} 等同于 *, {1,} 等同于\n+, 而 {0,1} 等同于 ?。 在可能的情况下使用 *, + 或 ? 会更好，因为它们更为简短易读。\n使用正则表达式\n现在我们已经了解了一些简单的正则表达式，那么我们如何在 Python 中实际使用它们呢？ re 模块\n提供了正则表达式引擎的接口，可以让你将正则编译为对象，然后用它们来进行匹配。\n编译正则表达式\n正则表达式被编译成模式对象，模式对象具有各种操作的方法，例如搜索模式匹配或执行字符串替\n换。:\n>>> import re\n>>> p = re.compile('ab*')\n>>> p\nre.compile('ab*')\nre.compile() 也接受一个可选的 flags 参数，用于启用各种特殊功能和语法变体。 我们稍后将介绍\n可用的设置，但现在只需一个例子\n>>> p = re.compile('ab*', re.IGNORECASE)\n正则作为字符串传递给 re.compile() 。 正则被处理为字符串，因为正则表达式不是核心Python语\n言的一部分，并且没有创建用于表达它们的特殊语法。 （有些应用程序根本不需要正则，因此不需\n要通过包含它们来扩展语言规范。）相反，re 模块只是Python附带的C扩展模块，就类似于 socket\n或 zlib 模块。\n将正则放在字符串中可以使 Python 语言更简单，但有一个缺点是下一节的主题。\n反斜杠灾难\n如前所述，正则表达式使用反斜杠字符 ('\\') 来表示特殊形式或允许使用特殊字符而不调用它们的\n特殊含义。 这与 Python 在字符串文字中用于相同目的的相同字符的使用相冲突。\n\n|  | 此外还有两个重复操作符或限定符。 问号 ? 表示匹配一次或零次；你可以认为它把某项内容变成了\n可选的。 例如，home-?brew 可以匹配 'homebrew' 或 'home-brew'。\n最复杂的限定符是 {m,n}，其中 m 和 n 都是十进制整数。 该限定符表示必须至少重复 m 次，至多\n重复 n 次。 例如，a/{1,3}b 将匹配 'a/b', 'a//b' 和 'a///b'。 它不能匹配 'ab'，因为其中没\n有斜杠，也不能匹配 'a////b'，因为其中有四个斜杠。\nm 和 n 不是必填的，缺失的情况下会设定为默认值。缺失 m 会解释为最少重复 0 次 ，缺失 n 则解\n释为最多重复无限次。\n最简单情况 {m} 将与前一项完全匹配 m 次。 例如，a/{2}b 将只匹配 'a//b'。\n细心的读者可能会注意到另外三个限定符都可以使用此标记法来表示。 {0,} 等同于 *, {1,} 等同于\n+, 而 {0,1} 等同于 ?。 在可能的情况下使用 *, + 或 ? 会更好，因为它们更为简短易读。\n使用正则表达式\n现在我们已经了解了一些简单的正则表达式，那么我们如何在 Python 中实际使用它们呢？ re 模块\n提供了正则表达式引擎的接口，可以让你将正则编译为对象，然后用它们来进行匹配。\n编译正则表达式\n正则表达式被编译成模式对象，模式对象具有各种操作的方法，例如搜索模式匹配或执行字符串替\n换。: |  |\n| --- | --- | --- |\n|  | >>> import re\n>>> p = re.compile('ab*')\n>>> p\nre.compile('ab*') |  |\n|  | re.compile() 也接受一个可选的 flags 参数，用于启用各种特殊功能和语法变体。 我们稍后将介绍\n可用的设置，但现在只需一个例子 |  |\n|  | >>> p = re.compile('ab*', re.IGNORECASE) |  |\n|  | 正则作为字符串传递给 re.compile() 。 正则被处理为字符串，因为正则表达式不是核心Python语\n言的一部分，并且没有创建用于表达它们的特殊语法。 （有些应用程序根本不需要正则，因此不需\n要通过包含它们来扩展语言规范。）相反，re 模块只是Python附带的C扩展模块，就类似于 socket\n或 zlib 模块。\n将正则放在字符串中可以使 Python 语言更简单，但有一个缺点是下一节的主题。\n反斜杠灾难\n如前所述，正则表达式使用反斜杠字符 ('\\') 来表示特殊形式或允许使用特殊字符而不调用它们的\n特殊含义。 这与 Python 在字符串文字中用于相同目的的相同字符的使用相冲突。 |  |\n\n假设你想要编写一个与字符串 \\section 相匹配的正则，它可以在 LaTeX 文件中找到。 要找出在程\n序代码中写入的内容，请从要匹配的字符串开始。 接下来，您必须通过在反斜杠前面添加反斜杠和\n其他元字符，从而产生字符串 \\\\section。 必须传递给 re.compile() 的结果字符串必须是\n\\\\section。 但是，要将其表示为 Python 字符串文字，必须 再次 转义两个反斜杠。\n字符 阶段\n\\section 被匹配的字符串\n\\\\section 为 re.compile() 转义的反斜杠\n\"\\\\\\\\section\" 为字符串字面转义的反斜杠\n简而言之，要匹配文字反斜杠，必须将 '\\\\\\\\' 写为正则字符串，因为正则表达式必须是 \\\\，并且\n每个反斜杠必须表示为 \\\\ 在常规Python字符串字面中。 在反复使用反斜杠的正则中，这会导致大\n量重复的反斜杠，并使得生成的字符串难以理解。\n解决方案是使用 Python 的原始字符串表示法来表示正则表达式；反斜杠不以任何特殊的方式处理前\n缀为 'r' 的字符串字面，因此 r\"\\n\" 是一个包含 '\\' 和 'n' 的双字符字符串，而 \"\\n\" 是一个包\n含换行符的单字符字符串。 正则表达式通常使用这种原始字符串表示法用 Python 代码编写。\n此外，在正则表达式中有效但在 Python 字符串文字中无效的特殊转义序列现在导致\nDeprecationWarning 并最终变为 SyntaxError。 这意味着如果未使用原始字符串表示法或转义反\n斜杠，序列将无效。\n常规字符串 原始字符串\n\"ab*\" r\"ab*\"\n\"\\\\\\\\section\" r\"\\\\section\"\n\"\\\\w+\\\\s+\\\\1\" r\"\\w+\\s+\\1\"\n应用匹配\n一旦你有一个表示编译正则表达式的对象，你用它做什么？ 模式对象有几种方法和属性。 这里只介\n绍最重要的内容；请参阅 re 文档获取完整列表。\n方法 / 属性 目的\nmatch() 确定正则是否从字符串的开头匹配。\nsearch() 扫描字符串，查找此正则匹配的任何位置。\nfindall() 找到正则匹配的所有子字符串，并将它们作为列表返回。\nfinditer() 找到正则匹配的所有子字符串，并将它们返回为一个 iterator。\n\n|  | 假设你想要编写一个与字符串 \\section 相匹配的正则，它可以在 LaTeX 文件中找到。 要找出在程\n序代码中写入的内容，请从要匹配的字符串开始。 接下来，您必须通过在反斜杠前面添加反斜杠和\n其他元字符，从而产生字符串 \\\\section。 必须传递给 re.compile() 的结果字符串必须是\n\\\\section。 但是，要将其表示为 Python 字符串文字，必须 再次 转义两个反斜杠。\n字符 阶段\n\\section 被匹配的字符串\n\\\\section 为 re.compile() 转义的反斜杠\n\"\\\\\\\\section\" 为字符串字面转义的反斜杠\n简而言之，要匹配文字反斜杠，必须将 '\\\\\\\\' 写为正则字符串，因为正则表达式必须是 \\\\，并且\n每个反斜杠必须表示为 \\\\ 在常规Python字符串字面中。 在反复使用反斜杠的正则中，这会导致大\n量重复的反斜杠，并使得生成的字符串难以理解。\n解决方案是使用 Python 的原始字符串表示法来表示正则表达式；反斜杠不以任何特殊的方式处理前\n缀为 'r' 的字符串字面，因此 r\"\\n\" 是一个包含 '\\' 和 'n' 的双字符字符串，而 \"\\n\" 是一个包\n含换行符的单字符字符串。 正则表达式通常使用这种原始字符串表示法用 Python 代码编写。\n此外，在正则表达式中有效但在 Python 字符串文字中无效的特殊转义序列现在导致\nDeprecationWarning 并最终变为 SyntaxError。 这意味着如果未使用原始字符串表示法或转义反\n斜杠，序列将无效。\n常规字符串 原始字符串\n\"ab*\" r\"ab*\"\n\"\\\\\\\\section\" r\"\\\\section\"\n\"\\\\w+\\\\s+\\\\1\" r\"\\w+\\s+\\1\"\n应用匹配\n一旦你有一个表示编译正则表达式的对象，你用它做什么？ 模式对象有几种方法和属性。 这里只介\n绍最重要的内容；请参阅 re 文档获取完整列表。\n方法 / 属性 目的\nmatch() 确定正则是否从字符串的开头匹配。\nsearch() 扫描字符串，查找此正则匹配的任何位置。\nfindall() 找到正则匹配的所有子字符串，并将它们作为列表返回。\nfinditer() 找到正则匹配的所有子字符串，并将它们返回为一个 iterator。 |  |\n| --- | --- | --- |\n\n| 字符 | 阶段 |\n| --- | --- |\n| \\section | 被匹配的字符串 |\n| \\\\section | 为 re.compile() 转义的反斜杠 |\n| \"\\\\\\\\section\" | 为字符串字面转义的反斜杠 |\n\n| 常规字符串 | 原始字符串 |\n| --- | --- |\n| \"ab*\" | r\"ab*\" |\n| \"\\\\\\\\section\" | r\"\\\\section\" |\n| \"\\\\w+\\\\s+\\\\1\" | r\"\\w+\\s+\\1\" |\n\n| 方法 / 属性 | 目的 |\n| --- | --- |\n| match() | 确定正则是否从字符串的开头匹配。 |\n| search() | 扫描字符串，查找此正则匹配的任何位置。 |\n| findall() | 找到正则匹配的所有子字符串，并将它们作为列表返回。 |\n| finditer() | 找到正则匹配的所有子字符串，并将它们返回为一个 iterator。 |\n\n如果没有找到匹配， match() 和 search() 返回 None 。如果它们成功， 一个 匹配对象 实例将被\n返回，包含匹配相关的信息：起始和终结位置、匹配的子串以及其它。\n你可以通过交互式地试验 re 模块来学习这一点。\n本 HOWTO 使用标准 Python 解释器作为示例。 首先，运行 Python 解释器，导入 re 模块，然后编\n译一个正则\n>>> import re\n>>> p = re.compile('[a-z]+')\n>>> p\nre.compile('[a-z]+')\n现在，你可以尝试匹配正则 [a-z]+ 的各种字符串。 空字符串根本不匹配，因为 + 表示“一次或多次\n重复”。 match() 在这种情况下应返回 None，这将导致解释器不打印输出。 你可以显式打印\nmatch() 的结果，使其清晰。:\n>>> p.match(\"\")\n>>> print(p.match(\"\"))\nNone\n现在，让我们尝试一下它应该匹配的字符串，例如 tempo。在这个例子中 match() 将返回一个 匹配\n对象，因此你应该将结果储存到一个变量中以供稍后使用。\n>>> m = p.match('tempo')\n>>> m\n<re.Match object; span=(0, 5), match='tempo'>\n现在你可以检查 匹配对象 以获取有关匹配字符串的信息。 匹配对象实例也有几个方法和属性；最重\n要的是：\n方法 / 属性 目的\ngroup() 返回正则匹配的字符串\nstart() 返回匹配的开始位置\nend() 返回匹配的结束位置\nspan() 返回包含匹配 (start, end) 位置的元组\n尝试这些方法很快就会清楚它们的含义:\n>>> m.group()\n'tempo'\n>>> m.start(), m.end()\n(0, 5)\n>>> m.span()\n(0, 5)\n\n|  | 如果没有找到匹配， match() 和 search() 返回 None 。如果它们成功， 一个 匹配对象 实例将被\n返回，包含匹配相关的信息：起始和终结位置、匹配的子串以及其它。\n你可以通过交互式地试验 re 模块来学习这一点。\n本 HOWTO 使用标准 Python 解释器作为示例。 首先，运行 Python 解释器，导入 re 模块，然后编\n译一个正则 |  |\n| --- | --- | --- |\n|  | >>> import re\n>>> p = re.compile('[a-z]+')\n>>> p\nre.compile('[a-z]+') |  |\n|  | 现在，你可以尝试匹配正则 [a-z]+ 的各种字符串。 空字符串根本不匹配，因为 + 表示“一次或多次\n重复”。 match() 在这种情况下应返回 None，这将导致解释器不打印输出。 你可以显式打印\nmatch() 的结果，使其清晰。: |  |\n|  | >>> p.match(\"\")\n>>> print(p.match(\"\"))\nNone |  |\n|  | 现在，让我们尝试一下它应该匹配的字符串，例如 tempo。在这个例子中 match() 将返回一个 匹配\n对象，因此你应该将结果储存到一个变量中以供稍后使用。 |  |\n|  | >>> m = p.match('tempo')\n>>> m\n<re.Match object; span=(0, 5), match='tempo'> |  |\n|  | 现在你可以检查 匹配对象 以获取有关匹配字符串的信息。 匹配对象实例也有几个方法和属性；最重\n要的是：\n方法 / 属性 目的\ngroup() 返回正则匹配的字符串\nstart() 返回匹配的开始位置\nend() 返回匹配的结束位置\nspan() 返回包含匹配 (start, end) 位置的元组\n尝试这些方法很快就会清楚它们的含义: |  |\n|  | >>> m.group()\n'tempo'\n>>> m.start(), m.end()\n(0, 5)\n>>> m.span()\n(0, 5) |  |\n|  |  |  |\n\n| 方法 / 属性 | 目的 |\n| --- | --- |\n| group() | 返回正则匹配的字符串 |\n| start() | 返回匹配的开始位置 |\n| end() | 返回匹配的结束位置 |\n| span() | 返回包含匹配 (start, end) 位置的元组 |\n\ngroup() 返回正则匹配的子字符串。 start() 和 end() 返回匹配的起始和结束索引。 span() 在单\n个元组中返回开始和结束索引。 由于 match() 方法只检查正则是否在字符串的开头匹配，所以\nstart() 将始终为零。 但是，模式的 search() 方法会扫描字符串，因此在这种情况下匹配可能不\n会从零开始。:\n>>> print(p.match('::: message'))\nNone\n>>> m = p.search('::: message'); print(m)\n<re.Match object; span=(4, 11), match='message'>\n>>> m.group()\n'message'\n>>> m.span()\n(4, 11)\n在实际程序中，最常见的样式是在变量中存储 匹配对象，然后检查它是否为 None。 这通常看起来\n像:\np = re.compile( ... )\nm = p.match( 'string goes here' )\nif m:\nprint('Match found: ', m.group())\nelse:\nprint('No match')\n两种模式方法返回模式的所有匹配项。 findall() 返回匹配字符串的列表:\n>>> p = re.compile(r'\\d+')\n>>> p.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')\n['12', '11', '10']\n在这个例子中需要 r 前缀，使字面为原始字符串字面，因为普通的“加工”字符串字面中的转义序列\n不能被 Python 识别为正则表达式，导致 DeprecationWarning 并最终产生 SyntaxError。 请参阅\n反斜杠灾难。\nfindall() 必须先创建整个列表才能返回结果。 finditer() 方法将一个 匹配对象 的序列返回为一\n个 iterator\n>>> iterator = p.finditer('12 drummers drumming, 11 ... 10 ...')\n>>> iterator\n<callable_iterator object at 0x...>\n>>> for match in iterator:\n... print(match.span())\n...\n(0, 2)\n(22, 24)\n(29, 31)\n模块级函数\n你不必创建模式对象并调用其方法；re 模块还提供了顶级函数 match()，search()，\nfindall()，sub() 等等。 这些函数采用与相应模式方法相同的参数，并将正则字符串作为第一个\n参数添加，并仍然返回 None 或 匹配对象 实例。:\n\n|  | group() 返回正则匹配的子字符串。 start() 和 end() 返回匹配的起始和结束索引。 span() 在单\n个元组中返回开始和结束索引。 由于 match() 方法只检查正则是否在字符串的开头匹配，所以\nstart() 将始终为零。 但是，模式的 search() 方法会扫描字符串，因此在这种情况下匹配可能不\n会从零开始。: |  |\n| --- | --- | --- |\n|  | >>> print(p.match('::: message'))\nNone\n>>> m = p.search('::: message'); print(m)\n<re.Match object; span=(4, 11), match='message'>\n>>> m.group()\n'message'\n>>> m.span()\n(4, 11) |  |\n|  | 在实际程序中，最常见的样式是在变量中存储 匹配对象，然后检查它是否为 None。 这通常看起来\n像: |  |\n|  | p = re.compile( ... )\nm = p.match( 'string goes here' )\nif m:\nprint('Match found: ', m.group())\nelse:\nprint('No match') |  |\n|  | 两种模式方法返回模式的所有匹配项。 findall() 返回匹配字符串的列表: |  |\n|  | >>> p = re.compile(r'\\d+')\n>>> p.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')\n['12', '11', '10'] |  |\n|  | 在这个例子中需要 r 前缀，使字面为原始字符串字面，因为普通的“加工”字符串字面中的转义序列\n不能被 Python 识别为正则表达式，导致 DeprecationWarning 并最终产生 SyntaxError。 请参阅\n反斜杠灾难。\nfindall() 必须先创建整个列表才能返回结果。 finditer() 方法将一个 匹配对象 的序列返回为一\n个 iterator |  |\n|  | >>> iterator = p.finditer('12 drummers drumming, 11 ... 10 ...')\n>>> iterator\n<callable_iterator object at 0x...>\n>>> for match in iterator:\n... print(match.span())\n...\n(0, 2)\n(22, 24)\n(29, 31) |  |\n|  | 模块级函数\n你不必创建模式对象并调用其方法；re 模块还提供了顶级函数 match()，search()，\nfindall()，sub() 等等。 这些函数采用与相应模式方法相同的参数，并将正则字符串作为第一个\n参数添加，并仍然返回 None 或 匹配对象 实例。: |  |\n\n>>> print(re.match(r'From\\s+', 'Fromage amk'))\nNone\n>>> re.match(r'From\\s+', 'From amk Thu May 14 19:12:10 1998')\n<re.Match object; span=(0, 5), match='From '>\n本质上，这些函数只是为你创建一个模式对象，并在其上调用适当的方法。 它们还将编译对象存储\n在缓存中，因此使用相同的未来调用将不需要一次又一次地解析该模式。\n你是否应该使用这些模块级函数，还是应该自己获取模式并调用其方法？ 如果你正在循环中访问正\n则表达式，预编译它将节省一些函数调用。 在循环之外，由于有内部缓存，没有太大区别。\n编译标志\n编译标志允许你修改正则表达式的工作方式。 标志在 re 模块中有两个名称，长名称如 IGNORECASE\n和一个简短的单字母形式，例如 I。 （如果你熟悉 Perl 的模式修饰符，则单字母形式使用和其相同\n的字母；例如， re.VERBOSE 的缩写形式为 re.X。）多个标志可以 通过按位或运算来指定它们；例\n如，re.I | re.M 设置 I 和 M 标志。\n这是一个可用标志表，以及每个标志的更详细说明。\n旗标 含意\n使几个转义如 \\w、\\b、\\s 和 \\d 匹配仅与具有相应特征属性的 ASCII\nASCII, A\n字符匹配。\nDOTALL, S 使 . 匹配任何字符，包括换行符。\nIGNORECASE, I 进行大小写不敏感匹配。\nLOCALE, L 进行区域设置感知匹配。\nMULTILINE, M 多行匹配，影响 ^ 和 $。\nVERBOSE, X （为 '扩\n启用详细的正则，可以更清晰，更容易理解。\n展'）\nre.I\nre.IGNORECASE\n执行不区分大小写的匹配；字符类和字面字符串将通过忽略大小写来匹配字母。 例如，[A-Z]\n也匹配小写字母。 除非使用 ASCII 标志来禁用非ASCII匹配，否则完全 Unicode 匹配也有效。\n当 Unicode 模式 [a-z] 或 [A-Z] 与 IGNORECASE 标志结合使用时，它们将匹配 52 个 ASCII 字\n母和 4 个额外的非 ASCII 字母：'İ' (U+0130，拉丁大写字母 I，带上面的点)，'ı' (U+0131，拉丁\n文小写字母无点 i)，'s' (U+017F，拉丁文小写字母长 s) 和'K' (U+212A，开尔文符号)。 Spam 将\n匹配 'Spam'，'spam'，'spAM' 或 'ſpam' (后者仅在 Unicode 模式下匹配)。 此小写不考虑当\n前区域设置；如果你还设置了 LOCALE 标志，则将考虑。\nre.L\nre.LOCALE\n使 \\w、\\W、\\b、\\B 和大小写敏感匹配依赖于当前区域而不是 Unicode 数据库。\n\n|  | >>> print(re.match(r'From\\s+', 'Fromage amk'))\nNone\n>>> re.match(r'From\\s+', 'From amk Thu May 14 19:12:10 1998')\n<re.Match object; span=(0, 5), match='From '> |  |  |\n| --- | --- | --- | --- |\n|  | 本质上，这些函数只是为你创建一个模式对象，并在其上调用适当的方法。 它们还将编译对象存储\n在缓存中，因此使用相同的未来调用将不需要一次又一次地解析该模式。\n你是否应该使用这些模块级函数，还是应该自己获取模式并调用其方法？ 如果你正在循环中访问正\n则表达式，预编译它将节省一些函数调用。 在循环之外，由于有内部缓存，没有太大区别。\n编译标志\n编译标志允许你修改正则表达式的工作方式。 标志在 re 模块中有两个名称，长名称如 IGNORECASE\n和一个简短的单字母形式，例如 I。 （如果你熟悉 Perl 的模式修饰符，则单字母形式使用和其相同\n的字母；例如， re.VERBOSE 的缩写形式为 re.X。）多个标志可以 通过按位或运算来指定它们；例\n如，re.I | re.M 设置 I 和 M 标志。\n这是一个可用标志表，以及每个标志的更详细说明。 |  |  |\n|  | 旗标 | 含意 |  |\n|  | ASCII, A | 使几个转义如 \\w、\\b、\\s 和 \\d 匹配仅与具有相应特征属性的 ASCII\n字符匹配。 |  |\n|  | DOTALL, S | 使 . 匹配任何字符，包括换行符。 |  |\n|  | IGNORECASE, I | 进行大小写不敏感匹配。 |  |\n|  | LOCALE, L | 进行区域设置感知匹配。 |  |\n|  | MULTILINE, M | 多行匹配，影响 ^ 和 $。 |  |\n|  | VERBOSE, X （为 '扩\n展'） | 启用详细的正则，可以更清晰，更容易理解。 |  |\n|  | re.I\nre.IGNORECASE\n执行不区分大小写的匹配；字符类和字面字符串将通过忽略大小写来匹配字母。 例如，[A-Z]\n也匹配小写字母。 除非使用 ASCII 标志来禁用非ASCII匹配，否则完全 Unicode 匹配也有效。\n当 Unicode 模式 [a-z] 或 [A-Z] 与 IGNORECASE 标志结合使用时，它们将匹配 52 个 ASCII 字\n母和 4 个额外的非 ASCII 字母：'İ' (U+0130，拉丁大写字母 I，带上面的点)，'ı' (U+0131，拉丁\n文小写字母无点 i)，'s' (U+017F，拉丁文小写字母长 s) 和'K' (U+212A，开尔文符号)。 Spam 将\n匹配 'Spam'，'spam'，'spAM' 或 'ſpam' (后者仅在 Unicode 模式下匹配)。 此小写不考虑当\n前区域设置；如果你还设置了 LOCALE 标志，则将考虑。\nre.L\nre.LOCALE\n使 \\w、\\W、\\b、\\B 和大小写敏感匹配依赖于当前区域而不是 Unicode 数据库。 |  |  |\n\n区域设置是 C 库的一个功能，旨在帮助编写考虑到语言差异的程序。例如，如果你正在处理编\n码的法语文本，那么你希望能够编写 \\w+ 来匹配单词，但 \\w 只匹配字符类 [A-Za-z] 字节模\n式；它不会匹配对应于 é 或 ç 的字节。如果你的系统配置正确并且选择了法语区域设置，某些\nC函数将告诉程序对应于 é 的字节也应该被视为字母。在编译正则表达式时设置 LOCALE 标志\n将导致生成的编译对象将这些C函数用于 \\w；这比较慢，但也可以使 \\w+ 匹配你所期望的法语\n单词。在 Python 3 中不鼓励使用此标志，因为语言环境机制非常不可靠，它一次只处理一个\n“文化”，它只适用于 8 位语言环境。默认情况下，Python 3 中已经为 Unicode（str）模式启用\n了 Unicode 匹配，并且它能够处理不同的区域/语言。\nre.M\nre.MULTILINE\n(^ 和 $ 还没有解释；它们将在以下部分介绍 更多元字符。)\n通常 ^ 只匹配字符串的开头，而 $ 只匹配字符串的结尾，紧接在字符串末尾的换行符（如果有\n的话）之前。 当指定了这个标志时，^ 匹配字符串的开头和字符串中每一行的开头，紧跟在每\n个换行符之后。 类似地，$ 元字符匹配字符串的结尾和每行的结尾（紧接在每个换行符之\n前）。\nre.S\nre.DOTALL\n使 '.' 特殊字符匹配任何字符，包括换行符；没有这个标志，'.' 将匹配任何字符 除了 换行\n符。\nre.A\nre.ASCII\n使 \\w、\\W、\\b、\\B、\\s 和 \\S 执行仅 ASCII 匹配而不是完整匹配 Unicode 匹配。 这仅对\nUnicode 模式有意义，并且对于字节模式将被忽略。\nre.X\nre.VERBOSE\n此标志允许你编写更易读的正则表达式，方法是为您提供更灵活的格式化方式。 指定此标志\n后，将忽略正则字符串中的空格，除非空格位于字符类中或前面带有未转义的反斜杠；这使你\n可以更清楚地组织和缩进正则。 此标志还允许你将注释放在正则中，引擎将忽略该注释；注释\n标记为 '#' 既不是在字符类中，也不是在未转义的反斜杠之前。\n例如，这里的正则使用 re.VERBOSE；看看阅读有多容易？:\ncharref = re.compile(r\"\"\"\n&[#] # 数字实体引用的开始\n(\n0[0-7]+ # 八进制形式\n| [0-9]+ # 十进制形式\n| x[0-9a-fA-F]+ # 十六进制形式\n)\n; # 末尾分号\n\"\"\", re.VERBOSE)\n如果没有详细设置，正则将如下所示:\n\n|  | 区域设置是 C 库的一个功能，旨在帮助编写考虑到语言差异的程序。例如，如果你正在处理编\n码的法语文本，那么你希望能够编写 \\w+ 来匹配单词，但 \\w 只匹配字符类 [A-Za-z] 字节模\n式；它不会匹配对应于 é 或 ç 的字节。如果你的系统配置正确并且选择了法语区域设置，某些\nC函数将告诉程序对应于 é 的字节也应该被视为字母。在编译正则表达式时设置 LOCALE 标志\n将导致生成的编译对象将这些C函数用于 \\w；这比较慢，但也可以使 \\w+ 匹配你所期望的法语\n单词。在 Python 3 中不鼓励使用此标志，因为语言环境机制非常不可靠，它一次只处理一个\n“文化”，它只适用于 8 位语言环境。默认情况下，Python 3 中已经为 Unicode（str）模式启用\n了 Unicode 匹配，并且它能够处理不同的区域/语言。\nre.M\nre.MULTILINE\n(^ 和 $ 还没有解释；它们将在以下部分介绍 更多元字符。)\n通常 ^ 只匹配字符串的开头，而 $ 只匹配字符串的结尾，紧接在字符串末尾的换行符（如果有\n的话）之前。 当指定了这个标志时，^ 匹配字符串的开头和字符串中每一行的开头，紧跟在每\n个换行符之后。 类似地，$ 元字符匹配字符串的结尾和每行的结尾（紧接在每个换行符之\n前）。\nre.S\nre.DOTALL\n使 '.' 特殊字符匹配任何字符，包括换行符；没有这个标志，'.' 将匹配任何字符 除了 换行\n符。\nre.A\nre.ASCII\n使 \\w、\\W、\\b、\\B、\\s 和 \\S 执行仅 ASCII 匹配而不是完整匹配 Unicode 匹配。 这仅对\nUnicode 模式有意义，并且对于字节模式将被忽略。\nre.X\nre.VERBOSE\n此标志允许你编写更易读的正则表达式，方法是为您提供更灵活的格式化方式。 指定此标志\n后，将忽略正则字符串中的空格，除非空格位于字符类中或前面带有未转义的反斜杠；这使你\n可以更清楚地组织和缩进正则。 此标志还允许你将注释放在正则中，引擎将忽略该注释；注释\n标记为 '#' 既不是在字符类中，也不是在未转义的反斜杠之前。\n例如，这里的正则使用 re.VERBOSE；看看阅读有多容易？:\ncharref = re.compile(r\"\"\"\n&[#] # 数字实体引用的开始\n(\n0[0-7]+ # 八进制形式\n| [0-9]+ # 十进制形式\n| x[0-9a-fA-F]+ # 十六进制形式\n)\n; # 末尾分号\n\"\"\", re.VERBOSE)\n如果没有详细设置，正则将如下所示: |  |\n| --- | --- | --- |\n\ncharref = re.compile(\"&#(0[0-7]+\"\n\"|[0-9]+\"\n\"|x[0-9a-fA-F]+);\")\n在上面的例子中，Python的字符串文字的自动连接已被用于将正则分解为更小的部分，但它仍\n然比以下使用 re.VERBOSE 版本更难理解。\n更多模式能力\n到目前为止，我们只介绍了正则表达式的一部分功能。 在本节中，我们将介绍一些新的元字符，以\n及如何使用组来检索匹配的文本部分。\n更多元字符\n我们还没有涉及到一些元字符。 其中大部分内容将在本节中介绍。\n要讨论的其余一些元字符是 零宽度断言 。 它们不会使解析引擎在字符串中前进一个字符；相反，它\n们根本不占用任何字符，只是成功或失败。例如，\\b 是一个断言，指明当前位置位于字边界；这个\n位置根本不会被 \\b 改变。这意味着永远不应重复零宽度断言，因为如果它们在给定位置匹配一次，\n它们显然可以无限次匹配。\n|\n或者“or”运算符。 如果 A 和 B 是正则表达式，A|B 将匹配任何与 A 或 B 匹配的字符串。 | 具\n有非常低的优先级，以便在交替使用多字符字符串时使其合理地工作。 Crow|Servo 将匹配\n'Crow' 或 'Servo'，而不是 'Cro'、'w' 或 'S' 和 'ervo'。\n要匹配字面 '|'，请使用 \\|，或将其括在字符类中，如 [|]。\n^\n在行的开头匹配。 除非设置了 MULTILINE 标志，否则只会在字符串的开头匹配。 在\nMULTILINE 模式下，这也在字符串中的每个换行符后立即匹配。\n例如，如果你希望仅在行的开头匹配单词 From，则要使用的正则 ^From。:\n>>> print(re.search('^From', 'From Here to Eternity'))\n<re.Match object; span=(0, 4), match='From'>\n>>> print(re.search('^From', 'Reciting From Memory'))\nNone\n要匹配字面 '^'，使用 \\^。\n$\n匹配行的末尾，定义为字符串的结尾，或者后跟换行符的任何位置。:\n>>> print(re.search('}$', '{block}'))\n<re.Match object; span=(6, 7), match='}'>\n>>> print(re.search('}$', '{block} '))\nNone\n>>> print(re.search('}$', '{block}\\n'))\n<re.Match object; span=(6, 7), match='}'>\n\n|  | charref = re.compile(\"&#(0[0-7]+\"\n\"|[0-9]+\"\n\"|x[0-9a-fA-F]+);\")\n在上面的例子中，Python的字符串文字的自动连接已被用于将正则分解为更小的部分，但它仍\n然比以下使用 re.VERBOSE 版本更难理解。\n更多模式能力\n到目前为止，我们只介绍了正则表达式的一部分功能。 在本节中，我们将介绍一些新的元字符，以\n及如何使用组来检索匹配的文本部分。\n更多元字符\n我们还没有涉及到一些元字符。 其中大部分内容将在本节中介绍。\n要讨论的其余一些元字符是 零宽度断言 。 它们不会使解析引擎在字符串中前进一个字符；相反，它\n们根本不占用任何字符，只是成功或失败。例如，\\b 是一个断言，指明当前位置位于字边界；这个\n位置根本不会被 \\b 改变。这意味着永远不应重复零宽度断言，因为如果它们在给定位置匹配一次，\n它们显然可以无限次匹配。\n|\n或者“or”运算符。 如果 A 和 B 是正则表达式，A|B 将匹配任何与 A 或 B 匹配的字符串。 | 具\n有非常低的优先级，以便在交替使用多字符字符串时使其合理地工作。 Crow|Servo 将匹配\n'Crow' 或 'Servo'，而不是 'Cro'、'w' 或 'S' 和 'ervo'。\n要匹配字面 '|'，请使用 \\|，或将其括在字符类中，如 [|]。\n^\n在行的开头匹配。 除非设置了 MULTILINE 标志，否则只会在字符串的开头匹配。 在\nMULTILINE 模式下，这也在字符串中的每个换行符后立即匹配。\n例如，如果你希望仅在行的开头匹配单词 From，则要使用的正则 ^From。:\n>>> print(re.search('^From', 'From Here to Eternity'))\n<re.Match object; span=(0, 4), match='From'>\n>>> print(re.search('^From', 'Reciting From Memory'))\nNone\n要匹配字面 '^'，使用 \\^。\n$\n匹配行的末尾，定义为字符串的结尾，或者后跟换行符的任何位置。:\n>>> print(re.search('}$', '{block}'))\n<re.Match object; span=(6, 7), match='}'>\n>>> print(re.search('}$', '{block} '))\nNone\n>>> print(re.search('}$', '{block}\\n'))\n<re.Match object; span=(6, 7), match='}'> | charref = re.compile(\"&#(0[0-7]+\"\n\"|[0-9]+\"\n\"|x[0-9a-fA-F]+);\") |  |\n| --- | --- | --- | --- |\n\n以匹配字面 '$'，使用 \\$ 或者将其包裹在一个字符类中，例如 [$]。\n\\A\n仅匹配字符串的开头。 当不在 MULTILINE 模式时，\\A 和 ^ 实际上是相同的。 在 MULTILINE\n模式中，它们是不同的: \\A 仍然只在字符串的开头匹配，但 ^ 可以匹配在换行符之后的字符串\n内的任何位置。\n\\z\n只匹配字符串尾。\n\\Z\n与``z`` 相同。 与旧版本 Python 保持兼容性。\n\\b\n字边界。 这是一个零宽度断言，仅在单词的开头或结尾处匹配。 单词被定义为一个字母数字字\n符序列，因此单词的结尾由空格或非字母数字字符表示。\n以下示例仅当它是一个完整的单词时匹配 class；当它包含在另一个单词中时将不会匹配。\n>>> p = re.compile(r'\\bclass\\b')\n>>> print(p.search('no class at all'))\n<re.Match object; span=(3, 8), match='class'>\n>>> print(p.search('the declassified algorithm'))\nNone\n>>> print(p.search('one subclass is'))\nNone\n使用这个特殊序列时，你应该记住两个细微之处。 首先，这是 Python 的字符串文字和正则表\n达式序列之间最严重的冲突。 在 Python 的字符串文字中，\\b 是退格字符，ASCII 值为8。 如\n果你没有使用原始字符串，那么 Python 会将 \\b 转换为退格，你的正则不会按照你的预期匹\n配。 以下示例与我们之前的正则看起来相同，但省略了正则字符串前面的 'r'。:\n>>> p = re.compile('\\bclass\\b')\n>>> print(p.search('no class at all'))\nNone\n>>> print(p.search('\\b' + 'class' + '\\b'))\n<re.Match object; span=(0, 7), match='\\x08class\\x08'>\n其次，在一个字符类中，这个断言没有用处，\\b 表示退格字符，以便与 Python 的字符串文字\n兼容。\n\\B\n另一个零宽度断言，这与 \\b 相反，仅在当前位置不在字边界时才匹配。\n分组\n通常，你需要获取更多信息，而不仅仅是正则是否匹配。 正则表达式通常用于通过将正则分成几个\n子组来解析字符串，这些子组匹配不同的感兴趣组件。 例如，RFC-822 标题行分为标题名称和值，\n用 ':' 分隔，如下所示：\n\n|  | 以匹配字面 '$'，使用 \\$ 或者将其包裹在一个字符类中，例如 [$]。\n\\A\n仅匹配字符串的开头。 当不在 MULTILINE 模式时，\\A 和 ^ 实际上是相同的。 在 MULTILINE\n模式中，它们是不同的: \\A 仍然只在字符串的开头匹配，但 ^ 可以匹配在换行符之后的字符串\n内的任何位置。\n\\z\n只匹配字符串尾。\n\\Z\n与``z`` 相同。 与旧版本 Python 保持兼容性。\n\\b\n字边界。 这是一个零宽度断言，仅在单词的开头或结尾处匹配。 单词被定义为一个字母数字字\n符序列，因此单词的结尾由空格或非字母数字字符表示。\n以下示例仅当它是一个完整的单词时匹配 class；当它包含在另一个单词中时将不会匹配。\n>>> p = re.compile(r'\\bclass\\b')\n>>> print(p.search('no class at all'))\n<re.Match object; span=(3, 8), match='class'>\n>>> print(p.search('the declassified algorithm'))\nNone\n>>> print(p.search('one subclass is'))\nNone\n使用这个特殊序列时，你应该记住两个细微之处。 首先，这是 Python 的字符串文字和正则表\n达式序列之间最严重的冲突。 在 Python 的字符串文字中，\\b 是退格字符，ASCII 值为8。 如\n果你没有使用原始字符串，那么 Python 会将 \\b 转换为退格，你的正则不会按照你的预期匹\n配。 以下示例与我们之前的正则看起来相同，但省略了正则字符串前面的 'r'。:\n>>> p = re.compile('\\bclass\\b')\n>>> print(p.search('no class at all'))\nNone\n>>> print(p.search('\\b' + 'class' + '\\b'))\n<re.Match object; span=(0, 7), match='\\x08class\\x08'>\n其次，在一个字符类中，这个断言没有用处，\\b 表示退格字符，以便与 Python 的字符串文字\n兼容。\n\\B\n另一个零宽度断言，这与 \\b 相反，仅在当前位置不在字边界时才匹配。\n分组\n通常，你需要获取更多信息，而不仅仅是正则是否匹配。 正则表达式通常用于通过将正则分成几个\n子组来解析字符串，这些子组匹配不同的感兴趣组件。 例如，RFC-822 标题行分为标题名称和值，\n用 ':' 分隔，如下所示： |  |\n| --- | --- | --- |\n\nFrom: author@example.com\nUser-Agent: Thunderbird 1.5.0.9 (X11/20061227)\nMIME-Version: 1.0\nTo: editor@example.com\n这可以通过编写与整个标题行匹配的正则表达式来处理，并且具有与标题名称匹配的一个组，以及\n与标题的值匹配的另一个组。\n分组是用 '(', ')' 元字符来标记的。 '(' 和 ')' 与它们在数学表达式中的含义基本一致；它们会\n将所包含的表达式合为一组，并且你可以使用限定符例如 *, +, ?, 或 {m,n} 来重复一个分组的内\n容。 举例来说，(ab)* 将匹配 ab 的零次或多次重复。\n>>> p = re.compile('(ab)*')\n>>> print(p.match('ababababab').span())\n(0, 10)\n用 '('，')' 表示的组也捕获它们匹配的文本的起始和结束索引；这可以通过将参数传递给\ngroup()、start()、end() 以及 span()。 组从 0 开始编号。组 0 始终存在；它表示整个正则，所\n以 匹配对象 方法都将组 0 作为默认参数。 稍后我们将看到如何表达不捕获它们匹配的文本范围的\n组。:\n>>> p = re.compile('(a)b')\n>>> m = p.match('ab')\n>>> m.group()\n'ab'\n>>> m.group(0)\n'ab'\n子组从左到右编号，从 1 向上编号。 组可以嵌套；要确定编号，只需计算从左到右的左括号字符。:\n>>> p = re.compile('(a(b)c)d')\n>>> m = p.match('abcd')\n>>> m.group(0)\n'abcd'\n>>> m.group(1)\n'abc'\n>>> m.group(2)\n'b'\ngroup() 可以一次传递多个组号，在这种情况下，它将返回一个包含这些组的相应值的元组。:\n>>> m.group(2,1,2)\n('b', 'abc', 'b')\ngroups() 方法返回一个元组，其中包含所有子组的字符串，从1到最后一个子组。:\n>>> m.groups()\n('abc', 'b')\n模式中的后向引用允许你指定还必须在字符串中的当前位置找到先前捕获组的内容。 例如，如果可\n以在当前位置找到组 1 的确切内容，则 \\1 将成功，否则将失败。 请记住，Python 的字符串文字也\n\n|  | From: author@example.com\nUser-Agent: Thunderbird 1.5.0.9 (X11/20061227)\nMIME-Version: 1.0\nTo: editor@example.com |  |\n| --- | --- | --- |\n|  | 这可以通过编写与整个标题行匹配的正则表达式来处理，并且具有与标题名称匹配的一个组，以及\n与标题的值匹配的另一个组。\n分组是用 '(', ')' 元字符来标记的。 '(' 和 ')' 与它们在数学表达式中的含义基本一致；它们会\n将所包含的表达式合为一组，并且你可以使用限定符例如 *, +, ?, 或 {m,n} 来重复一个分组的内\n容。 举例来说，(ab)* 将匹配 ab 的零次或多次重复。 |  |\n|  | >>> p = re.compile('(ab)*')\n>>> print(p.match('ababababab').span())\n(0, 10) |  |\n|  | 用 '('，')' 表示的组也捕获它们匹配的文本的起始和结束索引；这可以通过将参数传递给\ngroup()、start()、end() 以及 span()。 组从 0 开始编号。组 0 始终存在；它表示整个正则，所\n以 匹配对象 方法都将组 0 作为默认参数。 稍后我们将看到如何表达不捕获它们匹配的文本范围的\n组。: |  |\n|  | >>> p = re.compile('(a)b')\n>>> m = p.match('ab')\n>>> m.group()\n'ab'\n>>> m.group(0)\n'ab' |  |\n|  | 子组从左到右编号，从 1 向上编号。 组可以嵌套；要确定编号，只需计算从左到右的左括号字符。: |  |\n|  | >>> p = re.compile('(a(b)c)d')\n>>> m = p.match('abcd')\n>>> m.group(0)\n'abcd'\n>>> m.group(1)\n'abc'\n>>> m.group(2)\n'b' |  |\n|  | group() 可以一次传递多个组号，在这种情况下，它将返回一个包含这些组的相应值的元组。: |  |\n|  | >>> m.group(2,1,2)\n('b', 'abc', 'b') |  |\n|  | groups() 方法返回一个元组，其中包含所有子组的字符串，从1到最后一个子组。: |  |\n|  | >>> m.groups()\n('abc', 'b') |  |\n|  | 模式中的后向引用允许你指定还必须在字符串中的当前位置找到先前捕获组的内容。 例如，如果可\n以在当前位置找到组 1 的确切内容，则 \\1 将成功，否则将失败。 请记住，Python 的字符串文字也 |  |\n\n使用反斜杠后跟数字以允许在字符串中包含任意字符，因此正则中引入反向引用时务必使用原始字\n符串。\n例如，以下正则检测字符串中重复的单词。:\n>>> p = re.compile(r'\\b(\\w+)\\s+\\1\\b')\n>>> p.search('Paris in the the spring').group()\n'the the'\n像这样的后向引用通常不仅仅用于搜索字符串 —— 很少有文本格式以这种方式重复数据 —— 但是\n你很快就会发现它们在执行字符串替换时 非常 有用。\n非捕获和命名组\n精心设计的正则可以使用许多组，既可以捕获感兴趣的子串，也可以对正则本身进行分组和构建。\n在复杂的正则中，很难跟踪组号。 有两个功能可以帮助解决这个问题。 它们都使用常用语法进行正\n则表达式扩展，因此我们首先看一下。\nPerl 5 以其对标准正则表达式的强大补充而闻名。 对于这些新功能，Perl 开发人员无法选择新的单\n键击元字符或以 \\ 开头的新特殊序列，否则 Perl 的正则表达式与标准正则容易混淆。 例如，如果他\n们选择 & 作为一个新的元字符，旧的表达式将假设 & 是一个普通字符，并且不会编写 \\& 或 [&]。\nPerl 开发人员选择的解决方案是使用 (?...) 作为扩展语法。 括号后面紧跟 ? 是一个语法错误，因\n为 ? 没有什么可重复的，所以这样并不会带来任何兼容性问题。 紧跟在 ? 之后的字符表示正在使用\n的扩展语法，所以 (?=foo) 是一种语法（一个前视断言）和 (?:foo) 是另一种语法（ 包含子表达\n式 foo 的非捕获组）。\nPython 支持一些 Perl 的扩展，并增加了新的扩展语法用于 Perl 的扩展语法。 如果在问号之后的第\n一个字符为 P，即表明其为 Python 专属的扩展。\n现在我们已经了解了一般的扩展语法，我们可以回到简化复杂正则中组处理的功能。\n有时你会想要使用组来表示正则表达式的一部分，但是对检索组的内容不感兴趣。 你可以通过使用\n非捕获组来显式表达这个事实: (?:...)，你可以用任何其他正则表达式替换 ...。:\n>>> m = re.match(\"([abc])+\", \"abc\")\n>>> m.groups()\n('c',)\n>>> m = re.match(\"(?:[abc])+\", \"abc\")\n>>> m.groups()\n()\n除了你无法检索组匹配内容的事实外，非捕获组的行为与捕获组完全相同；你可以在里面放任何东\n西，用重复元字符重复它，比如 *，然后把它嵌入其他组（捕获或不捕获）。 (?:...) 在修改现有\n模式时特别有用，因为你可以添加新组而不更改所有其他组的编号方式。 值得一提的是，捕获和非\n捕获组之间的搜索没有性能差异；两种形式没有一种更快。\n更重要的功能是命名组：不是通过数字引用它们，而是可以通过名称引用组。\n\n|  | 使用反斜杠后跟数字以允许在字符串中包含任意字符，因此正则中引入反向引用时务必使用原始字\n符串。\n例如，以下正则检测字符串中重复的单词。: |  |\n| --- | --- | --- |\n|  | >>> p = re.compile(r'\\b(\\w+)\\s+\\1\\b')\n>>> p.search('Paris in the the spring').group()\n'the the' |  |\n|  | 像这样的后向引用通常不仅仅用于搜索字符串 —— 很少有文本格式以这种方式重复数据 —— 但是\n你很快就会发现它们在执行字符串替换时 非常 有用。\n非捕获和命名组\n精心设计的正则可以使用许多组，既可以捕获感兴趣的子串，也可以对正则本身进行分组和构建。\n在复杂的正则中，很难跟踪组号。 有两个功能可以帮助解决这个问题。 它们都使用常用语法进行正\n则表达式扩展，因此我们首先看一下。\nPerl 5 以其对标准正则表达式的强大补充而闻名。 对于这些新功能，Perl 开发人员无法选择新的单\n键击元字符或以 \\ 开头的新特殊序列，否则 Perl 的正则表达式与标准正则容易混淆。 例如，如果他\n们选择 & 作为一个新的元字符，旧的表达式将假设 & 是一个普通字符，并且不会编写 \\& 或 [&]。\nPerl 开发人员选择的解决方案是使用 (?...) 作为扩展语法。 括号后面紧跟 ? 是一个语法错误，因\n为 ? 没有什么可重复的，所以这样并不会带来任何兼容性问题。 紧跟在 ? 之后的字符表示正在使用\n的扩展语法，所以 (?=foo) 是一种语法（一个前视断言）和 (?:foo) 是另一种语法（ 包含子表达\n式 foo 的非捕获组）。\nPython 支持一些 Perl 的扩展，并增加了新的扩展语法用于 Perl 的扩展语法。 如果在问号之后的第\n一个字符为 P，即表明其为 Python 专属的扩展。\n现在我们已经了解了一般的扩展语法，我们可以回到简化复杂正则中组处理的功能。\n有时你会想要使用组来表示正则表达式的一部分，但是对检索组的内容不感兴趣。 你可以通过使用\n非捕获组来显式表达这个事实: (?:...)，你可以用任何其他正则表达式替换 ...。: |  |\n|  | >>> m = re.match(\"([abc])+\", \"abc\")\n>>> m.groups()\n('c',)\n>>> m = re.match(\"(?:[abc])+\", \"abc\")\n>>> m.groups()\n() |  |\n|  | 除了你无法检索组匹配内容的事实外，非捕获组的行为与捕获组完全相同；你可以在里面放任何东\n西，用重复元字符重复它，比如 *，然后把它嵌入其他组（捕获或不捕获）。 (?:...) 在修改现有\n模式时特别有用，因为你可以添加新组而不更改所有其他组的编号方式。 值得一提的是，捕获和非\n捕获组之间的搜索没有性能差异；两种形式没有一种更快。\n更重要的功能是命名组：不是通过数字引用它们，而是可以通过名称引用组。 |  |\n\n命名组的语法是Python特定的扩展之一: (?P<name>...)。 name 显然是该组的名称。 命名组的行\n为与捕获组完全相同，并且还将名称与组关联。 处理捕获组的 匹配对象 方法都接受按编号引用组的\n整数或包含所需组名的字符串。 命名组仍然是给定的数字，因此你可以通过两种方式检索有关组的\n信息:\n>>> p = re.compile(r'(?P<word>\\b\\w+\\b)')\n>>> m = p.search( '(((( Lots of punctuation )))' )\n>>> m.group('word')\n'Lots'\n>>> m.group(1)\n'Lots'\n此外，你可以通过 groupdict() 将命名分组提取为一个字典:\n>>> m = re.match(r'(?P<first>\\w+) (?P<last>\\w+)', 'Jane Doe')\n>>> m.groupdict()\n{'first': 'Jane', 'last': 'Doe'}\n命名分组很方便因为它们让你可以使用容易记忆的名称，而不必记忆数字。 下面是一个来自\nimaplib 模块的正则表达式示例:\nInternalDate = re.compile(r'INTERNALDATE \"'\nr'(?P<day>[ 123][0-9])-(?P<mon>[A-Z][a-z][a-z])-'\nr'(?P<year>[0-9][0-9][0-9][0-9])'\nr' (?P<hour>[0-9][0-9]):(?P<min>[0-9][0-9]):(?P<sec>[0-9][0-9])'\nr' (?P<zonen>[-+])(?P<zoneh>[0-9][0-9])(?P<zonem>[0-9][0-9])'\nr'\"')\n检索 m.group('zonem') 显然要容易得多，而不必记住检索第 9 组。\n表达式中的后向引用语法，例如 (...)\\1，指的是组的编号。 当然有一种变体使用组名而不是数\n字。 这是另一个 Python 扩展: (?P=name) 表示在当前点再次匹配名为 name 的组的内容。 用于查\n找重复单词的正则表达式，\\b(\\w+)\\s+\\1\\b 也可以写为 \\b(?P<word>\\w+)\\s+(?P=word)\\b:\n>>> p = re.compile(r'\\b(?P<word>\\w+)\\s+(?P=word)\\b')\n>>> p.search('Paris in the the spring').group()\n'the the'\n前视断言\n另一个零宽断言是前视断言。 前视断言有肯定型和否定型两种形式，如下所示：\n(?=…)\n肯定型前视断言。如果内部的表达式（这里用 ... 来表示）在当前位置可以匹配，则匹配成\n功，否则匹配失败。 但是，内部表达式尝试匹配之后，正则引擎并不会向前推进；正则表达式\n的其余部分依然会在断言开始的地方尝试匹配。\n(?!…)\n否定型前视断言。 与肯定型断言正好相反，如果内部表达式在字符串中的当前位置 不 匹配，\n则成功。\n\n|  | 命名组的语法是Python特定的扩展之一: (?P<name>...)。 name 显然是该组的名称。 命名组的行\n为与捕获组完全相同，并且还将名称与组关联。 处理捕获组的 匹配对象 方法都接受按编号引用组的\n整数或包含所需组名的字符串。 命名组仍然是给定的数字，因此你可以通过两种方式检索有关组的\n信息: |  |\n| --- | --- | --- |\n|  | >>> p = re.compile(r'(?P<word>\\b\\w+\\b)')\n>>> m = p.search( '(((( Lots of punctuation )))' )\n>>> m.group('word')\n'Lots'\n>>> m.group(1)\n'Lots' |  |\n|  | 此外，你可以通过 groupdict() 将命名分组提取为一个字典: |  |\n|  | >>> m = re.match(r'(?P<first>\\w+) (?P<last>\\w+)', 'Jane Doe')\n>>> m.groupdict()\n{'first': 'Jane', 'last': 'Doe'} |  |\n|  | 命名分组很方便因为它们让你可以使用容易记忆的名称，而不必记忆数字。 下面是一个来自\nimaplib 模块的正则表达式示例: |  |\n|  | InternalDate = re.compile(r'INTERNALDATE \"'\nr'(?P<day>[ 123][0-9])-(?P<mon>[A-Z][a-z][a-z])-'\nr'(?P<year>[0-9][0-9][0-9][0-9])'\nr' (?P<hour>[0-9][0-9]):(?P<min>[0-9][0-9]):(?P<sec>[0-9][0-9])'\nr' (?P<zonen>[-+])(?P<zoneh>[0-9][0-9])(?P<zonem>[0-9][0-9])'\nr'\"') |  |\n|  | 检索 m.group('zonem') 显然要容易得多，而不必记住检索第 9 组。\n表达式中的后向引用语法，例如 (...)\\1，指的是组的编号。 当然有一种变体使用组名而不是数\n字。 这是另一个 Python 扩展: (?P=name) 表示在当前点再次匹配名为 name 的组的内容。 用于查\n找重复单词的正则表达式，\\b(\\w+)\\s+\\1\\b 也可以写为 \\b(?P<word>\\w+)\\s+(?P=word)\\b: |  |\n|  | >>> p = re.compile(r'\\b(?P<word>\\w+)\\s+(?P=word)\\b')\n>>> p.search('Paris in the the spring').group()\n'the the' |  |\n|  | 前视断言\n另一个零宽断言是前视断言。 前视断言有肯定型和否定型两种形式，如下所示：\n(?=…)\n肯定型前视断言。如果内部的表达式（这里用 ... 来表示）在当前位置可以匹配，则匹配成\n功，否则匹配失败。 但是，内部表达式尝试匹配之后，正则引擎并不会向前推进；正则表达式\n的其余部分依然会在断言开始的地方尝试匹配。\n(?!…)\n否定型前视断言。 与肯定型断言正好相反，如果内部表达式在字符串中的当前位置 不 匹配，\n则成功。 |  |\n\n更具体一些，来看一个前视的实用案例。 考虑用一个简单的表达式来匹配文件名并将其拆分为基本\n名称和扩展名，以 . 分隔。 例如，在 news.rc 中，news 是基本名称，rc 是文件名的扩展名。\n与此匹配的模式非常简单：\n.*[.].*$\n请注意，. 需要特别处理，因为它是元字符，所以它在字符类中只能匹配特定字符。 还要注意尾随\n的 $；添加此项以确保扩展名中的所有其余字符串都必须包含在扩展名中。 这个正则表达式匹配\nfoo.bar、autoexec.bat、sendmail.cf 和 printers.conf。\n现在，考虑使更复杂一点的问题；如果你想匹配扩展名不是 bat 的文件名怎么办？ 一些错误的尝\n试：\n.*[.][^b].*$\n上面的第一次尝试将通过要求扩展的第一个字符不为 b 来排除 bat。 这是错误的，因为该模式同样\n不能匹配 foo.bar。\n.*[.]([^b]..|.[^a].|..[^t])$\n当你尝试通过要求以下一种情况匹配来修补第一个解决方案时，表达式变得更加混乱：扩展的第一\n个字符不是 b。 第二个字符不 a；或者第三个字符不是 t。 这接受 foo.bar 并拒绝\nautoexec.bat，但它需要三个字母的扩展名，并且不接受带有两个字母扩展名的文件名，例如\nsendmail.cf。 为了解决这个问题，我们会再次使模式复杂化。\n.*[.]([^b].?.?|.[^a]?.?|..?[^t]?)$\n在第三次尝试中，第二个和第三个字母都是可选的，以便允许匹配的扩展名短于三个字符，例如\nsendmail.cf。\n模式现在变得非常复杂，这使得它难以阅读和理解。 更糟糕的是，如果问题发生变化并且你想要将\nbat 和 exe 排除为扩展，那么该模式将变得更加复杂和混乱。\n否定型前视可以解决所有这些困扰：\n.*[.](?!bat$)[^.]*$\n否定前视意味着：如果表达式 bat 在这个点位不匹配，则尝试模式的其余部分；如果 bat$ 不匹\n配，整个模式匹配将失败。 需要有末尾的 $ 来确保 sample.batch 这样的内容，其中扩展名只能以\nbat 开头，将被允许。 [^.]* 将确保当文件名中有多个点号时该模式仍能正常工作。\n现在很容易排除另一个文件扩展名；只需在断言中添加它作为替代。 以下模块排除以 bat 或 exe:\n.*[.](?!bat$|exe$)[^.]*$\n修改字符串\n\n|  | 更具体一些，来看一个前视的实用案例。 考虑用一个简单的表达式来匹配文件名并将其拆分为基本\n名称和扩展名，以 . 分隔。 例如，在 news.rc 中，news 是基本名称，rc 是文件名的扩展名。\n与此匹配的模式非常简单：\n.*[.].*$\n请注意，. 需要特别处理，因为它是元字符，所以它在字符类中只能匹配特定字符。 还要注意尾随\n的 $；添加此项以确保扩展名中的所有其余字符串都必须包含在扩展名中。 这个正则表达式匹配\nfoo.bar、autoexec.bat、sendmail.cf 和 printers.conf。\n现在，考虑使更复杂一点的问题；如果你想匹配扩展名不是 bat 的文件名怎么办？ 一些错误的尝\n试：\n.*[.][^b].*$\n上面的第一次尝试将通过要求扩展的第一个字符不为 b 来排除 bat。 这是错误的，因为该模式同样\n不能匹配 foo.bar。\n.*[.]([^b]..|.[^a].|..[^t])$\n当你尝试通过要求以下一种情况匹配来修补第一个解决方案时，表达式变得更加混乱：扩展的第一\n个字符不是 b。 第二个字符不 a；或者第三个字符不是 t。 这接受 foo.bar 并拒绝\nautoexec.bat，但它需要三个字母的扩展名，并且不接受带有两个字母扩展名的文件名，例如\nsendmail.cf。 为了解决这个问题，我们会再次使模式复杂化。\n.*[.]([^b].?.?|.[^a]?.?|..?[^t]?)$\n在第三次尝试中，第二个和第三个字母都是可选的，以便允许匹配的扩展名短于三个字符，例如\nsendmail.cf。\n模式现在变得非常复杂，这使得它难以阅读和理解。 更糟糕的是，如果问题发生变化并且你想要将\nbat 和 exe 排除为扩展，那么该模式将变得更加复杂和混乱。\n否定型前视可以解决所有这些困扰：\n.*[.](?!bat$)[^.]*$\n否定前视意味着：如果表达式 bat 在这个点位不匹配，则尝试模式的其余部分；如果 bat$ 不匹\n配，整个模式匹配将失败。 需要有末尾的 $ 来确保 sample.batch 这样的内容，其中扩展名只能以\nbat 开头，将被允许。 [^.]* 将确保当文件名中有多个点号时该模式仍能正常工作。\n现在很容易排除另一个文件扩展名；只需在断言中添加它作为替代。 以下模块排除以 bat 或 exe:\n.*[.](?!bat$|exe$)[^.]*$\n修改字符串 |  |\n| --- | --- | --- |\n\n到目前为止，我们只是针对静态字符串执行搜索。 正则表达式通常也用于以各种方式修改字符串，\n使用以下模式方法：\n方法 / 属性 目的\nsplit() 将字符串拆分为一个列表，在正则匹配的任何地方将其拆分\nsub() 找到正则匹配的所有子字符串，并用不同的字符串替换它们\nsubn() 与 sub() 相同，但返回新字符串和替换次数\n分割字符串\n模式的 split() 方法在正则匹配的任何地方拆分字符串，返回一个片段列表。 它类似于 split()\n字符串方法，但在分隔符的分隔符中提供了更多的通用性；字符串的 split() 仅支持按空格或固定\n字符串进行拆分。 正如你所期望的那样，还有一个模块级 re.split() 函数。\n.split(string[, maxsplit=0])\n通过正则表达式的匹配拆分 字符串。 如果在正则中使用捕获括号，则它们的内容也将作为结果\n列表的一部分返回。 如果 maxsplit 非零，则最多执行 maxsplit 次拆分。\n你可以通过传递 maxsplit 的值来限制分割的数量。 当 maxsplit 非零时，将最多进行 maxsplit 次拆\n分，并且字符串的其余部分将作为列表的最后一个元素返回。 在以下示例中，分隔符是任何非字母\n数字字符序列。:\n>>> p = re.compile(r'\\W+')\n>>> p.split('This is a test, short and sweet, of split().')\n['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']\n>>> p.split('This is a test, short and sweet, of split().', 3)\n['This', 'is', 'a', 'test, short and sweet, of split().']\n有时你不仅对分隔符之间的文本感兴趣，而且还需要知道分隔符是什么。 如果在正则中使用捕获括\n号，则它们的值也将作为列表的一部分返回。 比较以下调用:\n>>> p = re.compile(r'\\W+')\n>>> p2 = re.compile(r'(\\W+)')\n>>> p.split('This... is a test.')\n['This', 'is', 'a', 'test', '']\n>>> p2.split('This... is a test.')\n['This', '... ', 'is', ' ', 'a', ' ', 'test', '.', '']\n模块级函数 re.split() 添加要正则作为第一个参数，但在其他方面是相同的。:\n>>> re.split(r'[\\W]+', 'Words, words, words.')\n['Words', 'words', 'words', '']\n>>> re.split(r'([\\W]+)', 'Words, words, words.')\n['Words', ', ', 'words', ', ', 'words', '.', '']\n>>> re.split(r'[\\W]+', 'Words, words, words.', 1)\n['Words', 'words, words.']\n\n|  | 到目前为止，我们只是针对静态字符串执行搜索。 正则表达式通常也用于以各种方式修改字符串，\n使用以下模式方法：\n方法 / 属性 目的\nsplit() 将字符串拆分为一个列表，在正则匹配的任何地方将其拆分\nsub() 找到正则匹配的所有子字符串，并用不同的字符串替换它们\nsubn() 与 sub() 相同，但返回新字符串和替换次数\n分割字符串\n模式的 split() 方法在正则匹配的任何地方拆分字符串，返回一个片段列表。 它类似于 split()\n字符串方法，但在分隔符的分隔符中提供了更多的通用性；字符串的 split() 仅支持按空格或固定\n字符串进行拆分。 正如你所期望的那样，还有一个模块级 re.split() 函数。\n.split(string[, maxsplit=0])\n通过正则表达式的匹配拆分 字符串。 如果在正则中使用捕获括号，则它们的内容也将作为结果\n列表的一部分返回。 如果 maxsplit 非零，则最多执行 maxsplit 次拆分。\n你可以通过传递 maxsplit 的值来限制分割的数量。 当 maxsplit 非零时，将最多进行 maxsplit 次拆\n分，并且字符串的其余部分将作为列表的最后一个元素返回。 在以下示例中，分隔符是任何非字母\n数字字符序列。: |  |\n| --- | --- | --- |\n|  | >>> p = re.compile(r'\\W+')\n>>> p.split('This is a test, short and sweet, of split().')\n['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']\n>>> p.split('This is a test, short and sweet, of split().', 3)\n['This', 'is', 'a', 'test, short and sweet, of split().'] |  |\n|  | 有时你不仅对分隔符之间的文本感兴趣，而且还需要知道分隔符是什么。 如果在正则中使用捕获括\n号，则它们的值也将作为列表的一部分返回。 比较以下调用: |  |\n|  | >>> p = re.compile(r'\\W+')\n>>> p2 = re.compile(r'(\\W+)')\n>>> p.split('This... is a test.')\n['This', 'is', 'a', 'test', '']\n>>> p2.split('This... is a test.')\n['This', '... ', 'is', ' ', 'a', ' ', 'test', '.', ''] |  |\n|  | 模块级函数 re.split() 添加要正则作为第一个参数，但在其他方面是相同的。: |  |\n|  | >>> re.split(r'[\\W]+', 'Words, words, words.')\n['Words', 'words', 'words', '']\n>>> re.split(r'([\\W]+)', 'Words, words, words.')\n['Words', ', ', 'words', ', ', 'words', '.', '']\n>>> re.split(r'[\\W]+', 'Words, words, words.', 1)\n['Words', 'words, words.'] |  |\n|  |  |  |\n\n| 方法 / 属性 | 目的 |\n| --- | --- |\n| split() | 将字符串拆分为一个列表，在正则匹配的任何地方将其拆分 |\n| sub() | 找到正则匹配的所有子字符串，并用不同的字符串替换它们 |\n| subn() | 与 sub() 相同，但返回新字符串和替换次数 |\n\n搜索和替换\n另一个常见任务是找到模式的所有匹配项，并用不同的字符串替换它们。 sub() 方法接受一个替换\n值，可以是字符串或函数，也可以是要处理的字符串。\n.sub(replacement, string[, count=0])\n返回通过替换 replacement 替换 string 中正则的最左边非重叠出现而获得的字符串。 如果未找\n到模式，则 string 将保持不变。\n可选参数 count 是要替换的模式最大的出现次数；count 必须是非负整数。 默认值 0 表示替换\n所有。\n这是一个使用 sub() 方法的简单示例。 它用 colour 这个词取代颜色名称:\n>>> p = re.compile('(blue|white|red)')\n>>> p.sub('colour', 'blue socks and red shoes')\n'colour socks and colour shoes'\n>>> p.sub('colour', 'blue socks and red shoes', count=1)\n'colour socks and red shoes'\nsubn() 方法完成相同的工作，但返回一个包含新字符串值和已执行的替换次数的 2 元组:\n>>> p = re.compile('(blue|white|red)')\n>>> p.subn('colour', 'blue socks and red shoes')\n('colour socks and colour shoes', 2)\n>>> p.subn('colour', 'no colours at all')\n('no colours at all', 0)\n仅当空匹配与前一个空匹配不相邻时，才会替换空匹配。:\n>>> p = re.compile('x*')\n>>> p.sub('-', 'abxd')\n'-a-b--d-'\n如果 replacement 是一个字符串，则处理其中的任何反斜杠转义。 也就是说，\\n 被转换为单个换行\n符，\\r 被转换为回车符，依此类推。 诸如 \\& 之类的未知转义是孤立的。 后向引用，例如 \\6，被\n替换为正则中相应组匹配的子字符串。 这使你可以在生成的替换字符串中合并原始文本的部分内\n容。\n这个例子匹配单词 section 后跟一个用 {，} 括起来的字符串，并将 section 改为 subsection\n>>> p = re.compile('section{ ( [^}]* ) }', re.VERBOSE)\n>>> p.sub(r'subsection{\\1}','section{First} section{second}')\n'subsection{First} subsection{second}'\n还有一种语法用于引用由 (?P<name>...) 语法定义的命名组。 \\g<name> 将使用名为 name 的组匹\n配的子字符串，\\g<number> 使用相应的组号。 因此 \\g<2> 等同于 \\2，但在诸如 \\g<2>0 之类的替\n换字符串中并不模糊。 (\\20 将被解释为对组 20 的引用，而不是对组 2 的引用，后跟字面字符\n'0'。) 以下替换都是等效的，但使用所有三种变体替换字符串。:\n\n|  | 搜索和替换\n另一个常见任务是找到模式的所有匹配项，并用不同的字符串替换它们。 sub() 方法接受一个替换\n值，可以是字符串或函数，也可以是要处理的字符串。\n.sub(replacement, string[, count=0])\n返回通过替换 replacement 替换 string 中正则的最左边非重叠出现而获得的字符串。 如果未找\n到模式，则 string 将保持不变。\n可选参数 count 是要替换的模式最大的出现次数；count 必须是非负整数。 默认值 0 表示替换\n所有。\n这是一个使用 sub() 方法的简单示例。 它用 colour 这个词取代颜色名称: |  |\n| --- | --- | --- |\n|  | >>> p = re.compile('(blue|white|red)')\n>>> p.sub('colour', 'blue socks and red shoes')\n'colour socks and colour shoes'\n>>> p.sub('colour', 'blue socks and red shoes', count=1)\n'colour socks and red shoes' |  |\n|  | subn() 方法完成相同的工作，但返回一个包含新字符串值和已执行的替换次数的 2 元组: |  |\n|  | >>> p = re.compile('(blue|white|red)')\n>>> p.subn('colour', 'blue socks and red shoes')\n('colour socks and colour shoes', 2)\n>>> p.subn('colour', 'no colours at all')\n('no colours at all', 0) |  |\n|  | 仅当空匹配与前一个空匹配不相邻时，才会替换空匹配。: |  |\n|  | >>> p = re.compile('x*')\n>>> p.sub('-', 'abxd')\n'-a-b--d-' |  |\n|  | 如果 replacement 是一个字符串，则处理其中的任何反斜杠转义。 也就是说，\\n 被转换为单个换行\n符，\\r 被转换为回车符，依此类推。 诸如 \\& 之类的未知转义是孤立的。 后向引用，例如 \\6，被\n替换为正则中相应组匹配的子字符串。 这使你可以在生成的替换字符串中合并原始文本的部分内\n容。\n这个例子匹配单词 section 后跟一个用 {，} 括起来的字符串，并将 section 改为 subsection |  |\n|  | >>> p = re.compile('section{ ( [^}]* ) }', re.VERBOSE)\n>>> p.sub(r'subsection{\\1}','section{First} section{second}')\n'subsection{First} subsection{second}' |  |\n|  | 还有一种语法用于引用由 (?P<name>...) 语法定义的命名组。 \\g<name> 将使用名为 name 的组匹\n配的子字符串，\\g<number> 使用相应的组号。 因此 \\g<2> 等同于 \\2，但在诸如 \\g<2>0 之类的替\n换字符串中并不模糊。 (\\20 将被解释为对组 20 的引用，而不是对组 2 的引用，后跟字面字符\n'0'。) 以下替换都是等效的，但使用所有三种变体替换字符串。: |  |\n\n>>> p = re.compile('section{ (?P<name> [^}]* ) }', re.VERBOSE)\n>>> p.sub(r'subsection{\\1}','section{First}')\n'subsection{First}'\n>>> p.sub(r'subsection{\\g<1>}','section{First}')\n'subsection{First}'\n>>> p.sub(r'subsection{\\g<name>}','section{First}')\n'subsection{First}'\nreplacement 也可以是一个函数，它可以为你提供更多控制。 如果 replacement 是一个函数，则为\npattern 的每次非重叠出现将调用该函数。 在每次调用时，函数都会传递一个匹配的 匹配对象 参\n数，并可以使用此信息计算所需的替换字符串并将其返回。\n在以下示例中，替换函数将小数转换为十六进制:\n>>> def hexrepl(match):\n... \"返回十进制数字的十六进制字符串\"\n... value = int(match.group())\n... return hex(value)\n...\n>>> p = re.compile(r'\\d+')\n>>> p.sub(hexrepl, 'Call 65490 for printing, 49152 for user code.')\n'Call 0xffd2 for printing, 0xc000 for user code.'\n使用模块级别 re.sub() 函数时，模式作为第一个参数传递。 模式可以是对象或字符串；如果需要\n指定正则表达式标志，则必须使用模式对象作为第一个参数，或者在模式字符串中使用嵌入式修饰\n符，例如: sub(\"(?i)b+\", \"x\", \"bbbb BBBB\") 返回 'x x'。\n常见问题\n正则表达式对于某些应用程序来说是一个强大的工具，但在某些方面，它们的行为并不直观，有时\n它们的行为方式与你的预期不同。 本节将指出一些最常见的陷阱。\n使用字符串方法\n有时使用 re 模块是一个错误。 如果你匹配固定字符串或单个字符类，并且你没有使用任何 re 功\n能，例如 IGNORECASE 标志，那么正则表达式的全部功能可能不是必需的。 字符串有几种方法可以\n使用固定字符串执行操作，它们通常要快得多，因为实现是一个针对此目的而优化的单个小 C 循\n环，而不是大型、更通用的正则表达式引擎。\n一个例子可能是用另一个固定字符串替换一个固定字符串；例如，你可以用 deed 替换 word 。\nre.sub() 看起来像是用于此的函数，但请考虑 replace() 方法。 注意 replace() 也会替换单词\n里面的 word ，把 swordfish 变成 sdeedfish ，但简单的正则 word 也会这样做。 （为了避免对单\n词的部分进行替换，模式必须是 \\bword\\b，以便要求 word 在任何一方都有一个单词边界。这使得\n工作超出了 replace() 的能力。）\n另一个常见任务是从字符串中删除单个字符的每个匹配项或将其替换为另一个字符。 你可以用\nre.sub('\\n', ' ', S) 之类的东西来做这件事，但是 translate() 能够完成这两项任务，并且比\n任何正则表达式都快。\n简而言之，在转向 re 模块之前，请考虑是否可以使用更快更简单的字符串方法解决问题。\n\n|  | >>> p = re.compile('section{ (?P<name> [^}]* ) }', re.VERBOSE)\n>>> p.sub(r'subsection{\\1}','section{First}')\n'subsection{First}'\n>>> p.sub(r'subsection{\\g<1>}','section{First}')\n'subsection{First}'\n>>> p.sub(r'subsection{\\g<name>}','section{First}')\n'subsection{First}' |  |\n| --- | --- | --- |\n|  | replacement 也可以是一个函数，它可以为你提供更多控制。 如果 replacement 是一个函数，则为\npattern 的每次非重叠出现将调用该函数。 在每次调用时，函数都会传递一个匹配的 匹配对象 参\n数，并可以使用此信息计算所需的替换字符串并将其返回。\n在以下示例中，替换函数将小数转换为十六进制: |  |\n|  | >>> def hexrepl(match):\n... \"返回十进制数字的十六进制字符串\"\n... value = int(match.group())\n... return hex(value)\n...\n>>> p = re.compile(r'\\d+')\n>>> p.sub(hexrepl, 'Call 65490 for printing, 49152 for user code.')\n'Call 0xffd2 for printing, 0xc000 for user code.' |  |\n|  | 使用模块级别 re.sub() 函数时，模式作为第一个参数传递。 模式可以是对象或字符串；如果需要\n指定正则表达式标志，则必须使用模式对象作为第一个参数，或者在模式字符串中使用嵌入式修饰\n符，例如: sub(\"(?i)b+\", \"x\", \"bbbb BBBB\") 返回 'x x'。\n常见问题\n正则表达式对于某些应用程序来说是一个强大的工具，但在某些方面，它们的行为并不直观，有时\n它们的行为方式与你的预期不同。 本节将指出一些最常见的陷阱。\n使用字符串方法\n有时使用 re 模块是一个错误。 如果你匹配固定字符串或单个字符类，并且你没有使用任何 re 功\n能，例如 IGNORECASE 标志，那么正则表达式的全部功能可能不是必需的。 字符串有几种方法可以\n使用固定字符串执行操作，它们通常要快得多，因为实现是一个针对此目的而优化的单个小 C 循\n环，而不是大型、更通用的正则表达式引擎。\n一个例子可能是用另一个固定字符串替换一个固定字符串；例如，你可以用 deed 替换 word 。\nre.sub() 看起来像是用于此的函数，但请考虑 replace() 方法。 注意 replace() 也会替换单词\n里面的 word ，把 swordfish 变成 sdeedfish ，但简单的正则 word 也会这样做。 （为了避免对单\n词的部分进行替换，模式必须是 \\bword\\b，以便要求 word 在任何一方都有一个单词边界。这使得\n工作超出了 replace() 的能力。）\n另一个常见任务是从字符串中删除单个字符的每个匹配项或将其替换为另一个字符。 你可以用\nre.sub('\\n', ' ', S) 之类的东西来做这件事，但是 translate() 能够完成这两项任务，并且比\n任何正则表达式都快。\n简而言之，在转向 re 模块之前，请考虑是否可以使用更快更简单的字符串方法解决问题。 |  |\n\nmatch() 和 search()\nThe match() function only checks if the RE matches at the beginning of the string while search()\nwill scan forward through the string for a match. It's important to keep this distinction in mind.\nRemember, match() will only report a successful match which will start at 0; if the match wouldn't\nstart at zero, match() will not report it.\n>>> print(re.match('super', 'superstition').span())\n(0, 5)\n>>> print(re.match('super', 'insuperable'))\nNone\n另一方面， search() 将向前扫描字符串，报告它找到的第一个匹配项。:\n>>> print(re.search('super', 'superstition').span())\n(0, 5)\n>>> print(re.search('super', 'insuperable').span())\n(2, 7)\n有时你会被诱惑继续使用 re.match() ，只需在你的正则前面添加 .* 。抵制这种诱惑并使用\nre.search() 代替。 正则表达式编译器对正则进行一些分析，以加快寻找匹配的过程。 其中一个分\n析可以确定匹配的第一个特征必须是什么；例如，以 Crow 开头的模式必须与 'C' 匹配。 分析让引\n擎快速扫描字符串，寻找起始字符，只在找到 'C' 时尝试完全匹配。\n添加 .* 会使这个优化失效，需要扫描到字符串的末尾，然后回溯以找到正则的其余部分的匹配。\n使用 re.search() 代替。\n贪婪与非贪婪\n当重复一个正则表达式时，就像在 a* 中一样，最终的动作就是消耗尽可能多的模式。 当你尝试匹\n配一对对称分隔符，例如 HTML 标记周围的尖括号时，这个事实经常会让你感到困惑。因为 .* 的\n贪婪性质， 用于匹配单个 HTML 标记的简单模式不起作用。\n>>> s = '<html><head><title>Title</title>'\n>>> len(s)\n32\n>>> print(re.match('<.*>', s).span())\n(0, 32)\n>>> print(re.match('<.*>', s).group())\n<html><head><title>Title</title>\n正则匹配 '<' 中的 '<html>' 和 .* 消耗字符串的其余部分。 正则中还有更多的剩余东西，并且 >\n在字符串的末尾不能匹配，所以正则表达式引擎必须逐个字符地回溯，直到它找到匹配 > 。最终匹\n配从 '<html>' 中的 '<' 扩展到 '</title>' 中的 '>' ，而这并不是你想要的结果。\n在这种情况下，解决方案是使用非贪婪限定符 *?, +?, ?? 或 {m,n}?，它们会匹配尽可能 少的 文\n本。 在上面的例子中，'>' 会在第一个 '<' 匹配后被立即尝试，而当匹配失败时，引擎将每次前进\n一个字符，并在每一步重试 '>'。 这将产生正确的结果:\n\n|  | match() 和 search()\nThe match() function only checks if the RE matches at the beginning of the string while search()\nwill scan forward through the string for a match. It's important to keep this distinction in mind.\nRemember, match() will only report a successful match which will start at 0; if the match wouldn't\nstart at zero, match() will not report it. |  |\n| --- | --- | --- |\n|  | >>> print(re.match('super', 'superstition').span())\n(0, 5)\n>>> print(re.match('super', 'insuperable'))\nNone |  |\n|  | 另一方面， search() 将向前扫描字符串，报告它找到的第一个匹配项。: |  |\n|  | >>> print(re.search('super', 'superstition').span())\n(0, 5)\n>>> print(re.search('super', 'insuperable').span())\n(2, 7) |  |\n|  | 有时你会被诱惑继续使用 re.match() ，只需在你的正则前面添加 .* 。抵制这种诱惑并使用\nre.search() 代替。 正则表达式编译器对正则进行一些分析，以加快寻找匹配的过程。 其中一个分\n析可以确定匹配的第一个特征必须是什么；例如，以 Crow 开头的模式必须与 'C' 匹配。 分析让引\n擎快速扫描字符串，寻找起始字符，只在找到 'C' 时尝试完全匹配。\n添加 .* 会使这个优化失效，需要扫描到字符串的末尾，然后回溯以找到正则的其余部分的匹配。\n使用 re.search() 代替。\n贪婪与非贪婪\n当重复一个正则表达式时，就像在 a* 中一样，最终的动作就是消耗尽可能多的模式。 当你尝试匹\n配一对对称分隔符，例如 HTML 标记周围的尖括号时，这个事实经常会让你感到困惑。因为 .* 的\n贪婪性质， 用于匹配单个 HTML 标记的简单模式不起作用。 |  |\n|  | >>> s = '<html><head><title>Title</title>'\n>>> len(s)\n32\n>>> print(re.match('<.*>', s).span())\n(0, 32)\n>>> print(re.match('<.*>', s).group())\n<html><head><title>Title</title> |  |\n|  | 正则匹配 '<' 中的 '<html>' 和 .* 消耗字符串的其余部分。 正则中还有更多的剩余东西，并且 >\n在字符串的末尾不能匹配，所以正则表达式引擎必须逐个字符地回溯，直到它找到匹配 > 。最终匹\n配从 '<html>' 中的 '<' 扩展到 '</title>' 中的 '>' ，而这并不是你想要的结果。\n在这种情况下，解决方案是使用非贪婪限定符 *?, +?, ?? 或 {m,n}?，它们会匹配尽可能 少的 文\n本。 在上面的例子中，'>' 会在第一个 '<' 匹配后被立即尝试，而当匹配失败时，引擎将每次前进\n一个字符，并在每一步重试 '>'。 这将产生正确的结果: |  |\n\n>>> print(re.match('<.*?>', s).group())\n<html>\n（请注意，使用正则表达式解析 HTML 或 XML 很痛苦。快而脏的模式将处理常见情况，但 HTML 和\nXML 有特殊情况会破坏明显的正则表达式；当你编写正则表达式处理所有可能的情况时，模式将非\n常复杂。使用 HTML 或 XML 解析器模块来执行此类任务。）\n使用 re.VERBOSE\n到目前为止，你可能已经注意到正则表达式是一种非常紧凑的表示法，但它们并不是非常易读。 具\n有中等复杂度的正则可能会成为反斜杠、括号和元字符的冗长集合，使其难以阅读和理解。\n对于这样的正则，在编译正则表达式时指定 re.VERBOSE 标志可能会有所帮助，因为它允许你更清\n楚地格式化正则表达式。\nre.VERBOSE 标志有几种效果。 正则表达式中的 不是 在字符类中的空格将被忽略。 这意味着表达式\n如 dog | cat 等同于不太可读的 dog|cat ，但 [a b] 仍将匹配字符 'a' 、 'b' 或空格。 此外，\n你还可以在正则中放置注释；注释从 # 字符扩展到下一个换行符。 当与三引号字符串一起使用时，\n这使正则的格式更加整齐:\npat = re.compile(r\"\"\"\n\\s* # Skip leading whitespace\n(?P<header>[^:]+) # Header name\n\\s* : # Whitespace, and a colon\n(?P<value>.*?) # The header's value -- *? used to\n# lose the following trailing whitespace\n\\s*$ # Trailing whitespace to end-of-line\n\"\"\", re.VERBOSE)\n这更具有可读性:\npat = re.compile(r\"\\s*(?P<header>[^:]+)\\s*:(?P<value>.*?)\\s*$\")\n反馈\n正则表达式是一个复杂的主题。 这份文档是否有助于你理解它们？ 是否存在不清楚的部分，或者你\n遇到的问题未在此处涉及？ 如果是，请向作者发送改进建议。\n关于正则表达式的最完整的书几乎肯定是由 O'Reilly 出版的 Jeffrey Friedl 的 Mastering Regular\nExpressions 。 不幸的是，它专注于 Perl 和 Java 的正则表达式，并且根本不包含任何 Python 材\n料，因此它不能用作 Python 编程的参考。 （第一版涵盖了 Python 现在删除的 regex 模块，这对\n你没有多大帮助。）考虑从你的图书馆中查找它。\n\n| >>> print(re.match('<.*?>', s).group())\n<html> |\n| --- |\n| （请注意，使用正则表达式解析 HTML 或 XML 很痛苦。快而脏的模式将处理常见情况，但 HTML 和\nXML 有特殊情况会破坏明显的正则表达式；当你编写正则表达式处理所有可能的情况时，模式将非\n常复杂。使用 HTML 或 XML 解析器模块来执行此类任务。）\n使用 re.VERBOSE\n到目前为止，你可能已经注意到正则表达式是一种非常紧凑的表示法，但它们并不是非常易读。 具\n有中等复杂度的正则可能会成为反斜杠、括号和元字符的冗长集合，使其难以阅读和理解。\n对于这样的正则，在编译正则表达式时指定 re.VERBOSE 标志可能会有所帮助，因为它允许你更清\n楚地格式化正则表达式。\nre.VERBOSE 标志有几种效果。 正则表达式中的 不是 在字符类中的空格将被忽略。 这意味着表达式\n如 dog | cat 等同于不太可读的 dog|cat ，但 [a b] 仍将匹配字符 'a' 、 'b' 或空格。 此外，\n你还可以在正则中放置注释；注释从 # 字符扩展到下一个换行符。 当与三引号字符串一起使用时，\n这使正则的格式更加整齐: |\n| pat = re.compile(r\"\"\"\n\\s* # Skip leading whitespace\n(?P<header>[^:]+) # Header name\n\\s* : # Whitespace, and a colon\n(?P<value>.*?) # The header's value -- *? used to\n# lose the following trailing whitespace\n\\s*$ # Trailing whitespace to end-of-line\n\"\"\", re.VERBOSE) |\n| 这更具有可读性: |\n| pat = re.compile(r\"\\s*(?P<header>[^:]+)\\s*:(?P<value>.*?)\\s*$\") |\n| 反馈\n正则表达式是一个复杂的主题。 这份文档是否有助于你理解它们？ 是否存在不清楚的部分，或者你\n遇到的问题未在此处涉及？ 如果是，请向作者发送改进建议。\n关于正则表达式的最完整的书几乎肯定是由 O'Reilly 出版的 Jeffrey Friedl 的 Mastering Regular\nExpressions 。 不幸的是，它专注于 Perl 和 Java 的正则表达式，并且根本不包含任何 Python 材\n料，因此它不能用作 Python 编程的参考。 （第一版涵盖了 Python 现在删除的 regex 模块，这对\n你没有多大帮助。）考虑从你的图书馆中查找它。 |", "metadata": {"title": "10_正则表达式指南", "source": "md_docs\\python_howto_md\\10_正则表达式指南.md", "doc_type": "指南", "language": "中文", "doc_id": "1d9d579e"}}
{"doc_id": "0d0cce3d", "content": "排序的技术\n作者: Andrew Dalke 与 Raymond Hettinger\n内置列表方法 list.sort() 原地修改列表，而内置函数 sorted() 由可迭代对象新建有序列表。\n在本文档中，我们将探索使用 Python 对数据进行排序的各种技术。\n排序的基础知识\n普通的升序排序非常容易：只需调用 sorted() 函数。它返回新有序列表：\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\n亦可用 list.sort() 方法。它原地修改原列表（并返回 None 以避免混淆）。往往不如 sorted()\n方便——但若不需原列表，用它会略高效些。\n>>> a = [5, 2, 3, 1, 4]\n>>> a.sort()\n>>> a\n[1, 2, 3, 4, 5]\n另一个区别是 list.sort() 方法只为列表定义，而 sorted() 函数接受任何可迭代对象。\n>>> sorted({1: 'D', 2: 'B', 3: 'B', 4: 'E', 5: 'A'})\n[1, 2, 3, 4, 5]\n键函数\nlist.sort() 方法以及 sorted(), min(), max(), heapq.nsmallest() 和 heapq.nlargest() 等函\n数都有一个 key 形参用以指定要在进行比较之前对每个列表元素调用的函数（或其它可调用对\n象）。\n例如，下面是使用 str.casefold() 进行不区分大小写的字符串比较：\n>>> sorted(\"This is a test string from Andrew\".split(), key=str.casefold)\n['a', 'Andrew', 'from', 'is', 'string', 'test', 'This']\nkey 形参的值需为一元函数（或其它可调用对象），其返回值用于排序。这很快，因为键函数只需在\n输入的每个记录上调用恰好一次。\n常见的模式是用对象的某一些索引作为键对复杂对象排序。例如：\n>>> student_tuples = [\n... ('john', 'A', 15),\n\n| 排序的技术\n作者: Andrew Dalke 与 Raymond Hettinger\n内置列表方法 list.sort() 原地修改列表，而内置函数 sorted() 由可迭代对象新建有序列表。\n在本文档中，我们将探索使用 Python 对数据进行排序的各种技术。\n排序的基础知识\n普通的升序排序非常容易：只需调用 sorted() 函数。它返回新有序列表： |\n| --- |\n| >>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5] |\n| 亦可用 list.sort() 方法。它原地修改原列表（并返回 None 以避免混淆）。往往不如 sorted()\n方便——但若不需原列表，用它会略高效些。 |\n| >>> a = [5, 2, 3, 1, 4]\n>>> a.sort()\n>>> a\n[1, 2, 3, 4, 5] |\n| 另一个区别是 list.sort() 方法只为列表定义，而 sorted() 函数接受任何可迭代对象。 |\n| >>> sorted({1: 'D', 2: 'B', 3: 'B', 4: 'E', 5: 'A'})\n[1, 2, 3, 4, 5] |\n| 键函数\nlist.sort() 方法以及 sorted(), min(), max(), heapq.nsmallest() 和 heapq.nlargest() 等函\n数都有一个 key 形参用以指定要在进行比较之前对每个列表元素调用的函数（或其它可调用对\n象）。\n例如，下面是使用 str.casefold() 进行不区分大小写的字符串比较： |\n| >>> sorted(\"This is a test string from Andrew\".split(), key=str.casefold)\n['a', 'Andrew', 'from', 'is', 'string', 'test', 'This'] |\n| key 形参的值需为一元函数（或其它可调用对象），其返回值用于排序。这很快，因为键函数只需在\n输入的每个记录上调用恰好一次。\n常见的模式是用对象的某一些索引作为键对复杂对象排序。例如： |\n| >>> student_tuples = [\n... ('john', 'A', 15), |\n\n... ('jane', 'B', 12),\n... ('dave', 'B', 10),\n... ]\n>>> sorted(student_tuples, key=lambda student: student[2]) # 按年龄排序\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]\n同样的方法对于有具名属性的对象也适用。例如：\n>>> class Student:\n... def __init__(self, name, grade, age):\n... self.name = name\n... self.grade = grade\n... self.age = age\n... def __repr__(self):\n... return repr((self.name, self.grade, self.age))\n>>> student_objects = [\n... Student('john', 'A', 15),\n... Student('jane', 'B', 12),\n... Student('dave', 'B', 10),\n... ]\n>>> sorted(student_objects, key=lambda student: student.age) # 按年龄排序\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]\n有具名属性的对象可像上面这样用一个常规的类来创建，亦可是 dataclass 实例或 named tuple。\n运算符模块的函数与函数的偏求值\n上述 key function 模式相当常见，为了让访问器函数更加好写好用，Python 提供了一些便捷函数。\noperator 模块里有 itemgetter()、attrgetter() 和 methodcaller() 函数。\n用了那些函数之后，前面的示例变得更简单，运行起来也更快：\n>>> from operator import itemgetter, attrgetter\n>>> sorted(student_tuples, key=itemgetter(2))\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]\n>>> sorted(student_objects, key=attrgetter('age'))\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]\n运算符模块的函数可以用来作多级排序。例如，按 grade 排序，然后按 age 排序：\n>>> sorted(student_tuples, key=itemgetter(1,2))\n[('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)]\n>>> sorted(student_objects, key=attrgetter('grade', 'age'))\n[('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)]\n另一个有助于创建键函数的工具位于 functools 模块。partial() 函数可以降低多元函数的 元数\n使之适合做键函数。\n>>> from functools import partial\n>>> from unicodedata import normalize\n\n|  | ... ('jane', 'B', 12),\n... ('dave', 'B', 10),\n... ]\n>>> sorted(student_tuples, key=lambda student: student[2]) # 按年龄排序\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)] |  |\n| --- | --- | --- |\n|  | 同样的方法对于有具名属性的对象也适用。例如： |  |\n|  | >>> class Student:\n... def __init__(self, name, grade, age):\n... self.name = name\n... self.grade = grade\n... self.age = age\n... def __repr__(self):\n... return repr((self.name, self.grade, self.age))\n>>> student_objects = [\n... Student('john', 'A', 15),\n... Student('jane', 'B', 12),\n... Student('dave', 'B', 10),\n... ]\n>>> sorted(student_objects, key=lambda student: student.age) # 按年龄排序\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)] |  |\n|  | 有具名属性的对象可像上面这样用一个常规的类来创建，亦可是 dataclass 实例或 named tuple。\n运算符模块的函数与函数的偏求值\n上述 key function 模式相当常见，为了让访问器函数更加好写好用，Python 提供了一些便捷函数。\noperator 模块里有 itemgetter()、attrgetter() 和 methodcaller() 函数。\n用了那些函数之后，前面的示例变得更简单，运行起来也更快： |  |\n|  | >>> from operator import itemgetter, attrgetter\n>>> sorted(student_tuples, key=itemgetter(2))\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]\n>>> sorted(student_objects, key=attrgetter('age'))\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)] |  |\n|  | 运算符模块的函数可以用来作多级排序。例如，按 grade 排序，然后按 age 排序： |  |\n|  | >>> sorted(student_tuples, key=itemgetter(1,2))\n[('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)]\n>>> sorted(student_objects, key=attrgetter('grade', 'age'))\n[('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)] |  |\n|  | 另一个有助于创建键函数的工具位于 functools 模块。partial() 函数可以降低多元函数的 元数\n使之适合做键函数。 |  |\n|  | >>> from functools import partial\n>>> from unicodedata import normalize |  |\n\n>>> names = 'Zoë Åbjørn Núñez Élana Zeke Abe Nubia Eloise'.split()\n>>> sorted(names, key=partial(normalize, 'NFD'))\n['Abe', 'Åbjørn', 'Eloise', 'Élana', 'Nubia', 'Núñez', 'Zeke', 'Zoë']\n>>> sorted(names, key=partial(normalize, 'NFC'))\n['Abe', 'Eloise', 'Nubia', 'Núñez', 'Zeke', 'Zoë', 'Åbjørn', 'Élana']\n升序与降序\nlist.sort() 和 sorted() 接受布尔形参 reverse 用于标记降序排序。例如，将学生数据按 age 倒\n序排序：\n>>> sorted(student_tuples, key=itemgetter(2), reverse=True)\n[('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]\n>>> sorted(student_objects, key=attrgetter('age'), reverse=True)\n[('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]\n排序稳定性与复杂排序\n排序保证 稳定：等键记录保持原始顺序。\n>>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]\n>>> sorted(data, key=itemgetter(0))\n[('blue', 1), ('blue', 2), ('red', 1), ('red', 2)]\n注意 blue 的两个记录是如何保序的：('blue', 1) 保证先于 ('blue', 2)。\n这个了不起的特性使得借助一系列排序步骤构建出复杂排序成为可能。例如，要按 grade 降序后 age\n升序排序学生数据，只需先用 age 排序再用 grade 排序即可：\n>>> s = sorted(student_objects, key=attrgetter('age')) # 根据次要键（年龄）排序\n>>> sorted(s, key=attrgetter('grade'), reverse=True) # 现在根据主要键（成绩）\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)\n可抽象为包装函数，依据接收的一些字段序的元组对接收的列表做多趟排序。\n>>> def multisort(xs, specs):\n... for key, reverse in reversed(specs):\n... xs.sort(key=attrgetter(key), reverse=reverse)\n... return xs\n>>> multisort(list(student_objects), (('grade', True), ('age', False)))\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]\nPython 中曾用的 Timsort 算法借助数据集中任何已有的有序性来高效进行多种排序。\n装饰-排序-去装饰\n装饰-排序-去装饰 (Decorate-Sort-Undecorate) 得名于它的三个步骤：\n\n|  | >>> names = 'Zoë Åbjørn Núñez Élana Zeke Abe Nubia Eloise'.split()\n>>> sorted(names, key=partial(normalize, 'NFD'))\n['Abe', 'Åbjørn', 'Eloise', 'Élana', 'Nubia', 'Núñez', 'Zeke', 'Zoë']\n>>> sorted(names, key=partial(normalize, 'NFC'))\n['Abe', 'Eloise', 'Nubia', 'Núñez', 'Zeke', 'Zoë', 'Åbjørn', 'Élana'] |  |  |\n| --- | --- | --- | --- |\n|  | 升序与降序\nlist.sort() 和 sorted() 接受布尔形参 reverse 用于标记降序排序。例如，将学生数据按 age 倒\n序排序： |  |  |\n|  | >>> sorted(student_tuples, key=itemgetter(2), reverse=True)\n[('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]\n>>> sorted(student_objects, key=attrgetter('age'), reverse=True)\n[('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)] |  |  |\n|  | 排序稳定性与复杂排序\n排序保证 稳定：等键记录保持原始顺序。 |  |  |\n|  | >>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]\n>>> sorted(data, key=itemgetter(0))\n[('blue', 1), ('blue', 2), ('red', 1), ('red', 2)] |  |  |\n|  | 注意 blue 的两个记录是如何保序的：('blue', 1) 保证先于 ('blue', 2)。\n这个了不起的特性使得借助一系列排序步骤构建出复杂排序成为可能。例如，要按 grade 降序后 age\n升序排序学生数据，只需先用 age 排序再用 grade 排序即可： |  |  |\n|  | >>> s = sorted(student_objects, key=attrgetter('age')) # 根据次要键（年龄）排序\n>>> sorted(s, key=attrgetter('grade'), reverse=True) # 现在根据主要键（成绩）\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15) |  |  |\n|  | 可抽象为包装函数，依据接收的一些字段序的元组对接收的列表做多趟排序。 |  |  |\n|  | >>> def multisort(xs, specs):\n... for key, reverse in reversed(specs):\n... xs.sort(key=attrgetter(key), reverse=reverse)\n... return xs\n>>> multisort(list(student_objects), (('grade', True), ('age', False)))\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)] |  |  |\n|  | Python 中曾用的 Timsort 算法借助数据集中任何已有的有序性来高效进行多种排序。\n装饰-排序-去装饰\n装饰-排序-去装饰 (Decorate-Sort-Undecorate) 得名于它的三个步骤： |  |  |\n\n首先，用控制排序顺序的新值装饰初始列表。\n其次，排序装饰后的列表。\n最后，去除装饰即得按新顺序排列的初始值的列表。\n例如，用 DSU 方法按 grade 排序学生数据：\n>>> decorated = [(student.grade, i, student) for i, student in enumerate(student_o\n>>> decorated.sort()\n>>> [student for grade, i, student in decorated] # 取消装饰\n[('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]\n这方法语有效是因为元组按字典顺序进行比较，先比较第一项；如果它们相同则比较第二个项目，\n依此类推。\n不一定在所有情况下都要在装饰列表中包含索引 i ，但包含它有两个好处：\n排序是稳定的——如果两个项具有相同的键，它们的顺序将保留在排序列表中。\n原始项目不必具有可比性，因为装饰元组的排序最多由前两项决定。 因此，例如原始列表可能包\n含无法直接排序的复数。\n这个方法的另一个名字是 Randal L. Schwartz 在 Perl 程序员中推广的 Schwartzian transform。\n既然 Python 排序提供了键函数，那么通常不需要这种技术。\n比较函数\n与返回一个用于排序的绝对值的键函数不同，比较函数是计算两个输入的相对排序。\n例如，一个 天平 会比较两个样本并给出一个相对排序：较轻、相等或较重。 类似地，一个比较函数\n如 cmp(a, b) 将返回一个负值表示小于，零表示相等，或是一个正值表示大于。\n当从其他语言转写算法时经常会遇到比较函数。 此外，某些库也提供了比较函数作为其 API 的组成\n部分。 例如，locale.strcoll() 就是一个比较函数。\n为了适应这些情况，Python 提供了 functools.cmp_to_key 用来包装比较函数使其可以作为键函数\n来使用:\nsorted(words, key=cmp_to_key(strcoll)) # 基于地区的排序规则\n不可排序类型和值的策略\n在排序时可能出现多种涉及类型和值的问题。 下面是一些有助于解决问题的策略：\n在排序之前将不可比较的输入类型转换为字符串。\n>>> data = ['twelve', '11', 10]\n>>> sorted(map(str, data))\n['10', '11', 'twelve']\n\n|  | 首先，用控制排序顺序的新值装饰初始列表。\n其次，排序装饰后的列表。\n最后，去除装饰即得按新顺序排列的初始值的列表。\n例如，用 DSU 方法按 grade 排序学生数据： |  |  |\n| --- | --- | --- | --- |\n|  | >>> decorated = [(student.grade, i, student) for i, student in enumerate(student_o\n>>> decorated.sort()\n>>> [student for grade, i, student in decorated] # 取消装饰\n[('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)] |  |  |\n|  | 这方法语有效是因为元组按字典顺序进行比较，先比较第一项；如果它们相同则比较第二个项目，\n依此类推。\n不一定在所有情况下都要在装饰列表中包含索引 i ，但包含它有两个好处：\n排序是稳定的——如果两个项具有相同的键，它们的顺序将保留在排序列表中。\n原始项目不必具有可比性，因为装饰元组的排序最多由前两项决定。 因此，例如原始列表可能包\n含无法直接排序的复数。\n这个方法的另一个名字是 Randal L. Schwartz 在 Perl 程序员中推广的 Schwartzian transform。\n既然 Python 排序提供了键函数，那么通常不需要这种技术。\n比较函数\n与返回一个用于排序的绝对值的键函数不同，比较函数是计算两个输入的相对排序。\n例如，一个 天平 会比较两个样本并给出一个相对排序：较轻、相等或较重。 类似地，一个比较函数\n如 cmp(a, b) 将返回一个负值表示小于，零表示相等，或是一个正值表示大于。\n当从其他语言转写算法时经常会遇到比较函数。 此外，某些库也提供了比较函数作为其 API 的组成\n部分。 例如，locale.strcoll() 就是一个比较函数。\n为了适应这些情况，Python 提供了 functools.cmp_to_key 用来包装比较函数使其可以作为键函数\n来使用: |  |  |\n|  | sorted(words, key=cmp_to_key(strcoll)) # 基于地区的排序规则 |  |  |\n|  | 不可排序类型和值的策略\n在排序时可能出现多种涉及类型和值的问题。 下面是一些有助于解决问题的策略：\n在排序之前将不可比较的输入类型转换为字符串。 |  |  |\n|  | >>> data = ['twelve', '11', 10]\n>>> sorted(map(str, data))\n['10', '11', 'twelve'] |  |  |\n|  |  |  |  |\n\n需要这样做是因为大多数跨类型比较都会引发 TypeError。\n在排序之前移除特殊的值：\n>>> from math import isnan\n>>> from itertools import filterfalse\n>>> data = [3.3, float('nan'), 1.1, 2.2]\n>>> sorted(filterfalse(isnan, data))\n[1.1, 2.2, 3.3]\n这是必要的，因为 IEEE-754标准 规定，“每一个NaN都应该与任何事物进行无序比较，包括它自\n身。”\n同样，None 也可以从数据集中剥离:\n>>> data = [3.3, None, 1.1, 2.2]\n>>> sorted(x for x in data if x is not None)\n[1.1, 2.2, 3.3]\n这是必需的，因为``None``与其他类型不具有可比性。\n在排序之前将映射类型转换为已排序的项列表：\n>>> data = [{'a': 1}, {'b': 2}]\n>>> sorted(data, key=lambda d: sorted(d.items()))\n[{'a': 1}, {'b': 2}]\n这是必需的，因为字典到字典的比较会引发 TypeError。\n在排序之前将集合类型转换为排序列表：\n>>> data = [{'a', 'b', 'c'}, {'b', 'c', 'd'}]\n>>> sorted(map(sorted, data))\n[['a', 'b', 'c'], ['b', 'c', 'd']]\n这是必需的，因为集合类型中包含的元素没有确定的顺序。例如,``list({'a', 'b'})``可以产生``['a', 'b']`` 或\n['b', 'a']。\n杂项说明\n对于可感知语言区域的排序，请使用 locale.strxfrm() 作为键函数或使用 locale.strcoll()\n作为比较函数。 因为在不同语言中即便字母表相同“字母”排列顺序也可能不同所以这样做是必要\n的。\nreverse 参数仍然保持排序稳定性（因此具有相等键的记录保留原始顺序）。 有趣的是，通过使用\n内置的 reversed() 函数两次，可以在没有参数的情况下模拟该效果：\n>>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]\n>>> standard_way = sorted(data, key=itemgetter(0), reverse=True)\n>>> double_reversed = list(reversed(sorted(reversed(data), key=itemgetter(0))))\n>>> assert standard_way == double_reversed\n\n|  | 需要这样做是因为大多数跨类型比较都会引发 TypeError。\n在排序之前移除特殊的值： |  |  |\n| --- | --- | --- | --- |\n|  | >>> from math import isnan\n>>> from itertools import filterfalse\n>>> data = [3.3, float('nan'), 1.1, 2.2]\n>>> sorted(filterfalse(isnan, data))\n[1.1, 2.2, 3.3] |  |  |\n|  | 这是必要的，因为 IEEE-754标准 规定，“每一个NaN都应该与任何事物进行无序比较，包括它自\n身。”\n同样，None 也可以从数据集中剥离: |  |  |\n|  | >>> data = [3.3, None, 1.1, 2.2]\n>>> sorted(x for x in data if x is not None)\n[1.1, 2.2, 3.3] |  |  |\n|  | 这是必需的，因为``None``与其他类型不具有可比性。\n在排序之前将映射类型转换为已排序的项列表： |  |  |\n|  | >>> data = [{'a': 1}, {'b': 2}]\n>>> sorted(data, key=lambda d: sorted(d.items()))\n[{'a': 1}, {'b': 2}] |  |  |\n|  | 这是必需的，因为字典到字典的比较会引发 TypeError。\n在排序之前将集合类型转换为排序列表： |  |  |\n|  | >>> data = [{'a', 'b', 'c'}, {'b', 'c', 'd'}]\n>>> sorted(map(sorted, data))\n[['a', 'b', 'c'], ['b', 'c', 'd']] |  |  |\n|  | 这是必需的，因为集合类型中包含的元素没有确定的顺序。例如,``list({'a', 'b'})``可以产生``['a', 'b']`` 或\n['b', 'a']。\n杂项说明\n对于可感知语言区域的排序，请使用 locale.strxfrm() 作为键函数或使用 locale.strcoll()\n作为比较函数。 因为在不同语言中即便字母表相同“字母”排列顺序也可能不同所以这样做是必要\n的。\nreverse 参数仍然保持排序稳定性（因此具有相等键的记录保留原始顺序）。 有趣的是，通过使用\n内置的 reversed() 函数两次，可以在没有参数的情况下模拟该效果：\n>>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]\n>>> standard_way = sorted(data, key=itemgetter(0), reverse=True)\n>>> double_reversed = list(reversed(sorted(reversed(data), key=itemgetter(0))))\n>>> assert standard_way == double_reversed |  |  |\n|  |  | >>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]\n>>> standard_way = sorted(data, key=itemgetter(0), reverse=True)\n>>> double_reversed = list(reversed(sorted(reversed(data), key=itemgetter(0))))\n>>> assert standard_way == double_reversed |  |\n|  |  |  |  |\n\n>>> standard_way\n[('red', 1), ('red', 2), ('blue', 1), ('blue', 2)]\n排序例程在两个对象之间进行比较时使用 <。 因此，通过定义一个 __lt__() 方法，就可以轻松\n地为类添加标准排序顺序:\n>>> Student.__lt__ = lambda self, other: self.age < other.age\n>>> sorted(student_objects)\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]\n不过，请注意 < 在 __lt__() 未被实现时可以回退为使用 __gt__() (请参阅 object.__lt__()\n了解相关机制的细节)。 为避免意外，PEP 8 建议实现所有的六个比较方法。 total_ordering()\n装饰器被提供用来令此任务更为容易。\n键函数不需要直接依赖于被排序的对象。键函数还可以访问外部资源。例如，如果学生成绩存储\n在字典中，则可以使用它们对单独的学生姓名列表进行排序：\n>>> students = ['dave', 'john', 'jane']\n>>> newgrades = {'john': 'F', 'jane':'A', 'dave': 'C'}\n>>> sorted(students, key=newgrades.__getitem__)\n['jane', 'dave', 'john']\n部分排序\n有些应用程序只需要对部分数据进行排序。 标准库提供了几种工具可以执行比完整排序更轻量的任\n务：\nmin() 和 max() 可分别返回最小和最大值。 这两个函数只需逐一检查输入数据而几乎不需要任何\n额外的内存。\nheapq.nsmallest() 和 heapq.nlargest() 可分别返回 n 个最小和最大的值。 这两个函数每次\n只需逐一检查数据并仅需在内存中保留 n 个元素。 对于相对于输入总数来说较小的 n 值来说，这\n两个函数将进行远少于完整排序的比较。\nheapq.heappush() 和 heapq.heappop() 会创建并维护一组部分排序的数据其中最小的元素将处\n在 0 位置上。 这两个函数很适合实现常用于任务调度的优先级队列。\n\n| >>> standard_way\n[('red', 1), ('red', 2), ('blue', 1), ('blue', 2)]\n排序例程在两个对象之间进行比较时使用 <。 因此，通过定义一个 __lt__() 方法，就可以轻松\n地为类添加标准排序顺序:\n>>> Student.__lt__ = lambda self, other: self.age < other.age\n>>> sorted(student_objects)\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]\n不过，请注意 < 在 __lt__() 未被实现时可以回退为使用 __gt__() (请参阅 object.__lt__()\n了解相关机制的细节)。 为避免意外，PEP 8 建议实现所有的六个比较方法。 total_ordering()\n装饰器被提供用来令此任务更为容易。\n键函数不需要直接依赖于被排序的对象。键函数还可以访问外部资源。例如，如果学生成绩存储\n在字典中，则可以使用它们对单独的学生姓名列表进行排序：\n>>> students = ['dave', 'john', 'jane']\n>>> newgrades = {'john': 'F', 'jane':'A', 'dave': 'C'}\n>>> sorted(students, key=newgrades.__getitem__)\n['jane', 'dave', 'john']\n部分排序\n有些应用程序只需要对部分数据进行排序。 标准库提供了几种工具可以执行比完整排序更轻量的任\n务：\nmin() 和 max() 可分别返回最小和最大值。 这两个函数只需逐一检查输入数据而几乎不需要任何\n额外的内存。\nheapq.nsmallest() 和 heapq.nlargest() 可分别返回 n 个最小和最大的值。 这两个函数每次\n只需逐一检查数据并仅需在内存中保留 n 个元素。 对于相对于输入总数来说较小的 n 值来说，这\n两个函数将进行远少于完整排序的比较。\nheapq.heappush() 和 heapq.heappop() 会创建并维护一组部分排序的数据其中最小的元素将处\n在 0 位置上。 这两个函数很适合实现常用于任务调度的优先级队列。 | >>> standard_way\n[('red', 1), ('red', 2), ('blue', 1), ('blue', 2)] |\n| --- | --- |\n|  | 排序例程在两个对象之间进行比较时使用 <。 因此，通过定义一个 __lt__() 方法，就可以轻松\n地为类添加标准排序顺序: |\n|  | >>> Student.__lt__ = lambda self, other: self.age < other.age |\n|  | >>> sorted(student_objects)\n[('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)] |", "metadata": {"title": "11_排序的技术", "source": "md_docs\\python_howto_md\\11_排序的技术.md", "doc_type": "指南", "language": "中文", "doc_id": "0d0cce3d"}}
{"doc_id": "da5fbc71", "content": "Unicode 指南\n发布版本: 1.12\n本文介绍了 Python 对表示文本数据的 Unicode 规范的支持，并对各种 Unicode 常见使用问题做了\n解释。\nUnicode 概述\n定义\n如今的程序需要能够处理各种各样的字符。应用程序通常做了国际化处理，用户可以选择不同的语\n言显示信息和输出数据。同一个程序可能需要以英语、法语、日语、希伯来语或俄语输出错误信\n息。网页内容可能由这些语言书写，并且可能包含不同的表情符号。Python 的字符串类型采用\nUnicode 标准来表示字符，使得 Python 程序能够正常处理所有这些不同的字符。\nUnicode 规范（https://www.unicode.org/）旨在罗列人类语言所用到的所有字符，并赋予每个字符\n唯一的编码。该规范一直在进行修订和更新，不断加入新的语种和符号。\n一个 字符 是文本的最小组件。‘A’、‘B’、‘C’ 等都是不同的字符。‘È’ 和 ‘Í’ 也一样。字符会随着语言或\n者上下文的变化而变化。比如，‘Ⅰ’ 是一个表示 “罗马数字 1” 的字符，它与大写字母 ‘I’ 不同。他们\n往往看起来相同，但这是两个有着不同含义的字符。\nUnicode 标准描述了字符是如何用 码位（code point） 表示的。码位的取值范围是 0 到 0x10FFFF\n的整数（大约 110 万个值，实际分配的数字 没有那么多）。在 Unicode 标准和本文中，码位采用\nU+265E 的形式，表示值为 0x265e 的字符（十进制为 9822）。\nUnicode 标准中包含了许多表格，列出了很多字符及其对应的码位。\n0061 'a'; 拉丁字母 A 小写\n0062 'b'; 拉丁字母 B 小写\n0063 'c'; 拉丁字母 C 小写\n...\n007B '{'; 左花括号\n...\n2167 'Ⅷ'; 罗马数字八\n2168 'Ⅸ'; 罗马数字九\n...\n265E '♞'; 国际象棋黑马\n265F '♟'; 国际象棋黑兵\n...\n1F600 '😀'; 微笑脸\n1F609 '😉'; 眨眼脸\n...\n严格地说，上述定义暗示了以下说法是没有意义的：“这是字符 U+265E”。U+265E 只是一个码位，\n代表某个特定的字符；这里它代表了字符 “国际象棋黑骑士” '♞'。在非正式的上下文中，有时会忽略\n\n| Unicode 指南\n发布版本: 1.12\n本文介绍了 Python 对表示文本数据的 Unicode 规范的支持，并对各种 Unicode 常见使用问题做了\n解释。\nUnicode 概述\n定义\n如今的程序需要能够处理各种各样的字符。应用程序通常做了国际化处理，用户可以选择不同的语\n言显示信息和输出数据。同一个程序可能需要以英语、法语、日语、希伯来语或俄语输出错误信\n息。网页内容可能由这些语言书写，并且可能包含不同的表情符号。Python 的字符串类型采用\nUnicode 标准来表示字符，使得 Python 程序能够正常处理所有这些不同的字符。\nUnicode 规范（https://www.unicode.org/）旨在罗列人类语言所用到的所有字符，并赋予每个字符\n唯一的编码。该规范一直在进行修订和更新，不断加入新的语种和符号。\n一个 字符 是文本的最小组件。‘A’、‘B’、‘C’ 等都是不同的字符。‘È’ 和 ‘Í’ 也一样。字符会随着语言或\n者上下文的变化而变化。比如，‘Ⅰ’ 是一个表示 “罗马数字 1” 的字符，它与大写字母 ‘I’ 不同。他们\n往往看起来相同，但这是两个有着不同含义的字符。\nUnicode 标准描述了字符是如何用 码位（code point） 表示的。码位的取值范围是 0 到 0x10FFFF\n的整数（大约 110 万个值，实际分配的数字 没有那么多）。在 Unicode 标准和本文中，码位采用\nU+265E 的形式，表示值为 0x265e 的字符（十进制为 9822）。\nUnicode 标准中包含了许多表格，列出了很多字符及其对应的码位。 |\n| --- |\n| 0061 'a'; 拉丁字母 A 小写\n0062 'b'; 拉丁字母 B 小写\n0063 'c'; 拉丁字母 C 小写\n...\n007B '{'; 左花括号\n...\n2167 'Ⅷ'; 罗马数字八\n2168 'Ⅸ'; 罗马数字九\n...\n265E '♞'; 国际象棋黑马\n265F '♟'; 国际象棋黑兵\n...\n1F600 '😀'; 微笑脸\n1F609 '😉'; 眨眼脸\n... |\n| 严格地说，上述定义暗示了以下说法是没有意义的：“这是字符 U+265E”。U+265E 只是一个码位，\n代表某个特定的字符；这里它代表了字符 “国际象棋黑骑士” '♞'。在非正式的上下文中，有时会忽略 |\n\n码位和字符的区别。\n一个字符在屏幕或纸上被表示为一组图形元素，被称为 字形（glyph） 。比如，大写字母 A 的字\n形，是两笔斜线和一笔横线，而具体的细节取决于所使用的字体。大部分 Python 代码不必担心字\n形，找到正确的显示字形通常是交给 GUI 工具包或终端的字体渲染程序来完成。\n编码\n上一段可以归结为：一个 Unicode 字符串是一系列码位（从 0 到 0x10FFFF 或者说十进制的\n1,114,111 的数字）组成的序列。这一序列在内存中需被表示为一组 码元（code unit） ， 码元 会\n映射成包含八个二进制位的字节。将 Unicode 字符串翻译成字节序列的规则称为 字符编码 ，或者\n编码 。\n大家首先会想到的编码可能是用 32 位的整数作为代码位，然后采用 CPU 对 32 位整数的表示法。字\n符串 “Python” 用这种表示法可能会如下所示：\nP y t h o n\n0x50 00 00 00 79 00 00 00 74 00 00 00 68 00 00 00 6f 00 00 00 6e 00 00 00\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n这种表示法非常直白，但也存在 一些问题。\n1. 不具可移植性；不同的处理器的字节序不同。\n2. 非常浪费空间。 在大多数文本中，大部分码位都小于 127 或 255，因此字节 0x00 占用了大\n量空间。相较于 ASCII 表示法所需的 6 个字节，以上字符串需要占用 24 个字节。RAM 用量\n的增加没那么要紧（台式计算机有成 GB 的 RAM，而字符串通常不会有那么大），但要把磁\n盘和网络带宽的用量增加 4 倍是无法忍受的。\n3. 与现有的 C 函数（如 strlen() ）不兼容，因此需要采用一套新的宽字符串函数。\n因此这种编码用得不多，人们转而选择其他更高效、更方便的编码，比如 UTF-8。\nUTF-8 是最常用的编码之一，Python 往往默认会采用它。UTF 代表“Unicode Transformation\nFormat”，'8' 表示编码采用 8 位数。（UTF-16 和 UTF-32 编码也是存在的，但其使用频率不如 UTF-\n8。）UTF-8 的规则如下：\n1. 如果码位 < 128，则直接用对应的字节值表示。\n2. 如果码位 >= 128，则转换为 2、3、4 个字节的序列，每个字节值都位于 128 和 255 之间。\nUTF-8 有几个很方便的特性：\n1. 可以处理任何 Unicode 码位。\n2. Unicode 字符串被转换为一个字节序列，仅在表示空（null ）字符（U+0000）时才会包含零\n值的字节。这意味着 strcpy() 之类的C 函数可以处理 UTF-8 字符串，而且用那些不能处理\n字符串结束符之外的零值字节的协议也能发送。\n3. ASCII 字符串也是也是也是合法的 UTF-8 文本。\n4. UTF-8 相当紧凑；大多数常用字符均可用一两个字节表示。\n5. 如果字节数据被损坏或丢失，则可以找出下一个 UTF-8 码点的开始位置并重新开始同步。随\n机的 8 位数据也不太可能像是有效的 UTF-8 编码。\n\n|  | 码位和字符的区别。\n一个字符在屏幕或纸上被表示为一组图形元素，被称为 字形（glyph） 。比如，大写字母 A 的字\n形，是两笔斜线和一笔横线，而具体的细节取决于所使用的字体。大部分 Python 代码不必担心字\n形，找到正确的显示字形通常是交给 GUI 工具包或终端的字体渲染程序来完成。\n编码\n上一段可以归结为：一个 Unicode 字符串是一系列码位（从 0 到 0x10FFFF 或者说十进制的\n1,114,111 的数字）组成的序列。这一序列在内存中需被表示为一组 码元（code unit） ， 码元 会\n映射成包含八个二进制位的字节。将 Unicode 字符串翻译成字节序列的规则称为 字符编码 ，或者\n编码 。\n大家首先会想到的编码可能是用 32 位的整数作为代码位，然后采用 CPU 对 32 位整数的表示法。字\n符串 “Python” 用这种表示法可能会如下所示： |  |\n| --- | --- | --- |\n|  | P y t h o n\n0x50 00 00 00 79 00 00 00 74 00 00 00 68 00 00 00 6f 00 00 00 6e 00 00 00\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 |  |\n|  | 这种表示法非常直白，但也存在 一些问题。\n1. 不具可移植性；不同的处理器的字节序不同。\n2. 非常浪费空间。 在大多数文本中，大部分码位都小于 127 或 255，因此字节 0x00 占用了大\n量空间。相较于 ASCII 表示法所需的 6 个字节，以上字符串需要占用 24 个字节。RAM 用量\n的增加没那么要紧（台式计算机有成 GB 的 RAM，而字符串通常不会有那么大），但要把磁\n盘和网络带宽的用量增加 4 倍是无法忍受的。\n3. 与现有的 C 函数（如 strlen() ）不兼容，因此需要采用一套新的宽字符串函数。\n因此这种编码用得不多，人们转而选择其他更高效、更方便的编码，比如 UTF-8。\nUTF-8 是最常用的编码之一，Python 往往默认会采用它。UTF 代表“Unicode Transformation\nFormat”，'8' 表示编码采用 8 位数。（UTF-16 和 UTF-32 编码也是存在的，但其使用频率不如 UTF-\n8。）UTF-8 的规则如下：\n1. 如果码位 < 128，则直接用对应的字节值表示。\n2. 如果码位 >= 128，则转换为 2、3、4 个字节的序列，每个字节值都位于 128 和 255 之间。\nUTF-8 有几个很方便的特性：\n1. 可以处理任何 Unicode 码位。\n2. Unicode 字符串被转换为一个字节序列，仅在表示空（null ）字符（U+0000）时才会包含零\n值的字节。这意味着 strcpy() 之类的C 函数可以处理 UTF-8 字符串，而且用那些不能处理\n字符串结束符之外的零值字节的协议也能发送。\n3. ASCII 字符串也是也是也是合法的 UTF-8 文本。\n4. UTF-8 相当紧凑；大多数常用字符均可用一两个字节表示。\n5. 如果字节数据被损坏或丢失，则可以找出下一个 UTF-8 码点的开始位置并重新开始同步。随\n机的 8 位数据也不太可能像是有效的 UTF-8 编码。 |  |\n\n6. UTF-8 是一种面向字节的编码。编码规定了每个字符由一个或多个字节的序列表示。这避免了\n整数和双字节编码（如 UTF-16 和 UTF-32）可能出现的字节顺序问题，那时的字节序列会因\n执行编码的硬件而异。\n参考文献\nUnicode Consortium 站点 包含 Unicode 规范的字符图表、词汇表和 PDF 版本。请做好准备，有些\n内容读起来有点难度。该网站上还提供了 Unicode 起源和发展的 年表 。\n在 Computerphile 的 Youtube 频道上，Tom Scott 简要地 讨论了 Unicode 和 UTF-8 （9 分 36 秒）\n的历史。\n为了帮助理解该标准，Jukka Korpela 编写了阅读 Unicode 字符表的 介绍性指南 。\nJoel Spolsky 撰写了另一篇不错的介绍性文章 <https://www.joelonsoftware.com/2003/10/08/the-\nabsolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-\nand-character- set-no-excuses/>`_ 。如果本文没让您弄清楚，那应在继续之前先试着读读这篇文\n章。\nWikipedia 条目通常也有帮助；请参阅“字符编码”和 UTF-8 的条目，例如：\nPython对Unicode的支持\n现在您已经了解了 Unicode 的基础知识，可以看下 Python 的 Unicode 特性。\n字符串类型\n从 Python 3.0 开始， str 类型包含了 Unicode 字符，这意味着用 \"unicode rocks!\"、'unicode\nrocks!' 或三重引号字符串语法创建的任何字符串都会存储为 Unicode。\nPython 源代码的默认编码是 UTF-8，因此可以直接在字符串中包含 Unicode 字符：\ntry:\nwith open('/tmp/input.txt', 'r') as f:\n...\nexcept OSError:\n# 'File not found' 错误消息。\nprint(\"Fichier non trouvé\")\n旁注：Python 3 还支持在标识符中使用 Unicode 字符：\nrépertoire = \"/tmp/records.log\"\nwith open(répertoire, \"w\") as f:\nf.write(\"test\\n\")\n如果无法在编辑器中输入某个字符，或出于某种原因想只保留 ASCII 编码的源代码，则还可以在字\n符串中使用转义序列。（根据系统的不同，可能会看到真的大写 Delta 字体而不是 u 转义符。）：\n>>> \"\\N{GREEK CAPITAL LETTER DELTA}\" # 使用字符名称\n'\\u0394'\n>>> \"\\u0394\" # 使用 16 比特位十六进制数值\n\n|  |  | 6. UTF-8 是一种面向字节的编码。编码规定了每个字符由一个或多个字节的序列表示。这避免了\n整数和双字节编码（如 UTF-16 和 UTF-32）可能出现的字节顺序问题，那时的字节序列会因\n执行编码的硬件而异。\n参考文献\nUnicode Consortium 站点 包含 Unicode 规范的字符图表、词汇表和 PDF 版本。请做好准备，有些\n内容读起来有点难度。该网站上还提供了 Unicode 起源和发展的 年表 。\n在 Computerphile 的 Youtube 频道上，Tom Scott 简要地 讨论了 Unicode 和 UTF-8 （9 分 36 秒）\n的历史。\n为了帮助理解该标准，Jukka Korpela 编写了阅读 Unicode 字符表的 介绍性指南 。\nJoel Spolsky 撰写了另一篇不错的介绍性文章 <https://www.joelonsoftware.com/2003/10/08/the-\nabsolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-\nand-character- set-no-excuses/>`_ 。如果本文没让您弄清楚，那应在继续之前先试着读读这篇文\n章。\nWikipedia 条目通常也有帮助；请参阅“字符编码”和 UTF-8 的条目，例如：\nPython对Unicode的支持\n现在您已经了解了 Unicode 的基础知识，可以看下 Python 的 Unicode 特性。\n字符串类型\n从 Python 3.0 开始， str 类型包含了 Unicode 字符，这意味着用 \"unicode rocks!\"、'unicode\nrocks!' 或三重引号字符串语法创建的任何字符串都会存储为 Unicode。\nPython 源代码的默认编码是 UTF-8，因此可以直接在字符串中包含 Unicode 字符： |  |  |  |\n| --- | --- | --- | --- | --- | --- |\n|  |  |  | 'unicode |  |  |\n|  |  |  |  |  |  |\n|  |  | rocks!' |  |  |  |\n|  |  |  |  |  |  |\n|  |  | try:\nwith open('/tmp/input.txt', 'r') as f:\n...\nexcept OSError:\n# 'File not found' 错误消息。\nprint(\"Fichier non trouvé\") |  |  |  |\n|  |  | 旁注：Python 3 还支持在标识符中使用 Unicode 字符： |  |  |  |\n|  |  | répertoire = \"/tmp/records.log\"\nwith open(répertoire, \"w\") as f:\nf.write(\"test\\n\") |  |  |  |\n|  |  | 如果无法在编辑器中输入某个字符，或出于某种原因想只保留 ASCII 编码的源代码，则还可以在字\n符串中使用转义序列。（根据系统的不同，可能会看到真的大写 Delta 字体而不是 u 转义符。）： |  |  |  |\n|  |  | >>> \"\\N{GREEK CAPITAL LETTER DELTA}\" # 使用字符名称\n'\\u0394'\n>>> \"\\u0394\" # 使用 16 比特位十六进制数值 |  |  |  |\n\n'\\u0394'\n>>> \"\\U00000394\" # 使用 32 比特位十六进制数值\n'\\u0394'\n此外，可以用 bytes 的 decode() 方法创建一个字符串。 该方法可以接受 encoding 参数，比如可\n以为 UTF-8 ，以及可选的 errors 参数。\n若无法根据编码规则对输入字符串进行编码，errors 参数指定了响应策略。 该参数的合法值可以是\n'strict' (触发 UnicodeDecodeError 异常)、'replace' (用 U+FFFD、REPLACEMENT\nCHARACTER)、'ignore' (只是将字符从 Unicode 结果中去掉)，或 'backslashreplace' (插入一个\n\\xNN 转义序列)。 以下示例演示了这些不同的参数:\n>>> b'\\x80abc'.decode(\"utf-8\", \"strict\")\nTraceback (most recent call last):\n...\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0:\ninvalid start byte\n>>> b'\\x80abc'.decode(\"utf-8\", \"replace\")\n'\\ufffdabc'\n>>> b'\\x80abc'.decode(\"utf-8\", \"backslashreplace\")\n'\\\\x80abc'\n>>> b'\\x80abc'.decode(\"utf-8\", \"ignore\")\n'abc'\n编码格式以包含编码格式名称的字符串来指明。 Python 有大约 100 种不同的编码格式；清单详见\nPython 库参考文档 标准编码。 一些编码格式有多个名称，比如 'latin-1'、'iso_8859_1' 和\n'8859 都是指同一种编码。\n利用内置函数 chr() 还可以创建单字符的 Unicode 字符串，该函数可接受整数参数，并返回包含对\n应码位的长度为 1 的 Unicode 字符串。内置函数 ord() 是其逆操作，参数为单个字符的 Unicode 字\n符串，并返回码位值：\n>>> chr(57344)\n'\\ue000'\n>>> ord('\\ue000')\n57344\n转换为字节\nbytes.decode() 的逆方法是 str.encode() ，它会返回 Unicode 字符串的 bytes 形式，已按要求\n的 encoding 进行了编码。\n参数 errors 的意义与 decode() 方法相同，但支持更多可能的handler。除了 'strict' 、\n'ignore' 和 'replace' （这时会插入问号替换掉无法编码的字符），还有 'xmlcharrefreplace'\n（插入一个 XML 字符引用）、 backslashreplace （插入一个 \\uNNNN 转义序列）和 namereplace\n（插入一个 \\N{...} 转义序列 ）。\n以下例子演示了各种不同的结果：\n>>> u = chr(40960) + 'abcd' + chr(1972)\n>>> u.encode('utf-8')\n\n|  |  | '\\u0394'\n>>> \"\\U00000394\" # 使用 32 比特位十六进制数值\n'\\u0394' |  |\n| --- | --- | --- | --- |\n|  |  | 此外，可以用 bytes 的 decode() 方法创建一个字符串。 该方法可以接受 encoding 参数，比如可\n以为 UTF-8 ，以及可选的 errors 参数。\n若无法根据编码规则对输入字符串进行编码，errors 参数指定了响应策略。 该参数的合法值可以是\n'strict' (触发 UnicodeDecodeError 异常)、'replace' (用 U+FFFD、REPLACEMENT\nCHARACTER)、'ignore' (只是将字符从 Unicode 结果中去掉)，或 'backslashreplace' (插入一个\n\\xNN 转义序列)。 以下示例演示了这些不同的参数: |  |\n|  |  |  |  |\n|  |  |  |  |\n|  |  | >>> b'\\x80abc'.decode(\"utf-8\", \"strict\")\nTraceback (most recent call last):\n...\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0:\ninvalid start byte\n>>> b'\\x80abc'.decode(\"utf-8\", \"replace\")\n'\\ufffdabc'\n>>> b'\\x80abc'.decode(\"utf-8\", \"backslashreplace\")\n'\\\\x80abc'\n>>> b'\\x80abc'.decode(\"utf-8\", \"ignore\")\n'abc' |  |\n|  |  | 编码格式以包含编码格式名称的字符串来指明。 Python 有大约 100 种不同的编码格式；清单详见\nPython 库参考文档 标准编码。 一些编码格式有多个名称，比如 'latin-1'、'iso_8859_1' 和\n'8859 都是指同一种编码。\n利用内置函数 chr() 还可以创建单字符的 Unicode 字符串，该函数可接受整数参数，并返回包含对\n应码位的长度为 1 的 Unicode 字符串。内置函数 ord() 是其逆操作，参数为单个字符的 Unicode 字\n符串，并返回码位值： |  |\n|  |  | >>> chr(57344)\n'\\ue000'\n>>> ord('\\ue000')\n57344 |  |\n|  |  | 转换为字节\nbytes.decode() 的逆方法是 str.encode() ，它会返回 Unicode 字符串的 bytes 形式，已按要求\n的 encoding 进行了编码。\n参数 errors 的意义与 decode() 方法相同，但支持更多可能的handler。除了 'strict' 、\n'ignore' 和 'replace' （这时会插入问号替换掉无法编码的字符），还有 'xmlcharrefreplace'\n（插入一个 XML 字符引用）、 backslashreplace （插入一个 \\uNNNN 转义序列）和 namereplace\n（插入一个 \\N{...} 转义序列 ）。\n以下例子演示了各种不同的结果： |  |\n|  |  | >>> u = chr(40960) + 'abcd' + chr(1972)\n>>> u.encode('utf-8') |  |\n\nb'\\xea\\x80\\x80abcd\\xde\\xb4'\n>>> u.encode('ascii')\nTraceback (most recent call last):\n...\nUnicodeEncodeError: 'ascii' codec can't encode character '\\ua000' in\nposition 0: ordinal not in range(128)\n>>> u.encode('ascii', 'ignore')\nb'abcd'\n>>> u.encode('ascii', 'replace')\nb'?abcd?'\n>>> u.encode('ascii', 'xmlcharrefreplace')\nb'&#40960;abcd&#1972;'\n>>> u.encode('ascii', 'backslashreplace')\nb'\\\\ua000abcd\\\\u07b4'\n>>> u.encode('ascii', 'namereplace')\nb'\\\\N{YI SYLLABLE IT}abcd\\\\u07b4'\n用于注册和访问可用编码格式的底层函数，位于 codecs 模块中。 若要实现新的编码格式，则还需\n要了解 codecs 模块。 不过该模块返回的编码和解码函数通常更为底层一些，不大好用，编写新的\n编码格式是一项专业的任务，因此本文不会涉及该模块。\nPython 源代码中的 Unicode 文字\n在 Python 源代码中，可以用 \\u 转义序列书写特定的 Unicode 码位，该序列后跟 4 个代表码位的十\n六进制数字。\\U 转义序列用法类似，但要用8 个十六进制数字，而不是 4 个：\n>>> s = \"a\\xac\\u1234\\u20ac\\U00008000\"\n... # ^^^^ 两位十六进制数转义\n... # ^^^^^^ 四位 Unicode 转义\n... # ^^^^^^^^^^ 八位 Unicode 转义\n>>> [ord(c) for c in s]\n[97, 172, 4660, 8364, 32768]\n对大于 127 的码位使用转义序列，数量不多时没什么问题，但如果要用到很多重音字符，这会变得\n很烦人，类似于程序中的信息是用法语或其他使用重音的语言写的。也可以用内置函数 chr() 拼装\n字符串，但会更加乏味。\n理想情况下，都希望能用母语的编码书写文本。还能用喜好的编辑器编辑 Python 源代码，编辑器要\n能自然地显示重音符，并在运行时使用正确的字符。\n默认情况下，Python 支持以 UTF-8 格式编写源代码，但如果声明要用的编码，则几乎可以使用任何\n编码。只要在源文件的第一行或第二行包含一个特殊注释即可：\n#!/usr/bin/env python\n# -*- coding: latin-1 -*-\nu = 'abcdé'\nprint(ord(u[-1]))\n上述语法的灵感来自于 Emacs 用于指定文件局部变量的符号。Emacs 支持许多不同的变量，但\nPython 仅支持“编码”。 -*- 符号向 Emacs 标明该注释是特殊的；这对 Python 没有什么意义，只是\n一种约定。Python 会在注释中查找 coding: name 或 coding=name 。\n\n|  | b'\\xea\\x80\\x80abcd\\xde\\xb4'\n>>> u.encode('ascii')\nTraceback (most recent call last):\n...\nUnicodeEncodeError: 'ascii' codec can't encode character '\\ua000' in\nposition 0: ordinal not in range(128)\n>>> u.encode('ascii', 'ignore')\nb'abcd'\n>>> u.encode('ascii', 'replace')\nb'?abcd?'\n>>> u.encode('ascii', 'xmlcharrefreplace')\nb'&#40960;abcd&#1972;'\n>>> u.encode('ascii', 'backslashreplace')\nb'\\\\ua000abcd\\\\u07b4'\n>>> u.encode('ascii', 'namereplace')\nb'\\\\N{YI SYLLABLE IT}abcd\\\\u07b4' |  |\n| --- | --- | --- |\n|  | 用于注册和访问可用编码格式的底层函数，位于 codecs 模块中。 若要实现新的编码格式，则还需\n要了解 codecs 模块。 不过该模块返回的编码和解码函数通常更为底层一些，不大好用，编写新的\n编码格式是一项专业的任务，因此本文不会涉及该模块。\nPython 源代码中的 Unicode 文字\n在 Python 源代码中，可以用 \\u 转义序列书写特定的 Unicode 码位，该序列后跟 4 个代表码位的十\n六进制数字。\\U 转义序列用法类似，但要用8 个十六进制数字，而不是 4 个： |  |\n|  | >>> s = \"a\\xac\\u1234\\u20ac\\U00008000\"\n... # ^^^^ 两位十六进制数转义\n... # ^^^^^^ 四位 Unicode 转义\n... # ^^^^^^^^^^ 八位 Unicode 转义\n>>> [ord(c) for c in s]\n[97, 172, 4660, 8364, 32768] |  |\n|  | 对大于 127 的码位使用转义序列，数量不多时没什么问题，但如果要用到很多重音字符，这会变得\n很烦人，类似于程序中的信息是用法语或其他使用重音的语言写的。也可以用内置函数 chr() 拼装\n字符串，但会更加乏味。\n理想情况下，都希望能用母语的编码书写文本。还能用喜好的编辑器编辑 Python 源代码，编辑器要\n能自然地显示重音符，并在运行时使用正确的字符。\n默认情况下，Python 支持以 UTF-8 格式编写源代码，但如果声明要用的编码，则几乎可以使用任何\n编码。只要在源文件的第一行或第二行包含一个特殊注释即可： |  |\n|  | #!/usr/bin/env python\n# -*- coding: latin-1 -*-\nu = 'abcdé'\nprint(ord(u[-1])) |  |\n|  | 上述语法的灵感来自于 Emacs 用于指定文件局部变量的符号。Emacs 支持许多不同的变量，但\nPython 仅支持“编码”。 -*- 符号向 Emacs 标明该注释是特殊的；这对 Python 没有什么意义，只是\n一种约定。Python 会在注释中查找 coding: name 或 coding=name 。 |  |\n\n如果没有这种注释，则默认编码将会是前面提到的 UTF-8。更多信息请参阅 PEP 263 。\nUnicode属性\nUnicode 规范包含了一个码位信息数据库。对于定义的每一个码位，都包含了字符的名称、类别、\n数值（对于表示数字概念的字符，如罗马数字、分数如三分之一和五分之四等）。还有有关显示的\n属性，比如如何在双向文本中使用码位。\n以下程序显示了几个字符的信息，并打印一个字符的数值：\nimport unicodedata\nu = chr(233) + chr(0x0bf2) + chr(3972) + chr(6000) + chr(13231)\nfor i, c in enumerate(u):\nprint(i, '%04x' % ord(c), unicodedata.category(c), end=\" \")\nprint(unicodedata.name(c))\n# 获取第二个字符的数值\nprint(unicodedata.numeric(u[1]))\n当运行时，这将打印出：\n0 00e9 Ll LATIN SMALL LETTER E WITH ACUTE\n1 0bf2 No TAMIL NUMBER ONE THOUSAND\n2 0f84 Mn TIBETAN MARK HALANTA\n3 1770 Lo TAGBANWA LETTER SA\n4 33af So SQUARE RAD OVER S SQUARED\n1000.0\n类别代码是描述字符性质的一个缩写。分为“字母”、“数字”、“标点符号”或“符号”等类别，而这些类\n别又分为子类别。就以上输出的代码而言，'Ll' 表示“字母，小写”，'No' 表示“数字，其他”，'Mn'\n表示“标记，非空白符” , 'So' 是“符号，其他”。有关类别代码的清单，请参阅 Unicode 字符库文档\n的“通用类别值”部分。\n字符串比较\nUnicode 让字符串的比较变得复杂了一些，因为同一组字符可能由不同的码位序列组成。例如，像\n“ê”这样的字母可以表示为单码位 U+00EA，或是 U+0065 U+0302，即“e”的码位后跟“COMBINING\nCIRCUMFLEX ACCENT”的码位。虽然在打印时会产生同样的输出，但一个是长度为 1 的字符串，另\n一个是长度为 2 的字符串。\n一种不区分大小写比较的工具是字符串方法 casefold() ，将按照 Unicode 标准描述的算法将字符\n串转换为不区分大小写的形式。该算法对诸如德语字母“ß”（代码点 U+00DF）之类的字符进行了特\n殊处理，变为一对小写字母“ss”。\n>>> street = 'Gürzenichstraße'\n>>> street.casefold()\n'gürzenichstrasse'\n\n|  | 如果没有这种注释，则默认编码将会是前面提到的 UTF-8。更多信息请参阅 PEP 263 。\nUnicode属性\nUnicode 规范包含了一个码位信息数据库。对于定义的每一个码位，都包含了字符的名称、类别、\n数值（对于表示数字概念的字符，如罗马数字、分数如三分之一和五分之四等）。还有有关显示的\n属性，比如如何在双向文本中使用码位。\n以下程序显示了几个字符的信息，并打印一个字符的数值： |  |\n| --- | --- | --- |\n|  | import unicodedata\nu = chr(233) + chr(0x0bf2) + chr(3972) + chr(6000) + chr(13231)\nfor i, c in enumerate(u):\nprint(i, '%04x' % ord(c), unicodedata.category(c), end=\" \")\nprint(unicodedata.name(c))\n# 获取第二个字符的数值\nprint(unicodedata.numeric(u[1])) |  |\n|  | 当运行时，这将打印出： |  |\n|  | 0 00e9 Ll LATIN SMALL LETTER E WITH ACUTE\n1 0bf2 No TAMIL NUMBER ONE THOUSAND\n2 0f84 Mn TIBETAN MARK HALANTA\n3 1770 Lo TAGBANWA LETTER SA\n4 33af So SQUARE RAD OVER S SQUARED\n1000.0 |  |\n|  | 类别代码是描述字符性质的一个缩写。分为“字母”、“数字”、“标点符号”或“符号”等类别，而这些类\n别又分为子类别。就以上输出的代码而言，'Ll' 表示“字母，小写”，'No' 表示“数字，其他”，'Mn'\n表示“标记，非空白符” , 'So' 是“符号，其他”。有关类别代码的清单，请参阅 Unicode 字符库文档\n的“通用类别值”部分。\n字符串比较\nUnicode 让字符串的比较变得复杂了一些，因为同一组字符可能由不同的码位序列组成。例如，像\n“ê”这样的字母可以表示为单码位 U+00EA，或是 U+0065 U+0302，即“e”的码位后跟“COMBINING\nCIRCUMFLEX ACCENT”的码位。虽然在打印时会产生同样的输出，但一个是长度为 1 的字符串，另\n一个是长度为 2 的字符串。\n一种不区分大小写比较的工具是字符串方法 casefold() ，将按照 Unicode 标准描述的算法将字符\n串转换为不区分大小写的形式。该算法对诸如德语字母“ß”（代码点 U+00DF）之类的字符进行了特\n殊处理，变为一对小写字母“ss”。 |  |\n|  | >>> street = 'Gürzenichstraße'\n>>> street.casefold()\n'gürzenichstrasse' |  |\n|  |  |  |\n\n第二个工具是 unicodedata 模块的 normalize() 函数，该函数可将字符串转换为几种规范化形式\n之一，即用单字符替换后面带一个组合字符的多个字母。 normalize() 可被用于执行字符串比较，\n如果两个字符串使用不同的组合字符，也不会错误地报告两者不相等:\nimport unicodedata\ndef compare_strs(s1, s2):\ndef NFD(s):\nreturn unicodedata.normalize('NFD', s)\nreturn NFD(s1) == NFD(s2)\nsingle_char = 'ê'\nmultiple_chars = '\\N{LATIN SMALL LETTER E}\\N{COMBINING CIRCUMFLEX ACCENT}'\nprint('length of first string=', len(single_char))\nprint('length of second string=', len(multiple_chars))\nprint(compare_strs(single_char, multiple_chars))\n当运行时，这将输出：\n$ python compare-strs.py\nlength of first string= 1\nlength of second string= 2\nTrue\nnormalize() 函数的第一个参数是个字符串，给出所需的规范化形式，可以是“NFC”、“NFKC”、\n“NFD”和“NFKD”之一。\nUnicode 标准还设定了如何进行不区分大小写的比较：\nimport unicodedata\ndef compare_caseless(s1, s2):\ndef NFD(s):\nreturn unicodedata.normalize('NFD', s)\nreturn NFD(NFD(s1).casefold()) == NFD(NFD(s2).casefold())\n# 使用示例\nsingle_char = 'ê'\nmultiple_chars = '\\N{LATIN CAPITAL LETTER E}\\N{COMBINING CIRCUMFLEX ACCENT}'\nprint(compare_caseless(single_char, multiple_chars))\n这将打印 True。 （为什么 NFD() 会两次被唤起？ 因为有几个字符会使 casefold() 返回非规范化\n的字符串，所以需要再次对结果进行规范化处理。 有关讨论和示例，请参阅 Unicode 标准第 3.13\n节）。\nUnicode 正则表达式\nre 模块支持的正则表达式可以用字节串或字符串的形式提供。有一些特殊字符序列，比如 \\d 和 \\w\n具有不同的含义，具体取决于匹配模式是以字节串还是字符串形式提供的。例如，\\d 将匹配字节串\n中的字符 [0-9] ，但对于字符串将会匹配 'Nd' 类别中的任何字符。\n\n|  | 第二个工具是 unicodedata 模块的 normalize() 函数，该函数可将字符串转换为几种规范化形式\n之一，即用单字符替换后面带一个组合字符的多个字母。 normalize() 可被用于执行字符串比较，\n如果两个字符串使用不同的组合字符，也不会错误地报告两者不相等: |  |\n| --- | --- | --- |\n|  | import unicodedata\ndef compare_strs(s1, s2):\ndef NFD(s):\nreturn unicodedata.normalize('NFD', s)\nreturn NFD(s1) == NFD(s2)\nsingle_char = 'ê'\nmultiple_chars = '\\N{LATIN SMALL LETTER E}\\N{COMBINING CIRCUMFLEX ACCENT}'\nprint('length of first string=', len(single_char))\nprint('length of second string=', len(multiple_chars))\nprint(compare_strs(single_char, multiple_chars)) |  |\n|  | 当运行时，这将输出： |  |\n|  | $ python compare-strs.py\nlength of first string= 1\nlength of second string= 2\nTrue |  |\n|  | normalize() 函数的第一个参数是个字符串，给出所需的规范化形式，可以是“NFC”、“NFKC”、\n“NFD”和“NFKD”之一。\nUnicode 标准还设定了如何进行不区分大小写的比较： |  |\n|  | import unicodedata\ndef compare_caseless(s1, s2):\ndef NFD(s):\nreturn unicodedata.normalize('NFD', s)\nreturn NFD(NFD(s1).casefold()) == NFD(NFD(s2).casefold())\n# 使用示例\nsingle_char = 'ê'\nmultiple_chars = '\\N{LATIN CAPITAL LETTER E}\\N{COMBINING CIRCUMFLEX ACCENT}'\nprint(compare_caseless(single_char, multiple_chars)) |  |\n|  | 这将打印 True。 （为什么 NFD() 会两次被唤起？ 因为有几个字符会使 casefold() 返回非规范化\n的字符串，所以需要再次对结果进行规范化处理。 有关讨论和示例，请参阅 Unicode 标准第 3.13\n节）。\nUnicode 正则表达式\nre 模块支持的正则表达式可以用字节串或字符串的形式提供。有一些特殊字符序列，比如 \\d 和 \\w\n具有不同的含义，具体取决于匹配模式是以字节串还是字符串形式提供的。例如，\\d 将匹配字节串\n中的字符 [0-9] ，但对于字符串将会匹配 'Nd' 类别中的任何字符。 |  |\n\n上述示例中的字符串包含了泰语和阿拉伯数字书写的数字 57：\nimport re\np = re.compile(r'\\d+')\ns = \"Over \\u0e55\\u0e57 57 flavours\"\nm = p.search(s)\nprint(repr(m.group()))\n执行时，\\d+ 将匹配上泰语数字并打印出来。如果向 compile() 提供的是 re.ASCII 标志，\\d+ 则\n会匹配子串 \"57\"。\n类似地，\\w 将匹配多种 Unicode 字符，但对于字节串则只会匹配 [a-zA-Z0-9_] ，如果指定\nre.ASCII ， \\s 将匹配 Unicode 空白符或 [ \\t\\n\\r\\f\\v] 。\n参考文献\n关于 Python 的 Unicode 支持，其他还有一些很好的讨论：\n用 Python 3 处理文本文件 ，作者 Nick Coghlan。\n实用的 Unicode，Ned Batchelder 在 PyCon 2012 上的演示。\nstr 类型在 Python 库参考文档 文本序列类型 --- str 中有介绍。\nunicodedata 模块的文档\ncodecs 模块的文档\nMarc-André Lemburg 在 EuroPython 2002 上做了一个题为“Python 和 Unicode”（PDF 幻灯片）\n<https://downloads.egenix.com/python/Unicode-EPC2002-Talk.pdf>`_ 的演示文稿。该幻灯片很好\n地概括了 Python 2 的 Unicode 功能设计（其中 Unicode 字符串类型称为 unicode，文字以 u 开\n头）。\nUnicode 数据的读写\n既然处理 Unicode 数据的代码写好了，下一个问题就是输入/输出了。如何将 Unicode 字符串读入程\n序，如何将 Unicode 转换为适于存储或传输的形式呢？\n根据输入源和输出目标的不同，或许什么都不用干；请检查一下应用程序用到的库是否原生支持\nUnicode。例如，XML 解析器往往会返回 Unicode 数据。许多关系数据库的字段也支持 Unicode\n值，并且 SQL 查询也能返回 Unicode 值。\n在写入磁盘或通过套接字发送之前，Unicode 数据通常要转换为特定的编码。可以自己完成所有工\n作：打开一个文件，从中读取一个 8 位字节对象，然后用 bytes.decode(encoding) 对字节串进行\n转换。但是，不推荐采用这种全人工的方案。\n编码的多字节特性就是一个难题； 一个 Unicode 字符可以用几个字节表示。 如果要以任意大小的块\n（例如 1024 或 4096 字节）读取文件，那么在块的末尾可能只读到某个 Unicode 字符的部分字节，\n这就需要编写错误处理代码。 有一种解决方案是将整个文件读入内存，然后进行解码，但这样就没\n\n|  | 上述示例中的字符串包含了泰语和阿拉伯数字书写的数字 57： |  |\n| --- | --- | --- |\n|  | import re\np = re.compile(r'\\d+')\ns = \"Over \\u0e55\\u0e57 57 flavours\"\nm = p.search(s)\nprint(repr(m.group())) |  |\n|  | 执行时，\\d+ 将匹配上泰语数字并打印出来。如果向 compile() 提供的是 re.ASCII 标志，\\d+ 则\n会匹配子串 \"57\"。\n类似地，\\w 将匹配多种 Unicode 字符，但对于字节串则只会匹配 [a-zA-Z0-9_] ，如果指定\nre.ASCII ， \\s 将匹配 Unicode 空白符或 [ \\t\\n\\r\\f\\v] 。\n参考文献\n关于 Python 的 Unicode 支持，其他还有一些很好的讨论：\n用 Python 3 处理文本文件 ，作者 Nick Coghlan。\n实用的 Unicode，Ned Batchelder 在 PyCon 2012 上的演示。\nstr 类型在 Python 库参考文档 文本序列类型 --- str 中有介绍。\nunicodedata 模块的文档\ncodecs 模块的文档\nMarc-André Lemburg 在 EuroPython 2002 上做了一个题为“Python 和 Unicode”（PDF 幻灯片）\n<https://downloads.egenix.com/python/Unicode-EPC2002-Talk.pdf>`_ 的演示文稿。该幻灯片很好\n地概括了 Python 2 的 Unicode 功能设计（其中 Unicode 字符串类型称为 unicode，文字以 u 开\n头）。\nUnicode 数据的读写\n既然处理 Unicode 数据的代码写好了，下一个问题就是输入/输出了。如何将 Unicode 字符串读入程\n序，如何将 Unicode 转换为适于存储或传输的形式呢？\n根据输入源和输出目标的不同，或许什么都不用干；请检查一下应用程序用到的库是否原生支持\nUnicode。例如，XML 解析器往往会返回 Unicode 数据。许多关系数据库的字段也支持 Unicode\n值，并且 SQL 查询也能返回 Unicode 值。\n在写入磁盘或通过套接字发送之前，Unicode 数据通常要转换为特定的编码。可以自己完成所有工\n作：打开一个文件，从中读取一个 8 位字节对象，然后用 bytes.decode(encoding) 对字节串进行\n转换。但是，不推荐采用这种全人工的方案。\n编码的多字节特性就是一个难题； 一个 Unicode 字符可以用几个字节表示。 如果要以任意大小的块\n（例如 1024 或 4096 字节）读取文件，那么在块的末尾可能只读到某个 Unicode 字符的部分字节，\n这就需要编写错误处理代码。 有一种解决方案是将整个文件读入内存，然后进行解码，但这样就没 |  |\n\n法处理很大的文件了；若要读取 2 GB 的文件，就需要 2 GB 的 RAM。（其实需要的内存会更多些，\n因为至少有一段时间需要在内存中同时存放已编码字符串及其 Unicode 版本。）\n解决方案是利用底层解码接口去捕获编码序列不完整的情况。这部分代码已经是现成的：内置函数\nopen() 可以返回一个文件类的对象，该对象认为文件的内容采用指定的编码，read() 和 write()\n等方法接受 Unicode 参数。只要用 open() 的 encoding 和 errors 参数即可，参数释义同\nstr.encode() 和 bytes.decode() 。\n因此从文件读取 Unicode 就比较简单了：\nwith open('unicode.txt', encoding='utf-8') as f:\nfor line in f:\nprint(repr(line))\n也可以在更新模式下打开文件，以便同时读取和写入：\nwith open('test', encoding='utf-8', mode='w+') as f:\nf.write('\\u4500 blah blah blah\\n')\nf.seek(0)\nprint(repr(f.readline()[:1]))\nUnicode 字符 U+FEFF 用作字节顺序标记（BOM），通常作为文件的第一个字符写入，以帮助自动\n检测文件的字节顺序。某些编码（例如 UTF-16）期望在文件开头出现 BOM；当采用这种编码时，\nBOM 将自动作为第一个字符写入，并在读取文件时会静默删除。这些编码有多种变体，例如用于\nlittle-endian 和 big-endian 编码的 “utf-16-le” 和 “utf-16-be”，会指定一种特定的字节顺序并且不会\n忽略 BOM。\n在某些地区，习惯在 UTF-8 编码文件的开头用上“BOM”；此名称具有误导性，因为 UTF-8 与字节顺\n序无关。此标记只是声明该文件以 UTF-8 编码。要读取此类文件，请使用“utf-8-sig”编解码器自动忽\n略此标记。\nUnicode 文件名\n当今大多数操作系统都支持包含任意 Unicode 字符的文件名。 通常这是通过将 Unicode 字符串转换\n为某种根据具体系统而定的编码格式来实现的。 如今的 Python 倾向于使用 UTF-8：MacOS 上的\nPython 已经在多个版本中使用了 UTF-8，而 Python 3.6 也已在 Windows 上改用了 UTF-8。 在 Unix\n系统中，将只有一个 文件系统编码格式。 如果你已设置了 LANG 或 LC_CTYPE 环境变量的话；如果\n未设置，则默认编码格式还是 UTF-8。\nsys.getfilesystemencoding() 函数将返回要在当前系统采用的编码，若想手动进行编码时即可用\n到，但无需多虑。在打开文件进行读写时，通常只需提供 Unicode 字符串作为文件名，会自动转换\n为合适的编码格式：\nfilename = 'filename\\u4500abc'\nwith open(filename, 'w') as f:\nf.write('blah\\n')\nos 模块中的函数也能接受 Unicode 文件名，如 os.stat() 。\n\n|  | 法处理很大的文件了；若要读取 2 GB 的文件，就需要 2 GB 的 RAM。（其实需要的内存会更多些，\n因为至少有一段时间需要在内存中同时存放已编码字符串及其 Unicode 版本。）\n解决方案是利用底层解码接口去捕获编码序列不完整的情况。这部分代码已经是现成的：内置函数\nopen() 可以返回一个文件类的对象，该对象认为文件的内容采用指定的编码，read() 和 write()\n等方法接受 Unicode 参数。只要用 open() 的 encoding 和 errors 参数即可，参数释义同\nstr.encode() 和 bytes.decode() 。\n因此从文件读取 Unicode 就比较简单了： |  |\n| --- | --- | --- |\n|  | with open('unicode.txt', encoding='utf-8') as f:\nfor line in f:\nprint(repr(line)) |  |\n|  | 也可以在更新模式下打开文件，以便同时读取和写入： |  |\n|  | with open('test', encoding='utf-8', mode='w+') as f:\nf.write('\\u4500 blah blah blah\\n')\nf.seek(0)\nprint(repr(f.readline()[:1])) |  |\n|  | Unicode 字符 U+FEFF 用作字节顺序标记（BOM），通常作为文件的第一个字符写入，以帮助自动\n检测文件的字节顺序。某些编码（例如 UTF-16）期望在文件开头出现 BOM；当采用这种编码时，\nBOM 将自动作为第一个字符写入，并在读取文件时会静默删除。这些编码有多种变体，例如用于\nlittle-endian 和 big-endian 编码的 “utf-16-le” 和 “utf-16-be”，会指定一种特定的字节顺序并且不会\n忽略 BOM。\n在某些地区，习惯在 UTF-8 编码文件的开头用上“BOM”；此名称具有误导性，因为 UTF-8 与字节顺\n序无关。此标记只是声明该文件以 UTF-8 编码。要读取此类文件，请使用“utf-8-sig”编解码器自动忽\n略此标记。\nUnicode 文件名\n当今大多数操作系统都支持包含任意 Unicode 字符的文件名。 通常这是通过将 Unicode 字符串转换\n为某种根据具体系统而定的编码格式来实现的。 如今的 Python 倾向于使用 UTF-8：MacOS 上的\nPython 已经在多个版本中使用了 UTF-8，而 Python 3.6 也已在 Windows 上改用了 UTF-8。 在 Unix\n系统中，将只有一个 文件系统编码格式。 如果你已设置了 LANG 或 LC_CTYPE 环境变量的话；如果\n未设置，则默认编码格式还是 UTF-8。\nsys.getfilesystemencoding() 函数将返回要在当前系统采用的编码，若想手动进行编码时即可用\n到，但无需多虑。在打开文件进行读写时，通常只需提供 Unicode 字符串作为文件名，会自动转换\n为合适的编码格式： |  |\n|  | filename = 'filename\\u4500abc'\nwith open(filename, 'w') as f:\nf.write('blah\\n') |  |\n|  | os 模块中的函数也能接受 Unicode 文件名，如 os.stat() 。 |  |\n\nos.listdir() 函数返回文件名，这引发了一个问题：它应该返回文件名的 Unicode 版本，还是应\n该返回包含已编码版本的字节串？ 这两者 os.listdir() 都能做到，具体取决于你给出的目录路径\n是字节串还是 Unicode 字符串形式的。 如果你传入一个 Unicode 字符串作为路径，文件名将使用文\n件系统的编码格式进行解码并返回一个 Unicode 字符串列表，而传入一个字节串形式的路径则将返\n回字节串形式的文件名。 例如，假定默认 文件系统编码 为 UTF-8，运行以下程序:\nfn = 'filename\\u4500abc'\nf = open(fn, 'w')\nf.close()\nimport os\nprint(os.listdir(b'.'))\nprint(os.listdir('.'))\n将产生以下输出：\n$ python listdir-test.py\n[b'filename\\xe4\\x94\\x80abc', ...]\n['filename\\u4500abc', ...]\n第一个列表包含 UTF-8 编码的文件名，第二个列表则包含 Unicode 版本的。\n请注意，大多时候应该坚持用这些 API 处理 Unicode。字节串 API 应该仅用于可能存在不可解码文\n件名的系统；现在几乎仅剩 Unix 系统了。\n识别 Unicode 的编程技巧\n本节提供了一些关于编写 Unicode 处理软件的建议。\n最重要的技巧如下：\n程序应只在内部处理 Unicode 字符串，尽快对输入数据进行解码，并只在最后对输出进行编码。\n如果尝试编写的处理函数对 Unicode 和字节串形式的字符串都能接受，就会发现组合使用两种不同\n类型的字符串时，容易产生差错。没办法做到自动编码或解码：如果执行 str + bytes，则会触发\nTypeError。\n当要使用的数据来自 Web 浏览器或其他不受信来源时，常用技术是在用该字符串生成命令行之前，\n或要存入数据库之前，先检查字符串中是否包含非法字符。请仔细检查解码后的字符串，而不是编\n码格式的字节串数据；有些编码可能具备一些有趣的特性，例如与 ASCII 不是一一对应或不完全兼\n容。如果输入数据还指定了编码格式，则尤其如此，因为攻击者可以选择一种巧妙的方式将恶意文\n本隐藏在经过编码的字节流中。\n在文件编码格式之间进行转换\nStreamRecoder 类可以在两种编码之间透明地进行转换，参数为编码格式为 #1 的数据流，表现行\n为则是编码格式为 #2 的数据流。\n假设输入文件 f 采用 Latin-1 编码格式，即可用 StreamRecoder 包装后返回 UTF-8 编码的字节串：\n\n|  | os.listdir() 函数返回文件名，这引发了一个问题：它应该返回文件名的 Unicode 版本，还是应\n该返回包含已编码版本的字节串？ 这两者 os.listdir() 都能做到，具体取决于你给出的目录路径\n是字节串还是 Unicode 字符串形式的。 如果你传入一个 Unicode 字符串作为路径，文件名将使用文\n件系统的编码格式进行解码并返回一个 Unicode 字符串列表，而传入一个字节串形式的路径则将返\n回字节串形式的文件名。 例如，假定默认 文件系统编码 为 UTF-8，运行以下程序: |  |\n| --- | --- | --- |\n|  | fn = 'filename\\u4500abc'\nf = open(fn, 'w')\nf.close()\nimport os\nprint(os.listdir(b'.'))\nprint(os.listdir('.')) |  |\n|  | 将产生以下输出： |  |\n|  | $ python listdir-test.py\n[b'filename\\xe4\\x94\\x80abc', ...]\n['filename\\u4500abc', ...] |  |\n|  | 第一个列表包含 UTF-8 编码的文件名，第二个列表则包含 Unicode 版本的。\n请注意，大多时候应该坚持用这些 API 处理 Unicode。字节串 API 应该仅用于可能存在不可解码文\n件名的系统；现在几乎仅剩 Unix 系统了。\n识别 Unicode 的编程技巧\n本节提供了一些关于编写 Unicode 处理软件的建议。\n最重要的技巧如下：\n程序应只在内部处理 Unicode 字符串，尽快对输入数据进行解码，并只在最后对输出进行编码。\n如果尝试编写的处理函数对 Unicode 和字节串形式的字符串都能接受，就会发现组合使用两种不同\n类型的字符串时，容易产生差错。没办法做到自动编码或解码：如果执行 str + bytes，则会触发\nTypeError。\n当要使用的数据来自 Web 浏览器或其他不受信来源时，常用技术是在用该字符串生成命令行之前，\n或要存入数据库之前，先检查字符串中是否包含非法字符。请仔细检查解码后的字符串，而不是编\n码格式的字节串数据；有些编码可能具备一些有趣的特性，例如与 ASCII 不是一一对应或不完全兼\n容。如果输入数据还指定了编码格式，则尤其如此，因为攻击者可以选择一种巧妙的方式将恶意文\n本隐藏在经过编码的字节流中。\n在文件编码格式之间进行转换\nStreamRecoder 类可以在两种编码之间透明地进行转换，参数为编码格式为 #1 的数据流，表现行\n为则是编码格式为 #2 的数据流。\n假设输入文件 f 采用 Latin-1 编码格式，即可用 StreamRecoder 包装后返回 UTF-8 编码的字节串： |  |\n\nnew_f = codecs.StreamRecoder(f,\n# en/decoder: 被 read() 用来编码其结果\n# 并被 write() 用来解码其输入。\ncodecs.getencoder('utf-8'), codecs.getdecoder('utf-8'),\n# reader/writer: 用于读取和写入流。\ncodecs.getreader('latin-1'), codecs.getwriter('latin-1') )\n编码格式未知的文件\n若需对文件进行修改，但不知道文件的编码，那该怎么办呢？如果已知编码格式与 ASCII 兼容，并\n且只想查看或修改 ASCII 部分，则可利用 surrogateescape 错误处理 handler 打开文件：\nwith open(fname, 'r', encoding=\"ascii\", errors=\"surrogateescape\") as f:\ndata = f.read()\n# 对字符串“data”进行更改\nwith open(fname + '.new', 'w',\nencoding=\"ascii\", errors=\"surrogateescape\") as f:\nf.write(data)\nsurrogateescape 错误处理 handler 会把所有非 ASCII 字节解码为 U+DC80 至 U+DCFF 这一特殊范\n围的码位。当 surrogateescape 错误处理 handler用于数据编码并回写时，这些码位将转换回原\n样。\n参考文献\nDavid Beazley 在 PyCon 2010 上的演讲 掌握 Python 3 输入/输出 中，有一节讨论了文本和二进制数\n据的处理。\nMarc-André Lemburg 演示的PDF 幻灯片“在 Python 中编写支持 Unicode 的应用程序” ，讨论了字符\n编码问题以及如何国际化和本地化应用程序。这些幻灯片仅涵盖 Python 2.x。\nPython Unicode 实质 是 Benjamin Peterson 在 PyCon 2013 上的演讲，讨论了 Unicode 在 Python\n3.3 中的内部表示。\n致谢\n本文初稿由 Andrew Kuchling 撰写。此后，Alexander Belopolsky、Georg Brandl、Andrew Kuchling\n和 Ezio Melotti 作了进一步修订。\n感谢以下各位指出本文错误或提出建议：Éric Araujo、Nicholas Bastin、Nick Coghlan、Marius\nGedminas、Kent Johnson、Ken Krugler、Marc-André Lemburg、Martin von Löwis、Terry J.\nReedy、Serhiy Storchaka , Eryk Sun, Chad Whitacre, Graham Wideman。\n\n| new_f = codecs.StreamRecoder(f,\n# en/decoder: 被 read() 用来编码其结果\n# 并被 write() 用来解码其输入。\ncodecs.getencoder('utf-8'), codecs.getdecoder('utf-8'),\n# reader/writer: 用于读取和写入流。\ncodecs.getreader('latin-1'), codecs.getwriter('latin-1') ) |\n| --- |\n| 编码格式未知的文件\n若需对文件进行修改，但不知道文件的编码，那该怎么办呢？如果已知编码格式与 ASCII 兼容，并\n且只想查看或修改 ASCII 部分，则可利用 surrogateescape 错误处理 handler 打开文件： |\n| with open(fname, 'r', encoding=\"ascii\", errors=\"surrogateescape\") as f:\ndata = f.read()\n# 对字符串“data”进行更改\nwith open(fname + '.new', 'w',\nencoding=\"ascii\", errors=\"surrogateescape\") as f:\nf.write(data) |\n| surrogateescape 错误处理 handler 会把所有非 ASCII 字节解码为 U+DC80 至 U+DCFF 这一特殊范\n围的码位。当 surrogateescape 错误处理 handler用于数据编码并回写时，这些码位将转换回原\n样。\n参考文献\nDavid Beazley 在 PyCon 2010 上的演讲 掌握 Python 3 输入/输出 中，有一节讨论了文本和二进制数\n据的处理。\nMarc-André Lemburg 演示的PDF 幻灯片“在 Python 中编写支持 Unicode 的应用程序” ，讨论了字符\n编码问题以及如何国际化和本地化应用程序。这些幻灯片仅涵盖 Python 2.x。\nPython Unicode 实质 是 Benjamin Peterson 在 PyCon 2013 上的演讲，讨论了 Unicode 在 Python\n3.3 中的内部表示。\n致谢\n本文初稿由 Andrew Kuchling 撰写。此后，Alexander Belopolsky、Georg Brandl、Andrew Kuchling\n和 Ezio Melotti 作了进一步修订。\n感谢以下各位指出本文错误或提出建议：Éric Araujo、Nicholas Bastin、Nick Coghlan、Marius\nGedminas、Kent Johnson、Ken Krugler、Marc-André Lemburg、Martin von Löwis、Terry J.\nReedy、Serhiy Storchaka , Eryk Sun, Chad Whitacre, Graham Wideman。 |", "metadata": {"title": "12_Unicode_指南", "source": "md_docs\\python_howto_md\\12_Unicode_指南.md", "doc_type": "指南", "language": "中文", "doc_id": "da5fbc71"}}
{"doc_id": "52aa518c", "content": "如何利用 urllib 包获取网络资源\n作者: Michael Foord\n概述\nurllib.request 是用于获取 URL （统一资源定位符）的\nRelated Articles\nPython 模块。它以 urlopen 函数的形式提供了一个非\n常简单的接口，能用不同的协议获取 URL。同时它还为 关于如何用 Python 获取 web 资源，以\n处理各种常见情形提供了一个稍微复杂一些的接口—— 下文章或许也很有用：\n比如：基础身份认证、cookies、代理等等。这些功能\n基本身份认证\n是由名为 handlers 和 opener 的对象提供的。\n基本认证 的教程，带有一些\nurllib.request 支持多种 \"URL 方案\" （通过 URL中 \":\"\nPython 示例。\n之前的字符串加以区分——如 \"ftp://python.org/\"\n中的 \"ftp\"）即为采用其关联网络协议（FTP、HTTP\n之类）的 URL 方案 。本教程重点关注最常用的 HTTP 场景。\n对于简单场景而言， urlopen 用起来十分容易。但只要在打开 HTTP URL 时遇到错误或非常情况，就\n需要对超文本传输协议有所了解才行。最全面、最权威的 HTTP 参考是 RFC 2616 。那是一份技术文\n档，并没有追求可读性。本 文旨在说明 urllib 的用法，为了便于阅读也附带了足够详细的 HTTP 信\n息。本文并不是为了替代 urllib.request 文档，只是其补充说明而已。\n获取 URL 资源\nurllib.request 最简单的使用方式如下所示：\nimport urllib.request\nwith urllib.request.urlopen('http://python.org/') as response:\nhtml = response.read()\n如果想通过 URL 获取资源并临时存储一下，可以采用 shutil.copyfileobj() 和\ntempfile.NamedTemporaryFile() 函数：\nimport shutil\nimport tempfile\nimport urllib.request\nwith urllib.request.urlopen('http://python.org/') as response:\nwith tempfile.NamedTemporaryFile(delete=False) as tmp_file:\nshutil.copyfileobj(response, tmp_file)\nwith open(tmp_file.name) as html:\npass\n\n| 如何利用 urllib 包获取网络资源\n作者: Michael Foord\n概述\nurllib.request 是用于获取 URL （统一资源定位符）的\nRelated Articles\nPython 模块。它以 urlopen 函数的形式提供了一个非\n常简单的接口，能用不同的协议获取 URL。同时它还为 关于如何用 Python 获取 web 资源，以\n处理各种常见情形提供了一个稍微复杂一些的接口—— 下文章或许也很有用：\n比如：基础身份认证、cookies、代理等等。这些功能\n基本身份认证\n是由名为 handlers 和 opener 的对象提供的。\n基本认证 的教程，带有一些\nurllib.request 支持多种 \"URL 方案\" （通过 URL中 \":\"\nPython 示例。\n之前的字符串加以区分——如 \"ftp://python.org/\"\n中的 \"ftp\"）即为采用其关联网络协议（FTP、HTTP\n之类）的 URL 方案 。本教程重点关注最常用的 HTTP 场景。\n对于简单场景而言， urlopen 用起来十分容易。但只要在打开 HTTP URL 时遇到错误或非常情况，就\n需要对超文本传输协议有所了解才行。最全面、最权威的 HTTP 参考是 RFC 2616 。那是一份技术文\n档，并没有追求可读性。本 文旨在说明 urllib 的用法，为了便于阅读也附带了足够详细的 HTTP 信\n息。本文并不是为了替代 urllib.request 文档，只是其补充说明而已。\n获取 URL 资源\nurllib.request 最简单的使用方式如下所示： |\n| --- |\n| import urllib.request\nwith urllib.request.urlopen('http://python.org/') as response:\nhtml = response.read() |\n| 如果想通过 URL 获取资源并临时存储一下，可以采用 shutil.copyfileobj() 和\ntempfile.NamedTemporaryFile() 函数： |\n| import shutil\nimport tempfile\nimport urllib.request\nwith urllib.request.urlopen('http://python.org/') as response:\nwith tempfile.NamedTemporaryFile(delete=False) as tmp_file:\nshutil.copyfileobj(response, tmp_file)\nwith open(tmp_file.name) as html:\npass |\n|  |\n\nurllib 的很多用法就是这么简单（注意 URL 不仅可以 http: 开头，还可以是 ftp: 、file: 等）。不过本\n教程的目的是介绍更加复杂的应用场景，重点还是关注 HTTP。\nHTTP 以请求和响应为基础——客户端生成请求，服务器发送响应。urllib.request 用 Request 对象\n来表示要生成的 HTTP 请求。最简单的形式就是创建一个 Request 对象，指定了想要获取的 URL。\n用这个 Request 对象作为参数调用 urlopen ，将会返回该 URL 的响应对象。响应对象类似于文件对\n象，就是说可以对其调用 .read() 之类的命令：\nimport urllib.request\nreq = urllib.request.Request('http://python.org/')\nwith urllib.request.urlopen(req) as response:\nthe_page = response.read()\n请注意，urllib.request 用同一个 Request 接口处理所有 URL 方案。比如可生成 FTP 请求如下：\nreq = urllib.request.Request('ftp://example.com/')\n就 HTTP 而言，Request 对象能够做两件额外的事情：首先可以把数据传给服务器。其次，可以将\n有关 数据或请求本身的额外信息（metadata）传给服务器——这些信息将会作为 HTTP “头部”数据\n发送。下面依次看下。\n数据\n有时需要向某个 URL 发送数据，通常此 URL 会指向某个CGI（通用网关接口）脚本或其他 web 应\n用。对于 HTTP 而言，这通常会用所谓的 POST 请求来完成。当要把 Web 页填写的 HTML 表单提交\n时，浏览器通常会执行此操作。但并不是所有的 POST 都来自表单：可以用 POST 方式传输任何数据\n到自己的应用上。对于通常的 HTML 表单，数据需要以标准的方式编码，然后作为 data 参数传给\nRequest 对象。编码过程是用 urllib.parse 库的函数完成的：\nimport urllib.parse\nimport urllib.request\nurl = 'http://www.someserver.com/cgi-bin/register.cgi'\nvalues = {'name' : 'Michael Foord',\n'location' : 'Northampton',\n'language' : 'Python' }\ndata = urllib.parse.urlencode(values)\ndata = data.encode('ascii') # 数据应为字节串\nreq = urllib.request.Request(url, data)\nwith urllib.request.urlopen(req) as response:\nthe_page = response.read()\n请注意，有时还需要采用其他编码，比如由 HTML 表单上传文件——更多细节请参见 HTML 规范，\n提交表单 。\n如果不传递 data 参数，urllib 将采用 GET 请求。GET 和 POST 请求有一点不同，POST 请求往往具\n有“副作用”，他们会以某种方式改变系统的状态。例如，从网站下一个订单，购买一大堆罐装垃圾并\n运送到家。 尽管 HTTP 标准明确指出 POST 总是 要导致副作用，而 GET 请求 从来不会 导致副作\n\n|  | urllib 的很多用法就是这么简单（注意 URL 不仅可以 http: 开头，还可以是 ftp: 、file: 等）。不过本\n教程的目的是介绍更加复杂的应用场景，重点还是关注 HTTP。\nHTTP 以请求和响应为基础——客户端生成请求，服务器发送响应。urllib.request 用 Request 对象\n来表示要生成的 HTTP 请求。最简单的形式就是创建一个 Request 对象，指定了想要获取的 URL。\n用这个 Request 对象作为参数调用 urlopen ，将会返回该 URL 的响应对象。响应对象类似于文件对\n象，就是说可以对其调用 .read() 之类的命令： |  |\n| --- | --- | --- |\n|  | import urllib.request\nreq = urllib.request.Request('http://python.org/')\nwith urllib.request.urlopen(req) as response:\nthe_page = response.read() |  |\n|  | 请注意，urllib.request 用同一个 Request 接口处理所有 URL 方案。比如可生成 FTP 请求如下： |  |\n|  | req = urllib.request.Request('ftp://example.com/') |  |\n|  | 就 HTTP 而言，Request 对象能够做两件额外的事情：首先可以把数据传给服务器。其次，可以将\n有关 数据或请求本身的额外信息（metadata）传给服务器——这些信息将会作为 HTTP “头部”数据\n发送。下面依次看下。\n数据\n有时需要向某个 URL 发送数据，通常此 URL 会指向某个CGI（通用网关接口）脚本或其他 web 应\n用。对于 HTTP 而言，这通常会用所谓的 POST 请求来完成。当要把 Web 页填写的 HTML 表单提交\n时，浏览器通常会执行此操作。但并不是所有的 POST 都来自表单：可以用 POST 方式传输任何数据\n到自己的应用上。对于通常的 HTML 表单，数据需要以标准的方式编码，然后作为 data 参数传给\nRequest 对象。编码过程是用 urllib.parse 库的函数完成的： |  |\n|  | import urllib.parse\nimport urllib.request\nurl = 'http://www.someserver.com/cgi-bin/register.cgi'\nvalues = {'name' : 'Michael Foord',\n'location' : 'Northampton',\n'language' : 'Python' }\ndata = urllib.parse.urlencode(values)\ndata = data.encode('ascii') # 数据应为字节串\nreq = urllib.request.Request(url, data)\nwith urllib.request.urlopen(req) as response:\nthe_page = response.read() |  |\n|  | 请注意，有时还需要采用其他编码，比如由 HTML 表单上传文件——更多细节请参见 HTML 规范，\n提交表单 。\n如果不传递 data 参数，urllib 将采用 GET 请求。GET 和 POST 请求有一点不同，POST 请求往往具\n有“副作用”，他们会以某种方式改变系统的状态。例如，从网站下一个订单，购买一大堆罐装垃圾并\n运送到家。 尽管 HTTP 标准明确指出 POST 总是 要导致副作用，而 GET 请求 从来不会 导致副作 |  |\n\n用。但没有什么办法能阻止 GET 和 POST 请求的副作用。数据也可以在 HTTP GET 请求中传递，只\n要把数据编码到 URL 中即可。\n做法如下所示：\n>>> import urllib.request\n>>> import urllib.parse\n>>> data = {}\n>>> data['name'] = 'Somebody Here'\n>>> data['location'] = 'Northampton'\n>>> data['language'] = 'Python'\n>>> url_values = urllib.parse.urlencode(data)\n>>> print(url_values) # The order may differ from below.\nname=Somebody+Here&language=Python&location=Northampton\n>>> url = 'http://www.example.com/example.cgi'\n>>> full_url = url + '?' + url_values\n>>> data = urllib.request.urlopen(full_url)\n请注意，完整的 URL 是通过在其中添加 ? 创建的，后面跟着经过编码的数据。\nHTTP 头部信息\n下面介绍一个具体的 HTTP 头部信息，以此说明如何在 HTTP 请求加入头部信息。\n有些网站 [1] 不愿被程序浏览到，或者要向不同的浏览器发送不同版本 [2] 的网页。默认情况下，\nurllib 将自身标识为“Python-urllib/xy”（其中 x 、 y 是 Python 版本的主、次版本号，例如 Python-\nurllib/2.5），这可能会让网站不知所措，或者干脆就使其无法正常工作。浏览器是通过头部信息\nUser-Agent [3] 来标识自己的。在创建 Request 对象时，可以传入字典形式的头部信息。以下示例\n将生成与之前相同的请求，只是将自身标识为某个版本的 Internet Explorer [4] ：\nimport urllib.parse\nimport urllib.request\nurl = 'http://www.someserver.com/cgi-bin/register.cgi'\nuser_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\nvalues = {'name': 'Michael Foord',\n'location': 'Northampton',\n'language': 'Python' }\nheaders = {'User-Agent': user_agent}\ndata = urllib.parse.urlencode(values)\ndata = data.encode('ascii')\nreq = urllib.request.Request(url, data, headers)\nwith urllib.request.urlopen(req) as response:\nthe_page = response.read()\n响应对象也有两个很有用的方法。请参阅有关 info 和 geturl 部分，了解出现问题时会发生什么。\n异常的处理\n当 urlopen 无法处理响应信息时将会引发 URLError (当然与 Python API 通常的情况一样，也可能会\n引发如 ValueError, TypeError 之类的内置异常)。\nHTTPError 是在 HTTP URL 的特定情况下引发的 URLError 的子类。\n\n|  |  | 用。但没有什么办法能阻止 GET 和 POST 请求的副作用。数据也可以在 HTTP GET 请求中传递，只\n要把数据编码到 URL 中即可。\n做法如下所示： |  |  |  |\n| --- | --- | --- | --- | --- | --- |\n|  |  | >>> import urllib.request\n>>> import urllib.parse\n>>> data = {}\n>>> data['name'] = 'Somebody Here'\n>>> data['location'] = 'Northampton'\n>>> data['language'] = 'Python'\n>>> url_values = urllib.parse.urlencode(data)\n>>> print(url_values) # The order may differ from below.\nname=Somebody+Here&language=Python&location=Northampton\n>>> url = 'http://www.example.com/example.cgi'\n>>> full_url = url + '?' + url_values\n>>> data = urllib.request.urlopen(full_url) |  |  |  |\n|  |  | 请注意，完整的 URL 是通过在其中添加 ? 创建的，后面跟着经过编码的数据。\nHTTP 头部信息\n下面介绍一个具体的 HTTP 头部信息，以此说明如何在 HTTP 请求加入头部信息。\n有些网站 [1] 不愿被程序浏览到，或者要向不同的浏览器发送不同版本 [2] 的网页。默认情况下，\nurllib 将自身标识为“Python-urllib/xy”（其中 x 、 y 是 Python 版本的主、次版本号，例如 Python-\nurllib/2.5），这可能会让网站不知所措，或者干脆就使其无法正常工作。浏览器是通过头部信息\nUser-Agent [3] 来标识自己的。在创建 Request 对象时，可以传入字典形式的头部信息。以下示例\n将生成与之前相同的请求，只是将自身标识为某个版本的 Internet Explorer [4] ： |  |  |  |\n|  |  |  | Python- |  |  |\n|  |  |  |  |  |  |\n|  |  | urllib/2.5 |  |  |  |\n|  |  |  |  |  |  |\n|  |  | import urllib.parse\nimport urllib.request\nurl = 'http://www.someserver.com/cgi-bin/register.cgi'\nuser_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\nvalues = {'name': 'Michael Foord',\n'location': 'Northampton',\n'language': 'Python' }\nheaders = {'User-Agent': user_agent}\ndata = urllib.parse.urlencode(values)\ndata = data.encode('ascii')\nreq = urllib.request.Request(url, data, headers)\nwith urllib.request.urlopen(req) as response:\nthe_page = response.read() |  |  |  |\n|  |  | 响应对象也有两个很有用的方法。请参阅有关 info 和 geturl 部分，了解出现问题时会发生什么。\n异常的处理\n当 urlopen 无法处理响应信息时将会引发 URLError (当然与 Python API 通常的情况一样，也可能会\n引发如 ValueError, TypeError 之类的内置异常)。\nHTTPError 是在 HTTP URL 的特定情况下引发的 URLError 的子类。 |  |  |  |\n\n上述异常类是从 urllib.error 模块中导出的。\nURLError\n触发 URLError 的原因，通常是网络不通（或者没有到指定服务器的路由），或者指定的服务器不存\n在。这时触发的异常会带有一个 reason 属性，是一个包含错误代码和文本错误信息的元组。\n例如：\n>>> req = urllib.request.Request('http://www.pretend_server.org')\n>>> try: urllib.request.urlopen(req)\n... except urllib.error.URLError as e:\n... print(e.reason)\n...\n(4, 'getaddrinfo failed')\nHTTPError\n来自服务器的每个 HTTP 响应都包含一个数字形式的“状态码”。 有时该状态码表明服务器无法完成\n请求。默认的处理器将会为你处理其中的部分响应（例如，当响应为要求客户端从另一 URL 获取文\n档的“重定向”响应时，urllib 将为你处理该响应）。 对于无法处理的响应，urlopen 将会引发\nHTTPError。 典型的错误包括 \"404\"（页面未找到）、\"403\"（请求遭拒）和 \"401\"（需要身份认\n证）等。\n全部的 HTTP 错误码请参阅 RFC 2616 。\n被引发的 HTTPError 实例将有一个整数形式的 'code' 属性，对应于服务器发送的错误信息。\n错误代码\n由于默认处理函数会自行处理重定向（300 以内的错误码），而且 100--299 的状态码表示成功，因\n此通常只会出现 400--599 的错误码。\nhttp.server.BaseHTTPRequestHandler.responses 是一个很有用的响应码字典，它提供了 RFC\n2616 用到的所有码。 下面显示了来自该字典的一段摘录\nresponses = {\n...\n<HTTPStatus.OK: 200>: ('OK', 'Request fulfilled, document follows'),\n...\n<HTTPStatus.FORBIDDEN: 403>: ('Forbidden',\n'Request forbidden -- authorization will '\n'not help'),\n<HTTPStatus.NOT_FOUND: 404>: ('Not Found',\n'Nothing matches the given URI'),\n...\n<HTTPStatus.IM_A_TEAPOT: 418>: (\"I'm a Teapot\",\n'Server refuses to brew coffee because '\n'it is a teapot'),\n...\n<HTTPStatus.SERVICE_UNAVAILABLE: 503>: ('Service Unavailable',\n'The server cannot process the '\n\n|  | 上述异常类是从 urllib.error 模块中导出的。\nURLError\n触发 URLError 的原因，通常是网络不通（或者没有到指定服务器的路由），或者指定的服务器不存\n在。这时触发的异常会带有一个 reason 属性，是一个包含错误代码和文本错误信息的元组。\n例如： |  |\n| --- | --- | --- |\n|  | >>> req = urllib.request.Request('http://www.pretend_server.org')\n>>> try: urllib.request.urlopen(req)\n... except urllib.error.URLError as e:\n... print(e.reason)\n...\n(4, 'getaddrinfo failed') |  |\n|  | HTTPError\n来自服务器的每个 HTTP 响应都包含一个数字形式的“状态码”。 有时该状态码表明服务器无法完成\n请求。默认的处理器将会为你处理其中的部分响应（例如，当响应为要求客户端从另一 URL 获取文\n档的“重定向”响应时，urllib 将为你处理该响应）。 对于无法处理的响应，urlopen 将会引发\nHTTPError。 典型的错误包括 \"404\"（页面未找到）、\"403\"（请求遭拒）和 \"401\"（需要身份认\n证）等。\n全部的 HTTP 错误码请参阅 RFC 2616 。\n被引发的 HTTPError 实例将有一个整数形式的 'code' 属性，对应于服务器发送的错误信息。\n错误代码\n由于默认处理函数会自行处理重定向（300 以内的错误码），而且 100--299 的状态码表示成功，因\n此通常只会出现 400--599 的错误码。\nhttp.server.BaseHTTPRequestHandler.responses 是一个很有用的响应码字典，它提供了 RFC\n2616 用到的所有码。 下面显示了来自该字典的一段摘录 |  |\n|  | responses = {\n...\n<HTTPStatus.OK: 200>: ('OK', 'Request fulfilled, document follows'),\n...\n<HTTPStatus.FORBIDDEN: 403>: ('Forbidden',\n'Request forbidden -- authorization will '\n'not help'),\n<HTTPStatus.NOT_FOUND: 404>: ('Not Found',\n'Nothing matches the given URI'),\n...\n<HTTPStatus.IM_A_TEAPOT: 418>: (\"I'm a Teapot\",\n'Server refuses to brew coffee because '\n'it is a teapot'),\n...\n<HTTPStatus.SERVICE_UNAVAILABLE: 503>: ('Service Unavailable',\n'The server cannot process the ' |  |\n\n'request due to a high load'),\n...\n}\n当错误被引发时服务器会通过返回 HTTP 错误码 和 错误页面进行响应。 你可以在返回的页面上使用\nHTTPError 实例作为响应。 这意味着除了 code 属性之外，它还像 urllib.response 模块: 所返回\n对象那样具有 read, geturl 和 info 等方法:\n>>> req = urllib.request.Request('http://www.python.org/fish.html')\n>>> try:\n... urllib.request.urlopen(req)\n... except urllib.error.HTTPError as e:\n... print(e.code)\n... print(e.read())\n...\n404\nb'<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n\\n\\n<html\n...\n<title>Page Not Found</title>\\n\n...\n总之\n因此当你想为 HTTPError 或 URLError 做好准备时有两种基本的方案。 我更倾向使用第二种方案。\n第一种方案\nfrom urllib.request import Request, urlopen\nfrom urllib.error import URLError, HTTPError\nreq = Request(someurl)\ntry:\nresponse = urlopen(req)\nexcept HTTPError as e:\nprint('The server couldn\\'t fulfill the request.')\nprint('Error code: ', e.code)\nexcept URLError as e:\nprint('We failed to reach a server.')\nprint('Reason: ', e.reason)\nelse:\n# 一切正常\n备注: except HTTPError 必须 首先被处理，否则 except URLError 将会 同时 捕获\nHTTPError。\n第二种方案\nfrom urllib.request import Request, urlopen\nfrom urllib.error import URLError\nreq = Request(someurl)\ntry:\nresponse = urlopen(req)\nexcept URLError as e:\nif hasattr(e, 'reason'):\n\n|  | 'request due to a high load'),\n...\n} |  |\n| --- | --- | --- |\n|  | 当错误被引发时服务器会通过返回 HTTP 错误码 和 错误页面进行响应。 你可以在返回的页面上使用\nHTTPError 实例作为响应。 这意味着除了 code 属性之外，它还像 urllib.response 模块: 所返回\n对象那样具有 read, geturl 和 info 等方法: |  |\n|  | >>> req = urllib.request.Request('http://www.python.org/fish.html')\n>>> try:\n... urllib.request.urlopen(req)\n... except urllib.error.HTTPError as e:\n... print(e.code)\n... print(e.read())\n...\n404\nb'<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n\\n\\n<html\n...\n<title>Page Not Found</title>\\n\n... |  |\n|  | 总之\n因此当你想为 HTTPError 或 URLError 做好准备时有两种基本的方案。 我更倾向使用第二种方案。\n第一种方案 |  |\n|  | from urllib.request import Request, urlopen\nfrom urllib.error import URLError, HTTPError\nreq = Request(someurl)\ntry:\nresponse = urlopen(req)\nexcept HTTPError as e:\nprint('The server couldn\\'t fulfill the request.')\nprint('Error code: ', e.code)\nexcept URLError as e:\nprint('We failed to reach a server.')\nprint('Reason: ', e.reason)\nelse:\n# 一切正常 |  |\n|  |  |  |\n|  | 备注: except HTTPError 必须 首先被处理，否则 except URLError 将会 同时 捕获\nHTTPError。 |  |\n|  | 第二种方案 |  |\n|  | from urllib.request import Request, urlopen\nfrom urllib.error import URLError\nreq = Request(someurl)\ntry:\nresponse = urlopen(req)\nexcept URLError as e:\nif hasattr(e, 'reason'): |  |\n\nprint('We failed to reach a server.')\nprint('Reason: ', e.reason)\nelif hasattr(e, 'code'):\nprint('The server couldn\\'t fulfill the request.')\nprint('Error code: ', e.code)\nelse:\n# 一切正常\ninfo 和 geturl 方法\nurlopen 返回的响应（或 HTTPError 实例）包含两个有用的方法 info() 和 geturl() 并且是在\nurllib.response 模块中定义的。\ngeturl ——返回所获取页面的真实 URL。该方法很有用，因为 urlopen （或 opener 对象）可能\n已经经过了一次重定向。已获取页面的 URL 未必就是所请求的 URL 。\ninfo - 该方法返回一个类似字典的对象，描述了所获取的页面，特别是由服务器送出的头部信息\n（headers） 。目前它是一个 http.client.HTTPMessage 实例。\n典型的标头包括 'Content-length', 'Content-type' 等等。 请参阅 HTTP 标头快速参考 获取 HTTP 标\n头的完整列表及其含义和用法的简要说明。\nOpener 和 Handler\n当你获取 URL 时会使用一个 opener (名称可能有些令人困惑的 urllib.request.OpenerDirector\n的实例)。 通常我们会使用默认的 opener —— 通过 urlopen —— 但你也可以创建自定义的\nopener。 opener 还会用到 handler。 所有 \"繁重工作\" 都是由 handler 来完成的。 每种 handler 都\n知道要以何种 URL 方案 (http, ftp 等等) 来打开特定的 URL，或是如何处理 URL 打开时的特定操作，\n例如 HTTP 重定向或 HTTP cookie 等。\n若要用已安装的某个 handler 获取 URL，需要创建一个 opener 对象，例如处理 cookie 的 opener，\n或对重定向不做处理的 opener。\n若要创建 opener，请实例化一个 OpenerDirector ，然后重复调用\n.add_handler(some_handler_instance) 。\n或者也可以用 build_opener ，这是个用单次调用创建 opener 对象的便捷函数。build_opener 默\n认会添加几个 handler，不过还提供了一种快速添加和/或覆盖默认 handler 的方法。\n可能还需要其他类型的 handler，以便处理代理、身份认证和其他常见但稍微特殊的情况。\ninstall_opener 可用于让 opener 对象成为（全局）默认 opener。这意味着调用 urlopen 时会采\n用已安装的 opener。\nopener 对象带有一个 `open 方法，可供直接调用以获取 url，方式与 urlopen 函数相同。除非是为\n了调用方便，否则没必要去调用 install_opener 。\n基本认证\n\n|  | print('We failed to reach a server.')\nprint('Reason: ', e.reason)\nelif hasattr(e, 'code'):\nprint('The server couldn\\'t fulfill the request.')\nprint('Error code: ', e.code)\nelse:\n# 一切正常 |  |\n| --- | --- | --- |\n|  | info 和 geturl 方法\nurlopen 返回的响应（或 HTTPError 实例）包含两个有用的方法 info() 和 geturl() 并且是在\nurllib.response 模块中定义的。\ngeturl ——返回所获取页面的真实 URL。该方法很有用，因为 urlopen （或 opener 对象）可能\n已经经过了一次重定向。已获取页面的 URL 未必就是所请求的 URL 。\ninfo - 该方法返回一个类似字典的对象，描述了所获取的页面，特别是由服务器送出的头部信息\n（headers） 。目前它是一个 http.client.HTTPMessage 实例。\n典型的标头包括 'Content-length', 'Content-type' 等等。 请参阅 HTTP 标头快速参考 获取 HTTP 标\n头的完整列表及其含义和用法的简要说明。\nOpener 和 Handler\n当你获取 URL 时会使用一个 opener (名称可能有些令人困惑的 urllib.request.OpenerDirector\n的实例)。 通常我们会使用默认的 opener —— 通过 urlopen —— 但你也可以创建自定义的\nopener。 opener 还会用到 handler。 所有 \"繁重工作\" 都是由 handler 来完成的。 每种 handler 都\n知道要以何种 URL 方案 (http, ftp 等等) 来打开特定的 URL，或是如何处理 URL 打开时的特定操作，\n例如 HTTP 重定向或 HTTP cookie 等。\n若要用已安装的某个 handler 获取 URL，需要创建一个 opener 对象，例如处理 cookie 的 opener，\n或对重定向不做处理的 opener。\n若要创建 opener，请实例化一个 OpenerDirector ，然后重复调用\n.add_handler(some_handler_instance) 。\n或者也可以用 build_opener ，这是个用单次调用创建 opener 对象的便捷函数。build_opener 默\n认会添加几个 handler，不过还提供了一种快速添加和/或覆盖默认 handler 的方法。\n可能还需要其他类型的 handler，以便处理代理、身份认证和其他常见但稍微特殊的情况。\ninstall_opener 可用于让 opener 对象成为（全局）默认 opener。这意味着调用 urlopen 时会采\n用已安装的 opener。\nopener 对象带有一个 `open 方法，可供直接调用以获取 url，方式与 urlopen 函数相同。除非是为\n了调用方便，否则没必要去调用 install_opener 。\n基本认证 |  |\n\n为了说明 handler 的创建和安装过程我们将使用 HTTPBasicAuthHandler。 有关该主题的更详细讨\n论 -- 包括对基本身份认证的原理的阐述 -- 请参阅 Basic Authentication Tutorial。\n如果需要身份认证，服务器会发送一条请求身份认证的头部信息（以及 401 错误代码）。这条信息\n中指明了身份认证方式和“安全区域（realm）”。格式如下所示：WWW-Authenticate: SCHEME\nrealm=\"REALM\" 。\n例如\nWWW-Authenticate: Basic realm=\"cPanel Users\"\n然后，客户端应重试发起请求，请求数据中的头部信息应包含安全区域对应的用户名和密码。这就\n是“基本身份认证”。为了简化此过程，可以创建 HTTPBasicAuthHandler 的一个实例及使用它的\nopener。\nHTTPBasicAuthHandler 用一个名为密码管理器的对象来管理 URL、安全区域与密码、用户名之间\n的映射关系。如果知道确切的安全区域（来自服务器发送的身份认证头部信息），那就可以用到\nHTTPPasswordMgr 。通常人们并不关心安全区域是什么，这时用\nHTTPPasswordMgrWithDefaultRealm 就很方便，允许为 URL 指定默认的用户名和密码。当没有为\n某个安全区域提供用户名和密码时，就会用到默认值。下面用 None 作为 add_password 方法的安\n全区域参数，表明采用默认用户名和密码。\n首先需要身份认证的是顶级 URL。比传给 .add_password() 的 URL 级别“更深”的 URL 也会得以匹\n配：\n# 创建一个密码管理器\npassword_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()\n# 添加用户名和密码。\n# 如果我们知道域，可以用它代替 None。\ntop_level_url = \"http://example.com/foo/\"\npassword_mgr.add_password(None, top_level_url, username, password)\nhandler = urllib.request.HTTPBasicAuthHandler(password_mgr)\n# 创建 \"opener\" (OpenerDirector 实例)\nopener = urllib.request.build_opener(handler)\n# 使用 opener 获取一个 URL\nopener.open(a_url)\n# 安装 opener。\n# 现在所有对 urllib.request.urlopen 的调用都将使用此 opener。\nurllib.request.install_opener(opener)\n备注: 在上面的救命中我们只向 build_opener 提供了 HTTPBasicAuthHandler。 在默认情况下\nopener 会包含针对常见状况的处理器 -- ProxyHandler (如果设置了代理如设置了 http_proxy\n环境变量)，UnknownHandler, HTTPHandler, HTTPDefaultErrorHandler,\nHTTPRedirectHandler, FTPHandler, FileHandler, DataHandler, HTTPErrorProcessor。\n\n|  |  | 为了说明 handler 的创建和安装过程我们将使用 HTTPBasicAuthHandler。 有关该主题的更详细讨\n论 -- 包括对基本身份认证的原理的阐述 -- 请参阅 Basic Authentication Tutorial。\n如果需要身份认证，服务器会发送一条请求身份认证的头部信息（以及 401 错误代码）。这条信息\n中指明了身份认证方式和“安全区域（realm）”。格式如下所示：WWW-Authenticate: SCHEME\nrealm=\"REALM\" 。\n例如 |  |  |  |\n| --- | --- | --- | --- | --- | --- |\n|  |  |  | WWW-Authenticate: SCHEME |  |  |\n|  |  |  |  |  |  |\n|  |  | realm=\"REALM\" |  |  |  |\n|  |  |  |  |  |  |\n|  |  | WWW-Authenticate: Basic realm=\"cPanel Users\" |  |  |  |\n|  |  | 然后，客户端应重试发起请求，请求数据中的头部信息应包含安全区域对应的用户名和密码。这就\n是“基本身份认证”。为了简化此过程，可以创建 HTTPBasicAuthHandler 的一个实例及使用它的\nopener。\nHTTPBasicAuthHandler 用一个名为密码管理器的对象来管理 URL、安全区域与密码、用户名之间\n的映射关系。如果知道确切的安全区域（来自服务器发送的身份认证头部信息），那就可以用到\nHTTPPasswordMgr 。通常人们并不关心安全区域是什么，这时用\nHTTPPasswordMgrWithDefaultRealm 就很方便，允许为 URL 指定默认的用户名和密码。当没有为\n某个安全区域提供用户名和密码时，就会用到默认值。下面用 None 作为 add_password 方法的安\n全区域参数，表明采用默认用户名和密码。\n首先需要身份认证的是顶级 URL。比传给 .add_password() 的 URL 级别“更深”的 URL 也会得以匹\n配： |  |  |  |\n|  |  | # 创建一个密码管理器\npassword_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()\n# 添加用户名和密码。\n# 如果我们知道域，可以用它代替 None。\ntop_level_url = \"http://example.com/foo/\"\npassword_mgr.add_password(None, top_level_url, username, password)\nhandler = urllib.request.HTTPBasicAuthHandler(password_mgr)\n# 创建 \"opener\" (OpenerDirector 实例)\nopener = urllib.request.build_opener(handler)\n# 使用 opener 获取一个 URL\nopener.open(a_url)\n# 安装 opener。\n# 现在所有对 urllib.request.urlopen 的调用都将使用此 opener。\nurllib.request.install_opener(opener) |  |  |  |\n|  |  |  |  |  |  |\n|  |  | 备注: 在上面的救命中我们只向 build_opener 提供了 HTTPBasicAuthHandler。 在默认情况下\nopener 会包含针对常见状况的处理器 -- ProxyHandler (如果设置了代理如设置了 http_proxy\n环境变量)，UnknownHandler, HTTPHandler, HTTPDefaultErrorHandler,\nHTTPRedirectHandler, FTPHandler, FileHandler, DataHandler, HTTPErrorProcessor。 |  |  |  |\n|  |  |  |  |  |  |\n\ntop_level_url 其实 要么 是一条完整的 URL（包括 “http:” 部分和主机名及可选的端口号），比如\n\"http://example.com/\" ， 要么 是一条“访问权限”（即主机名，及可选的端口号），比如\n\"example.com\" 或 \"example.com:8080\" （后一个示例包含了端口号）。访问权限 不得 包含“用户\n信息”部分——比如 \"joe:password@example.com\" 就不正确。\n代理\nurllib 将自动检测并使用代理设置。 这是通过 ProxyHandler 实现的，当检测到代理设置时，是正\n常 handler 链中的一部分。通常这是一件好事，但有时也可能会无效 [5]。 一种方案是配置自己的\nProxyHandler ，不要定义代理。 设置的步骤与 Basic Authentication handler 类似:\n>>> proxy_support = urllib.request.ProxyHandler({})\n>>> opener = urllib.request.build_opener(proxy_support)\n>>> urllib.request.install_opener(opener)\n备注: 目前 urllib.request 尚不 支持通过代理抓取 https 链接地址。 但此功能可以通过扩展\nurllib.request 来启用，如以下例程所示 [6]。\n备注: 如果设置了 REQUEST_METHOD 变量，则会忽略 HTTP_PROXY ；参阅 getproxies() 文档。\n套接字与分层\nPython 获取 Web 资源的能力是分层的。urllib 用到的是 http.client 库，而后者又用到了套接字\n库。\n从 Python 2.3 开始，可以指定套接字等待响应的超时时间。这对必须要读到网页数据的应用程序会\n很有用。默认情况下，套接字模块 不会超时 并且可以挂起。目前，套接字超时机制未暴露给\nhttp.client 或 urllib.request 层使用。不过可以为所有套接字应用设置默认的全局超时。\nimport socket\nimport urllib.request\n# 超时秒数\ntimeout = 10\nsocket.setdefaulttimeout(timeout)\n# 这个对 urllib.request.urlopen 的调用现在将使用\n# 我们在 socket 模块中设置的默认超时值\nreq = urllib.request.Request('http://www.voidspace.org.uk')\nresponse = urllib.request.urlopen(req)\n备注\n这篇文档由 John Lee 审订。\n[1] 例如 Google。\n\n|  | top_level_url 其实 要么 是一条完整的 URL（包括 “http:” 部分和主机名及可选的端口号），比如\n\"http://example.com/\" ， 要么 是一条“访问权限”（即主机名，及可选的端口号），比如\n\"example.com\" 或 \"example.com:8080\" （后一个示例包含了端口号）。访问权限 不得 包含“用户\n信息”部分——比如 \"joe:password@example.com\" 就不正确。\n代理\nurllib 将自动检测并使用代理设置。 这是通过 ProxyHandler 实现的，当检测到代理设置时，是正\n常 handler 链中的一部分。通常这是一件好事，但有时也可能会无效 [5]。 一种方案是配置自己的\nProxyHandler ，不要定义代理。 设置的步骤与 Basic Authentication handler 类似: |  |\n| --- | --- | --- |\n|  | >>> proxy_support = urllib.request.ProxyHandler({})\n>>> opener = urllib.request.build_opener(proxy_support)\n>>> urllib.request.install_opener(opener) |  |\n|  |  |  |\n|  | 备注: 目前 urllib.request 尚不 支持通过代理抓取 https 链接地址。 但此功能可以通过扩展\nurllib.request 来启用，如以下例程所示 [6]。 |  |\n|  |  |  |\n|  | 备注: 如果设置了 REQUEST_METHOD 变量，则会忽略 HTTP_PROXY ；参阅 getproxies() 文档。 |  |\n|  | 套接字与分层\nPython 获取 Web 资源的能力是分层的。urllib 用到的是 http.client 库，而后者又用到了套接字\n库。\n从 Python 2.3 开始，可以指定套接字等待响应的超时时间。这对必须要读到网页数据的应用程序会\n很有用。默认情况下，套接字模块 不会超时 并且可以挂起。目前，套接字超时机制未暴露给\nhttp.client 或 urllib.request 层使用。不过可以为所有套接字应用设置默认的全局超时。 |  |\n|  | import socket\nimport urllib.request\n# 超时秒数\ntimeout = 10\nsocket.setdefaulttimeout(timeout)\n# 这个对 urllib.request.urlopen 的调用现在将使用\n# 我们在 socket 模块中设置的默认超时值\nreq = urllib.request.Request('http://www.voidspace.org.uk')\nresponse = urllib.request.urlopen(req) |  |\n|  |  |  |\n|  | 备注\n这篇文档由 John Lee 审订。\n[1] 例如 Google。 |  |\n\n[2] 对于网站设计而言，探测不同的浏览器是非常糟糕的做法——更为明智的做法是采用 web 标准\n构建网站。不幸的是，很多网站依然向不同的浏览器发送不同版本的网页。\n[3] MSIE 6 的 user-agent 信息是 “Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR\n1.1.4322)”\n[4] 有关 HTTP 请求的头部信息，详情请参阅 Quick Reference to HTTP Headers。\n[5] 本人必须使用代理才能在工作中访问互联网。如果尝试通过代理获取 localhost URL，将会遭到\n阻止。IE 设置为代理模式，urllib 就会获取到配置信息。为了用 localhost 服务器测试脚本，我\n必须阻止 urllib 使用代理。\n[6] urllib 的 SSL 代理 opener (CONNECT 方法): ASPN Cookbook Recipe。", "metadata": {"title": "13_如何利用_urllib_包获取网络资源", "source": "md_docs\\python_howto_md\\13_如何利用_urllib_包获取网络资源.md", "doc_type": "指南", "language": "中文", "doc_id": "52aa518c"}}
{"doc_id": "b604be47", "content": "用 Python 进行 Curses 编程\n作者: A.M. Kuchling, Eric S. Raymond\n发布版本: 2.04\n摘要\n本文档介绍了如何使用 curses 扩展模块控制文本模式的显示。\ncurses 是什么？\ncurses 库为基于文本的终端提供了独立于终端的屏幕绘制和键盘处理功能；这些终端包括 VT100，\nLinux 控制台以及各种程序提供的模拟终端。显示终端支持各种控制代码以执行常见的操作，例如移\n动光标，滚动屏幕和擦除区域。不同的终端使用相差很大的代码，并且往往有自己的小怪癖。\n在普遍使用图形显示的世界中，人们可能会问“为什么自找要麻烦”？毕竟字符单元显示终端确实是一\n种过时的技术，但是在某些领域中，能够用它们做花哨的事情仍然很有价值。一个小众市场是在不\n运行 X server 的小型或嵌入式 Unix 上。另一个是在提供图形支持之前，可能需要运行的工具，例如\n操作系统安装程序和内核配置程序。\ncurses 库提供了相当基础的功能，为程序员提供了包含多个非重叠文本窗口的显示的抽象。 窗口的\n内容可以通过多种方式更改 --- 添加文本、擦除文本、更改其外观 --- 并且 curses 库将确定需要向终\n端发送哪些控制代码以产生正确的输出。 curses 并没有提供很多用户界面概念如按钮、复选框或对\n话框等；如果你需要这些特性，请考虑某种用户界面库例如 Urwid。\ncurses 库最初是为BSD Unix 编写的。 后来 AT&T 的Unix System V 版本加入了许多增强功能和新功\n能。如今BSD curses已不再维护，被ncurses取代，ncurses是 AT&T 接口的开源实现。如果使用的是\nLinux 或 FreeBSD 等开源Unix系统，则几乎肯定会使用ncurses。由于大多数当前的商业Unix版本都\n基于System V代码，因此这里描述的所有功能可能都可用。但是，某些专有Unix所带来的较早版本\n的curses可能无法支持所有功能。\nPython 的 Windows 版不包括 curses 模块。 一个可用的移植版本是 UniCurses。\nPython 的 curses 模块\n此 Python 模块是对 curses 所提供的 C 函数的一个相当简单的包装器；如果你已经熟悉在 C 中进行\ncurses 编程，把这些知识转移到 Python 是非常容易的。 最大的差异在于 Python 接口通过将不同的\nC 函数比如 addstr(), mvaddstr() 和 mvwaddstr() 合并为一个 addstr() 方法让事情变得更简\n单。 你将在稍后看到更详细的介绍。\n本 HOWTO 是关于使用 curses 和 Python 编写文本模式程序的概述。它并不被设计为一个 curses\nAPI 的完整指南；如需完整指南，请参见 ncurses 的 Python 库指南章节和 ncurses 的 C 手册页。相\n\n| 用 Python 进行 Curses 编程\n作者: A.M. Kuchling, Eric S. Raymond\n发布版本: 2.04 |\n| --- |\n| 摘要\n本文档介绍了如何使用 curses 扩展模块控制文本模式的显示。 |\n| curses 是什么？\ncurses 库为基于文本的终端提供了独立于终端的屏幕绘制和键盘处理功能；这些终端包括 VT100，\nLinux 控制台以及各种程序提供的模拟终端。显示终端支持各种控制代码以执行常见的操作，例如移\n动光标，滚动屏幕和擦除区域。不同的终端使用相差很大的代码，并且往往有自己的小怪癖。\n在普遍使用图形显示的世界中，人们可能会问“为什么自找要麻烦”？毕竟字符单元显示终端确实是一\n种过时的技术，但是在某些领域中，能够用它们做花哨的事情仍然很有价值。一个小众市场是在不\n运行 X server 的小型或嵌入式 Unix 上。另一个是在提供图形支持之前，可能需要运行的工具，例如\n操作系统安装程序和内核配置程序。\ncurses 库提供了相当基础的功能，为程序员提供了包含多个非重叠文本窗口的显示的抽象。 窗口的\n内容可以通过多种方式更改 --- 添加文本、擦除文本、更改其外观 --- 并且 curses 库将确定需要向终\n端发送哪些控制代码以产生正确的输出。 curses 并没有提供很多用户界面概念如按钮、复选框或对\n话框等；如果你需要这些特性，请考虑某种用户界面库例如 Urwid。\ncurses 库最初是为BSD Unix 编写的。 后来 AT&T 的Unix System V 版本加入了许多增强功能和新功\n能。如今BSD curses已不再维护，被ncurses取代，ncurses是 AT&T 接口的开源实现。如果使用的是\nLinux 或 FreeBSD 等开源Unix系统，则几乎肯定会使用ncurses。由于大多数当前的商业Unix版本都\n基于System V代码，因此这里描述的所有功能可能都可用。但是，某些专有Unix所带来的较早版本\n的curses可能无法支持所有功能。\nPython 的 Windows 版不包括 curses 模块。 一个可用的移植版本是 UniCurses。\nPython 的 curses 模块\n此 Python 模块是对 curses 所提供的 C 函数的一个相当简单的包装器；如果你已经熟悉在 C 中进行\ncurses 编程，把这些知识转移到 Python 是非常容易的。 最大的差异在于 Python 接口通过将不同的\nC 函数比如 addstr(), mvaddstr() 和 mvwaddstr() 合并为一个 addstr() 方法让事情变得更简\n单。 你将在稍后看到更详细的介绍。\n本 HOWTO 是关于使用 curses 和 Python 编写文本模式程序的概述。它并不被设计为一个 curses\nAPI 的完整指南；如需完整指南，请参见 ncurses 的 Python 库指南章节和 ncurses 的 C 手册页。相 |\n\n| 作者: |\n| --- |\n| 发布版本: |\n\n对地，本 HOWTO 将会给你一些基本思路。\n开始和结束 curses 应用程序\n在做任何事情之前，curses 必须被初始化。 这是通过调用 initscr() 函数来完成的，它将确定终端\n的类型，向终端发送任何必须的设置代码，并创建多种内部数据结构。 如果执行成功，initscr()\n将返回一个代表整个屏幕的窗口对象；它通常会按照对应的 C 变量被称为 stdscr。\nimport curses\nstdscr = curses.initscr()\n使用 curses 的应用程序通常会关闭按键自动上屏，目的是读取按键并只在特定情况下展示它们。这\n需要调用函数 noecho()：\ncurses.noecho()\n应用程序也会广泛地需要立即响应按键，而不需要按下回车键；这被称为 “cbreak” 模式，与通常的\n缓冲输入模式相对：\ncurses.cbreak()\n终端通常会以多字节转义序列的形式返回特殊按键，比如光标键和导航键比如 Page Up 键和 Home\n键。尽管你可以编写你的程序来应对这些序列，curses 能够代替你做到这件事，返回一个特殊值比\n如 curses.KEY_LEFT。为了让 curses 做这项工作，你需要启用 keypad 模式：\nstdscr.keypad(True)\n终止一个 curses 应用程序比建立一个容易得多，你只需要调用：\ncurses.nocbreak()\nstdscr.keypad(False)\ncurses.echo()\n来还原对终端作出的 curses 友好设置。然后，调用函数 endwin() 来将终端还原到它的原始操作模\n式：\ncurses.endwin()\n调试一个 curses 应用程序时常会发生，一个应用程序还未能还原终端到原本的状态就意外退出了，\n这会搅乱你的终端。在 Python 中这常常会发生在你的代码中有 bug 并引发了一个未捕获的异常。\n当你尝试输入时按键不会上屏，这使得使用终端变得困难。\n在 Python 中你可以避免这些复杂问题并让调试变得更简单，只需要导入 curses.wrapper() 函数并\n像这样使用它：\nfrom curses import wrapper\ndef main(stdscr):\n# 清空屏幕\n\n|  | 对地，本 HOWTO 将会给你一些基本思路。\n开始和结束 curses 应用程序\n在做任何事情之前，curses 必须被初始化。 这是通过调用 initscr() 函数来完成的，它将确定终端\n的类型，向终端发送任何必须的设置代码，并创建多种内部数据结构。 如果执行成功，initscr()\n将返回一个代表整个屏幕的窗口对象；它通常会按照对应的 C 变量被称为 stdscr。 |  |\n| --- | --- | --- |\n|  | import curses\nstdscr = curses.initscr() |  |\n|  | 使用 curses 的应用程序通常会关闭按键自动上屏，目的是读取按键并只在特定情况下展示它们。这\n需要调用函数 noecho()： |  |\n|  | curses.noecho() |  |\n|  | 应用程序也会广泛地需要立即响应按键，而不需要按下回车键；这被称为 “cbreak” 模式，与通常的\n缓冲输入模式相对： |  |\n|  | curses.cbreak() |  |\n|  | 终端通常会以多字节转义序列的形式返回特殊按键，比如光标键和导航键比如 Page Up 键和 Home\n键。尽管你可以编写你的程序来应对这些序列，curses 能够代替你做到这件事，返回一个特殊值比\n如 curses.KEY_LEFT。为了让 curses 做这项工作，你需要启用 keypad 模式： |  |\n|  | stdscr.keypad(True) |  |\n|  | 终止一个 curses 应用程序比建立一个容易得多，你只需要调用： |  |\n|  | curses.nocbreak()\nstdscr.keypad(False)\ncurses.echo() |  |\n|  | 来还原对终端作出的 curses 友好设置。然后，调用函数 endwin() 来将终端还原到它的原始操作模\n式： |  |\n|  | curses.endwin() |  |\n|  | 调试一个 curses 应用程序时常会发生，一个应用程序还未能还原终端到原本的状态就意外退出了，\n这会搅乱你的终端。在 Python 中这常常会发生在你的代码中有 bug 并引发了一个未捕获的异常。\n当你尝试输入时按键不会上屏，这使得使用终端变得困难。\n在 Python 中你可以避免这些复杂问题并让调试变得更简单，只需要导入 curses.wrapper() 函数并\n像这样使用它： |  |\n|  | from curses import wrapper\ndef main(stdscr):\n# 清空屏幕 |  |\n\nstdscr.clear()\n# 当 i == 10 时这将引发 ZeroDivisionError。\nfor i in range(0, 11):\nv = i-10\nstdscr.addstr(i, 0, '10 divided by {} is {}'.format(v, 10/v))\nstdscr.refresh()\nstdscr.getkey()\nwrapper(main)\nwrapper() 函数接受一个可调用对象并进行上述的初始化过程，如果终端支持彩色还会初始化颜\n色。 接下来 wrapper() 会运行你提供的可调用对象。 当该可调用对象返回时，wrapper() 将恢复\n终端的初始状态。 该可调用对象会在 try...except 再被调用以捕获异常，恢复终端状态，然后重新\n引发该异常。 这样你的终端将不会在发生异常时处于不正常状态，你将能够读取异常的消息和回\n溯。\n窗口和面板\n窗口是 curses 中的基本抽象。一个窗口对象表示了屏幕上的一个矩形区域，并且提供方法来显示文\n本、擦除文本、允许用户输入字符串等等。\n函数 initscr() 返回的 stdscr 对象覆盖整个屏幕。许多程序可能只需要这一个窗口，但你可能希\n望把屏幕分割为多个更小的窗口，来分别重绘或者清除它们。函数 newwin() 根据给定的尺寸创建\n一个新窗口，并返回这个新的窗口对象：\nbegin_x = 20; begin_y = 7\nheight = 5; width = 40\nwin = curses.newwin(height, width, begin_y, begin_x)\n注意 curses 使用的坐标系统与寻常的不同。坐标始终是以 y,x 的顺序传递，并且左上角是坐标\n(0,0)。这打破了正常的坐标处理约定，即 x 坐标在前。这是一个与其他计算机应用程序糟糕的差\n异，但这从 curses 最初被编写出来就已是它的一部分，现在想要修改它已为时已晚。\n你的应用程序能够查明屏幕的尺寸，curses.LINES 和 curses.COLS 分别代表了 y 和 x 方向上的尺\n寸。合理的坐标应位于 (0,0) 到 (curses.LINES - 1, curses.COLS - 1) 范围内。\n当你调用一个方法来显示或擦除文本时，效果并不会立即显示。相反，你必须调用窗口对象的\nrefresh() 方法来更新屏幕。\n这是因为 curses 最初是针对 300 波特的龟速终端连接编写的；在这些终端上，减少重绘屏幕的时间\n非常重要。 相应地当你调用 refresh() 时 curses 会累积对屏幕的修改并以最高效的方式显示它\n们。 打个比方，如果你的程序在某个窗口内显示一些文本然后清空了该窗口，那么就没有必要发送\n这些原始文本因为它们从来都不可见。\n在实践中，显式地告诉 curses 重绘一个窗口并不会真的让 curses 复杂多少。 大部分程序会进行一\n系列活动，然后暂停并等待按键或者用户方的其他动作。 你要做的事情就是保证屏幕在暂停并等待\n用户输入之前已被重绘，具体方式是首先调用 stdscr.refresh() 或其他相关窗口的 refresh() 方\n法。\n\n|  | stdscr.clear()\n# 当 i == 10 时这将引发 ZeroDivisionError。\nfor i in range(0, 11):\nv = i-10\nstdscr.addstr(i, 0, '10 divided by {} is {}'.format(v, 10/v))\nstdscr.refresh()\nstdscr.getkey()\nwrapper(main) |  |\n| --- | --- | --- |\n|  | wrapper() 函数接受一个可调用对象并进行上述的初始化过程，如果终端支持彩色还会初始化颜\n色。 接下来 wrapper() 会运行你提供的可调用对象。 当该可调用对象返回时，wrapper() 将恢复\n终端的初始状态。 该可调用对象会在 try...except 再被调用以捕获异常，恢复终端状态，然后重新\n引发该异常。 这样你的终端将不会在发生异常时处于不正常状态，你将能够读取异常的消息和回\n溯。\n窗口和面板\n窗口是 curses 中的基本抽象。一个窗口对象表示了屏幕上的一个矩形区域，并且提供方法来显示文\n本、擦除文本、允许用户输入字符串等等。\n函数 initscr() 返回的 stdscr 对象覆盖整个屏幕。许多程序可能只需要这一个窗口，但你可能希\n望把屏幕分割为多个更小的窗口，来分别重绘或者清除它们。函数 newwin() 根据给定的尺寸创建\n一个新窗口，并返回这个新的窗口对象： |  |\n|  | begin_x = 20; begin_y = 7\nheight = 5; width = 40\nwin = curses.newwin(height, width, begin_y, begin_x) |  |\n|  | 注意 curses 使用的坐标系统与寻常的不同。坐标始终是以 y,x 的顺序传递，并且左上角是坐标\n(0,0)。这打破了正常的坐标处理约定，即 x 坐标在前。这是一个与其他计算机应用程序糟糕的差\n异，但这从 curses 最初被编写出来就已是它的一部分，现在想要修改它已为时已晚。\n你的应用程序能够查明屏幕的尺寸，curses.LINES 和 curses.COLS 分别代表了 y 和 x 方向上的尺\n寸。合理的坐标应位于 (0,0) 到 (curses.LINES - 1, curses.COLS - 1) 范围内。\n当你调用一个方法来显示或擦除文本时，效果并不会立即显示。相反，你必须调用窗口对象的\nrefresh() 方法来更新屏幕。\n这是因为 curses 最初是针对 300 波特的龟速终端连接编写的；在这些终端上，减少重绘屏幕的时间\n非常重要。 相应地当你调用 refresh() 时 curses 会累积对屏幕的修改并以最高效的方式显示它\n们。 打个比方，如果你的程序在某个窗口内显示一些文本然后清空了该窗口，那么就没有必要发送\n这些原始文本因为它们从来都不可见。\n在实践中，显式地告诉 curses 重绘一个窗口并不会真的让 curses 复杂多少。 大部分程序会进行一\n系列活动，然后暂停并等待按键或者用户方的其他动作。 你要做的事情就是保证屏幕在暂停并等待\n用户输入之前已被重绘，具体方式是首先调用 stdscr.refresh() 或其他相关窗口的 refresh() 方\n法。 |  |\n\n一个面板是一种特殊的窗口，它可以比实际的显示屏幕更大，并且能只显示它的一部分。创建面板\n需要指定面板的高度和宽度，但刷新一个面板需要给出屏幕坐标和面板的需要显示的局部。\npad = curses.newpad(100, 100)\n# 这个循环使用字母填充 pad；addch() 函数将在下一部分解释\nfor y in range(0, 99):\nfor x in range(0, 99):\npad.addch(y,x, ord('a') + (x*x+y*y) % 26)\n# 在屏幕中央显示 pad 的某个区域。\n# (0,0) ：要显示的 pad 区域的左上角坐标。\n# (5,5) ：要填充到窗口的左上角坐标。\n# (20, 75) ：填充到窗口的右下角坐标。\npad.refresh( 0,0, 5,5, 20,75)\n此 refresh() 调用位在屏幕坐标 (5,5) 到坐标 (20,75) 的矩形范围内显示面板的一个部分；被显示部\n分在面板上的坐标是 (0,0)。 除了上述差异，面板非常像是普通窗口并支持相同的方法。\n如果你在屏幕上有多个窗口和面板那么有个更高效的方式来更新屏幕并防止屏幕的每部分被更新时\n出现烦人的屏幕闪烁。 refresh() 实际上做了两件事:\n1. 调用每个窗口的 noutrefresh() 方法来更新一个表达屏幕期望状态的底层的数据结构。\n2. 调用函数 doupdate() 来改变物理屏幕来符合这个数据结构中记录的期望状态。\n你可以改为在多个窗口上调用 noutrefresh() 来更新该数据结构，然后调用 doupdate() 来更新屏\n幕。\n显示文字\n从一名 C 程序员的视角来看，curses 有时看起来就像是一堆函数组成的迷宫，每个都有细微的差\n异。 举个例子，addstr() 是在 stdscr 窗口的当前光标位置显示一个字符串，而 mvaddstr() 则是\n在显示字符串之前先移动到给定的 y,x 坐标。 waddstr() 与 addstr() 很像，但允许指定一个要使\n用的窗口而不是默认使用 stdscr。 mvwaddstr() 允许同时指定一个窗口和一个坐标。\n幸运的是，Python 接口隐藏了所有这些细节。stdscr 和其他任何窗口一样是一个窗口对象，并且\n诸如 addstr() 之类的方法接受多种参数形式。通常有四种形式。\n形式 描述\nstr 或 ch 在当前位置显示字符串 str 或字符 ch\nstr 或 ch, attr 在当前位置使用 attr 属性显示字符串 str 或字符 ch\ny, x, str 或 ch 移动到窗口内的 y,x 位置，并显示 str 或 ch\ny, x, str 或 ch, attr 移至窗口内的 y,x 位置，并使用 attr 属性显示 str 或 ch\n属性允许以突出显示形态显示文本，比如加粗、下划线、反相或添加颜色。这些属性将来下一小节\n细说。\n\n|  | 一个面板是一种特殊的窗口，它可以比实际的显示屏幕更大，并且能只显示它的一部分。创建面板\n需要指定面板的高度和宽度，但刷新一个面板需要给出屏幕坐标和面板的需要显示的局部。 |  |\n| --- | --- | --- |\n|  | pad = curses.newpad(100, 100)\n# 这个循环使用字母填充 pad；addch() 函数将在下一部分解释\nfor y in range(0, 99):\nfor x in range(0, 99):\npad.addch(y,x, ord('a') + (x*x+y*y) % 26)\n# 在屏幕中央显示 pad 的某个区域。\n# (0,0) ：要显示的 pad 区域的左上角坐标。\n# (5,5) ：要填充到窗口的左上角坐标。\n# (20, 75) ：填充到窗口的右下角坐标。\npad.refresh( 0,0, 5,5, 20,75) |  |\n|  | 此 refresh() 调用位在屏幕坐标 (5,5) 到坐标 (20,75) 的矩形范围内显示面板的一个部分；被显示部\n分在面板上的坐标是 (0,0)。 除了上述差异，面板非常像是普通窗口并支持相同的方法。\n如果你在屏幕上有多个窗口和面板那么有个更高效的方式来更新屏幕并防止屏幕的每部分被更新时\n出现烦人的屏幕闪烁。 refresh() 实际上做了两件事:\n1. 调用每个窗口的 noutrefresh() 方法来更新一个表达屏幕期望状态的底层的数据结构。\n2. 调用函数 doupdate() 来改变物理屏幕来符合这个数据结构中记录的期望状态。\n你可以改为在多个窗口上调用 noutrefresh() 来更新该数据结构，然后调用 doupdate() 来更新屏\n幕。\n显示文字\n从一名 C 程序员的视角来看，curses 有时看起来就像是一堆函数组成的迷宫，每个都有细微的差\n异。 举个例子，addstr() 是在 stdscr 窗口的当前光标位置显示一个字符串，而 mvaddstr() 则是\n在显示字符串之前先移动到给定的 y,x 坐标。 waddstr() 与 addstr() 很像，但允许指定一个要使\n用的窗口而不是默认使用 stdscr。 mvwaddstr() 允许同时指定一个窗口和一个坐标。\n幸运的是，Python 接口隐藏了所有这些细节。stdscr 和其他任何窗口一样是一个窗口对象，并且\n诸如 addstr() 之类的方法接受多种参数形式。通常有四种形式。\n形式 描述\nstr 或 ch 在当前位置显示字符串 str 或字符 ch\nstr 或 ch, attr 在当前位置使用 attr 属性显示字符串 str 或字符 ch\ny, x, str 或 ch 移动到窗口内的 y,x 位置，并显示 str 或 ch\ny, x, str 或 ch, attr 移至窗口内的 y,x 位置，并使用 attr 属性显示 str 或 ch\n属性允许以突出显示形态显示文本，比如加粗、下划线、反相或添加颜色。这些属性将来下一小节\n细说。 |  |\n\n| 形式 | 描述 |\n| --- | --- |\n| str 或 ch | 在当前位置显示字符串 str 或字符 ch |\n| str 或 ch, attr | 在当前位置使用 attr 属性显示字符串 str 或字符 ch |\n| y, x, str 或 ch | 移动到窗口内的 y,x 位置，并显示 str 或 ch |\n| y, x, str 或 ch, attr | 移至窗口内的 y,x 位置，并使用 attr 属性显示 str 或 ch |\n\naddstr() 方法接受一个 Python 字符串或字节串作为要显示的值。 字节串的内容会被原样发送到终\n端。 字符串会使用窗口的 encoding 属性值指定的编码格式编码为字节串；该值默认为\nlocale.getencoding() 所返回的系统编码格式。\n方法 addch() 接受一个字符，可以是长度为 1 的字符串，长度为 1 的字节串或者一个整数。\n对于特殊扩展字符有一些常量，这些常量是大于 255 的整数。比如，ACS_PLMINUS 是一个 “加减” 符\n号，ACS_ULCORNER 是一个框的左上角（方便绘制边界）。你也可以使用正确的 Unicode 字符。\n窗口会记住上次操作之后光标所在位置，所以如果你忽略 y,x 坐标，字符串和字符会出现在上次操作\n结束的位置。你也可以通过 move(y,x) 的方法来移动光标。因为一些终端始终会显示一个闪烁的光\n标，你可能会想要保证光标处于一些不会让人感到分心的位置。在看似随机的位置出现一个闪烁的\n光标会令人非常迷惑。\n如果你的应用程序完全不需要一个闪烁的光标，你可以调用 curs_set(False) 来使它隐形。为与旧\n版本 curses 的兼容性的关系，有函数 leaveok(bool) 作为 curs_set() 的等价替换。如果 bool 是\n真值，curses 库会尝试移除闪烁光标，并且你也不必担心它会留在一些奇怪的位置。\n属性和颜色\n字符可以以不同的方式显示。基于文本的应用程序常常以反相显示状态行，一个文本查看器可能需\n要突出显示某些单词。为了支持这种用法，curses 允许你为屏幕上的每个单元指定一个属性值。\n属性值是一个整数，它的每一个二进制位代表一个不同的属性。你可以尝试以多种不属性位组合来\n显示文本，但 curses 不保证所有的组合都是有效的，或者看上去有明显不同。这一点取决于用户终\n端的能力，所以最稳妥的方式是只采用最常见的有效属性，见下表。\n属性 描述\nA_BLINK 闪烁文本\nA_BOLD 超亮或粗体文本\nA_DIM 半明亮文本\nA_REVERSE 反相显示文本\nA_STANDOUT 可用的最佳突出显示模式\nA_UNDERLINE 带下划线的文本\n所以，为了在屏幕顶部显示一个反相的状态行，你可以这么编写：\nstdscr.addstr(0, 0, \"Current mode: Typing mode\",\ncurses.A_REVERSE)\nstdscr.refresh()\ncurses 库还支持在提供了颜色功能的终端上显示颜色的功能。最常见的提供颜色的终端很可能是\nLinux 控制台，采用了 xterms 配色方案。\n\n|  | addstr() 方法接受一个 Python 字符串或字节串作为要显示的值。 字节串的内容会被原样发送到终\n端。 字符串会使用窗口的 encoding 属性值指定的编码格式编码为字节串；该值默认为\nlocale.getencoding() 所返回的系统编码格式。\n方法 addch() 接受一个字符，可以是长度为 1 的字符串，长度为 1 的字节串或者一个整数。\n对于特殊扩展字符有一些常量，这些常量是大于 255 的整数。比如，ACS_PLMINUS 是一个 “加减” 符\n号，ACS_ULCORNER 是一个框的左上角（方便绘制边界）。你也可以使用正确的 Unicode 字符。\n窗口会记住上次操作之后光标所在位置，所以如果你忽略 y,x 坐标，字符串和字符会出现在上次操作\n结束的位置。你也可以通过 move(y,x) 的方法来移动光标。因为一些终端始终会显示一个闪烁的光\n标，你可能会想要保证光标处于一些不会让人感到分心的位置。在看似随机的位置出现一个闪烁的\n光标会令人非常迷惑。\n如果你的应用程序完全不需要一个闪烁的光标，你可以调用 curs_set(False) 来使它隐形。为与旧\n版本 curses 的兼容性的关系，有函数 leaveok(bool) 作为 curs_set() 的等价替换。如果 bool 是\n真值，curses 库会尝试移除闪烁光标，并且你也不必担心它会留在一些奇怪的位置。\n属性和颜色\n字符可以以不同的方式显示。基于文本的应用程序常常以反相显示状态行，一个文本查看器可能需\n要突出显示某些单词。为了支持这种用法，curses 允许你为屏幕上的每个单元指定一个属性值。\n属性值是一个整数，它的每一个二进制位代表一个不同的属性。你可以尝试以多种不属性位组合来\n显示文本，但 curses 不保证所有的组合都是有效的，或者看上去有明显不同。这一点取决于用户终\n端的能力，所以最稳妥的方式是只采用最常见的有效属性，见下表。\n属性 描述\nA_BLINK 闪烁文本\nA_BOLD 超亮或粗体文本\nA_DIM 半明亮文本\nA_REVERSE 反相显示文本\nA_STANDOUT 可用的最佳突出显示模式\nA_UNDERLINE 带下划线的文本\n所以，为了在屏幕顶部显示一个反相的状态行，你可以这么编写： |  |\n| --- | --- | --- |\n|  | stdscr.addstr(0, 0, \"Current mode: Typing mode\",\ncurses.A_REVERSE)\nstdscr.refresh() |  |\n|  | curses 库还支持在提供了颜色功能的终端上显示颜色的功能。最常见的提供颜色的终端很可能是\nLinux 控制台，采用了 xterms 配色方案。 |  |\n\n| 属性 | 描述 |\n| --- | --- |\n| A_BLINK | 闪烁文本 |\n| A_BOLD | 超亮或粗体文本 |\n| A_DIM | 半明亮文本 |\n| A_REVERSE | 反相显示文本 |\n| A_STANDOUT | 可用的最佳突出显示模式 |\n| A_UNDERLINE | 带下划线的文本 |\n\n为了使用颜色，你必须在调用完函数 initscr() 后尽快调用函数 start_color()，来初始化默认颜\n色集 (curses.wrapper() 函数自动完成了这一点)。 当它完成后，如果使用中的终端支持显示颜\n色， has_colors() 会返回真值。 （注意：curses 使用美式拼写 “color”，而不是英式／加拿大拼写\n“colour”。如果你习惯了英式拼写，你需要避免自己在这些函数上拼写错误。）\ncurses 库维护一个有限数量的颜色对，包括一个前景（文本）色和一个背景色。你可以使用函数\ncolor_pair() 获得一个颜色对对应的属性值。它可以通过按位或运算与其他属性，比如\nA_REVERSE 组合。但再说明一遍，这种组合并不保证在所有终端上都有效。\n一个样例，用 1 号颜色对显示一行文本：\nstdscr.addstr(\"Pretty text\", curses.color_pair(1))\nstdscr.refresh()\n如前所述， 颜色对由前景色和背景色组成。 init_pair(n, f, b) 函数可改变颜色对 n 的定义 为\n前景色 f 和背景色 b。 颜色对 0 硬编码为黑底白字，不能改变。\n颜色已经被编号，并且当其激活 color 模式时 start_color() 会初始化 8 种基本颜色。 它们是:\n0:black, 1:red, 2:green, 3:yellow, 4:blue, 5:magenta, 6:cyan 和 7:white。 curses 模块为这些颜色定义\n了相应的名称常量: curses.COLOR_BLACK, curses.COLOR_RED 等等。\n让我们来做个综合练习。 要将颜色 1 改为红色文本白色背景，你应当调用:\ncurses.init_pair(1, curses.COLOR_RED, curses.COLOR_WHITE)\n当你改变一个颜色对时，任何已经使用该颜色对来显示的文本将会更改为新的颜色。 你还可以这样\n来显示新颜色的文本:\nstdscr.addstr(0,0, \"RED ALERT!\", curses.color_pair(1))\n某些非常花哨的终端可以将实际颜色定义修改为给定的 RGB 值。 这允许你将通常为红色的 1 号颜色\n改成紫色或蓝色或者任何你喜欢的颜色。 不幸的是，Linux 控制台不支持此特性，所以我无法尝试\n它，也无法提供任何示例。 想要检查你的终端是否能做到你可以调用 can_change_color()，如果\n有此功能则它将返回 True。 如果你幸运地拥有一个如此优秀的终端，请查询你的系统的帮助页面来\n了解详情。\n用户输入\nC curses 库只提供了非常简单的输入机制。 Python 的 curses 模块增加了一个基本的文本输入控\n件。 （其他的库如 Urwid 拥有更丰富的控件集。）\n有两个方法可以从窗口获取输入:\ngetch() 会刷新屏幕然后等待用户按键，如果之前调用过 echo() 还会显示所按的键。 你还可以\n选择指定一个坐标以便在暂停之前让光标移动到那里。\ngetkey() 将做同样的事但是会把整数转换为字符串。 每个字符将返回为长度为 1 个字符的字符\n串，特殊键例如函数键将返回包含键名的较长字符串例如 KEY_UP 或 ^G。\n\n|  | 为了使用颜色，你必须在调用完函数 initscr() 后尽快调用函数 start_color()，来初始化默认颜\n色集 (curses.wrapper() 函数自动完成了这一点)。 当它完成后，如果使用中的终端支持显示颜\n色， has_colors() 会返回真值。 （注意：curses 使用美式拼写 “color”，而不是英式／加拿大拼写\n“colour”。如果你习惯了英式拼写，你需要避免自己在这些函数上拼写错误。）\ncurses 库维护一个有限数量的颜色对，包括一个前景（文本）色和一个背景色。你可以使用函数\ncolor_pair() 获得一个颜色对对应的属性值。它可以通过按位或运算与其他属性，比如\nA_REVERSE 组合。但再说明一遍，这种组合并不保证在所有终端上都有效。\n一个样例，用 1 号颜色对显示一行文本： |  |\n| --- | --- | --- |\n|  | stdscr.addstr(\"Pretty text\", curses.color_pair(1))\nstdscr.refresh() |  |\n|  | 如前所述， 颜色对由前景色和背景色组成。 init_pair(n, f, b) 函数可改变颜色对 n 的定义 为\n前景色 f 和背景色 b。 颜色对 0 硬编码为黑底白字，不能改变。\n颜色已经被编号，并且当其激活 color 模式时 start_color() 会初始化 8 种基本颜色。 它们是:\n0:black, 1:red, 2:green, 3:yellow, 4:blue, 5:magenta, 6:cyan 和 7:white。 curses 模块为这些颜色定义\n了相应的名称常量: curses.COLOR_BLACK, curses.COLOR_RED 等等。\n让我们来做个综合练习。 要将颜色 1 改为红色文本白色背景，你应当调用: |  |\n|  | curses.init_pair(1, curses.COLOR_RED, curses.COLOR_WHITE) |  |\n|  | 当你改变一个颜色对时，任何已经使用该颜色对来显示的文本将会更改为新的颜色。 你还可以这样\n来显示新颜色的文本: |  |\n|  | stdscr.addstr(0,0, \"RED ALERT!\", curses.color_pair(1)) |  |\n|  | 某些非常花哨的终端可以将实际颜色定义修改为给定的 RGB 值。 这允许你将通常为红色的 1 号颜色\n改成紫色或蓝色或者任何你喜欢的颜色。 不幸的是，Linux 控制台不支持此特性，所以我无法尝试\n它，也无法提供任何示例。 想要检查你的终端是否能做到你可以调用 can_change_color()，如果\n有此功能则它将返回 True。 如果你幸运地拥有一个如此优秀的终端，请查询你的系统的帮助页面来\n了解详情。\n用户输入\nC curses 库只提供了非常简单的输入机制。 Python 的 curses 模块增加了一个基本的文本输入控\n件。 （其他的库如 Urwid 拥有更丰富的控件集。）\n有两个方法可以从窗口获取输入:\ngetch() 会刷新屏幕然后等待用户按键，如果之前调用过 echo() 还会显示所按的键。 你还可以\n选择指定一个坐标以便在暂停之前让光标移动到那里。\ngetkey() 将做同样的事但是会把整数转换为字符串。 每个字符将返回为长度为 1 个字符的字符\n串，特殊键例如函数键将返回包含键名的较长字符串例如 KEY_UP 或 ^G。 |  |\n\n使用 nodelay() 窗口方法可以不等待用户操作。 在 nodelay(True) 之后，窗口的 getch() 和\ngetkey() 将成为非阻塞的。 为表明输入未就绪，getch() 会返回 curses.ERR (值为 -1) 并且\ngetkey() 会引发异常。 此外还有 halfdelay() 函数，它可被用来 (实际地) 在每个 getch() 上设\n置一个计时器；如果在指定的延迟内 (以十分之一秒为单位) 输入还不可用，curses 将引发异常。\ngetch() 方法返回一个整数；如果其值在 0 到 255 之间，它代表所按的键的 ASCII 码。 大于 255 的\n值为特殊键例如 Page Up, Home 或方向键等。 你可以将返回的值与 curses.KEY_PPAGE,\ncurses.KEY_HOME 或 curses.KEY_LEFT 等常量做比较。 你的程序的主循环看起来可能会像这样:\nwhile True:\nc = stdscr.getch()\nif c == ord('p'):\nPrintDocument()\nelif c == ord('q'):\nbreak # 退出 while 循环\nelif c == curses.KEY_HOME:\nx = y = 0\ncurses.ascii 模块提供了一些 ASCII 类成员函数，它们接受整数或长度为 1 个字符的字符串参数；\n这些函数在为这样的循环编写更具可读性的测试时可能会很有用。 它还提供了一些转换函数，它们\n接受整数或长度为 1 个字符的字符串参数并返回同样的类型。 例如，curses.ascii.ctrl() 返回\n与其参数相对应的控制字符。\n还有一个可以提取整个字符串的方法 getstr()。 它并不经常被使用，因为它的功能相当受限；可\n用的编辑键只有 Backspace 和 Enter 键，它们会结束字符串。 也可以选择限制为固定数量的字符。\ncurses.echo() # 启用字符回显\n# 获取一个 15 个字符的字符串，光标位于顶端行\ns = stdscr.getstr(0,0, 15)\ncurses.textpad 模块提供了一个文本框，它支持类似 Emacs 的键绑定集。 Textbox 类的各种方法\n支持带输入验证的编辑及包含或不包含末尾空格地收集编辑结果。 下面是一个例子:\nimport curses\nfrom curses.textpad import Textbox, rectangle\ndef main(stdscr):\nstdscr.addstr(0, 0, \"Enter IM message: (hit Ctrl-G to send)\")\neditwin = curses.newwin(5,30, 2,1)\nrectangle(stdscr, 1,0, 1+5+1, 1+30+1)\nstdscr.refresh()\nbox = Textbox(editwin)\n# 让用户编辑直到按下 Ctrl-G。\nbox.edit()\n# 获取结果内容\nmessage = box.gather()\n\n|  | 使用 nodelay() 窗口方法可以不等待用户操作。 在 nodelay(True) 之后，窗口的 getch() 和\ngetkey() 将成为非阻塞的。 为表明输入未就绪，getch() 会返回 curses.ERR (值为 -1) 并且\ngetkey() 会引发异常。 此外还有 halfdelay() 函数，它可被用来 (实际地) 在每个 getch() 上设\n置一个计时器；如果在指定的延迟内 (以十分之一秒为单位) 输入还不可用，curses 将引发异常。\ngetch() 方法返回一个整数；如果其值在 0 到 255 之间，它代表所按的键的 ASCII 码。 大于 255 的\n值为特殊键例如 Page Up, Home 或方向键等。 你可以将返回的值与 curses.KEY_PPAGE,\ncurses.KEY_HOME 或 curses.KEY_LEFT 等常量做比较。 你的程序的主循环看起来可能会像这样: |  |\n| --- | --- | --- |\n|  | while True:\nc = stdscr.getch()\nif c == ord('p'):\nPrintDocument()\nelif c == ord('q'):\nbreak # 退出 while 循环\nelif c == curses.KEY_HOME:\nx = y = 0 |  |\n|  | curses.ascii 模块提供了一些 ASCII 类成员函数，它们接受整数或长度为 1 个字符的字符串参数；\n这些函数在为这样的循环编写更具可读性的测试时可能会很有用。 它还提供了一些转换函数，它们\n接受整数或长度为 1 个字符的字符串参数并返回同样的类型。 例如，curses.ascii.ctrl() 返回\n与其参数相对应的控制字符。\n还有一个可以提取整个字符串的方法 getstr()。 它并不经常被使用，因为它的功能相当受限；可\n用的编辑键只有 Backspace 和 Enter 键，它们会结束字符串。 也可以选择限制为固定数量的字符。 |  |\n|  | curses.echo() # 启用字符回显\n# 获取一个 15 个字符的字符串，光标位于顶端行\ns = stdscr.getstr(0,0, 15) |  |\n|  | curses.textpad 模块提供了一个文本框，它支持类似 Emacs 的键绑定集。 Textbox 类的各种方法\n支持带输入验证的编辑及包含或不包含末尾空格地收集编辑结果。 下面是一个例子: |  |\n|  | import curses\nfrom curses.textpad import Textbox, rectangle\ndef main(stdscr):\nstdscr.addstr(0, 0, \"Enter IM message: (hit Ctrl-G to send)\")\neditwin = curses.newwin(5,30, 2,1)\nrectangle(stdscr, 1,0, 1+5+1, 1+30+1)\nstdscr.refresh()\nbox = Textbox(editwin)\n# 让用户编辑直到按下 Ctrl-G。\nbox.edit()\n# 获取结果内容\nmessage = box.gather() |  |\n|  |  |  |\n\n请查看 curses.textpad 的库文档了解更多细节。\n更多的信息\n本 HOWTO 没有涵盖一些进阶主题，例如读取屏幕的内容或从 xterm 实例捕获鼠标事件等，但是\ncurses 模块的 Python 库文档页面现在已相当完善。 接下来你应当去浏览一下其中的内容。\n如果你对 curses 函数的细节行为有疑问，请查看你的 curses 具体实现的指南页面不论它是 ncurses\n还是特定 Unix 厂商的版本。 指南页面将写明各种怪异问题，并为你提供所有函数、属性及可用\nACS_* 字符的完整列表。\n由于 curses API 是如此的庞大，某些函数并不被 Python 接口所支持。 这往往不是因为它们难以实\n现，而是因为还没有人需要它们。 此外，Python 尚不支持与 ncurses 相关联的菜单库。 欢迎提供添\n加这些功能的补丁；请参阅 Python 开发者指南 了解有关为 Python 提交补丁的详情。\nWriting Programs with NCURSES: 一个面向 C 程序员的详细教程。\nncurses 手册主页\nncurses 常见问题\n\"使用 curses... 请勿爆粗\": 一场有关使用 curses 或 Urwid 来控制终端的 PyCon 2013 演讲的视频。\n\"使用 Urwid 的控制台应用程序\": 一场演示使用 Urwid 编写应用程序的 PyCon CA 2012 演讲的视\n频。", "metadata": {"title": "14_用_Python_进行_Curses_编程", "source": "md_docs\\python_howto_md\\14_用_Python_进行_Curses_编程.md", "doc_type": "指南", "language": "中文", "doc_id": "b604be47"}}
{"doc_id": "7bd8ef44", "content": "Python 对自由线程的支持\n从 3.13 发布版开始，CPython 支持 free threading 的 Python 构建，其禁用 global interpreter lock\n(GIL)。 自由线程化的执行允许在可用的 CPU 核心上并行运行线程，充分利用可用的处理能力。 尽\n管并非所有软件都能自动地从中受益，但是考虑到线程设计的程序在多核硬件上运行速度会更快。\n自由线程模式目前可用并在不断改进，但与常规构建相比，单线程工作负载会产生一些额外的开\n销。此外，第三方软件包，特别是带有 extension module 的软件包，可能无法在自由线程构建中使\n用，并将重新启用 GIL。\n本文档描述了自由线程对 Python 代码的影响。 请参阅 自由线程的 C API 扩展支持 了解如何编写支\n持自由线程构建的 C 扩展。\n参见: PEP 703 —— 查阅《在 CPython 中使全局解释器锁成为可选项》以了解对自由线程\nPython 的整体描述。\n安装\n从 Python 3.13 开始，官方 macOS 和 Windows 安装器提供了对可选安装自由线程 Python 二进制文\n件的支持。 安装器可在 https://www.python.org/downloads/ 获取。\n有关其他平台的信息，请参阅 Installing a Free-Threaded Python，这是一份由社区维护的针对安装\n自由线程版 Python 的安装指南。\n当从源码构建 CPython 时，应使用 --disable-gil 配置选项以构建自由线程 Python 解释器\n识别自由线程 Python\n要判断当前解释器是否支持自由线程，可检查 python -VV 和 sys.version 是否包含 \"free-\nthreading build\"。 新的 sys._is_gil_enabled() 函数可用于检查在运行进程中 GIL 是否确实被关\n闭。\nsysconfig.get_config_var(\"Py_GIL_DISABLED\") 配置变量可用于确定构建是否支持自由线程 。\n如果该变量设置为 1，则构建支持自由线程。 这是与构建配置相关的决策的推荐机制。\n自由线程版 Python 中的全局解释器锁\nCPython 的自由线程构建版支持在运行时使用环境变量 PYTHON_GIL 或命令行选项 -X gil 选择性\n地启用 GIL。\nGIL 也可能在导入未显式标记为支持自由线程模式的 C-API 扩展模块时被自动启用。 在这种情况下\n将会打印一条警告。\n\n| Python 对自由线程的支持\n从 3.13 发布版开始，CPython 支持 free threading 的 Python 构建，其禁用 global interpreter lock\n(GIL)。 自由线程化的执行允许在可用的 CPU 核心上并行运行线程，充分利用可用的处理能力。 尽\n管并非所有软件都能自动地从中受益，但是考虑到线程设计的程序在多核硬件上运行速度会更快。\n自由线程模式目前可用并在不断改进，但与常规构建相比，单线程工作负载会产生一些额外的开\n销。此外，第三方软件包，特别是带有 extension module 的软件包，可能无法在自由线程构建中使\n用，并将重新启用 GIL。\n本文档描述了自由线程对 Python 代码的影响。 请参阅 自由线程的 C API 扩展支持 了解如何编写支\n持自由线程构建的 C 扩展。 |\n| --- |\n| 参见: PEP 703 —— 查阅《在 CPython 中使全局解释器锁成为可选项》以了解对自由线程\nPython 的整体描述。 |\n| 安装\n从 Python 3.13 开始，官方 macOS 和 Windows 安装器提供了对可选安装自由线程 Python 二进制文\n件的支持。 安装器可在 https://www.python.org/downloads/ 获取。\n有关其他平台的信息，请参阅 Installing a Free-Threaded Python，这是一份由社区维护的针对安装\n自由线程版 Python 的安装指南。\n当从源码构建 CPython 时，应使用 --disable-gil 配置选项以构建自由线程 Python 解释器\n识别自由线程 Python\n要判断当前解释器是否支持自由线程，可检查 python -VV 和 sys.version 是否包含 \"free-\nthreading build\"。 新的 sys._is_gil_enabled() 函数可用于检查在运行进程中 GIL 是否确实被关\n闭。\nsysconfig.get_config_var(\"Py_GIL_DISABLED\") 配置变量可用于确定构建是否支持自由线程 。\n如果该变量设置为 1，则构建支持自由线程。 这是与构建配置相关的决策的推荐机制。\n自由线程版 Python 中的全局解释器锁\nCPython 的自由线程构建版支持在运行时使用环境变量 PYTHON_GIL 或命令行选项 -X gil 选择性\n地启用 GIL。\nGIL 也可能在导入未显式标记为支持自由线程模式的 C-API 扩展模块时被自动启用。 在这种情况下\n将会打印一条警告。 |\n\n在单独软件包的文档以外，还有下列网站在追踪热门软件包对自由线程模式的支持状态：\nhttps://py-free-threading.github.io/tracking/\nhttps://hugovk.github.io/free-threaded-wheels/\n线程安全\n自由线程构建的 CPython 旨在 Python 层级提供与默认全局解释器锁启用构建相似的线程安全行\n为。内置类型（如 dict 、 list 和 set 等）使用内部上锁来防止并发修改，其行为方式与全局解\n释器锁相似。 但是，Python 历来不对这些内置类型的并发修改提供特定的行为提供保证，因此这应\n被视为对当前实现的描述，而不是对当前或未来行为的保证。\n备注: 建议尽可能使用 threading.Lock 或其他同步的原语，而不是依赖内置类型的内部上锁 。\n已知的限制\n本节介绍自由线程 CPython 构建的已知限制。\n永生化\n3.13 版本的自由线程构建使某些对象 immortal。 永生对象不会被重新分配，其引用计数永远不会被\n修改。 这样做是为了避免引用计数发生争夺，以免妨碍高效的多线程扩展。\n当主线程运行后首次启动新的线程时，对象将被永生化。 以下对象将被永生化：\n在模块中声明的 函数 对象\n方法 描述器\n代码对象\nmodule 对象及其字典\n类 (类型对象)\n由于永生对象永远不会被重新分配，因此应用如果创建了许多此类对象，可能会增加内存使用。预\n计 3.14 版将解决这个问题。\n此外，代码中的数字和字符串字面值以及 sys.intern() 返回的字符串也将永久化。 预计在 3.14 自\n由线程构建中将保留这一行为 。\n帧对象\n从其他线程访问 帧 对象是不安全的，这样做可能会导致程序崩溃。 这意味着，在自由线程构建中使\n用 sys._current_frames() 一般是不安全的。 函数（如 inspect.currentframe() 和\nsys._getframe() 等）只要不将生成的帧对象传递给另一个线程，一般都是安全的。\n迭代器\n\n|  | 在单独软件包的文档以外，还有下列网站在追踪热门软件包对自由线程模式的支持状态：\nhttps://py-free-threading.github.io/tracking/\nhttps://hugovk.github.io/free-threaded-wheels/\n线程安全\n自由线程构建的 CPython 旨在 Python 层级提供与默认全局解释器锁启用构建相似的线程安全行\n为。内置类型（如 dict 、 list 和 set 等）使用内部上锁来防止并发修改，其行为方式与全局解\n释器锁相似。 但是，Python 历来不对这些内置类型的并发修改提供特定的行为提供保证，因此这应\n被视为对当前实现的描述，而不是对当前或未来行为的保证。 |  |\n| --- | --- | --- |\n|  | 备注: 建议尽可能使用 threading.Lock 或其他同步的原语，而不是依赖内置类型的内部上锁 。 |  |\n|  | 已知的限制\n本节介绍自由线程 CPython 构建的已知限制。\n永生化\n3.13 版本的自由线程构建使某些对象 immortal。 永生对象不会被重新分配，其引用计数永远不会被\n修改。 这样做是为了避免引用计数发生争夺，以免妨碍高效的多线程扩展。\n当主线程运行后首次启动新的线程时，对象将被永生化。 以下对象将被永生化：\n在模块中声明的 函数 对象\n方法 描述器\n代码对象\nmodule 对象及其字典\n类 (类型对象)\n由于永生对象永远不会被重新分配，因此应用如果创建了许多此类对象，可能会增加内存使用。预\n计 3.14 版将解决这个问题。\n此外，代码中的数字和字符串字面值以及 sys.intern() 返回的字符串也将永久化。 预计在 3.14 自\n由线程构建中将保留这一行为 。\n帧对象\n从其他线程访问 帧 对象是不安全的，这样做可能会导致程序崩溃。 这意味着，在自由线程构建中使\n用 sys._current_frames() 一般是不安全的。 函数（如 inspect.currentframe() 和\nsys._getframe() 等）只要不将生成的帧对象传递给另一个线程，一般都是安全的。\n迭代器 |  |\n\n在多个线程之间共享同一个迭代器对象通常是不安全的，线程在迭代时可能会出现元素重复或缺失\n的情况，或使解释器崩溃。\n单线程性能\n与启用默认全局解释器锁的构建相比，自由线程构建在执行 Python 代码时有额外的开销。 在 3.13\n中，pyperformance 套件的开销约为 40%。大部分时间花在 C 扩展或 I/O 上的程序受到的影响较\n小。影响最大的原因是在自由线程构建中禁用了特化自适应解释器 (PEP 659) 。 我们希望在 3.14 中\n以线程安全的方式重新启用它。在即将发布的 Python 版本中，这一开销有望减少。 我们的目标\n是，与启用默认全局解释器锁的构建相比，pyperformance 套件的开销不超过 10%。\n行为的变化\n本节描述CPython在自由线程构建时的行为变化。\n上下文变量\n在自由线程构建中，thread_inherit_context 标志默认设置为 true，这会导致使用\nthreading.Thread 创建的线程以 start() 的调用程序的 Context() 的副本启动。在默认启用 GIL\n的构建中，该标志默认为 false，因此线程以空 Context() 启动。\n警告过滤器\n在自由线程构建中，context_aware_warnings 标志默认设置为 true。 在默认启用 GIL 的构建中，\n该标志默认设置为 false。 如果该标志为 true，则 warnings.catch_warnings 上下文管理器使用上\n下文变量用于警告过滤器。 如果该标志为 false，则 catch_warnings 修改全局过滤器列表，这不是\n线程安全的。 详情请参阅 warnings 模块。", "metadata": {"title": "15_Python_对自由线程的支持", "source": "md_docs\\python_howto_md\\15_Python_对自由线程的支持.md", "doc_type": "指南", "language": "中文", "doc_id": "7bd8ef44"}}
{"doc_id": "445a96b3", "content": "自由线程的 C API 扩展支持\n从 3.13 发布版开始，CPython 通过名为 free threading 的配置引入了对于运行时禁用 global\ninterpreter lock (GIL) 的支持。 这份文档描述了如何调整 C API 扩展以支持自由线程。\n在 C 中识别自由线程构建\nCPython C API 提供了 Py_GIL_DISABLED 宏，它在自由线程构建中被定义为 1，而在常规构建中未\n被定义。你可以使用它让代码仅在自由线程构建中运行：\n#ifdef Py_GIL_DISABLED\n/* 仅在自由线程构建版中运行的代码 */\n#endif\n备注: 在 Windows 上，该宏不会被自动定义，而必须在构建时向编译器指明。\nsysconfig.get_config_var() 函数可被用来确定当前运行的解释器是否定义了该宏。\n模块初始化\n扩展模块需要明确指明它们支持在禁用 GIL 的情况下运行；否则导入扩展模块时会引发警告，并在\n运行时启用 GIL。\n取决于扩展使用多阶段还是单阶段初始化，有两种方式指明扩展模块支持在 GIL 禁用的情况下运\n行。\n多阶段初始化\n使用多阶段初始化（例如 PyModuleDef_Init()）的扩展应该在模块定义中添加 Py_mod_gil 槽\n位。如果你的扩展需要支持更老版本的 CPython，请检查 PY_VERSION_HEX 以保护槽位。\nstatic struct PyModuleDef_Slot module_slots[] = {\n...\n#if PY_VERSION_HEX >= 0x030D0000\n{Py_mod_gil, Py_MOD_GIL_NOT_USED},\n#endif\n{0, NULL}\n};\nstatic struct PyModuleDef moduledef = {\nPyModuleDef_HEAD_INIT,\n.m_slots = module_slots,\n...\n};\n单阶段初始化\n\n| 自由线程的 C API 扩展支持\n从 3.13 发布版开始，CPython 通过名为 free threading 的配置引入了对于运行时禁用 global\ninterpreter lock (GIL) 的支持。 这份文档描述了如何调整 C API 扩展以支持自由线程。\n在 C 中识别自由线程构建\nCPython C API 提供了 Py_GIL_DISABLED 宏，它在自由线程构建中被定义为 1，而在常规构建中未\n被定义。你可以使用它让代码仅在自由线程构建中运行： |\n| --- |\n| #ifdef Py_GIL_DISABLED\n/* 仅在自由线程构建版中运行的代码 */\n#endif |\n|  |\n| 备注: 在 Windows 上，该宏不会被自动定义，而必须在构建时向编译器指明。\nsysconfig.get_config_var() 函数可被用来确定当前运行的解释器是否定义了该宏。 |\n| 模块初始化\n扩展模块需要明确指明它们支持在禁用 GIL 的情况下运行；否则导入扩展模块时会引发警告，并在\n运行时启用 GIL。\n取决于扩展使用多阶段还是单阶段初始化，有两种方式指明扩展模块支持在 GIL 禁用的情况下运\n行。\n多阶段初始化\n使用多阶段初始化（例如 PyModuleDef_Init()）的扩展应该在模块定义中添加 Py_mod_gil 槽\n位。如果你的扩展需要支持更老版本的 CPython，请检查 PY_VERSION_HEX 以保护槽位。 |\n| static struct PyModuleDef_Slot module_slots[] = {\n...\n#if PY_VERSION_HEX >= 0x030D0000\n{Py_mod_gil, Py_MOD_GIL_NOT_USED},\n#endif\n{0, NULL}\n};\nstatic struct PyModuleDef moduledef = {\nPyModuleDef_HEAD_INIT,\n.m_slots = module_slots,\n...\n}; |\n| 单阶段初始化 |\n\n使用单阶段初始化（即 PyModule_Create()）的扩展应该调用 PyUnstable_Module_SetGIL() 来\n表明它们支持在禁用 GIL 的情况下运行。该函数只在自由线程构建中被定义，因此应使用 #ifdef\nPy_GIL_DISABLED 来保护调用，以避免在常规构建中出现编译错误。\nstatic struct PyModuleDef moduledef = {\nPyModuleDef_HEAD_INIT,\n...\n};\nPyMODINIT_FUNC\nPyInit_mymodule(void)\n{\nPyObject *m = PyModule_Create(&moduledef);\nif (m == NULL) {\nreturn NULL;\n}\n#ifdef Py_GIL_DISABLED\nPyUnstable_Module_SetGIL(m, Py_MOD_GIL_NOT_USED);\n#endif\nreturn m;\n}\n通用 API 指南\n大多数 C API 是线程安全的，但是也存在例外。\n结构字段：如果 Python C API 对象或结构的字段可能被并行修改，那么直接访问这些字段不是线\n程安全的。\n宏: 访问器宏如 PyList_GET_ITEM, PyList_SET_ITEM，以及 PySequence_Fast_GET_SIZE 这样\n使用由 PySequence_Fast() 返回的对象的宏不会进行任何错误检查或加锁。 当容器对象可能被\n并行修改时这些宏不是线程安全的。\n借入引用：返回 借入引用 的 C API 函数如果引用内容可能被并行修改，那么它不是线程安全的。\n详见 借入引用。\n容器相关的线程安全\nPyListObject, PyDictObject 及 PySetObject 等容器在自由线程构建中执行内部上锁机制，例如\nPyList_Append() 在追加对象前会对列表上锁。\nPyDict_Next\n一个值得注意的例外是 PyDict_Next()，它不会锁定目录。 在迭代目录时如果该目录可能被并发地\n修改那么你应当使用 Py_BEGIN_CRITICAL_SECTION 来保护它:\nPy_BEGIN_CRITICAL_SECTION(dict);\nPyObject *key, *value;\nPy_ssize_t pos = 0;\nwhile (PyDict_Next(dict, &pos, &key, &value)) {\n...\n}\nPy_END_CRITICAL_SECTION();\n\n|  |  | 使用单阶段初始化（即 PyModule_Create()）的扩展应该调用 PyUnstable_Module_SetGIL() 来\n表明它们支持在禁用 GIL 的情况下运行。该函数只在自由线程构建中被定义，因此应使用 #ifdef\nPy_GIL_DISABLED 来保护调用，以避免在常规构建中出现编译错误。 |  |  |  |\n| --- | --- | --- | --- | --- | --- |\n|  |  |  | #ifdef |  |  |\n|  |  |  |  |  |  |\n|  |  | Py_GIL_DISABLED |  |  |  |\n|  |  |  |  |  |  |\n|  |  | static struct PyModuleDef moduledef = {\nPyModuleDef_HEAD_INIT,\n...\n};\nPyMODINIT_FUNC\nPyInit_mymodule(void)\n{\nPyObject *m = PyModule_Create(&moduledef);\nif (m == NULL) {\nreturn NULL;\n}\n#ifdef Py_GIL_DISABLED\nPyUnstable_Module_SetGIL(m, Py_MOD_GIL_NOT_USED);\n#endif\nreturn m;\n} |  |  |  |\n|  |  | 通用 API 指南\n大多数 C API 是线程安全的，但是也存在例外。\n结构字段：如果 Python C API 对象或结构的字段可能被并行修改，那么直接访问这些字段不是线\n程安全的。\n宏: 访问器宏如 PyList_GET_ITEM, PyList_SET_ITEM，以及 PySequence_Fast_GET_SIZE 这样\n使用由 PySequence_Fast() 返回的对象的宏不会进行任何错误检查或加锁。 当容器对象可能被\n并行修改时这些宏不是线程安全的。\n借入引用：返回 借入引用 的 C API 函数如果引用内容可能被并行修改，那么它不是线程安全的。\n详见 借入引用。\n容器相关的线程安全\nPyListObject, PyDictObject 及 PySetObject 等容器在自由线程构建中执行内部上锁机制，例如\nPyList_Append() 在追加对象前会对列表上锁。\nPyDict_Next\n一个值得注意的例外是 PyDict_Next()，它不会锁定目录。 在迭代目录时如果该目录可能被并发地\n修改那么你应当使用 Py_BEGIN_CRITICAL_SECTION 来保护它: |  |  |  |\n|  |  | Py_BEGIN_CRITICAL_SECTION(dict);\nPyObject *key, *value;\nPy_ssize_t pos = 0;\nwhile (PyDict_Next(dict, &pos, &key, &value)) {\n...\n}\nPy_END_CRITICAL_SECTION(); |  |  |  |\n|  |  |  |  |  |  |\n\n借入引用\n有些 C API 函数返回 borrowed references。如果引用内容可能被并行修改，那么这些 API 不是线程\n安全的。例如，如果列表可能被并行修改，那么使用 PyList_GetItem() 是不安全的。\n下表列出了一些返回借入引用的 API 及它们返回 强引用 的替代版本。\n借入引用 API 强引用 API\nPyList_GetItem() PyList_GetItemRef()\nPyList_GET_ITEM() PyList_GetItemRef()\nPyDict_GetItem() PyDict_GetItemRef()\nPyDict_GetItemWithError() PyDict_GetItemRef()\nPyDict_GetItemString() PyDict_GetItemStringRef()\nPyDict_SetDefault() PyDict_SetDefaultRef()\nPyDict_Next() 无 (参见 PyDict_Next)\nPyWeakref_GetObject() PyWeakref_GetRef()\nPyWeakref_GET_OBJECT() PyWeakref_GetRef()\nPyImport_AddModule() PyImport_AddModuleRef()\nPyCell_GET() PyCell_Get()\n返回借用引用的 API 不一定都有问题。例如，PyTuple_GetItem() 是安全的，因为元组是不可变\n的。同样，上述 API 的使用不一定都有问题。 例如，PyDict_GetItem() 通常用于解析函数调用中\n的关键字参数字典；这些关键字参数字典实际上是私有（其他线程无法访问）的，因此在这种情况\n下使用借入引用是安全的。\n上述函数中有的是在 Python 3.13 中添加的。在旧 Python 版本上您可以使用提供这些函数实现的\npythoncapi-compat 包。\n内存分配 API\nPython 的内存管理 C API 提供了三个不同 分配域 的函数: \"raw\", \"mem\" 和 \"object\"。 为了保证线程\n安全，自由线程构建版要求只有 Python 对象使用 object 域来分配，并且所有 Python 对象都应使用\n该域来分配。 这不同于之前的 Python 版本，因为在此之前这只是一个最佳实践而不是硬性要求。\n备注: 搜索 PyObject_Malloc() 在您的扩展中的使用，并检查分配的内存是否用于 Python 对\n象。使用 PyMem_Malloc() 来分配缓冲区，而不是 PyObject_Malloc()。\n线程状态与 GIL API\n\n|  | 借入引用\n有些 C API 函数返回 borrowed references。如果引用内容可能被并行修改，那么这些 API 不是线程\n安全的。例如，如果列表可能被并行修改，那么使用 PyList_GetItem() 是不安全的。\n下表列出了一些返回借入引用的 API 及它们返回 强引用 的替代版本。\n借入引用 API 强引用 API\nPyList_GetItem() PyList_GetItemRef()\nPyList_GET_ITEM() PyList_GetItemRef()\nPyDict_GetItem() PyDict_GetItemRef()\nPyDict_GetItemWithError() PyDict_GetItemRef()\nPyDict_GetItemString() PyDict_GetItemStringRef()\nPyDict_SetDefault() PyDict_SetDefaultRef()\nPyDict_Next() 无 (参见 PyDict_Next)\nPyWeakref_GetObject() PyWeakref_GetRef()\nPyWeakref_GET_OBJECT() PyWeakref_GetRef()\nPyImport_AddModule() PyImport_AddModuleRef()\nPyCell_GET() PyCell_Get()\n返回借用引用的 API 不一定都有问题。例如，PyTuple_GetItem() 是安全的，因为元组是不可变\n的。同样，上述 API 的使用不一定都有问题。 例如，PyDict_GetItem() 通常用于解析函数调用中\n的关键字参数字典；这些关键字参数字典实际上是私有（其他线程无法访问）的，因此在这种情况\n下使用借入引用是安全的。\n上述函数中有的是在 Python 3.13 中添加的。在旧 Python 版本上您可以使用提供这些函数实现的\npythoncapi-compat 包。\n内存分配 API\nPython 的内存管理 C API 提供了三个不同 分配域 的函数: \"raw\", \"mem\" 和 \"object\"。 为了保证线程\n安全，自由线程构建版要求只有 Python 对象使用 object 域来分配，并且所有 Python 对象都应使用\n该域来分配。 这不同于之前的 Python 版本，因为在此之前这只是一个最佳实践而不是硬性要求。 |  |\n| --- | --- | --- |\n|  | 备注: 搜索 PyObject_Malloc() 在您的扩展中的使用，并检查分配的内存是否用于 Python 对\n象。使用 PyMem_Malloc() 来分配缓冲区，而不是 PyObject_Malloc()。 |  |\n|  | 线程状态与 GIL API |  |\n\n| 借入引用 API | 强引用 API |\n| --- | --- |\n| PyList_GetItem() | PyList_GetItemRef() |\n| PyList_GET_ITEM() | PyList_GetItemRef() |\n| PyDict_GetItem() | PyDict_GetItemRef() |\n| PyDict_GetItemWithError() | PyDict_GetItemRef() |\n| PyDict_GetItemString() | PyDict_GetItemStringRef() |\n| PyDict_SetDefault() | PyDict_SetDefaultRef() |\n| PyDict_Next() | 无 (参见 PyDict_Next) |\n| PyWeakref_GetObject() | PyWeakref_GetRef() |\n| PyWeakref_GET_OBJECT() | PyWeakref_GetRef() |\n| PyImport_AddModule() | PyImport_AddModuleRef() |\n| PyCell_GET() | PyCell_Get() |\n\nPython 提供了一系列函数和宏来管理线程状态和 GIL，例如：\nPyGILState_Ensure() 与 PyGILState_Release()\nPyEval_SaveThread() 与 PyEval_RestoreThread()\nPy_BEGIN_ALLOW_THREADS 与 Py_END_ALLOW_THREADS\n即使 GIL 被禁用，仍应在自由线程构建中使用这些函数管理线程状态。例如，如果在 Python 之外创\n建线程，则必须在调用 Python API 前调用 PyGILState_Ensure()，以确保线程具有有效的 Python\n线程状态。\n你应该继续在阻塞操作（如输入/输出或获取锁）前调用 PyEval_SaveThread() 或\nPy_BEGIN_ALLOW_THREADS，以允许其他线程运行 循环垃圾回收器。\n保护内部扩展状态\n您的扩展可能有以前受 GIL 保护的内部状态。您可能需要上锁来保护内部状态。具体方法取决于您\n的扩展，但一些常见的模式包括：\n缓存：全局缓存是共享状态的常见来源。如果缓存对性能并不重要，可考虑使用锁来保护缓存，\n或在自由线程构建中禁用缓存。\n全局状态：全局状态可能需要用锁保护或移至线程本地存储。C11 和 C++11 提供了\nthread_local 或 _Thread_local 用于 线程本地存储。\n关键节\n在自由线程构建中，CPython提供了一种称为“临界区”的机制来保护原本由GIL保护的数据。虽然扩\n展作者可能不会直接与内部临界区实现交互，但在使用某些C API函数或在自由线程构建中管理共享\n状态时，理解它们的行为是至关重要的。\n什么是临界区？\n从概念上讲，临界区充当建立在简单互斥锁之上的死锁避免层。 每个线程维护一个活动临界区堆\n栈。 当线程需要获取与临界区相关的锁时（例如，隐式调用线程安全的 C API 函数时，如\nPyDict_SetItem()，或显式使用宏），它会尝试获取底层互斥锁。\n使用临界区\n使用临界区的主要API有：\nPy_BEGIN_CRITICAL_SECTION 和 Py_END_CRITICAL_SECTION - 用于锁定单个对象\nPy_BEGIN_CRITICAL_SECTION2 和 Py_END_CRITICAL_SECTION2 - 用于同时锁定两个对象\n这些宏必须成对使用，并且必须出现在同一个C作用域中，因为它们建立了一个新的局部作用域。这\n些宏在非自由线程构建中是无操作的，因此可以安全地将它们添加到需要支持两种构建类型的代码\n中。\n\n|  | Python 提供了一系列函数和宏来管理线程状态和 GIL，例如：\nPyGILState_Ensure() 与 PyGILState_Release()\nPyEval_SaveThread() 与 PyEval_RestoreThread()\nPy_BEGIN_ALLOW_THREADS 与 Py_END_ALLOW_THREADS\n即使 GIL 被禁用，仍应在自由线程构建中使用这些函数管理线程状态。例如，如果在 Python 之外创\n建线程，则必须在调用 Python API 前调用 PyGILState_Ensure()，以确保线程具有有效的 Python\n线程状态。\n你应该继续在阻塞操作（如输入/输出或获取锁）前调用 PyEval_SaveThread() 或\nPy_BEGIN_ALLOW_THREADS，以允许其他线程运行 循环垃圾回收器。\n保护内部扩展状态\n您的扩展可能有以前受 GIL 保护的内部状态。您可能需要上锁来保护内部状态。具体方法取决于您\n的扩展，但一些常见的模式包括：\n缓存：全局缓存是共享状态的常见来源。如果缓存对性能并不重要，可考虑使用锁来保护缓存，\n或在自由线程构建中禁用缓存。\n全局状态：全局状态可能需要用锁保护或移至线程本地存储。C11 和 C++11 提供了\nthread_local 或 _Thread_local 用于 线程本地存储。\n关键节\n在自由线程构建中，CPython提供了一种称为“临界区”的机制来保护原本由GIL保护的数据。虽然扩\n展作者可能不会直接与内部临界区实现交互，但在使用某些C API函数或在自由线程构建中管理共享\n状态时，理解它们的行为是至关重要的。\n什么是临界区？\n从概念上讲，临界区充当建立在简单互斥锁之上的死锁避免层。 每个线程维护一个活动临界区堆\n栈。 当线程需要获取与临界区相关的锁时（例如，隐式调用线程安全的 C API 函数时，如\nPyDict_SetItem()，或显式使用宏），它会尝试获取底层互斥锁。\n使用临界区\n使用临界区的主要API有：\nPy_BEGIN_CRITICAL_SECTION 和 Py_END_CRITICAL_SECTION - 用于锁定单个对象\nPy_BEGIN_CRITICAL_SECTION2 和 Py_END_CRITICAL_SECTION2 - 用于同时锁定两个对象\n这些宏必须成对使用，并且必须出现在同一个C作用域中，因为它们建立了一个新的局部作用域。这\n些宏在非自由线程构建中是无操作的，因此可以安全地将它们添加到需要支持两种构建类型的代码\n中。 |  |\n| --- | --- | --- |\n\n临界区的一个常见用途是在访问对象的内部属性时锁定对象。例如，如果扩展类型有一个内部计数\n字段，你可以在读取或写入该字段时使用临界区:\n// 读取计数，返回对内部计数值的新引用\nPyObject *result;\nPy_BEGIN_CRITICAL_SECTION(obj);\nresult = Py_NewRef(obj->count);\nPy_END_CRITICAL_SECTION();\nreturn result;\n// 写入计数，从new_count中获取引用\nPy_BEGIN_CRITICAL_SECTION(obj);\nobj->count = new_count;\nPy_END_CRITICAL_SECTION();\n临界区如何运作\n与传统锁不同，临界区不能保证在其整个持续时间内的独占访问。如果线程在持有临界区时阻塞\n（例如，通过获取另一个锁或执行I/O），则临界区被暂时挂起——所有锁被释放——然后在阻塞操\n作完成时恢复。\n此行为类似于当线程执行阻塞型调用时 GIL 的行为。 主要的区别在于：\n关键节的运作是基于每个对象的而不是全局的\n关键节遵循设置于每个线程内部的纪律栈（\"begin\" 和 \"end\" 宏将应用该纪律栈，因为它们必须成\n对出现并位于相同作用域中）\n关键节会针对潜在的阻塞型操作自动释放和重新获取锁\n避免死锁\n关键节通过两种方式帮助避免死锁：\n1. 如果一个线程试图获取某个已被其他线程持有的锁，它会先挂起该线程的所有关键节，临时释\n放它们的锁。\n2. 当阻塞型操作完成时，只有最顶端的关键节会被首先重新获取\n这意味着你不能依赖嵌套的关键节来同时锁定多个对象，因为内层的关键节可能挂起外层的关键\n节。 作为替代，请使用 Py_BEGIN_CRITICAL_SECTION2 来同时锁定两个对象。\n注意，上面描述的锁只是基于 PyMutex 的锁。 临界区实现并不知道或影响其他可能正在使用的锁定\n机制，比如 POSIX 互斥锁。 还要注意，当任何 PyMutex 阻塞时会导致临界区被挂起，只有属于临\n界区的互斥锁才会被释放。 如果 PyMutex 在没有临界区的情况下使用，它不会被释放，因此不会得\n到同样的死锁避免。\n重要考量\n临界区可以暂时释放它们的锁，允许其他线程修改受保护的数据。在进行可能阻塞的操作之后，\n要谨慎地假设数据的状态。\n因为锁可以临时释放（挂起），所以进入临界区并不能保证在整个临界区期间对受保护资源的独\n占访问。如果临界区内的代码调用另一个阻塞函数（例如，获取另一个锁、执行阻塞I/O），则该\n\n|  | 临界区的一个常见用途是在访问对象的内部属性时锁定对象。例如，如果扩展类型有一个内部计数\n字段，你可以在读取或写入该字段时使用临界区: |  |\n| --- | --- | --- |\n|  | // 读取计数，返回对内部计数值的新引用\nPyObject *result;\nPy_BEGIN_CRITICAL_SECTION(obj);\nresult = Py_NewRef(obj->count);\nPy_END_CRITICAL_SECTION();\nreturn result;\n// 写入计数，从new_count中获取引用\nPy_BEGIN_CRITICAL_SECTION(obj);\nobj->count = new_count;\nPy_END_CRITICAL_SECTION(); |  |\n|  | 临界区如何运作\n与传统锁不同，临界区不能保证在其整个持续时间内的独占访问。如果线程在持有临界区时阻塞\n（例如，通过获取另一个锁或执行I/O），则临界区被暂时挂起——所有锁被释放——然后在阻塞操\n作完成时恢复。\n此行为类似于当线程执行阻塞型调用时 GIL 的行为。 主要的区别在于：\n关键节的运作是基于每个对象的而不是全局的\n关键节遵循设置于每个线程内部的纪律栈（\"begin\" 和 \"end\" 宏将应用该纪律栈，因为它们必须成\n对出现并位于相同作用域中）\n关键节会针对潜在的阻塞型操作自动释放和重新获取锁\n避免死锁\n关键节通过两种方式帮助避免死锁：\n1. 如果一个线程试图获取某个已被其他线程持有的锁，它会先挂起该线程的所有关键节，临时释\n放它们的锁。\n2. 当阻塞型操作完成时，只有最顶端的关键节会被首先重新获取\n这意味着你不能依赖嵌套的关键节来同时锁定多个对象，因为内层的关键节可能挂起外层的关键\n节。 作为替代，请使用 Py_BEGIN_CRITICAL_SECTION2 来同时锁定两个对象。\n注意，上面描述的锁只是基于 PyMutex 的锁。 临界区实现并不知道或影响其他可能正在使用的锁定\n机制，比如 POSIX 互斥锁。 还要注意，当任何 PyMutex 阻塞时会导致临界区被挂起，只有属于临\n界区的互斥锁才会被释放。 如果 PyMutex 在没有临界区的情况下使用，它不会被释放，因此不会得\n到同样的死锁避免。\n重要考量\n临界区可以暂时释放它们的锁，允许其他线程修改受保护的数据。在进行可能阻塞的操作之后，\n要谨慎地假设数据的状态。\n因为锁可以临时释放（挂起），所以进入临界区并不能保证在整个临界区期间对受保护资源的独\n占访问。如果临界区内的代码调用另一个阻塞函数（例如，获取另一个锁、执行阻塞I/O），则该 |  |\n\n线程通过临界区持有的所有锁将被释放。这类似于在阻塞调用期间释放GIL的方式。\n在任何给定时间，只有与最近进入（最顶部）的临界区相关的锁才能保证被持有。外部嵌套临界\n区的锁可能已经挂起。\n使用这些API最多可以同时锁定两个对象。如果你需要锁定更多的对象，你需要调整你的代码。\n虽然如果你尝试锁定同一个对象两次，临界区不会死锁，但是对于这种用例，它们的效率不如专\n门构建的可重入锁。\n当使用 Py_BEGIN_CRITICAL_SECTION2 时，对象的顺序不影响正确性（实现处理死锁避免），但\n始终以一致的顺序锁定对象是良好的实践。\n请记住，临界区宏主要用于保护对 Python对象 的访问，这些对象可能涉及易受上述死锁场景影响\n的内部CPython操作。为了保护纯粹的内部扩展状态，标准互斥体或其他同步原语可能更合适。\n为自由线程构建进行扩展构建\nC API 扩展需要专门为自由线程构建进行构建。构建的 wheel、共享库和二进制文件用后缀 t 指示。\npypa/manylinux 支持后缀为 t 的自由线程构建，如 python3.13t。\n如果你设置了 cpython-freethreading 的 CIBW_ENABLE 则 pypa/cibuildwheel 将支持自由线程构\n建版。\n受限的 C API 与稳定 ABI\n自由线程构建目前不支持 受限 C API 或稳定 ABI。 如果当前您使用 setuptools 来构建您的扩展，并\n且设置了 py_limited_api=True，您可以使用 py_limited_api=not\nsysconfig.get_config_var(\"Py_GIL_DISABLED\") 在使用自由线程构建进行构建时不使用受限\nAPI。\n备注: 您需要为自由线程构建单独构建 wheel。如果您当前使用稳定 ABI，则可以继续构建适用\n于多个非自由线程 Python 版本的单个 wheel。\nWindows\n由于 Windows 官方安装程序的限制，从源代码构建扩展时需要手动定义 Py_GIL_DISABLED=1。\n参见: Porting Extension Modules to Support Free-Threading: 一份由社区维护的针对扩展开发者\n的移植指南。\n\n|  |  | 线程通过临界区持有的所有锁将被释放。这类似于在阻塞调用期间释放GIL的方式。\n在任何给定时间，只有与最近进入（最顶部）的临界区相关的锁才能保证被持有。外部嵌套临界\n区的锁可能已经挂起。\n使用这些API最多可以同时锁定两个对象。如果你需要锁定更多的对象，你需要调整你的代码。\n虽然如果你尝试锁定同一个对象两次，临界区不会死锁，但是对于这种用例，它们的效率不如专\n门构建的可重入锁。\n当使用 Py_BEGIN_CRITICAL_SECTION2 时，对象的顺序不影响正确性（实现处理死锁避免），但\n始终以一致的顺序锁定对象是良好的实践。\n请记住，临界区宏主要用于保护对 Python对象 的访问，这些对象可能涉及易受上述死锁场景影响\n的内部CPython操作。为了保护纯粹的内部扩展状态，标准互斥体或其他同步原语可能更合适。\n为自由线程构建进行扩展构建\nC API 扩展需要专门为自由线程构建进行构建。构建的 wheel、共享库和二进制文件用后缀 t 指示。\npypa/manylinux 支持后缀为 t 的自由线程构建，如 python3.13t。\n如果你设置了 cpython-freethreading 的 CIBW_ENABLE 则 pypa/cibuildwheel 将支持自由线程构\n建版。\n受限的 C API 与稳定 ABI\n自由线程构建目前不支持 受限 C API 或稳定 ABI。 如果当前您使用 setuptools 来构建您的扩展，并\n且设置了 py_limited_api=True，您可以使用 py_limited_api=not\nsysconfig.get_config_var(\"Py_GIL_DISABLED\") 在使用自由线程构建进行构建时不使用受限\nAPI。 |  |  |  |\n| --- | --- | --- | --- | --- | --- |\n|  |  |  | py_limited_api=not |  |  |\n|  |  | sysconfig.get_config_var(\"Py_GIL_DISABLED\") |  |  |  |\n|  |  | 备注: 您需要为自由线程构建单独构建 wheel。如果您当前使用稳定 ABI，则可以继续构建适用\n于多个非自由线程 Python 版本的单个 wheel。 |  |  |  |\n|  |  | Windows\n由于 Windows 官方安装程序的限制，从源代码构建扩展时需要手动定义 Py_GIL_DISABLED=1。 |  |  |  |\n|  |  | 参见: Porting Extension Modules to Support Free-Threading: 一份由社区维护的针对扩展开发者\n的移植指南。 |  |  |  |\n|  |  |  |  |  |  |", "metadata": {"title": "16_自由线程的_C_API_扩展支持", "source": "md_docs\\python_howto_md\\16_自由线程的_C_API_扩展支持.md", "doc_type": "指南", "language": "中文", "doc_id": "445a96b3"}}
{"doc_id": "5879a73d", "content": "隔离扩展模块\n摘要\n在传统上，属于 Python 扩展模块的状态都是保存为 C static 变量，它们具有进程级的作用域。\n本文档描述了此类进程级状态的问题并演示了一种更安全的方式：模块级状态。\n本文档还描述了如何在可能的情况下切换到模块级状态。 这种转换涉及为状态分配空间、从静态\n类型到堆类型的潜在切换，以及 — 也许是最重要的 — 从代码访问模块级状态。\n谁应当阅读本文档\n本指南是针对想要让扩展更安全地在将 Python 本身用作库的应用程序中使用的 C-API 扩展维护者撰\n写的。\n背景\n解释器 是 Python 代码运行所在的上下文。 它包含配置（例如导入路径）和运行时状态（例如已导\n入模块的集合）。\nPython 支持在一个进程中运行多个解释器。 这里有两种情况需要考虑 — 用户可能会以下列方式运\n行解释器:\n串行，使用多个 Py_InitializeEx()/Py_FinalizeEx() 循环，以及\n并行，使用 Py_NewInterpreter()/Py_EndInterpreter() 管理多个“子解释器”。\n这两种情况（以及它们的组合）最适用于将 Python 嵌入到某个库中。 库通常不应假定使用它们的\n应用程序，这包括假定存在一个进程级的“主 Python 解释器”。\n在历史上，Python 扩展模块对这种应用场景处理不佳。 许多扩展模块（甚至是某些标准库模块）都\n是使用 进程内共享 的全局状态，因为 C static 变量十分易用。 结果，本应专属于某个解释器的数\n据最终却被多个解释器所共享。 除非扩展的开发者小心谨慎，否则当一个模块被相同进程内的多个\n解释器导入时很容易引入会导致崩溃的边界情况。\n不幸的是，解释器级 状态很不容易做到。 扩展的作者在开发中总是倾向于不考虑多解释器的情况，\n并且目前要测试此类行为也是很困难的。\n进入模块级状态\nPython 的 C API 不是专注于解释器级状态，而是演化为更好地支持更细粒度的 模块级 状态。 这意\n味着 C 层级数据应当关联到 模块对象。 每个解释器都会创建自己的模块对象，保持数据的相互分\n隔。 要测试这种分隔，甚至可以在单个解释器中加载对应于单个扩展的多个模块对象。\n\n| 隔离扩展模块 |\n| --- |\n| 摘要\n在传统上，属于 Python 扩展模块的状态都是保存为 C static 变量，它们具有进程级的作用域。\n本文档描述了此类进程级状态的问题并演示了一种更安全的方式：模块级状态。\n本文档还描述了如何在可能的情况下切换到模块级状态。 这种转换涉及为状态分配空间、从静态\n类型到堆类型的潜在切换，以及 — 也许是最重要的 — 从代码访问模块级状态。 |\n| 谁应当阅读本文档\n本指南是针对想要让扩展更安全地在将 Python 本身用作库的应用程序中使用的 C-API 扩展维护者撰\n写的。\n背景\n解释器 是 Python 代码运行所在的上下文。 它包含配置（例如导入路径）和运行时状态（例如已导\n入模块的集合）。\nPython 支持在一个进程中运行多个解释器。 这里有两种情况需要考虑 — 用户可能会以下列方式运\n行解释器:\n串行，使用多个 Py_InitializeEx()/Py_FinalizeEx() 循环，以及\n并行，使用 Py_NewInterpreter()/Py_EndInterpreter() 管理多个“子解释器”。\n这两种情况（以及它们的组合）最适用于将 Python 嵌入到某个库中。 库通常不应假定使用它们的\n应用程序，这包括假定存在一个进程级的“主 Python 解释器”。\n在历史上，Python 扩展模块对这种应用场景处理不佳。 许多扩展模块（甚至是某些标准库模块）都\n是使用 进程内共享 的全局状态，因为 C static 变量十分易用。 结果，本应专属于某个解释器的数\n据最终却被多个解释器所共享。 除非扩展的开发者小心谨慎，否则当一个模块被相同进程内的多个\n解释器导入时很容易引入会导致崩溃的边界情况。\n不幸的是，解释器级 状态很不容易做到。 扩展的作者在开发中总是倾向于不考虑多解释器的情况，\n并且目前要测试此类行为也是很困难的。\n进入模块级状态\nPython 的 C API 不是专注于解释器级状态，而是演化为更好地支持更细粒度的 模块级 状态。 这意\n味着 C 层级数据应当关联到 模块对象。 每个解释器都会创建自己的模块对象，保持数据的相互分\n隔。 要测试这种分隔，甚至可以在单个解释器中加载对应于单个扩展的多个模块对象。 |\n\n模块级状态提供了一种处理生命周期和资源归属的简单方式：扩展模块将在模块对象被创建时初始\n化，并在其释放时被清理。 在这一点上，模块就像是任何其他的 PyObject*；没有必要添加 — 或\n者去除 — 处理“解释器关闭”的钩子。\n请注意各种不同“全局”状态：进程级、解释器级、线程级状态的应用场景。 默认为模块级状态，其\n他状态也是可选择的，但你应当将它们视为特殊情况：如果你需要它们，你应当给予它们额外的关\n注和测试。 （请注意本指南并没有涉及它们。）\n隔离的模块对象\n在开发扩展模块时要记住的关键点是多个模块对象可以从单个共享库来创建。 例如:\n>>> import sys\n>>> import binascii\n>>> old_binascii = binascii\n>>> del sys.modules['binascii']\n>>> import binascii # create a new module object\n>>> old_binascii == binascii\nFalse\n作为经验法则，这两个模块应该是完全独立的。 模块专属的所有对象和状态应该被封装在模块对象\n内部，不与其他模块对象共享，并在模块对象被释放时进行清理。 由于这只是一个经验法则，例外\n情况也是可能的（参见 Managing Global State)，但这将需要更多的考虑并注意边界情况。\n虽然有些模块不用太多的严格限制，但是隔离的模块使得更容易制定适合各种应用场景的明确期望\n和指南。\n令人惊讶的边界情况\n请注意隔离的模块会创造一些令人惊讶的边界情况。 最明显的一点，每个模块对象通常都不会与其\n他类似模块共享它的类和异常。 继续 上面的例子，请注意 old_binascii.Error 和\nbinascii.Error 是单独的对象。 在下面的代码中，异常 不会 被捕获:\n>>> old_binascii.Error == binascii.Error\nFalse\n>>> try:\n... old_binascii.unhexlify(b'qwertyuiop')\n... except binascii.Error:\n... print('boo')\n...\nTraceback (most recent call last):\nFile \"<stdin>\", line 2, in <module>\nbinascii.Error: Non-hexadecimal digit found\n这是预期的结果。 请注意纯 Python 模块的行为相同：它是 Python 语言特性的一部分。\n最终目标是让扩展模块在 C 层级上保持安全，使破坏不容易实现。 “手动”改变 sys.modules 被视为\n是破坏行为。\n让多解释器下模块保持安全\n\n|  | 模块级状态提供了一种处理生命周期和资源归属的简单方式：扩展模块将在模块对象被创建时初始\n化，并在其释放时被清理。 在这一点上，模块就像是任何其他的 PyObject*；没有必要添加 — 或\n者去除 — 处理“解释器关闭”的钩子。\n请注意各种不同“全局”状态：进程级、解释器级、线程级状态的应用场景。 默认为模块级状态，其\n他状态也是可选择的，但你应当将它们视为特殊情况：如果你需要它们，你应当给予它们额外的关\n注和测试。 （请注意本指南并没有涉及它们。）\n隔离的模块对象\n在开发扩展模块时要记住的关键点是多个模块对象可以从单个共享库来创建。 例如: |  |\n| --- | --- | --- |\n|  | >>> import sys\n>>> import binascii\n>>> old_binascii = binascii\n>>> del sys.modules['binascii']\n>>> import binascii # create a new module object\n>>> old_binascii == binascii\nFalse |  |\n|  | 作为经验法则，这两个模块应该是完全独立的。 模块专属的所有对象和状态应该被封装在模块对象\n内部，不与其他模块对象共享，并在模块对象被释放时进行清理。 由于这只是一个经验法则，例外\n情况也是可能的（参见 Managing Global State)，但这将需要更多的考虑并注意边界情况。\n虽然有些模块不用太多的严格限制，但是隔离的模块使得更容易制定适合各种应用场景的明确期望\n和指南。\n令人惊讶的边界情况\n请注意隔离的模块会创造一些令人惊讶的边界情况。 最明显的一点，每个模块对象通常都不会与其\n他类似模块共享它的类和异常。 继续 上面的例子，请注意 old_binascii.Error 和\nbinascii.Error 是单独的对象。 在下面的代码中，异常 不会 被捕获: |  |\n|  | >>> old_binascii.Error == binascii.Error\nFalse\n>>> try:\n... old_binascii.unhexlify(b'qwertyuiop')\n... except binascii.Error:\n... print('boo')\n...\nTraceback (most recent call last):\nFile \"<stdin>\", line 2, in <module>\nbinascii.Error: Non-hexadecimal digit found |  |\n|  | 这是预期的结果。 请注意纯 Python 模块的行为相同：它是 Python 语言特性的一部分。\n最终目标是让扩展模块在 C 层级上保持安全，使破坏不容易实现。 “手动”改变 sys.modules 被视为\n是破坏行为。\n让多解释器下模块保持安全 |  |\n\n管理全局状态\n有时，与一个 Python 模块相关联的状态并不是该模块专属的，而是整个进程（或者比模块“更全局\n化”的其他东西）共享。 例如:\nreadline 模块管理 一个 终端。\n在电路板上运行的模块想要控制 一个 板载 LED。\n在这些情况下，Python 模块应当提供对全局状态的 访问，而不是 拥有 它。 如果可能，编写模块时\n要让它的多个副本可以独立地访问全局状态（能配合其它的库，不论它们是使用 Python 还是其他语\n言）。 如果这无法做到，可考虑显式加锁。\n如果有必要使用进程级全局状态，那么避免多解释器相关问题的最简单方式是显式地阻止模块在一\n个进程中被多次加载 — 参见 回退选项：每个进程限一个模块对象。\n管理模块级状态\n要使用模块级状态，请使用 多阶段扩展模块初始化。 这将标示你的模块能正确地支持多解释器。\n将 PyModuleDef.m_size 设为一个正数来为模块请求指定字节的本地存储。 通常，这将被设为某个\n模块专属 struct 的大小，它可以保存模块的所有 C 层级状态。 特别地，它应当是你存放类指针\n（包括异常，但不包括静态类型）和 C 代码正常运作所需设置（如 csv 的 field_size_limit 等）\n的地方。\n备注: 另一个选项是将状态保存在模块的 __dict__ 中，但你必须避免当用户从 Python 代码中\n修改 __dict__ 导致的程序崩溃。 这通常意味着要在 C 层级上进行错误和类型检查，很容易弄错\n又很难充分测试。\n但是，如果 C 代码不需要模块状态，则仅将其保存在 __dict__ 中就是一个好主意。\n如果模块状态包括 PyObject 指针，则模块对象必须持有对这些对象的引用并实现模块层级的钩子\nm_traverse, m_clear 和 m_free。 它们的作用方式很像类的 tp_traverse, tp_clear 和\ntp_free。 添加它们将会增加工作量并使代码更冗长；这是为了让模块能干净地卸载所需的代价。\n带有模块级状态的模块示例目前可在 xxlimited 获取；模块初始化的示例见文件的末尾部分。\n回退选项：每个进程限一个模块对象\n非负的 PyModuleDef.m_size 值表示一个模块能正确地支持多解释器。 如果你的模块还不能做到这\n样，你可以显式地设置你的模块在每个进程中只能加载一次。 例如:\n// 作用于进程的旗标\nstatic int loaded = 0;\n// 提供线程安全的互斥锁（仅在自由线程版 Python 中需要）\nstatic PyMutex modinit_mutex = {0};\nstatic int\n\n|  | 管理全局状态\n有时，与一个 Python 模块相关联的状态并不是该模块专属的，而是整个进程（或者比模块“更全局\n化”的其他东西）共享。 例如:\nreadline 模块管理 一个 终端。\n在电路板上运行的模块想要控制 一个 板载 LED。\n在这些情况下，Python 模块应当提供对全局状态的 访问，而不是 拥有 它。 如果可能，编写模块时\n要让它的多个副本可以独立地访问全局状态（能配合其它的库，不论它们是使用 Python 还是其他语\n言）。 如果这无法做到，可考虑显式加锁。\n如果有必要使用进程级全局状态，那么避免多解释器相关问题的最简单方式是显式地阻止模块在一\n个进程中被多次加载 — 参见 回退选项：每个进程限一个模块对象。\n管理模块级状态\n要使用模块级状态，请使用 多阶段扩展模块初始化。 这将标示你的模块能正确地支持多解释器。\n将 PyModuleDef.m_size 设为一个正数来为模块请求指定字节的本地存储。 通常，这将被设为某个\n模块专属 struct 的大小，它可以保存模块的所有 C 层级状态。 特别地，它应当是你存放类指针\n（包括异常，但不包括静态类型）和 C 代码正常运作所需设置（如 csv 的 field_size_limit 等）\n的地方。 |  |\n| --- | --- | --- |\n|  | 备注: 另一个选项是将状态保存在模块的 __dict__ 中，但你必须避免当用户从 Python 代码中\n修改 __dict__ 导致的程序崩溃。 这通常意味着要在 C 层级上进行错误和类型检查，很容易弄错\n又很难充分测试。\n但是，如果 C 代码不需要模块状态，则仅将其保存在 __dict__ 中就是一个好主意。 |  |\n|  | 如果模块状态包括 PyObject 指针，则模块对象必须持有对这些对象的引用并实现模块层级的钩子\nm_traverse, m_clear 和 m_free。 它们的作用方式很像类的 tp_traverse, tp_clear 和\ntp_free。 添加它们将会增加工作量并使代码更冗长；这是为了让模块能干净地卸载所需的代价。\n带有模块级状态的模块示例目前可在 xxlimited 获取；模块初始化的示例见文件的末尾部分。\n回退选项：每个进程限一个模块对象\n非负的 PyModuleDef.m_size 值表示一个模块能正确地支持多解释器。 如果你的模块还不能做到这\n样，你可以显式地设置你的模块在每个进程中只能加载一次。 例如: |  |\n|  | // 作用于进程的旗标\nstatic int loaded = 0;\n// 提供线程安全的互斥锁（仅在自由线程版 Python 中需要）\nstatic PyMutex modinit_mutex = {0};\nstatic int |  |\n\nexec_module(PyObject* module)\n{\nPyMutex_Lock(&modinit_mutex);\nif (loaded) {\nPyMutex_Unlock(&modinit_mutex);\nPyErr_SetString(PyExc_ImportError,\n\"cannot load module more than once per process\");\nreturn -1;\n}\nloaded = 1;\nPyMutex_Unlock(&modinit_mutex);\n// ... 初始化的其余部分\n}\n如果你的模块的 PyModuleDef.m_clear 函数能够为将来的重新初始化做好准备，它应当清除\nloaded 旗标。 在此情况下，你的模块将不支持多个实例 并发地 存在，但举例来说，它将支持在\nPython 运行时关闭 (Py_FinalizeEx()) 和重新初始化 (Py_Initialize()) 之后被加载。\n函数对模块状态的访问\n从模块层级的函数访问状态是相当直观的。 函数通过它们的第一个参数获得模块对象；要提取状\n态，你可以使用 PyModule_GetState:\nstatic PyObject *\nfunc(PyObject *module, PyObject *args)\n{\nmy_struct *state = (my_struct*)PyModule_GetState(module);\nif (state == NULL) {\nreturn NULL;\n}\n// ... 其余的逻辑\n}\n备注: 如果模块状态不存在则 PyModule_GetState 可能返回 NULL 而不设置异常，即\nPyModuleDef.m_size 为零。 在你自己的模块中，你可以任意控制 m_size，因此这很容易避\n免。\n堆类型\n在传统上，在 C 代码中定义的类型都是 静态的；也就是说，static PyTypeObject 结构体在代码\n中直接定义并使用 PyType_Ready() 来初始化。\n这样的类型必须在进程范围内共享。 在模块对象之间共享它们需要注意它们所拥有或访问的任何状\n态。 要限制可能出现的问题，静态类型在 Python 层级上是不可变的：例如，你无法设置\nstr.myattribute = 123。\n在解释器之间共享真正不可变的对象是可行的，只要它们不提供对可变对象的访问。 但是，在\nCPython 中，每个 Python 对象都有一个可变的实现细节：引用计数。 对引用计数的更改是由 GIL\n来保护的。 因此，跨解释器共享任何 Python 对象的代码都隐式地依赖于 CPython 现有的、进程级\n的 GIL。\n\n|  | exec_module(PyObject* module)\n{\nPyMutex_Lock(&modinit_mutex);\nif (loaded) {\nPyMutex_Unlock(&modinit_mutex);\nPyErr_SetString(PyExc_ImportError,\n\"cannot load module more than once per process\");\nreturn -1;\n}\nloaded = 1;\nPyMutex_Unlock(&modinit_mutex);\n// ... 初始化的其余部分\n} |  |\n| --- | --- | --- |\n|  | 如果你的模块的 PyModuleDef.m_clear 函数能够为将来的重新初始化做好准备，它应当清除\nloaded 旗标。 在此情况下，你的模块将不支持多个实例 并发地 存在，但举例来说，它将支持在\nPython 运行时关闭 (Py_FinalizeEx()) 和重新初始化 (Py_Initialize()) 之后被加载。\n函数对模块状态的访问\n从模块层级的函数访问状态是相当直观的。 函数通过它们的第一个参数获得模块对象；要提取状\n态，你可以使用 PyModule_GetState: |  |\n|  | static PyObject *\nfunc(PyObject *module, PyObject *args)\n{\nmy_struct *state = (my_struct*)PyModule_GetState(module);\nif (state == NULL) {\nreturn NULL;\n}\n// ... 其余的逻辑\n} |  |\n|  |  |  |\n|  | 备注: 如果模块状态不存在则 PyModule_GetState 可能返回 NULL 而不设置异常，即\nPyModuleDef.m_size 为零。 在你自己的模块中，你可以任意控制 m_size，因此这很容易避\n免。 |  |\n|  | 堆类型\n在传统上，在 C 代码中定义的类型都是 静态的；也就是说，static PyTypeObject 结构体在代码\n中直接定义并使用 PyType_Ready() 来初始化。\n这样的类型必须在进程范围内共享。 在模块对象之间共享它们需要注意它们所拥有或访问的任何状\n态。 要限制可能出现的问题，静态类型在 Python 层级上是不可变的：例如，你无法设置\nstr.myattribute = 123。\n在解释器之间共享真正不可变的对象是可行的，只要它们不提供对可变对象的访问。 但是，在\nCPython 中，每个 Python 对象都有一个可变的实现细节：引用计数。 对引用计数的更改是由 GIL\n来保护的。 因此，跨解释器共享任何 Python 对象的代码都隐式地依赖于 CPython 现有的、进程级\n的 GIL。 |  |\n\n因为它们是不可变的进程级全局对象，所以静态类型无法访问“它们的”模块状态。 如果任何此种类\n型的方法需要访问模块状态，则该类型必须被转换为 堆分配类型，或者简称为 堆类型。 此种类型相\n对更接近由 Python 的 class 语句所创建的类。\n对于新模块，默认使用堆类型是一个很好的经验法则。\n将静态类型改为堆类型\n静态类型可以转换为堆类型，但要注意堆类型 API 并非针对静态类型的“无损”转换 — 也就是说，创\n建与给定静态类型完全一致的类型来设计的。 因此，当在新的 API 中重写类定义时，你很容易在无\n意中改变一些细节（例如可封存性或所继承的槽位等）。 请始终确保测试对你来说重要的细节。\n特别要关注以下两点（但请注意这并非一个完整的列表）:\n不同于静态类型，堆类型对象默认是可变的。 请使用 Py_TPFLAGS_IMMUTABLETYPE 旗标来防止可\n变性。\n堆类型默认继承 tp_new，因此有可能通过 Python 代码来初始化它们。 你可以使用\nPy_TPFLAGS_DISALLOW_INSTANTIATION 旗标来防止此特性。\n定义堆类型\n堆类型可以通过填充 PyType_Spec 结构体来创建，它是对于特定类的描述或“蓝图”，并调用\nPyType_FromModuleAndSpec() 来构造新的类对象。to construct a new class object.\n备注: 其他的函数，如 PyType_FromSpec()，也可以创建堆类型，但\nPyType_FromModuleAndSpec() 会将模块关联到类，以允许从方法访问模块状态。\n类通常应当 同时 保存在模块的状态（用于从 C 中安全地访问）和模块的 __dict__ 中（用于从\nPython 代码中访问）。\n垃圾回收协议\n堆类型的实例会持有一个指向其类型的引用。 这能确保类型的销毁不会发生在其实例之前，但可能\n会导致需要由垃圾回收器来打破的引用循环。\n要避免内存泄漏，堆类型的实例必须实现垃圾回收协议。 也就是说，堆类型应当:\n具有 Py_TPFLAGS_HAVE_GC 旗标。\n定义一个使用 Py_tp_traverse 的遍历函数，它将访问该类型 (例如使用\nPy_VISIT(Py_TYPE(self)))。\n请参阅 Py_TPFLAGS_HAVE_GC 和 tp_traverse 的文档以获取更多说明。\n定义堆类型的 API 在有机地增长，使得它目前的使用状况有些尴尬。 以下章节将引导您解决常见的\n问题。\ntp_traverse 在 Python 3.8 及更低的版本中\n\n|  | 因为它们是不可变的进程级全局对象，所以静态类型无法访问“它们的”模块状态。 如果任何此种类\n型的方法需要访问模块状态，则该类型必须被转换为 堆分配类型，或者简称为 堆类型。 此种类型相\n对更接近由 Python 的 class 语句所创建的类。\n对于新模块，默认使用堆类型是一个很好的经验法则。\n将静态类型改为堆类型\n静态类型可以转换为堆类型，但要注意堆类型 API 并非针对静态类型的“无损”转换 — 也就是说，创\n建与给定静态类型完全一致的类型来设计的。 因此，当在新的 API 中重写类定义时，你很容易在无\n意中改变一些细节（例如可封存性或所继承的槽位等）。 请始终确保测试对你来说重要的细节。\n特别要关注以下两点（但请注意这并非一个完整的列表）:\n不同于静态类型，堆类型对象默认是可变的。 请使用 Py_TPFLAGS_IMMUTABLETYPE 旗标来防止可\n变性。\n堆类型默认继承 tp_new，因此有可能通过 Python 代码来初始化它们。 你可以使用\nPy_TPFLAGS_DISALLOW_INSTANTIATION 旗标来防止此特性。\n定义堆类型\n堆类型可以通过填充 PyType_Spec 结构体来创建，它是对于特定类的描述或“蓝图”，并调用\nPyType_FromModuleAndSpec() 来构造新的类对象。to construct a new class object. |  |\n| --- | --- | --- |\n|  | 备注: 其他的函数，如 PyType_FromSpec()，也可以创建堆类型，但\nPyType_FromModuleAndSpec() 会将模块关联到类，以允许从方法访问模块状态。 |  |\n|  | 类通常应当 同时 保存在模块的状态（用于从 C 中安全地访问）和模块的 __dict__ 中（用于从\nPython 代码中访问）。\n垃圾回收协议\n堆类型的实例会持有一个指向其类型的引用。 这能确保类型的销毁不会发生在其实例之前，但可能\n会导致需要由垃圾回收器来打破的引用循环。\n要避免内存泄漏，堆类型的实例必须实现垃圾回收协议。 也就是说，堆类型应当:\n具有 Py_TPFLAGS_HAVE_GC 旗标。\n定义一个使用 Py_tp_traverse 的遍历函数，它将访问该类型 (例如使用\nPy_VISIT(Py_TYPE(self)))。\n请参阅 Py_TPFLAGS_HAVE_GC 和 tp_traverse 的文档以获取更多说明。\n定义堆类型的 API 在有机地增长，使得它目前的使用状况有些尴尬。 以下章节将引导您解决常见的\n问题。\ntp_traverse 在 Python 3.8 及更低的版本中 |  |\n\n从``tp_traverse`` 访问类型的要求是在 Python 3.9 中添加的。 如果你要支持 Python 3.8 及更低版\n本，则遍历函数 不可 访问类型，因此必须使用更复杂的方式:\nstatic int my_traverse(PyObject *self, visitproc visit, void *arg)\n{\nif (Py_Version >= 0x03090000) {\nPy_VISIT(Py_TYPE(self));\n}\nreturn 0;\n}\n不幸的是，Py_Version 直到 Python 3.11 才被加入。 作为替代，请使用：\nPY_VERSION_HEX，如果不使用稳定 ABI 的话，或者\nsys.version_info (通过 PySys_GetObject() 和 PyArg_ParseTuple())。\n委托 tp_traverse\n如果你的遍历函数委托给了其基类（或另一个类型）的 tp_traverse，请确保 Py_TYPE(self) 只被\n访问一次。 请注意只有堆类型会被预期访问 tp_traverse 中的类型。\n举例来说，如果你的遍历函数包括:\nbase->tp_traverse(self, visit, arg)\n... 并且 base 可能是一个静态类型，则它也应当包括:\nif (base->tp_flags & Py_TPFLAGS_HEAPTYPE) {\n// 一个堆类型的 tp_traverse 已经访问了 Py_TYPE(self)\n} else {\nif (Py_Version >= 0x03090000) {\nPy_VISIT(Py_TYPE(self));\n}\n}\n不需要在 tp_new 和 tp_clear 中处理该类型的引用计数。\n定义 tp_dealloc\n如果你的类型有自定义的 tp_dealloc 函数，则它需要：\n在任何字段失效之前调用 PyObject_GC_UnTrack()，并且\n递减该类型的引用计数。\n要在 tp_free 被调用时保持类型有效，必须在撤销分配实例 之后 递减该类型的引用计数。 例如:\nstatic void my_dealloc(PyObject *self)\n{\nPyObject_GC_UnTrack(self);\n...\nPyTypeObject *type = Py_TYPE(self);\ntype->tp_free(self);\n\n|  | 从``tp_traverse`` 访问类型的要求是在 Python 3.9 中添加的。 如果你要支持 Python 3.8 及更低版\n本，则遍历函数 不可 访问类型，因此必须使用更复杂的方式: |  |\n| --- | --- | --- |\n|  | static int my_traverse(PyObject *self, visitproc visit, void *arg)\n{\nif (Py_Version >= 0x03090000) {\nPy_VISIT(Py_TYPE(self));\n}\nreturn 0;\n} |  |\n|  | 不幸的是，Py_Version 直到 Python 3.11 才被加入。 作为替代，请使用：\nPY_VERSION_HEX，如果不使用稳定 ABI 的话，或者\nsys.version_info (通过 PySys_GetObject() 和 PyArg_ParseTuple())。\n委托 tp_traverse\n如果你的遍历函数委托给了其基类（或另一个类型）的 tp_traverse，请确保 Py_TYPE(self) 只被\n访问一次。 请注意只有堆类型会被预期访问 tp_traverse 中的类型。\n举例来说，如果你的遍历函数包括: |  |\n|  | base->tp_traverse(self, visit, arg) |  |\n|  | ... 并且 base 可能是一个静态类型，则它也应当包括: |  |\n|  | if (base->tp_flags & Py_TPFLAGS_HEAPTYPE) {\n// 一个堆类型的 tp_traverse 已经访问了 Py_TYPE(self)\n} else {\nif (Py_Version >= 0x03090000) {\nPy_VISIT(Py_TYPE(self));\n}\n} |  |\n|  | 不需要在 tp_new 和 tp_clear 中处理该类型的引用计数。\n定义 tp_dealloc\n如果你的类型有自定义的 tp_dealloc 函数，则它需要：\n在任何字段失效之前调用 PyObject_GC_UnTrack()，并且\n递减该类型的引用计数。\n要在 tp_free 被调用时保持类型有效，必须在撤销分配实例 之后 递减该类型的引用计数。 例如: |  |\n|  | static void my_dealloc(PyObject *self)\n{\nPyObject_GC_UnTrack(self);\n...\nPyTypeObject *type = Py_TYPE(self);\ntype->tp_free(self); |  |\n\nPy_DECREF(type);\n}\n默认的 tp_dealloc 函数会执行此操作，因此如果你的类型 没有 重载 tp_dealloc 你就不需要添加\n它。\n没有重载 tp_free\n堆类型的 tp_free 槽位必须设为 PyObject_GC_Del()。 这是默认的设置；请不要重载它。\n避免 PyObject_New\n带 GC 追踪的对象需要使用带 GC 感知的函数来分配。\n如果你使用 PyObject_New() 或 PyObject_NewVar():\n如有可能，请获取并调用类型的 tp_alloc 槽位。 也就是说，将 TYPE *o =\nPyObject_New(TYPE, typeobj) 替换为:\nTYPE *o = typeobj->tp_alloc(typeobj, 0);\n同样地替换 o = PyObject_NewVar(TYPE, typeobj, size)，但要使用指定大小而不是 0。\n如果无法执行以上操作（例如在自定义的 tp_alloc 中），请调用 PyObject_GC_New() 或\nPyObject_GC_NewVar():\nTYPE *o = PyObject_GC_New(TYPE, typeobj);\nTYPE *o = PyObject_GC_NewVar(TYPE, typeobj, size);\n类对模块状态的访问\n如果你有一个使用 PyType_FromModuleAndSpec() 定义的类型对象，你可以调用\nPyType_GetModule() 来获取关联的模块，然后调用 PyModule_GetState() 来获取模块的状态。to\nget the module's state.\n要省略一些繁琐的错误处理样板代码，你可以使用 PyType_GetModuleState() 来合并这两步，得\n到:\nmy_struct *state = (my_struct*)PyType_GetModuleState(type);\nif (state == NULL) {\nreturn NULL;\n}\n常规方法对模块状态的访问\n从一个类的方法访问模块层级的状态在某些方面会更为复杂，但通过 Python 3.9 所引入的 API 这是\n可能做到的。 为了获取状态，你需要首先获取 定义的类，然后从中获取模块状态。\n\n|  |  | Py_DECREF(type);\n} |  |  |  |\n| --- | --- | --- | --- | --- | --- |\n|  |  | 默认的 tp_dealloc 函数会执行此操作，因此如果你的类型 没有 重载 tp_dealloc 你就不需要添加\n它。\n没有重载 tp_free\n堆类型的 tp_free 槽位必须设为 PyObject_GC_Del()。 这是默认的设置；请不要重载它。\n避免 PyObject_New\n带 GC 追踪的对象需要使用带 GC 感知的函数来分配。\n如果你使用 PyObject_New() 或 PyObject_NewVar():\n如有可能，请获取并调用类型的 tp_alloc 槽位。 也就是说，将 TYPE *o =\nPyObject_New(TYPE, typeobj) 替换为:\nTYPE *o = typeobj->tp_alloc(typeobj, 0);\n同样地替换 o = PyObject_NewVar(TYPE, typeobj, size)，但要使用指定大小而不是 0。\n如果无法执行以上操作（例如在自定义的 tp_alloc 中），请调用 PyObject_GC_New() 或\nPyObject_GC_NewVar():\nTYPE *o = PyObject_GC_New(TYPE, typeobj);\nTYPE *o = PyObject_GC_NewVar(TYPE, typeobj, size);\n类对模块状态的访问\n如果你有一个使用 PyType_FromModuleAndSpec() 定义的类型对象，你可以调用\nPyType_GetModule() 来获取关联的模块，然后调用 PyModule_GetState() 来获取模块的状态。to\nget the module's state.\n要省略一些繁琐的错误处理样板代码，你可以使用 PyType_GetModuleState() 来合并这两步，得\n到: |  |  |  |\n|  |  |  | TYPE *o = |  |  |\n|  |  |  |  |  |  |\n|  |  | PyObject_New(TYPE, typeobj) |  |  |  |\n|  |  |  |  |  |  |\n|  |  | my_struct *state = (my_struct*)PyType_GetModuleState(type);\nif (state == NULL) {\nreturn NULL;\n} |  |  |  |\n|  |  | 常规方法对模块状态的访问\n从一个类的方法访问模块层级的状态在某些方面会更为复杂，但通过 Python 3.9 所引入的 API 这是\n可能做到的。 为了获取状态，你需要首先获取 定义的类，然后从中获取模块状态。 |  |  |  |\n\n最大的障碍是获取 方法定义所在的类，简称为方法“定义的类”。 定义的类可以拥有一个指向作为其\n组成部分的方法的引用。\n不要混淆定义的类和 Py_TYPE(self)。 如果方法是在你的类型的一个 子类 上被调用的，则\nPy_TYPE(self) 将指向该子类，它可能是在另一个模块中定义的。\n备注: 下面的 Python 代码可以演示这一概念。 Base.get_defining_class 将返回 Base，即使\ntype(self) == Sub:\nclass Base:\ndef get_type_of_self(self):\nreturn type(self)\ndef get_defining_class(self):\nreturn __class__\nclass Sub(Base):\npass\n对于要获取其“定义方类”的方法，它必须使用 METH_METHOD | METH_FASTCALL |\nMETH_KEYWORDS 调用惯例 以及相应的 PyCMethod 签名:\nPyObject *PyCMethod(\nPyObject *self, // 方法调用所在的对象\nPyTypeObject *defining_class, // 定义的类\nPyObject *const *args, // 由参数组成的 C 数组\nPy_ssize_t nargs, // \"args\" 的长度\nPyObject *kwnames) // NULL，或由关键字参数组成的字典\n一旦你得到了定义的类，即可调用 PyType_GetModuleState() 来获取它所关联的模块的状态。\n例如：\nstatic PyObject *\nexample_method(PyObject *self,\nPyTypeObject *defining_class,\nPyObject *const *args,\nPy_ssize_t nargs,\nPyObject *kwnames)\n{\nmy_struct *state = (my_struct*)PyType_GetModuleState(defining_class);\nif (state == NULL) {\nreturn NULL;\n}\n... // rest of logic\n}\nPyDoc_STRVAR(example_method_doc, \"...\");\nstatic PyMethodDef my_methods[] = {\n{\"example_method\",\n(PyCFunction)(void(*)(void))example_method,\nMETH_METHOD|METH_FASTCALL|METH_KEYWORDS,\nexample_method_doc}\n\n|  | 最大的障碍是获取 方法定义所在的类，简称为方法“定义的类”。 定义的类可以拥有一个指向作为其\n组成部分的方法的引用。\n不要混淆定义的类和 Py_TYPE(self)。 如果方法是在你的类型的一个 子类 上被调用的，则\nPy_TYPE(self) 将指向该子类，它可能是在另一个模块中定义的。 |  |\n| --- | --- | --- |\n|  | 备注: 下面的 Python 代码可以演示这一概念。 Base.get_defining_class 将返回 Base，即使\ntype(self) == Sub:\nclass Base:\ndef get_type_of_self(self):\nreturn type(self)\ndef get_defining_class(self):\nreturn __class__\nclass Sub(Base):\npass |  |\n|  | 对于要获取其“定义方类”的方法，它必须使用 METH_METHOD | METH_FASTCALL |\nMETH_KEYWORDS 调用惯例 以及相应的 PyCMethod 签名: |  |\n|  | PyObject *PyCMethod(\nPyObject *self, // 方法调用所在的对象\nPyTypeObject *defining_class, // 定义的类\nPyObject *const *args, // 由参数组成的 C 数组\nPy_ssize_t nargs, // \"args\" 的长度\nPyObject *kwnames) // NULL，或由关键字参数组成的字典 |  |\n|  | 一旦你得到了定义的类，即可调用 PyType_GetModuleState() 来获取它所关联的模块的状态。\n例如： |  |\n|  | static PyObject *\nexample_method(PyObject *self,\nPyTypeObject *defining_class,\nPyObject *const *args,\nPy_ssize_t nargs,\nPyObject *kwnames)\n{\nmy_struct *state = (my_struct*)PyType_GetModuleState(defining_class);\nif (state == NULL) {\nreturn NULL;\n}\n... // rest of logic\n}\nPyDoc_STRVAR(example_method_doc, \"...\");\nstatic PyMethodDef my_methods[] = {\n{\"example_method\",\n(PyCFunction)(void(*)(void))example_method,\nMETH_METHOD|METH_FASTCALL|METH_KEYWORDS,\nexample_method_doc} |  |\n\n{NULL},\n}\n槽位方法、读取方法和设置方法对模块状态的访问\n备注: 这是 Python 3.11 的新增特性。\n槽位方法 — 即特殊方法的 C 快速等价物，如 nb_add 对应 __add__ 而 tp_new 对应初始化方法 —\n具有不允许传入定义类的非常简单的 API，这不同于 PyCMethod。 同样的机制也适用于通过\nPyGetSetDef 定义的读取方法和设置方法。\n要在这些场景下访问模块状态，请使用 PyType_GetModuleByDef() 函数，并传入模块定义。 一旦\n你得到该模块，即可调用 PyModule_GetState() 来获取状态:\nPyObject *module = PyType_GetModuleByDef(Py_TYPE(self), &module_def);\nmy_struct *state = (my_struct*)PyModule_GetState(module);\nif (state == NULL) {\nreturn NULL;\n}\nPyType_GetModuleByDef() 的作用方式是通过搜索 method resolution order (即所有超类) 来找到\n具有相应模块的第一个超类。\n备注: 在非常特别的情况下（继承链跨越由同样定义创建的多个模块），\nPyType_GetModuleByDef() 可能不会返回真正定义方法的类。 但是，它总是会返回一个具有同\n样定义的模块，这将确保具有兼容的 C 内存布局。\n模块状态的生命期\n当一个模块对象被当作垃圾回收时，它的模块状态将被释放。 对于每个指向（一部分）模块状态的\n指针来说，你必须持有一个对模块对象的引用。\n通常这不会有问题，因为使用 PyType_FromModuleAndSpec() 创建的类型，以及它们的实例，都持\n有对模块的引用。 但是，当你从其他地方，例如对外部库的回调引用模块状态时必须小心谨慎。\n未解决的问题\n围绕模块级状态和堆类型仍然存在一些未解决的问题。\n有关改进此状况最好的讨论是在 discuss 论坛的 c-api 标签下 进行的。\n类级作用域\n目前（即 Python 3.11）还无法将状态关联到单个 类型 而不依赖于 CPython 实现细节（这在未来可\n能发生改变 — 或许，会怪异地允许采用适当的类级作用域解决方案）。\n无损转换为堆类型\n\n|  | {NULL},\n} |  |\n| --- | --- | --- |\n|  | 槽位方法、读取方法和设置方法对模块状态的访问 |  |\n|  | 备注: 这是 Python 3.11 的新增特性。 |  |\n|  | 槽位方法 — 即特殊方法的 C 快速等价物，如 nb_add 对应 __add__ 而 tp_new 对应初始化方法 —\n具有不允许传入定义类的非常简单的 API，这不同于 PyCMethod。 同样的机制也适用于通过\nPyGetSetDef 定义的读取方法和设置方法。\n要在这些场景下访问模块状态，请使用 PyType_GetModuleByDef() 函数，并传入模块定义。 一旦\n你得到该模块，即可调用 PyModule_GetState() 来获取状态: |  |\n|  | PyObject *module = PyType_GetModuleByDef(Py_TYPE(self), &module_def);\nmy_struct *state = (my_struct*)PyModule_GetState(module);\nif (state == NULL) {\nreturn NULL;\n} |  |\n|  | PyType_GetModuleByDef() 的作用方式是通过搜索 method resolution order (即所有超类) 来找到\n具有相应模块的第一个超类。 |  |\n|  | 备注: 在非常特别的情况下（继承链跨越由同样定义创建的多个模块），\nPyType_GetModuleByDef() 可能不会返回真正定义方法的类。 但是，它总是会返回一个具有同\n样定义的模块，这将确保具有兼容的 C 内存布局。 |  |\n|  | 模块状态的生命期\n当一个模块对象被当作垃圾回收时，它的模块状态将被释放。 对于每个指向（一部分）模块状态的\n指针来说，你必须持有一个对模块对象的引用。\n通常这不会有问题，因为使用 PyType_FromModuleAndSpec() 创建的类型，以及它们的实例，都持\n有对模块的引用。 但是，当你从其他地方，例如对外部库的回调引用模块状态时必须小心谨慎。\n未解决的问题\n围绕模块级状态和堆类型仍然存在一些未解决的问题。\n有关改进此状况最好的讨论是在 discuss 论坛的 c-api 标签下 进行的。\n类级作用域\n目前（即 Python 3.11）还无法将状态关联到单个 类型 而不依赖于 CPython 实现细节（这在未来可\n能发生改变 — 或许，会怪异地允许采用适当的类级作用域解决方案）。\n无损转换为堆类型 |  |\n\n堆类型 API 没有从静态类型进行“无损”转换的设计；所谓无损转换，就是创建与给定静态类型完全一\n致的类型。", "metadata": {"title": "17_隔离扩展模块", "source": "md_docs\\python_howto_md\\17_隔离扩展模块.md", "doc_type": "指南", "language": "中文", "doc_id": "5879a73d"}}
{"doc_id": "52d2b077", "content": "Python 2.3 方法解析顺序\n备注: 这是一份历史性的文档，作为官方文档的附录提供。 这里所讨论的方法解析顺序在\nPython 2.3 中 被引入，但在之后的版本中仍然被使用 -- 包括 Python 3。\n由 Michele Simionato 撰写。\n摘要: 本文档的目标读者是那些希望理解 Python 2.3 中使用的 C3 方法解析顺序的 Python 程序\n员。 虽然它不是为新手准备的，但它具有很强的教学性，包含许多实用的例子。 据我所知\n还没有其他公开文档涵盖相同的领域，因此它应该是有用的。\n免责声明：\n我将此文档捐赠给 Python 软件基金会，采用 Python 2.3 许可。 如在这种情况下通常做法，我警\n示读者下面的内容 应该 是正确的，但我不提供任何保证。 请自行承担使用风险与损害！\n致谢：\nPython 邮件列表中所有对我表示支持的人。 Paul Foley，他指出了各种不精确之处并让我添加了\n本地优先排序的部分。 David Goodger 在 reStructuredText 格式化方面的帮助。David Mertz 在编\n辑方面提供的帮助。 最后，Guido van Rossum 热心地将本文档添加到官方 Python 2.3 主页。\n开始\nFelix qui potuit rerum cognoscere causas -- Virgilius\n事情开始于 Samuele Pedroni 在 Python 开发邮件列表上的一个帖子 [1]。 在他的帖子里，Samuele\n表示 Python 2.2 方法解析顺序不是单调的并提议用 C3 方法解析顺序来替代它。 Guido 认同他的意\n见因此现在 Python 2.3 使用了 C3。 C3 方法本身与 Python 没有关系，因为它由使用 Dylan 的人发\n明并在一篇针对 lisp 程序员的论文中描述 [2]。 本文给出了面向希望理解这项改变的理由的 Python\n使用者的（尽可能）易读的 C3 算法相关讨论。\n首先，我要指出我即将介绍的情况仅作用于在 Python 2.2 中引入的 新式类: 经典类 将保持其原有的\n方法解析顺序，深度优先并且从左至右。 因此，不存在对经典类原有代码的破坏；而且虽然在原理\n上存在对 Python 2.2 新式类代码的破坏，但在实践中 C3 解析顺序与 Python 2.2 方法解析顺序存在\n不同的情况是如此稀少以至于不会真正破坏原有代码。 所以：\n不必害怕！\n此外，除非你高强度地使用多重继承并且有复杂的层级结构，否则你就不需要理解 C3 算法，可以轻\n松地跳过本文。 另一方面，如果你真的想知道多重继承是如何工作的，那么本文就是为你准备的。\n好消息是事情并没有你想象的那么复杂。\n让我们从一些基本的定义开始。\n\n| Python 2.3 方法解析顺序 |\n| --- |\n| 备注: 这是一份历史性的文档，作为官方文档的附录提供。 这里所讨论的方法解析顺序在\nPython 2.3 中 被引入，但在之后的版本中仍然被使用 -- 包括 Python 3。 |\n| 由 Michele Simionato 撰写。\n摘要: 本文档的目标读者是那些希望理解 Python 2.3 中使用的 C3 方法解析顺序的 Python 程序\n员。 虽然它不是为新手准备的，但它具有很强的教学性，包含许多实用的例子。 据我所知\n还没有其他公开文档涵盖相同的领域，因此它应该是有用的。\n免责声明：\n我将此文档捐赠给 Python 软件基金会，采用 Python 2.3 许可。 如在这种情况下通常做法，我警\n示读者下面的内容 应该 是正确的，但我不提供任何保证。 请自行承担使用风险与损害！\n致谢：\nPython 邮件列表中所有对我表示支持的人。 Paul Foley，他指出了各种不精确之处并让我添加了\n本地优先排序的部分。 David Goodger 在 reStructuredText 格式化方面的帮助。David Mertz 在编\n辑方面提供的帮助。 最后，Guido van Rossum 热心地将本文档添加到官方 Python 2.3 主页。\n开始\nFelix qui potuit rerum cognoscere causas -- Virgilius\n事情开始于 Samuele Pedroni 在 Python 开发邮件列表上的一个帖子 [1]。 在他的帖子里，Samuele\n表示 Python 2.2 方法解析顺序不是单调的并提议用 C3 方法解析顺序来替代它。 Guido 认同他的意\n见因此现在 Python 2.3 使用了 C3。 C3 方法本身与 Python 没有关系，因为它由使用 Dylan 的人发\n明并在一篇针对 lisp 程序员的论文中描述 [2]。 本文给出了面向希望理解这项改变的理由的 Python\n使用者的（尽可能）易读的 C3 算法相关讨论。\n首先，我要指出我即将介绍的情况仅作用于在 Python 2.2 中引入的 新式类: 经典类 将保持其原有的\n方法解析顺序，深度优先并且从左至右。 因此，不存在对经典类原有代码的破坏；而且虽然在原理\n上存在对 Python 2.2 新式类代码的破坏，但在实践中 C3 解析顺序与 Python 2.2 方法解析顺序存在\n不同的情况是如此稀少以至于不会真正破坏原有代码。 所以：\n不必害怕！\n此外，除非你高强度地使用多重继承并且有复杂的层级结构，否则你就不需要理解 C3 算法，可以轻\n松地跳过本文。 另一方面，如果你真的想知道多重继承是如何工作的，那么本文就是为你准备的。\n好消息是事情并没有你想象的那么复杂。\n让我们从一些基本的定义开始。 |\n\n1. 在一个复杂的多重继承层级结构中给定一个类 C，要指明方法的覆盖顺序，即 C 的祖先的顺\n序是一项并不轻松的任务。\n2. 类 C 的祖先列表（包括类本身）从最近的祖先到最远的祖先排序，称为类优先级列表或 C 的\n线性化。\n3. 方法解析顺序 (MRO) 是构造线性化的规则集合。 在 Python 的语境中，术语 \"C 的 MRO\" 也\n会被用作类 C 的线性化的同义词。\n4. 举例来说，在单继承层级结构的情况下，如果 C 是 C1 的子类，而 C1 是 C2 的子类，那么 C\n的线性化就是简单的列表 [C, C1 , C2]。 但是，对于多继承层级结构，线性化的构造就比较麻\n烦了，因为要构造一个尊重 局部优先级排序 和 单调性 的线性化将更为困难。\n5. 我稍后会讨论局部优先级顺序问题，但我可以先在这里给出单调性的定义。 当以下情况为真\n时一个 MRO 就是单调的: 如果在 C 的线性化中 C1 先于 C2，那么在 C 的任何子类的线性化中\nC1 都先于 C2。 在其他情况下，派生新类的无害操作就可能会改变方法的解析顺序，从而可\n能引入非常微妙的程序错误。 稍后将举例说明这种情况。\n6. 并非所有的类都允许线性化。 在复杂的层级结构中，有些情况下不可能派生出一个类使其线\n性化遵循所有需要的属性。\n在此我举一个例子来说明这种情况。 考虑以下层级结构\n>>> O = object\n>>> class X(O): pass\n>>> class Y(O): pass\n>>> class A(X,Y): pass\n>>> class B(Y,X): pass\n它可以用以下继承图来表示，其中我用 O 来标记 object 类，它是任何新式类层级结构的起点：\n-----------\n| |\n| O |\n| / \\ |\n- X Y /\n| / | /\n| / |/\nA B\n\\ /\n?\n在此情况下，从 A 和 B 派生新类是不可能的，因为在 A 中 X 先于 Y，但在 B 中 Y 先于 X，因此在 C\n中方法解析顺序将出现歧义。\nPython 2.3 在此情况下会引发异常 (TypeError: MRO conflict among bases Y, X) 以防止程序员在无意\n中创建有歧义的层级结构。 Python 2.2 不会引发异常，而是会选择一个 临时 顺序 (在本例中为\nCABXYO)。\nC3 方法解析顺序\n让我们引入一些适用于接下来的讨论的简单标记法。 我会使用这样的快捷标记:\nC1 C2 ... CN\n\n|  | 1. 在一个复杂的多重继承层级结构中给定一个类 C，要指明方法的覆盖顺序，即 C 的祖先的顺\n序是一项并不轻松的任务。\n2. 类 C 的祖先列表（包括类本身）从最近的祖先到最远的祖先排序，称为类优先级列表或 C 的\n线性化。\n3. 方法解析顺序 (MRO) 是构造线性化的规则集合。 在 Python 的语境中，术语 \"C 的 MRO\" 也\n会被用作类 C 的线性化的同义词。\n4. 举例来说，在单继承层级结构的情况下，如果 C 是 C1 的子类，而 C1 是 C2 的子类，那么 C\n的线性化就是简单的列表 [C, C1 , C2]。 但是，对于多继承层级结构，线性化的构造就比较麻\n烦了，因为要构造一个尊重 局部优先级排序 和 单调性 的线性化将更为困难。\n5. 我稍后会讨论局部优先级顺序问题，但我可以先在这里给出单调性的定义。 当以下情况为真\n时一个 MRO 就是单调的: 如果在 C 的线性化中 C1 先于 C2，那么在 C 的任何子类的线性化中\nC1 都先于 C2。 在其他情况下，派生新类的无害操作就可能会改变方法的解析顺序，从而可\n能引入非常微妙的程序错误。 稍后将举例说明这种情况。\n6. 并非所有的类都允许线性化。 在复杂的层级结构中，有些情况下不可能派生出一个类使其线\n性化遵循所有需要的属性。\n在此我举一个例子来说明这种情况。 考虑以下层级结构 |  |\n| --- | --- | --- |\n|  | >>> O = object\n>>> class X(O): pass\n>>> class Y(O): pass\n>>> class A(X,Y): pass\n>>> class B(Y,X): pass |  |\n|  | 它可以用以下继承图来表示，其中我用 O 来标记 object 类，它是任何新式类层级结构的起点：\n-----------\n| |\n| O |\n| / \\ |\n- X Y /\n| / | /\n| / |/\nA B\n\\ /\n?\n在此情况下，从 A 和 B 派生新类是不可能的，因为在 A 中 X 先于 Y，但在 B 中 Y 先于 X，因此在 C\n中方法解析顺序将出现歧义。\nPython 2.3 在此情况下会引发异常 (TypeError: MRO conflict among bases Y, X) 以防止程序员在无意\n中创建有歧义的层级结构。 Python 2.2 不会引发异常，而是会选择一个 临时 顺序 (在本例中为\nCABXYO)。\nC3 方法解析顺序\n让我们引入一些适用于接下来的讨论的简单标记法。 我会使用这样的快捷标记: |  |\n|  | C1 C2 ... CN |  |\n|  |  |  |\n\n来表示类列表 [C1, C2, ... , CN]。\n列表的 head 是其第一个元素:\nhead = C1\n而 tail 则是列表的其余元素:\ntail = C2 ... CN.\n我还将使用这样的标记:\nC + (C1 C2 ... CN) = C C1 C2 ... CN\n来表示列表 [C] + [C1，C2，...，CN] 的总和。\n现在我就可以解释 MRO 在 Python 2.3 中的工作原理了。\n考虑多重继承层级结构中的类 C，C 继承自基类 B1, B2, ... , BN。 我们想要计算类 C 的线性化 L[C]。\n规则如下：\nC 的线性化就是 C 加上父类的线性化和父类列表的执行合并的总和。\n使用符号标记法:\nL[C(B1 ... BN)] = C + merge(L[B1] ... L[BN], B1 ... BN)\n特别地，如果 C 为 object 类，它是没有父类的，其线性化很简单:\nL[object] = object.\n不过，在通常情况下我们需要根据以下预设规则来计算合并结果：\n取第一个列表的 head，即 L[B1][0]；如果这个 head 不在任何其他列表的 tail 内，则将其添加到 C\n的线性化中，并在合并结果中将其从列表中移除，否则如果下一个列表的 head 是好的 head 则使\n用它。 然后重复上述操作直到所有类都被移除或是无法找到好的 head。 在这种情况下将无法构\n造合并结果，Python 2.3 将拒绝创建类 C 并将引发 异常。\n这一预设规则可以确保合并操作 保留 顺序，如果顺序能被保留的话。 在另一方面，如果顺序无法被\n保留（如上文讨论的顺序严重不一致的例子）则无法计算合并结果。\n如果 C 只有一个父类（单一继承）则合并结果的计算将很简单；在这种情况下:\nL[C(B)] = C + merge(L[B],B) = C + L[B]\n不过，对于多重继承的情况事情就会比较麻烦，如果不举几个例子我估计你是无法理解具体规则的\n;-)\n例子\n\n|  | 来表示类列表 [C1, C2, ... , CN]。\n列表的 head 是其第一个元素: |  |\n| --- | --- | --- |\n|  | head = C1 |  |\n|  | 而 tail 则是列表的其余元素: |  |\n|  | tail = C2 ... CN. |  |\n|  | 我还将使用这样的标记: |  |\n|  | C + (C1 C2 ... CN) = C C1 C2 ... CN |  |\n|  | 来表示列表 [C] + [C1，C2，...，CN] 的总和。\n现在我就可以解释 MRO 在 Python 2.3 中的工作原理了。\n考虑多重继承层级结构中的类 C，C 继承自基类 B1, B2, ... , BN。 我们想要计算类 C 的线性化 L[C]。\n规则如下：\nC 的线性化就是 C 加上父类的线性化和父类列表的执行合并的总和。\n使用符号标记法: |  |\n|  | L[C(B1 ... BN)] = C + merge(L[B1] ... L[BN], B1 ... BN) |  |\n|  | 特别地，如果 C 为 object 类，它是没有父类的，其线性化很简单: |  |\n|  | L[object] = object. |  |\n|  | 不过，在通常情况下我们需要根据以下预设规则来计算合并结果：\n取第一个列表的 head，即 L[B1][0]；如果这个 head 不在任何其他列表的 tail 内，则将其添加到 C\n的线性化中，并在合并结果中将其从列表中移除，否则如果下一个列表的 head 是好的 head 则使\n用它。 然后重复上述操作直到所有类都被移除或是无法找到好的 head。 在这种情况下将无法构\n造合并结果，Python 2.3 将拒绝创建类 C 并将引发 异常。\n这一预设规则可以确保合并操作 保留 顺序，如果顺序能被保留的话。 在另一方面，如果顺序无法被\n保留（如上文讨论的顺序严重不一致的例子）则无法计算合并结果。\n如果 C 只有一个父类（单一继承）则合并结果的计算将很简单；在这种情况下: |  |\n|  | L[C(B)] = C + merge(L[B],B) = C + L[B] |  |\n|  | 不过，对于多重继承的情况事情就会比较麻烦，如果不举几个例子我估计你是无法理解具体规则的\n;-)\n例子 |  |\n\n第一个例子。 考虑以下层级结构：\n>>> O = object\n>>> class F(O): pass\n>>> class E(O): pass\n>>> class D(O): pass\n>>> class C(D,F): pass\n>>> class B(D,E): pass\n>>> class A(B,C): pass\n在这种情况下继承图可以绘制为：\n6\n---\nLevel 3 | O | (more general)\n/ --- \\\n/ | \\ |\n/ | \\ |\n/ | \\ |\n--- --- --- |\nLevel 2 3 | D | 4| E | | F | 5 |\n--- --- --- |\n\\ \\ _ / | |\n\\ / \\ _ | |\n\\ / \\ | |\n--- --- |\nLevel 1 1 | B | | C | 2 |\n--- --- |\n\\ / |\n\\ / \\ /\n---\nLevel 0 0 | A | (more specialized)\n---\nO、D、E 和 F 的线性化很简单:\nL[O] = O\nL[D] = D O\nL[E] = E O\nL[F] = F O\nB 的线性化可以被计算为:\nL[B] = B + merge(DO, EO, DE)\n我们看到 D 是一个好的 head，因此我们使用它这样就可以简化为计算 merge(O,EO,E)。 现在 O 不\n是一个好的 head，因为它在序列 EO 的 tail 内。 在这种情况下规则要求我们必须跳到下一个序列。\n然后我们可以看到 E 是一个好的 head；我们使用它这样就可以简化为计算 merge(O,O) 从而得到\nO。 因此:\nL[B] = B D E O\n使用同样的步骤我们将发现:\n\n|  | 第一个例子。 考虑以下层级结构： |  |\n| --- | --- | --- |\n|  | >>> O = object\n>>> class F(O): pass\n>>> class E(O): pass\n>>> class D(O): pass\n>>> class C(D,F): pass\n>>> class B(D,E): pass\n>>> class A(B,C): pass |  |\n|  | 在这种情况下继承图可以绘制为：\n6\n---\nLevel 3 | O | (more general)\n/ --- \\\n/ | \\ |\n/ | \\ |\n/ | \\ |\n--- --- --- |\nLevel 2 3 | D | 4| E | | F | 5 |\n--- --- --- |\n\\ \\ _ / | |\n\\ / \\ _ | |\n\\ / \\ | |\n--- --- |\nLevel 1 1 | B | | C | 2 |\n--- --- |\n\\ / |\n\\ / \\ /\n---\nLevel 0 0 | A | (more specialized)\n---\nO、D、E 和 F 的线性化很简单: |  |\n|  | L[O] = O\nL[D] = D O\nL[E] = E O\nL[F] = F O |  |\n|  | B 的线性化可以被计算为: |  |\n|  | L[B] = B + merge(DO, EO, DE) |  |\n|  | 我们看到 D 是一个好的 head，因此我们使用它这样就可以简化为计算 merge(O,EO,E)。 现在 O 不\n是一个好的 head，因为它在序列 EO 的 tail 内。 在这种情况下规则要求我们必须跳到下一个序列。\n然后我们可以看到 E 是一个好的 head；我们使用它这样就可以简化为计算 merge(O,O) 从而得到\nO。 因此: |  |\n|  | L[B] = B D E O |  |\n|  | 使用同样的步骤我们将发现: |  |\n\nL[C] = C + merge(DO,FO,DF)\n= C + D + merge(O,FO,F)\n= C + D + F + merge(O,O)\n= C D F O\n现在我们可以计算:\nL[A] = A + merge(BDEO,CDFO,BC)\n= A + B + merge(DEO,CDFO,C)\n= A + B + C + merge(DEO,DFO)\n= A + B + C + D + merge(EO,FO)\n= A + B + C + D + E + merge(O,FO)\n= A + B + C + D + E + F + merge(O,O)\n= A B C D E F O\n在这个例子中，线性化按照继承级别进行了良好的排序，即级别越低（即更特化的类）优先级越高\n（见继承图）。 然而，这并不是一般的情况。\n我把计算第二个例子的线性化作为一个练习留给读者完成：\n>>> O = object\n>>> class F(O): pass\n>>> class E(O): pass\n>>> class D(O): pass\n>>> class C(D,F): pass\n>>> class B(E,D): pass\n>>> class A(B,C): pass\n与前一例子的唯一区别在于 B(D,E) --> B(E,D)；然而即使是这样一个小小的改动也完全改变了层级结\n构的顺序：\n6\n---\nLevel 3 | O |\n/ --- \\\n/ | \\\n/ | \\\n/ | \\\n--- --- ---\nLevel 2 2 | E | 4 | D | | F | 5\n--- --- ---\n\\ / \\ /\n\\ / \\ /\n\\ / \\ /\n--- ---\nLevel 1 1 | B | | C | 3\n--- ---\n\\ /\n\\ /\n---\nLevel 0 0 | A |\n---\n请注意处在层级结构第二层级的类 E，它先于处在层级结构第一层级的类 C，也就是说，E 比 C 更特\n化，即便它处在更高的层级。\n\n|  | L[C] = C + merge(DO,FO,DF)\n= C + D + merge(O,FO,F)\n= C + D + F + merge(O,O)\n= C D F O |  |\n| --- | --- | --- |\n|  | 现在我们可以计算: |  |\n|  | L[A] = A + merge(BDEO,CDFO,BC)\n= A + B + merge(DEO,CDFO,C)\n= A + B + C + merge(DEO,DFO)\n= A + B + C + D + merge(EO,FO)\n= A + B + C + D + E + merge(O,FO)\n= A + B + C + D + E + F + merge(O,O)\n= A B C D E F O |  |\n|  | 在这个例子中，线性化按照继承级别进行了良好的排序，即级别越低（即更特化的类）优先级越高\n（见继承图）。 然而，这并不是一般的情况。\n我把计算第二个例子的线性化作为一个练习留给读者完成： |  |\n|  | >>> O = object\n>>> class F(O): pass\n>>> class E(O): pass\n>>> class D(O): pass\n>>> class C(D,F): pass\n>>> class B(E,D): pass\n>>> class A(B,C): pass |  |\n|  | 与前一例子的唯一区别在于 B(D,E) --> B(E,D)；然而即使是这样一个小小的改动也完全改变了层级结\n构的顺序：\n6\n---\nLevel 3 | O |\n/ --- \\\n/ | \\\n/ | \\\n/ | \\\n--- --- ---\nLevel 2 2 | E | 4 | D | | F | 5\n--- --- ---\n\\ / \\ /\n\\ / \\ /\n\\ / \\ /\n--- ---\nLevel 1 1 | B | | C | 3\n--- ---\n\\ /\n\\ /\n---\nLevel 0 0 | A |\n---\n请注意处在层级结构第二层级的类 E，它先于处在层级结构第一层级的类 C，也就是说，E 比 C 更特\n化，即便它处在更高的层级。 |  |\n\n懒惰的程序员可以直接获取 Python 2.2 的 MRO，因为在这种情况下它会与 Python 2.3 的线程化恰\n好一致。 只需唤起类 A 的 mro() 方法就够了：\n>>> A.mro()\n[<class 'A'>, <class 'B'>, <class 'E'>,\n<class 'C'>, <class 'D'>, <class 'F'>,\n<class 'object'>]\n最后，让我来讲解第一小节所讨论的例子，其中涉及严重的顺序不一致问题。 在这种情况下，可以\n直接计算 O、X、Y、A 和 B 的线性化：\nL[O] = 0\nL[X] = X O\nL[Y] = Y O\nL[A] = A X Y O\nL[B] = B Y X O\n然而，要计算继承自 A 和 B 的类 C 的线性化则是不可能的:\nL[C] = C + merge(AXYO, BYXO, AB)\n= C + A + merge(XYO, BYXO, B)\n= C + A + B + merge(XYO, YXO)\n此时我们无法合并列表 XYO 和 YXO，因为 X 在 YXO 的 tail 内，而 Y 在 XYO 的 tail 内：因此没有好\n的 head 从而 C3 算法将停止。 Python 2.3 将引发一个错误并拒绝创建类 C。\n坏的方法解析顺序\n当一个 MOR 破坏了诸如局部优先顺序和单调性等基本属性时它就是 坏的。 在本节中，我将证明\nPython 2.2 中经典类的 MRO 和新式类的 MRO 都是坏的。\n从局部优先顺序开始会更简单。 请看下面的例子：\n>>> F=type('Food',(),{'remember2buy':'spam'})\n>>> E=type('Eggs',(F,),{'remember2buy':'eggs'})\n>>> G=type('GoodFood',(F,E),{}) # under Python 2.3 this is an error!\n继承图如下\nO\n|\n(buy spam) F\n| \\\n| E (buy eggs)\n| /\nG\n(buy eggs or spam ?)\n我们看到类 G 继承自 F 和 E，其中 F 先于 E：因此我们预期属性 G.remember2buy 会被\nF.remember2buy 而不是被 E.remember2buy 所继承：然而 Python 2.2 给出的结果是\n\n|  | 懒惰的程序员可以直接获取 Python 2.2 的 MRO，因为在这种情况下它会与 Python 2.3 的线程化恰\n好一致。 只需唤起类 A 的 mro() 方法就够了： |  |\n| --- | --- | --- |\n|  | >>> A.mro()\n[<class 'A'>, <class 'B'>, <class 'E'>,\n<class 'C'>, <class 'D'>, <class 'F'>,\n<class 'object'>] |  |\n|  | 最后，让我来讲解第一小节所讨论的例子，其中涉及严重的顺序不一致问题。 在这种情况下，可以\n直接计算 O、X、Y、A 和 B 的线性化：\nL[O] = 0\nL[X] = X O\nL[Y] = Y O\nL[A] = A X Y O\nL[B] = B Y X O\n然而，要计算继承自 A 和 B 的类 C 的线性化则是不可能的: |  |\n|  | L[C] = C + merge(AXYO, BYXO, AB)\n= C + A + merge(XYO, BYXO, B)\n= C + A + B + merge(XYO, YXO) |  |\n|  | 此时我们无法合并列表 XYO 和 YXO，因为 X 在 YXO 的 tail 内，而 Y 在 XYO 的 tail 内：因此没有好\n的 head 从而 C3 算法将停止。 Python 2.3 将引发一个错误并拒绝创建类 C。\n坏的方法解析顺序\n当一个 MOR 破坏了诸如局部优先顺序和单调性等基本属性时它就是 坏的。 在本节中，我将证明\nPython 2.2 中经典类的 MRO 和新式类的 MRO 都是坏的。\n从局部优先顺序开始会更简单。 请看下面的例子： |  |\n|  | >>> F=type('Food',(),{'remember2buy':'spam'})\n>>> E=type('Eggs',(F,),{'remember2buy':'eggs'})\n>>> G=type('GoodFood',(F,E),{}) # under Python 2.3 this is an error! |  |\n|  | 继承图如下\nO\n|\n(buy spam) F\n| \\\n| E (buy eggs)\n| /\nG\n(buy eggs or spam ?)\n我们看到类 G 继承自 F 和 E，其中 F 先于 E：因此我们预期属性 G.remember2buy 会被\nF.remember2buy 而不是被 E.remember2buy 所继承：然而 Python 2.2 给出的结果是 |  |\n\n>>> G.remember2buy\n'eggs'\n这是对局部优先顺序的破坏因为在 Python 2.2 对 G 进行线性化时，局部优先列表即 G 的父类列表中\n的顺序并不会被保留:\nL[G,P22]= G E F object # F 在 E *之后*\n有人可能会说在 Python 2.2 的线性化中 F 在 E 之后的原因是 F 的特化程度低于 E，因为 F 是 E 的超\n类；然而打破局部优先排序是相当反直觉且容易导致错误的。 这一点因为它与旧式类不同而尤其明\n显：\n>>> class F: remember2buy='spam'\n>>> class E(F): remember2buy='eggs'\n>>> class G(F,E): pass\n>>> G.remember2buy\n'spam'\n在这种情况下 MRO 为 GFEF 并保留了局部优先顺序。\n作为一般规则，应当避免像上面这样的层级结构，因为不清楚 F 是否应该重写 E，反之亦然。\nPython 2.3 通过在创建类 G 时引发异常解决了这个歧义性问题，有效地阻止了程序员生成有歧义的\n层级结构。 其原因是 C3 算法在执行以下合并时将会失败:\nmerge(FO,EFO,FE)\n这是无法计算的，因为 F 在 EFO 的 tail 内而 E 在 FE 的 tail 内。\n真正的解决办法是设计一个无歧义的层级结构，即从 E 和 F（更具体的说是第一个）而不是从 F 和 E\n派生出 G；在这种情况下 MRO 毫无疑问就是 GEF。\nO\n|\nF (spam)\n/ |\n(eggs) E |\n\\ |\nG\n(eggs, no doubt)\nPython 2.3 会强迫程序员编写好的（或者，至少不那么容易出错的）层级结构。\n与此相关的一点，我要指出 Python 2.3 的算法足够聪明，它能识别明显的错误，比如父类列表中重\n复的类：\n>>> class A(object): pass\n>>> class C(A,A): pass # error\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in ?\nTypeError: duplicate base class A\n\n|  | >>> G.remember2buy\n'eggs' |  |\n| --- | --- | --- |\n|  | 这是对局部优先顺序的破坏因为在 Python 2.2 对 G 进行线性化时，局部优先列表即 G 的父类列表中\n的顺序并不会被保留: |  |\n|  | L[G,P22]= G E F object # F 在 E *之后* |  |\n|  | 有人可能会说在 Python 2.2 的线性化中 F 在 E 之后的原因是 F 的特化程度低于 E，因为 F 是 E 的超\n类；然而打破局部优先排序是相当反直觉且容易导致错误的。 这一点因为它与旧式类不同而尤其明\n显： |  |\n|  | >>> class F: remember2buy='spam'\n>>> class E(F): remember2buy='eggs'\n>>> class G(F,E): pass\n>>> G.remember2buy\n'spam' |  |\n|  | 在这种情况下 MRO 为 GFEF 并保留了局部优先顺序。\n作为一般规则，应当避免像上面这样的层级结构，因为不清楚 F 是否应该重写 E，反之亦然。\nPython 2.3 通过在创建类 G 时引发异常解决了这个歧义性问题，有效地阻止了程序员生成有歧义的\n层级结构。 其原因是 C3 算法在执行以下合并时将会失败: |  |\n|  | merge(FO,EFO,FE) |  |\n|  | 这是无法计算的，因为 F 在 EFO 的 tail 内而 E 在 FE 的 tail 内。\n真正的解决办法是设计一个无歧义的层级结构，即从 E 和 F（更具体的说是第一个）而不是从 F 和 E\n派生出 G；在这种情况下 MRO 毫无疑问就是 GEF。\nO\n|\nF (spam)\n/ |\n(eggs) E |\n\\ |\nG\n(eggs, no doubt)\nPython 2.3 会强迫程序员编写好的（或者，至少不那么容易出错的）层级结构。\n与此相关的一点，我要指出 Python 2.3 的算法足够聪明，它能识别明显的错误，比如父类列表中重\n复的类： |  |\n|  | >>> class A(object): pass\n>>> class C(A,A): pass # error\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in ?\nTypeError: duplicate base class A |  |\n|  |  |  |\n\n在这种情况下，Python 2.2（包括经典类和新式类）则不会引发任何异常。\n最后，我想指出我们从这个例子中汲取的两点教训：\n1. 尽管名称如此，MRO 是决定属性的解析顺序，而不仅仅是方法的解析顺序；\n2. Python 爱好者的默认食物是 spam ! (不过你已经知道这一点了 ;-)\n在讨论了局部优先顺序问题之后，现在再让我来讲解单调性。 我的目标是证明经典类和 Python 2.2\n新式类的 MRO 都不是单调的。\n要证明经典类的 MRO 是非单调的相当简单，只要看一下这个钻石形图就够了：\nC\n/ \\\n/ \\\nA B\n\\ /\n\\ /\nD\n人们很容易发现其中的不一致性:\nL[B,P21] = B C # B 在 C 前 : B 的方法胜出\nL[D,P21] = D A C B C # B 在 C 之后 : C 的方法胜出!\n另一方面，Python 2.2 和 Python 2.3 的 MRO 则没有问题，它们都将给出以下结果:\nL[D] = D A B C\nGuido 在他的文章 [3] 中指出经典的 MRO 在实践中并没有那么坏，因为人们通常可以避免经典类形\n成钻石形继承图。 但是所有新式类都继承自 object，因此钻石形继承图是不可避免的并且在每个\n多重继承图中都会出现不一致性。\nPython 2.2 的 MRO 使打破单调性变得困难，但并非不可能。 下面是最初由 Samuele Pedroni 提供\n的例子，显示 Python 2.2 的 MRO 是非单调的：\n>>> class A(object): pass\n>>> class B(object): pass\n>>> class C(object): pass\n>>> class D(object): pass\n>>> class E(object): pass\n>>> class K1(A,B,C): pass\n>>> class K2(D,B,E): pass\n>>> class K3(D,A): pass\n>>> class Z(K1,K2,K3): pass\n以下是根据 C3 MRO 进行的线性化 (读者应当将验证这些线性化作为练习并绘制继承图 ;-)\nL[A] = A O\nL[B] = B O\nL[C] = C O\nL[D] = D O\n\n|  | 在这种情况下，Python 2.2（包括经典类和新式类）则不会引发任何异常。\n最后，我想指出我们从这个例子中汲取的两点教训：\n1. 尽管名称如此，MRO 是决定属性的解析顺序，而不仅仅是方法的解析顺序；\n2. Python 爱好者的默认食物是 spam ! (不过你已经知道这一点了 ;-)\n在讨论了局部优先顺序问题之后，现在再让我来讲解单调性。 我的目标是证明经典类和 Python 2.2\n新式类的 MRO 都不是单调的。\n要证明经典类的 MRO 是非单调的相当简单，只要看一下这个钻石形图就够了：\nC\n/ \\\n/ \\\nA B\n\\ /\n\\ /\nD\n人们很容易发现其中的不一致性: |  |\n| --- | --- | --- |\n|  | L[B,P21] = B C # B 在 C 前 : B 的方法胜出\nL[D,P21] = D A C B C # B 在 C 之后 : C 的方法胜出! |  |\n|  | 另一方面，Python 2.2 和 Python 2.3 的 MRO 则没有问题，它们都将给出以下结果: |  |\n|  | L[D] = D A B C |  |\n|  | Guido 在他的文章 [3] 中指出经典的 MRO 在实践中并没有那么坏，因为人们通常可以避免经典类形\n成钻石形继承图。 但是所有新式类都继承自 object，因此钻石形继承图是不可避免的并且在每个\n多重继承图中都会出现不一致性。\nPython 2.2 的 MRO 使打破单调性变得困难，但并非不可能。 下面是最初由 Samuele Pedroni 提供\n的例子，显示 Python 2.2 的 MRO 是非单调的： |  |\n|  | >>> class A(object): pass\n>>> class B(object): pass\n>>> class C(object): pass\n>>> class D(object): pass\n>>> class E(object): pass\n>>> class K1(A,B,C): pass\n>>> class K2(D,B,E): pass\n>>> class K3(D,A): pass\n>>> class Z(K1,K2,K3): pass |  |\n|  | 以下是根据 C3 MRO 进行的线性化 (读者应当将验证这些线性化作为练习并绘制继承图 ;-) |  |\n|  | L[A] = A O\nL[B] = B O\nL[C] = C O\nL[D] = D O |  |\n\nL[E] = E O\nL[K1]= K1 A B C O\nL[K2]= K2 D B E O\nL[K3]= K3 D A O\nL[Z] = Z K1 K2 K3 D A B C E O\nPython 2.2 对 A、B、C、D、E、K1、K2 和 K3 给出了完全相同的线性化，但对 Z 则给出了不同的线\n性化:\nL[Z,P22] = Z K1 K3 A K2 D B C E O\n很明显这种线性化是 错误 的，因为 A 在 D 之前，而在 K3 的线性化中 A 在 D 之后。 换句话说，在\nK3 中由 D 派生的方法会重写由 A 派生的方法，但在仍为 K3 子类的 Z 中，由 A 派生的方法会重写由\nD 派生的方法！ 这破坏了单调性。 此外，Z 的 Python 2.2 线性化也与局部优先顺序不一致，因为类\nZ 的局部优先列表是 [K1, K2, K3] (K2 先于 K3)，而在 Z 的线性化中则是 K2 跟随 K3。 这些问题解释\n了为什么 2.2 规则被否定而改用 C3 规则。\n结束\n本节是为没有耐心的读者准备的，他们会跳过前面的所有章节，直接跳到结尾。 这部分也是为懒惰\n的程序员准备的，因为他们不想动脑筋。 最后，这部分也是为有些自负的程序员准备的，否则他/她\n就不会去阅读一篇关于多重继承层次结构中的 C3 方法解析顺序的论文了 ;-) 这三个优点合在一起\n（而 不是 分开）应该得到一个奖励：这个奖励就是一个简短的 Python 2.2 脚本，它可以在不影响你\n的大脑的情况下计算 2.3 MRO。 只需修改最后一行就可以尝试我在本文中讨论的各种示例:\n#<mro.py>\n\"\"\"C3 algorithm by Samuele Pedroni (with readability enhanced by me).\"\"\"\nclass __metaclass__(type):\n\"All classes are metamagically modified to be nicely printed\"\n__repr__ = lambda cls: cls.__name__\nclass ex_2:\n\"Serious order disagreement\" #From Guido\nclass O: pass\nclass X(O): pass\nclass Y(O): pass\nclass A(X,Y): pass\nclass B(Y,X): pass\ntry:\nclass Z(A,B): pass #creates Z(A,B) in Python 2.2\nexcept TypeError:\npass # Z(A,B) cannot be created in Python 2.3\nclass ex_5:\n\"My first example\"\nclass O: pass\nclass F(O): pass\nclass E(O): pass\nclass D(O): pass\nclass C(D,F): pass\nclass B(D,E): pass\nclass A(B,C): pass\n\n|  | L[E] = E O\nL[K1]= K1 A B C O\nL[K2]= K2 D B E O\nL[K3]= K3 D A O\nL[Z] = Z K1 K2 K3 D A B C E O |  |\n| --- | --- | --- |\n|  | Python 2.2 对 A、B、C、D、E、K1、K2 和 K3 给出了完全相同的线性化，但对 Z 则给出了不同的线\n性化: |  |\n|  | L[Z,P22] = Z K1 K3 A K2 D B C E O |  |\n|  | 很明显这种线性化是 错误 的，因为 A 在 D 之前，而在 K3 的线性化中 A 在 D 之后。 换句话说，在\nK3 中由 D 派生的方法会重写由 A 派生的方法，但在仍为 K3 子类的 Z 中，由 A 派生的方法会重写由\nD 派生的方法！ 这破坏了单调性。 此外，Z 的 Python 2.2 线性化也与局部优先顺序不一致，因为类\nZ 的局部优先列表是 [K1, K2, K3] (K2 先于 K3)，而在 Z 的线性化中则是 K2 跟随 K3。 这些问题解释\n了为什么 2.2 规则被否定而改用 C3 规则。\n结束\n本节是为没有耐心的读者准备的，他们会跳过前面的所有章节，直接跳到结尾。 这部分也是为懒惰\n的程序员准备的，因为他们不想动脑筋。 最后，这部分也是为有些自负的程序员准备的，否则他/她\n就不会去阅读一篇关于多重继承层次结构中的 C3 方法解析顺序的论文了 ;-) 这三个优点合在一起\n（而 不是 分开）应该得到一个奖励：这个奖励就是一个简短的 Python 2.2 脚本，它可以在不影响你\n的大脑的情况下计算 2.3 MRO。 只需修改最后一行就可以尝试我在本文中讨论的各种示例: |  |\n|  | #<mro.py>\n\"\"\"C3 algorithm by Samuele Pedroni (with readability enhanced by me).\"\"\"\nclass __metaclass__(type):\n\"All classes are metamagically modified to be nicely printed\"\n__repr__ = lambda cls: cls.__name__\nclass ex_2:\n\"Serious order disagreement\" #From Guido\nclass O: pass\nclass X(O): pass\nclass Y(O): pass\nclass A(X,Y): pass\nclass B(Y,X): pass\ntry:\nclass Z(A,B): pass #creates Z(A,B) in Python 2.2\nexcept TypeError:\npass # Z(A,B) cannot be created in Python 2.3\nclass ex_5:\n\"My first example\"\nclass O: pass\nclass F(O): pass\nclass E(O): pass\nclass D(O): pass\nclass C(D,F): pass\nclass B(D,E): pass\nclass A(B,C): pass |  |\n\nclass ex_6:\n\"My second example\"\nclass O: pass\nclass F(O): pass\nclass E(O): pass\nclass D(O): pass\nclass C(D,F): pass\nclass B(E,D): pass\nclass A(B,C): pass\nclass ex_9:\n\"Difference between Python 2.2 MRO and C3\" #From Samuele\nclass O: pass\nclass A(O): pass\nclass B(O): pass\nclass C(O): pass\nclass D(O): pass\nclass E(O): pass\nclass K1(A,B,C): pass\nclass K2(D,B,E): pass\nclass K3(D,A): pass\nclass Z(K1,K2,K3): pass\ndef merge(seqs):\nprint '\\n\\nCPL[%s]=%s' % (seqs[0][0],seqs),\nres = []; i=0\nwhile 1:\nnonemptyseqs=[seq for seq in seqs if seq]\nif not nonemptyseqs: return res\ni+=1; print '\\n',i,'round: candidates...',\nfor seq in nonemptyseqs: # find merge candidates among seq heads\ncand = seq[0]; print ' ',cand,\nnothead=[s for s in nonemptyseqs if cand in s[1:]]\nif nothead: cand=None #reject candidate\nelse: break\nif not cand: raise \"Inconsistent hierarchy\"\nres.append(cand)\nfor seq in nonemptyseqs: # remove cand\nif seq[0] == cand: del seq[0]\ndef mro(C):\n\"Compute the class precedence list (mro) according to C3\"\nreturn merge([[C]]+map(mro,C.__bases__)+[list(C.__bases__)])\ndef print_mro(C):\nprint '\\nMRO[%s]=%s' % (C,mro(C))\nprint '\\nP22 MRO[%s]=%s' % (C,C.mro())\nprint_mro(ex_9.Z)\n#</mro.py>\n就是这样了朋友们，\n好好享受吧！\n参考资源\n\n|  | class ex_6:\n\"My second example\"\nclass O: pass\nclass F(O): pass\nclass E(O): pass\nclass D(O): pass\nclass C(D,F): pass\nclass B(E,D): pass\nclass A(B,C): pass\nclass ex_9:\n\"Difference between Python 2.2 MRO and C3\" #From Samuele\nclass O: pass\nclass A(O): pass\nclass B(O): pass\nclass C(O): pass\nclass D(O): pass\nclass E(O): pass\nclass K1(A,B,C): pass\nclass K2(D,B,E): pass\nclass K3(D,A): pass\nclass Z(K1,K2,K3): pass\ndef merge(seqs):\nprint '\\n\\nCPL[%s]=%s' % (seqs[0][0],seqs),\nres = []; i=0\nwhile 1:\nnonemptyseqs=[seq for seq in seqs if seq]\nif not nonemptyseqs: return res\ni+=1; print '\\n',i,'round: candidates...',\nfor seq in nonemptyseqs: # find merge candidates among seq heads\ncand = seq[0]; print ' ',cand,\nnothead=[s for s in nonemptyseqs if cand in s[1:]]\nif nothead: cand=None #reject candidate\nelse: break\nif not cand: raise \"Inconsistent hierarchy\"\nres.append(cand)\nfor seq in nonemptyseqs: # remove cand\nif seq[0] == cand: del seq[0]\ndef mro(C):\n\"Compute the class precedence list (mro) according to C3\"\nreturn merge([[C]]+map(mro,C.__bases__)+[list(C.__bases__)])\ndef print_mro(C):\nprint '\\nMRO[%s]=%s' % (C,mro(C))\nprint '\\nP22 MRO[%s]=%s' % (C,C.mro())\nprint_mro(ex_9.Z)\n#</mro.py> |  |\n| --- | --- | --- |\n|  | 就是这样了朋友们，\n好好享受吧！\n参考资源 |  |\n\n[1] 由 Samuele Pedroni 在 python-dev 发起的讨论: https://mail.python.org/pipermail/python-\ndev/2002-October/029035.html\n[2] 论文 A Monotonic Superclass Linearization for Dylan: https://doi.org/10.1145/236337.236343\n[3] Guido van Rossum 的文章，Unifying types and classes in Python 2.2:\nhttps://web.archive.org/web/20140210194412/http://www.python.org/download/releases/2.2.\n2/descrintro", "metadata": {"title": "18_Python_2.3_方法解析顺序", "source": "md_docs\\python_howto_md\\18_Python_2.3_方法解析顺序.md", "doc_type": "指南", "language": "中文", "doc_id": "52d2b077"}}
{"doc_id": "c2d28163", "content": "套接字编程指南\n作者: Gordon McMillan\n摘要\n套接字几乎无处不在，但是它却是被误解最严重的技术之一。这是一篇简单的套接字概述。并不\n是一篇真正的教程 —— 你需要做更多的事情才能让它工作起来。其中也并没有涵盖细节（细节会\n有很多），但是我希望它能提供足够的背景知识，让你像模像样的开始使用套接字\n套接字\n我将只讨论关于 INET（比如：IPv4 地址族）的套接字，但是它将覆盖几乎 99% 的套接字使用场\n景。并且我将仅讨论 STREAM（比如：TCP）类型的套接字 - 除非你真的知道你在做什么（那么这篇\nHOWTO 可能并不适合你），使用 STREAM 类型的套接字将会得到比其它类型更好的表现与性能。\n我将尝试揭开套接字的神秘面纱，也会讲到一些阻塞与非阻塞套接字的使用。但是我将以阻塞套接\n字为起点开始讨论。只有你了解它是如何工作的以后才能处理非阻塞套接字。\n理解这些东西的难点之一在于「套接字」可以表示很多微妙差异的东西，这取决于上下文。所以首\n先，让我们先分清楚「客户端」套接字和「服务端」套接字之间的不同，客户端套接字表示对话的\n一端，服务端套接字更像是总机接线员。客户端程序只能（比如：你的浏览器）使用「客户端」套\n接字；网络服务器则可以使用「服务端」套接字和「客户端」套接字来会话\n历史\n目前为止，在各种形式的 IPC 中，套接字是最流行的。在任何指定的平台上，可能会有其它更快的\nIPC 形式，但是就跨平台通信来说，套接字大概是唯一的玩法\n套接字作为 Unix 的 BSD 分支的一部分诞生于 Berkeley。 它们像野火一样在互联网上传播。 这是有\n充分理由的 --- 套接字与 INET 的结合让世界各地的任何机器之间的通信变得令人难以置信的简单\n（至少是与其他方案相比）。\n创建套接字\n简略地说，当你点击带你来到这个页面的链接时，你的浏览器就已经做了下面这几件事情:\n# 创建一个 INET, STREAMing 套接字\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n# 现在连接到 web 服务器 80 端口 - 标准的 http 端口\ns.connect((\"www.python.org\", 80))\n\n| 套接字编程指南\n作者: Gordon McMillan |\n| --- |\n| 摘要\n套接字几乎无处不在，但是它却是被误解最严重的技术之一。这是一篇简单的套接字概述。并不\n是一篇真正的教程 —— 你需要做更多的事情才能让它工作起来。其中也并没有涵盖细节（细节会\n有很多），但是我希望它能提供足够的背景知识，让你像模像样的开始使用套接字 |\n| 套接字\n我将只讨论关于 INET（比如：IPv4 地址族）的套接字，但是它将覆盖几乎 99% 的套接字使用场\n景。并且我将仅讨论 STREAM（比如：TCP）类型的套接字 - 除非你真的知道你在做什么（那么这篇\nHOWTO 可能并不适合你），使用 STREAM 类型的套接字将会得到比其它类型更好的表现与性能。\n我将尝试揭开套接字的神秘面纱，也会讲到一些阻塞与非阻塞套接字的使用。但是我将以阻塞套接\n字为起点开始讨论。只有你了解它是如何工作的以后才能处理非阻塞套接字。\n理解这些东西的难点之一在于「套接字」可以表示很多微妙差异的东西，这取决于上下文。所以首\n先，让我们先分清楚「客户端」套接字和「服务端」套接字之间的不同，客户端套接字表示对话的\n一端，服务端套接字更像是总机接线员。客户端程序只能（比如：你的浏览器）使用「客户端」套\n接字；网络服务器则可以使用「服务端」套接字和「客户端」套接字来会话\n历史\n目前为止，在各种形式的 IPC 中，套接字是最流行的。在任何指定的平台上，可能会有其它更快的\nIPC 形式，但是就跨平台通信来说，套接字大概是唯一的玩法\n套接字作为 Unix 的 BSD 分支的一部分诞生于 Berkeley。 它们像野火一样在互联网上传播。 这是有\n充分理由的 --- 套接字与 INET 的结合让世界各地的任何机器之间的通信变得令人难以置信的简单\n（至少是与其他方案相比）。\n创建套接字\n简略地说，当你点击带你来到这个页面的链接时，你的浏览器就已经做了下面这几件事情: |\n| # 创建一个 INET, STREAMing 套接字\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n# 现在连接到 web 服务器 80 端口 - 标准的 http 端口\ns.connect((\"www.python.org\", 80)) |\n|  |\n\n当连接完成，套接字可以用来发送请求来接收页面上显示的文字。同样是这个套接字也会用来读取\n响应，最后再被销毁。是的，被销毁了。客户端套接字通常用来做一次交换（或者说一小组序列的\n交换）。\n网络服务器发生了什么这个问题就有点复杂了。首页，服务器创建一个「服务端套接字」:\n# 创建一个 INET, STREAM 套接字\nserversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n# 将套接字绑定到一个全局的主机和知名的端口\nserversocket.bind((socket.gethostname(), 80))\n# 成为服务器套接字\nserversocket.listen(5)\n有几件事需要注意：我们使用了 socket.gethostname()，所以套接字将外网可见。如果我们使用\n的是 s.bind(('localhost', 80)) 或者 s.bind(('127.0.0.1', 80))，也会得到一个「服务端」\n套接字，但是后者只在同一机器上可见。s.bind(('', 80)) 则指定套接字可以被机器上的任何地\n址碰巧连接\n第二个需要注点是：低端口号通常被一些「常用的」服务（HTTP, SNMP 等）所保留。如果你想把程\n序跑起来，最好使用一个高位端口号（通常是4位的数字）。\n最后，listen 方法的参数会告诉套接字库，我们希望在队列中累积多达 5 个（通常的最大值）连接\n请求后再拒绝外部连接。 如果所有其他代码都准确无误，这个队列长度应该是足够的。\n现在我们已经有一个「服务端」套接字，监听了 80 端口，我们可以进入网络服务器的主循环了:\nwhile True:\n# 接受外来的连接\n(clientsocket, address) = serversocket.accept()\n# 现在使用 clientsocket 执行一些操作\n# 在本场景中，我们假装这是个线程化服务器\nct = make_client_thread(clientsocket)\nct.start()\n事际上，通常有 3 种方法可以让这个循环工作起来 - 调度一个线程来处理 客户端套接字，或者把这\n个应用改成使用非阻塞模式套接字，亦或是使用 select 库来实现「服务端」套接字与任意活动 客\n户端套接字 之间的多路复用。稍后会详细介绍。现在最重要的是理解：这就是一个 服务端 套接字\n做的 所有 事情。它并没有发送任何数据。也没有接收任何数据。它只创建「客户端」套接字。每个\n客户端套接字 都是为了响应某些其它客户端套接字 connect() 到我们绑定的主机。一旦创建 客户\n端套接字 完成，就会返回并监听更多的连接请求。现个客户端可以随意通信 - 它们使用了一些动态\n分配的端口，会话结束时端口才会被回收\n进程间通信\n如果你需要在同一台机器上进行两个进程间的快速 IPC 通信，你应该了解管道或者共享内存。如果\n你决定使用 AF_INET 类型的套接字，绑定「服务端」套接字到 'localhost' 。在大多数平台，这将\n会使用一个许多网络层间的通用快捷方式（本地回环地址）并且速度会快很多\n参见: multiprocessing 模块使跨平台 IPC 通信成为一个高层的 API\n\n|  |  | 当连接完成，套接字可以用来发送请求来接收页面上显示的文字。同样是这个套接字也会用来读取\n响应，最后再被销毁。是的，被销毁了。客户端套接字通常用来做一次交换（或者说一小组序列的\n交换）。\n网络服务器发生了什么这个问题就有点复杂了。首页，服务器创建一个「服务端套接字」: |  |  |  |  |\n| --- | --- | --- | --- | --- | --- | --- |\n|  |  | # 创建一个 INET, STREAM 套接字\nserversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n# 将套接字绑定到一个全局的主机和知名的端口\nserversocket.bind((socket.gethostname(), 80))\n# 成为服务器套接字\nserversocket.listen(5) |  |  |  |  |\n|  |  | 有几件事需要注意：我们使用了 socket.gethostname()，所以套接字将外网可见。如果我们使用\n的是 s.bind(('localhost', 80)) 或者 s.bind(('127.0.0.1', 80))，也会得到一个「服务端」\n套接字，但是后者只在同一机器上可见。s.bind(('', 80)) 则指定套接字可以被机器上的任何地\n址碰巧连接\n第二个需要注点是：低端口号通常被一些「常用的」服务（HTTP, SNMP 等）所保留。如果你想把程\n序跑起来，最好使用一个高位端口号（通常是4位的数字）。\n最后，listen 方法的参数会告诉套接字库，我们希望在队列中累积多达 5 个（通常的最大值）连接\n请求后再拒绝外部连接。 如果所有其他代码都准确无误，这个队列长度应该是足够的。\n现在我们已经有一个「服务端」套接字，监听了 80 端口，我们可以进入网络服务器的主循环了: |  |  |  |  |\n|  |  | while True:\n# 接受外来的连接\n(clientsocket, address) = serversocket.accept()\n# 现在使用 clientsocket 执行一些操作\n# 在本场景中，我们假装这是个线程化服务器\nct = make_client_thread(clientsocket)\nct.start() |  |  |  |  |\n|  |  | 事际上，通常有 3 种方法可以让这个循环工作起来 - 调度一个线程来处理 客户端套接字，或者把这\n个应用改成使用非阻塞模式套接字，亦或是使用 select 库来实现「服务端」套接字与任意活动 客\n户端套接字 之间的多路复用。稍后会详细介绍。现在最重要的是理解：这就是一个 服务端 套接字\n做的 所有 事情。它并没有发送任何数据。也没有接收任何数据。它只创建「客户端」套接字。每个\n客户端套接字 都是为了响应某些其它客户端套接字 connect() 到我们绑定的主机。一旦创建 客户\n端套接字 完成，就会返回并监听更多的连接请求。现个客户端可以随意通信 - 它们使用了一些动态\n分配的端口，会话结束时端口才会被回收\n进程间通信\n如果你需要在同一台机器上进行两个进程间的快速 IPC 通信，你应该了解管道或者共享内存。如果\n你决定使用 AF_INET 类型的套接字，绑定「服务端」套接字到 'localhost' 。在大多数平台，这将\n会使用一个许多网络层间的通用快捷方式（本地回环地址）并且速度会快很多 |  |  |  |  |\n|  |  |  |  | 客 |  |  |\n|  |  |  |  |  |  |  |\n|  |  | 户端套接字 |  |  |  |  |\n|  |  |  |  |  |  |  |\n|  |  |  | 客户 |  |  |  |\n|  |  |  |  |  |  |  |\n|  |  | 端套接字 |  |  |  |  |\n|  |  |  |  |  |  |  |\n|  |  | 参见: multiprocessing 模块使跨平台 IPC 通信成为一个高层的 API |  |  |  |  |\n\n使用一个套接字\n首先需要注意，浏览器的「客户端」套接字和网络服务器的「客户端」套接字是极为相似的。即这\n种会话是「点对点」的。或者也可以说 你作为设计师需要自行决定会话的规则和礼节 。通常情况\n下，连接 套接字通过发送一个请求或者信号来开始一次会话。但这属于设计决定，并不是套接字规\n则。\n现在有两组用于通信的动词。你可以使用 send 和 recv ，或者你可以把客户端套接字改成文件类型\n的形式来使用 read 和 write 方法。后者是 Java 语言中表示套接字的方法，我将不会在这儿讨论这\n个，但是要提醒你需要调用套接字的 flush 方法。这些是“缓冲”的文件，一个经常出现的错误是\nwrite 一些东西，然后就直接开始 read 一个响应。如果不调用 flush ，你可能会一直等待这个响\n应，因为请求可能还在你的输出缓冲中。\n现在我来到了套接字的两个主要的绊脚石 - send 和 recv 操作网络缓冲区。它们并不一定可以处理\n所有你想要（期望）的字节，因为它们主要关注点是处理网络缓冲。通常，它们在关联的网络缓冲\n区 send 或者清空 recv 时返回。然后告诉你处理了多少个字节。你 的责任是一直调用它们直到你\n所有的消息处理完成。\n当 recv 方法返回 0 字节时，就表示另一端已经关闭（或者它所在的进程关闭）了连接。你再也不\n能从这个连接上获取到任何数据了。你可以成功的发送数据；我将在后面讨论这一点。\n像 HTTP 这样的协议只使用一个套接字进行一次传输。客户端发送一个请求，然后读取响应。就这\n么简单。套接字会被销毁。 表示客户端可以通过接收 0 字节序列表示检测到响应的结束。\n但是如果你打算在随后来的传输中复用套接字的话，你需要明白 套接字里面是不存在 :abbr:`EOT (传\n输结束)` 的。重复一下：套接字 send 或者 recv 完 0 字节后返回，连接会中断。如果连接没有被断\n开，你可能会永远处于等待 recv 的状态，因为（就目前来说）套接字 不会 告诉你不用再读取了。\n现在如果你细心一点，你可能会意识到套接字基本事实：消息必须要么具有固定长度，要么可以界\n定，要么指定了长度（比较好的做法），要么以关闭连接为结束。选择完全由你而定（这比让别人\n定更合理）。\n假定你不希望结束连接，那么最简单的解决方案就是使用定长消息:\nclass MySocket:\n\"\"\"仅用于演示的类\n- 代码保证清析，不保证效率\n\"\"\"\ndef __init__(self, sock=None):\nif sock is None:\nself.sock = socket.socket(\nsocket.AF_INET, socket.SOCK_STREAM)\nelse:\nself.sock = sock\ndef connect(self, host, port):\nself.sock.connect((host, port))\ndef mysend(self, msg):\n\n|  |  |  |\n| --- | --- | --- |\n|  | 使用一个套接字\n首先需要注意，浏览器的「客户端」套接字和网络服务器的「客户端」套接字是极为相似的。即这\n种会话是「点对点」的。或者也可以说 你作为设计师需要自行决定会话的规则和礼节 。通常情况\n下，连接 套接字通过发送一个请求或者信号来开始一次会话。但这属于设计决定，并不是套接字规\n则。\n现在有两组用于通信的动词。你可以使用 send 和 recv ，或者你可以把客户端套接字改成文件类型\n的形式来使用 read 和 write 方法。后者是 Java 语言中表示套接字的方法，我将不会在这儿讨论这\n个，但是要提醒你需要调用套接字的 flush 方法。这些是“缓冲”的文件，一个经常出现的错误是\nwrite 一些东西，然后就直接开始 read 一个响应。如果不调用 flush ，你可能会一直等待这个响\n应，因为请求可能还在你的输出缓冲中。\n现在我来到了套接字的两个主要的绊脚石 - send 和 recv 操作网络缓冲区。它们并不一定可以处理\n所有你想要（期望）的字节，因为它们主要关注点是处理网络缓冲。通常，它们在关联的网络缓冲\n区 send 或者清空 recv 时返回。然后告诉你处理了多少个字节。你 的责任是一直调用它们直到你\n所有的消息处理完成。\n当 recv 方法返回 0 字节时，就表示另一端已经关闭（或者它所在的进程关闭）了连接。你再也不\n能从这个连接上获取到任何数据了。你可以成功的发送数据；我将在后面讨论这一点。\n像 HTTP 这样的协议只使用一个套接字进行一次传输。客户端发送一个请求，然后读取响应。就这\n么简单。套接字会被销毁。 表示客户端可以通过接收 0 字节序列表示检测到响应的结束。\n但是如果你打算在随后来的传输中复用套接字的话，你需要明白 套接字里面是不存在 :abbr:`EOT (传\n输结束)` 的。重复一下：套接字 send 或者 recv 完 0 字节后返回，连接会中断。如果连接没有被断\n开，你可能会永远处于等待 recv 的状态，因为（就目前来说）套接字 不会 告诉你不用再读取了。\n现在如果你细心一点，你可能会意识到套接字基本事实：消息必须要么具有固定长度，要么可以界\n定，要么指定了长度（比较好的做法），要么以关闭连接为结束。选择完全由你而定（这比让别人\n定更合理）。\n假定你不希望结束连接，那么最简单的解决方案就是使用定长消息: |  |\n|  | class MySocket:\n\"\"\"仅用于演示的类\n- 代码保证清析，不保证效率\n\"\"\"\ndef __init__(self, sock=None):\nif sock is None:\nself.sock = socket.socket(\nsocket.AF_INET, socket.SOCK_STREAM)\nelse:\nself.sock = sock\ndef connect(self, host, port):\nself.sock.connect((host, port))\ndef mysend(self, msg): |  |\n\ntotalsent = 0\nwhile totalsent < MSGLEN:\nsent = self.sock.send(msg[totalsent:])\nif sent == 0:\nraise RuntimeError(\"socket connection broken\")\ntotalsent = totalsent + sent\ndef myreceive(self):\nchunks = []\nbytes_recd = 0\nwhile bytes_recd < MSGLEN:\nchunk = self.sock.recv(min(MSGLEN - bytes_recd, 2048))\nif chunk == b'':\nraise RuntimeError(\"socket connection broken\")\nchunks.append(chunk)\nbytes_recd = bytes_recd + len(chunk)\nreturn b''.join(chunks)\n发送分部代码几乎可用于任何消息传递方案 —— 在 Python 中你发送字符串，可以使用 len() 方法\n来确定它的长度（即使它嵌入了 \\0 字符），主要是接收代码变得更复杂。（在 C 语言中，并没有\n更糟糕，除非消息嵌入了 \\0 字符而且你又无法使用 strlen ）\n最简单的改进是让消息的第一个字符表示消息类型，由类型决定长度。现在你需要两次 recv- 第一\n次取（至少）第一个字符来知晓长度，第二次在循环中获取剩余所有的消息。如果你决定到分界\n线，你将收到一些任意大小的块，（4096 或者 8192 通常是比较合适的网络缓冲区大小），扫描你\n接收到的分界符\n一个需要意识到的复杂情况是：如果你的会话协议允许多个消息被发送回来（没有响应），调用\nrecv 传入任意大小的块，你可能会因为读到后续接收的消息而停止读取。你需要将它放在一边并保\n存，直到它需要为止。\n以其长度（例如，作为5个数字字符）作为消息前缀时会变得更复杂，因为（信不信由你）你可能无\n法在一个 recv 中获得所有5个字符。在一般使用时，你会侥幸避免该状况；但是在高网络负载中，\n除非你使用两个 recv 循环，否则你的代码将很快中断 —— 第一个用于确定长度，第二个用于获取\n消息的数据部分。这很讨厌。当你发现 send 并不总是设法在支持搞定一切时，你也会有这种感觉。\n尽管已经阅读过这篇文章，但最终还是会有所了解！\n限于篇幅，建立你的角色，（保持与我的竞争位置），这些改进将留给读者做为练习。现在让我们\n继续。\n二进制数据\n通过套接字发送二进制数据是完全可能的。主要问题是，并非所有机器都使用相同的二进制数据格\n式。例如，网络字节顺序 是大端序的，最大的字节在前，所以一个值为 1 的16位整数将是两个十六\n进制字节 00 01 。然而，大多数常见的处理器（ x86 / AMD64 ，ARM，RISC-V）是小端序的，最\n小的字节在前 -- 同样的 1 将是 01 00 。\nSocket 库有转换 16 位和 32 位整数的调用 - ntohl, htonl, ntohs, htons ，其中 \"n\" 表示 网络\n， \"h\" 表示 主机 ， \"s\" 表示 short ， \"l\" 表示 long 。当网络顺序与主机顺序相同时，这些调用不做\n任何事情，但当机器的字节序相反时，这些调用会适当地交换字节。\n\n|  | totalsent = 0\nwhile totalsent < MSGLEN:\nsent = self.sock.send(msg[totalsent:])\nif sent == 0:\nraise RuntimeError(\"socket connection broken\")\ntotalsent = totalsent + sent\ndef myreceive(self):\nchunks = []\nbytes_recd = 0\nwhile bytes_recd < MSGLEN:\nchunk = self.sock.recv(min(MSGLEN - bytes_recd, 2048))\nif chunk == b'':\nraise RuntimeError(\"socket connection broken\")\nchunks.append(chunk)\nbytes_recd = bytes_recd + len(chunk)\nreturn b''.join(chunks) |  |\n| --- | --- | --- |\n|  | 发送分部代码几乎可用于任何消息传递方案 —— 在 Python 中你发送字符串，可以使用 len() 方法\n来确定它的长度（即使它嵌入了 \\0 字符），主要是接收代码变得更复杂。（在 C 语言中，并没有\n更糟糕，除非消息嵌入了 \\0 字符而且你又无法使用 strlen ）\n最简单的改进是让消息的第一个字符表示消息类型，由类型决定长度。现在你需要两次 recv- 第一\n次取（至少）第一个字符来知晓长度，第二次在循环中获取剩余所有的消息。如果你决定到分界\n线，你将收到一些任意大小的块，（4096 或者 8192 通常是比较合适的网络缓冲区大小），扫描你\n接收到的分界符\n一个需要意识到的复杂情况是：如果你的会话协议允许多个消息被发送回来（没有响应），调用\nrecv 传入任意大小的块，你可能会因为读到后续接收的消息而停止读取。你需要将它放在一边并保\n存，直到它需要为止。\n以其长度（例如，作为5个数字字符）作为消息前缀时会变得更复杂，因为（信不信由你）你可能无\n法在一个 recv 中获得所有5个字符。在一般使用时，你会侥幸避免该状况；但是在高网络负载中，\n除非你使用两个 recv 循环，否则你的代码将很快中断 —— 第一个用于确定长度，第二个用于获取\n消息的数据部分。这很讨厌。当你发现 send 并不总是设法在支持搞定一切时，你也会有这种感觉。\n尽管已经阅读过这篇文章，但最终还是会有所了解！\n限于篇幅，建立你的角色，（保持与我的竞争位置），这些改进将留给读者做为练习。现在让我们\n继续。\n二进制数据\n通过套接字发送二进制数据是完全可能的。主要问题是，并非所有机器都使用相同的二进制数据格\n式。例如，网络字节顺序 是大端序的，最大的字节在前，所以一个值为 1 的16位整数将是两个十六\n进制字节 00 01 。然而，大多数常见的处理器（ x86 / AMD64 ，ARM，RISC-V）是小端序的，最\n小的字节在前 -- 同样的 1 将是 01 00 。\nSocket 库有转换 16 位和 32 位整数的调用 - ntohl, htonl, ntohs, htons ，其中 \"n\" 表示 网络\n， \"h\" 表示 主机 ， \"s\" 表示 short ， \"l\" 表示 long 。当网络顺序与主机顺序相同时，这些调用不做\n任何事情，但当机器的字节序相反时，这些调用会适当地交换字节。 |  |\n\n在现今的 64 位机器中，二进制数据的 ASCII 表示往往比二进制表示要小。这是因为在非常多的时候\n所大部分整数的值均为 0 或者 1。字符串形式的 \"0\" 为两个字节，而一个完整的 64 位整数将是八\n个。当然这不适用于固定长度的信息。自行决定，请自行决定。\n断开连接\n严格地讲，你应该在 close 它之前将套接字 shutdown 。 shutdown 是发送给套接字另一端的一种\n建议。调用时参数不同意义也不一样，它可能意味着「我不会再发送了，但我仍然会监听」，或者\n「我没有监听了，真棒！」。然而，大多数套接字库或者程序员都习惯了忽略使用这种礼节，因为\n通常情况下 close 与 shutdown(); close() 是一样的。所以在大多数情况下，不需要显式的\nshutdown 。\n高效使用 shutdown 的一种方法是在类似 HTTP 的交换中。客户端发送请求，然后执行\nshutdown(1) 。 这告诉服务器“此客户端已完成发送，但仍可以接收”。服务器可以通过接收 0 字节\n来检测 “EOF” 。它可以假设它有完整的请求。服务器发送回复。如果 send 成功完成，那么客户端\n仍在接收。\nPython 进一步自动关闭，并说当一个套接字被垃圾收集时，如果需要它会自动执行 close 。但依靠\n这个机制是一个非常坏的习惯。如果你的套接字在没有 close 的情况下就消失了，那么另一端的套\n接字可能会无限期地挂起，以为你只是慢了一步。完成后 请 close 你的套接字。\n套接字何时销毁\n使用阻塞套接字最糟糕的事情可能就是当另一边下线时（没有 close ）会发生什么。你的套接字可\n能会挂起。 TCP 是一种可靠的协议，它会在放弃连接之前等待很长时间。如果你正在使用线程，那\n么整个线程基本上已经死了。你无能为力。只要你没有做一些愚蠢的事情，比如在进行阻塞读取时\n持有一个锁，那么线程并没有真正消耗掉资源。 不要 尝试杀死线程 —— 线程比进程更有效的部分\n原因是它们避免了与自动回收资源相关的开销。换句话说，如果你设法杀死线程，你的整个进程很\n可能被搞坏。\n非阻塞的套接字\n如果你已理解上述内容，那么你已经了解了使用套接字的机制所需了解的大部分内容。你仍将以相\n同的方式使用相同的函数调用。 只是，如果你做得对，你的应用程序几乎是由内到外的。\n在 Python 中是使用 socket.setblocking(False) 来设置非阻塞。 在 C 中的做法更为复杂（例\n如，你需要在 BSD 风格的 O_NONBLOCK 和几乎无区别的 POSIX 风格的 O_NDELAY 之间作出选择，这\n与 TCP_NODELAY 完全不一样），但其思路实际上是相同的。 你要在创建套接字之后但在使用它之前\n执行此操作。 （实际上，如果你是疯子的话也可以反复进行切换。）\n主要的机制差异是 send 、 recv 、 connect 和 accept 可以在没有做任何事情的情况下返回。 你\n（当然）有很多选择。你可以检查返回代码和错误代码，通常会让自己发疯。如果你不相信我，请\n尝试一下。你的应用程序将变得越来越大、越来越 Bug 、吸干 CPU。因此，让我们跳过脑死亡的解\n决方案并做正确的事。\n使用 select 库\n\n|  | 在现今的 64 位机器中，二进制数据的 ASCII 表示往往比二进制表示要小。这是因为在非常多的时候\n所大部分整数的值均为 0 或者 1。字符串形式的 \"0\" 为两个字节，而一个完整的 64 位整数将是八\n个。当然这不适用于固定长度的信息。自行决定，请自行决定。\n断开连接\n严格地讲，你应该在 close 它之前将套接字 shutdown 。 shutdown 是发送给套接字另一端的一种\n建议。调用时参数不同意义也不一样，它可能意味着「我不会再发送了，但我仍然会监听」，或者\n「我没有监听了，真棒！」。然而，大多数套接字库或者程序员都习惯了忽略使用这种礼节，因为\n通常情况下 close 与 shutdown(); close() 是一样的。所以在大多数情况下，不需要显式的\nshutdown 。\n高效使用 shutdown 的一种方法是在类似 HTTP 的交换中。客户端发送请求，然后执行\nshutdown(1) 。 这告诉服务器“此客户端已完成发送，但仍可以接收”。服务器可以通过接收 0 字节\n来检测 “EOF” 。它可以假设它有完整的请求。服务器发送回复。如果 send 成功完成，那么客户端\n仍在接收。\nPython 进一步自动关闭，并说当一个套接字被垃圾收集时，如果需要它会自动执行 close 。但依靠\n这个机制是一个非常坏的习惯。如果你的套接字在没有 close 的情况下就消失了，那么另一端的套\n接字可能会无限期地挂起，以为你只是慢了一步。完成后 请 close 你的套接字。\n套接字何时销毁\n使用阻塞套接字最糟糕的事情可能就是当另一边下线时（没有 close ）会发生什么。你的套接字可\n能会挂起。 TCP 是一种可靠的协议，它会在放弃连接之前等待很长时间。如果你正在使用线程，那\n么整个线程基本上已经死了。你无能为力。只要你没有做一些愚蠢的事情，比如在进行阻塞读取时\n持有一个锁，那么线程并没有真正消耗掉资源。 不要 尝试杀死线程 —— 线程比进程更有效的部分\n原因是它们避免了与自动回收资源相关的开销。换句话说，如果你设法杀死线程，你的整个进程很\n可能被搞坏。\n非阻塞的套接字\n如果你已理解上述内容，那么你已经了解了使用套接字的机制所需了解的大部分内容。你仍将以相\n同的方式使用相同的函数调用。 只是，如果你做得对，你的应用程序几乎是由内到外的。\n在 Python 中是使用 socket.setblocking(False) 来设置非阻塞。 在 C 中的做法更为复杂（例\n如，你需要在 BSD 风格的 O_NONBLOCK 和几乎无区别的 POSIX 风格的 O_NDELAY 之间作出选择，这\n与 TCP_NODELAY 完全不一样），但其思路实际上是相同的。 你要在创建套接字之后但在使用它之前\n执行此操作。 （实际上，如果你是疯子的话也可以反复进行切换。）\n主要的机制差异是 send 、 recv 、 connect 和 accept 可以在没有做任何事情的情况下返回。 你\n（当然）有很多选择。你可以检查返回代码和错误代码，通常会让自己发疯。如果你不相信我，请\n尝试一下。你的应用程序将变得越来越大、越来越 Bug 、吸干 CPU。因此，让我们跳过脑死亡的解\n决方案并做正确的事。\n使用 select 库 |  |\n| --- | --- | --- |\n\n在 C 中，编码 select 相当复杂。 在 Python 中，它是很简单，但它与 C 版本足够接近，如果你在\nPython 中理解 select ，那么在 C 中你会几乎不会遇到麻烦:\nready_to_read, ready_to_write, in_error = \\\nselect.select(\npotential_readers,\npotential_writers,\npotential_errs,\ntimeout)\n你传递给 select 三个列表：第一个包含你可能想要尝试读取的所有套接字；第二个是你可能想要\n尝试写入的所有套接字，以及要检查错误的最后一个（通常为空）。你应该注意，套接字可以进入\n多个列表。 select 调用是阻塞的，但你可以给它一个超时。这通常是一件明智的事情 —— 给它一\n个很长的超时（比如一分钟），除非你有充分的理由不这样做。\n作为返回，你将获得三个列表。它们包含实际可读、可写和有错误的套接字。 这些列表中的每一个\n都是你传入的相应列表的子集（可能为空）。\n如果一个套接字在输出可读列表中，那么你可以像我们一样接近这个业务，那个套接字上的 recv 将\n返回 一些内容 。可写列表的也相同，你将能够发送 一些内容 。 也许不是你想要的全部，但 有些东\n西 比没有东西更好。 （实际上，任何合理健康的套接字都将以可写方式返回 —— 它只是意味着出\n站网络缓冲区空间可用。）\n如果你有一个“服务器”套接字，请将其放在 potential_readers 列表中。如果它出现在可读列表中，\n那么你的 accept （几乎肯定）会起作用。如果你已经创建了一个新的套接字 connect 其他人，请\n将它放在 potential_writers 列表中。如果它出现在可写列表中，那么它有可能已连接。\n实际上，即使使用阻塞套接字， select 也很方便。这是确定是否阻塞的一种方法 —— 当缓冲区中\n存在某些内容时，套接字返回为可读。然而，这仍然无助于确定另一端是否完成或者只是忙于其他\n事情的问题。\n可移植性警告 ：在 Unix 上， select 适用于套接字和文件。 不要在 Windows 上尝试。在\nWindows 上， select 仅适用于套接字。另请注意，在 C 中，许多更高级的套接字选项在 Windows\n上的执行方式不同。事实上，在 Windows 上我通常在使用我的套接字使用线程（非常非常好）。\n\n| 在 C 中，编码 select 相当复杂。 在 Python 中，它是很简单，但它与 C 版本足够接近，如果你在\nPython 中理解 select ，那么在 C 中你会几乎不会遇到麻烦: |\n| --- |\n| ready_to_read, ready_to_write, in_error = \\\nselect.select(\npotential_readers,\npotential_writers,\npotential_errs,\ntimeout) |\n| 你传递给 select 三个列表：第一个包含你可能想要尝试读取的所有套接字；第二个是你可能想要\n尝试写入的所有套接字，以及要检查错误的最后一个（通常为空）。你应该注意，套接字可以进入\n多个列表。 select 调用是阻塞的，但你可以给它一个超时。这通常是一件明智的事情 —— 给它一\n个很长的超时（比如一分钟），除非你有充分的理由不这样做。\n作为返回，你将获得三个列表。它们包含实际可读、可写和有错误的套接字。 这些列表中的每一个\n都是你传入的相应列表的子集（可能为空）。\n如果一个套接字在输出可读列表中，那么你可以像我们一样接近这个业务，那个套接字上的 recv 将\n返回 一些内容 。可写列表的也相同，你将能够发送 一些内容 。 也许不是你想要的全部，但 有些东\n西 比没有东西更好。 （实际上，任何合理健康的套接字都将以可写方式返回 —— 它只是意味着出\n站网络缓冲区空间可用。）\n如果你有一个“服务器”套接字，请将其放在 potential_readers 列表中。如果它出现在可读列表中，\n那么你的 accept （几乎肯定）会起作用。如果你已经创建了一个新的套接字 connect 其他人，请\n将它放在 potential_writers 列表中。如果它出现在可写列表中，那么它有可能已连接。\n实际上，即使使用阻塞套接字， select 也很方便。这是确定是否阻塞的一种方法 —— 当缓冲区中\n存在某些内容时，套接字返回为可读。然而，这仍然无助于确定另一端是否完成或者只是忙于其他\n事情的问题。\n可移植性警告 ：在 Unix 上， select 适用于套接字和文件。 不要在 Windows 上尝试。在\nWindows 上， select 仅适用于套接字。另请注意，在 C 中，许多更高级的套接字选项在 Windows\n上的执行方式不同。事实上，在 Windows 上我通常在使用我的套接字使用线程（非常非常好）。 |", "metadata": {"title": "19_套接字编程指南", "source": "md_docs\\python_howto_md\\19_套接字编程指南.md", "doc_type": "指南", "language": "中文", "doc_id": "c2d28163"}}
{"doc_id": "b5306562", "content": "定时器文件描述符指南\n发布版本: 1.13\n本指南讨论了 Python 对 linux 定时器文件描述符的支持。\n例子\n下面的例子演示了如何使用定时器文件描述符每秒钟执行两次某个函数：\n# 真正实用的脚本应当使用非阻塞型定时器，\n# 这里我们使用阻塞型定时器是出于简单化考虑。\nimport os, time\n# 创建定时器文件描述符\nfd = os.timerfd_create(time.CLOCK_REALTIME)\n# 在 1 秒种时启动定时器，间隔时间为半秒\nos.timerfd_settime(fd, initial=1, interval=0.5)\ntry:\n# 处理定时器事件四次。\nfor _ in range(4):\n# read() 将会阻塞直到定时器过期\n_ = os.read(fd, 8)\nprint(\"Timer expired\")\nfinally:\n# 记住要关闭定时器文件描述符！\nos.close(fd)\n为避免 float 类型导致的精度损失，定时器文件描述符允许使用这些函数的 _ns 变种形式以整数纳\n秒值指定初始到期时间和间隔。\n这个例子演示了如何使用 epoll() 配合定时器文件描述符来执行等待直到文件描述符准备好读取：\nimport os, time, select, socket, sys\n# 创建一个轮询对象\nep = select.epoll()\n# 在本例中，使用回环地址向服务器发送 \"stop\" 命令。\n#\n# $ telnet 127.0.0.1 1234\n# Trying 127.0.0.1...\n# Connected to 127.0.0.1.\n# Escape character is '^]'.\n# stop\n# Connection closed by foreign host.\n#\nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nsock.bind((\"127.0.0.1\", 1234))\n\n| 定时器文件描述符指南\n发布版本: 1.13\n本指南讨论了 Python 对 linux 定时器文件描述符的支持。\n例子\n下面的例子演示了如何使用定时器文件描述符每秒钟执行两次某个函数：\n# 真正实用的脚本应当使用非阻塞型定时器，\n# 这里我们使用阻塞型定时器是出于简单化考虑。\nimport os, time\n# 创建定时器文件描述符\nfd = os.timerfd_create(time.CLOCK_REALTIME)\n# 在 1 秒种时启动定时器，间隔时间为半秒\nos.timerfd_settime(fd, initial=1, interval=0.5)\ntry:\n# 处理定时器事件四次。\nfor _ in range(4):\n# read() 将会阻塞直到定时器过期\n_ = os.read(fd, 8)\nprint(\"Timer expired\")\nfinally:\n# 记住要关闭定时器文件描述符！\nos.close(fd)\n为避免 float 类型导致的精度损失，定时器文件描述符允许使用这些函数的 _ns 变种形式以整数纳\n秒值指定初始到期时间和间隔。\n这个例子演示了如何使用 epoll() 配合定时器文件描述符来执行等待直到文件描述符准备好读取：\nimport os, time, select, socket, sys\n# 创建一个轮询对象\nep = select.epoll()\n# 在本例中，使用回环地址向服务器发送 \"stop\" 命令。\n#\n# $ telnet 127.0.0.1 1234\n# Trying 127.0.0.1...\n# Connected to 127.0.0.1.\n# Escape character is '^]'.\n# stop\n# Connection closed by foreign host.\n#\nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nsock.bind((\"127.0.0.1\", 1234)) |  |  |\n| --- | --- | --- |\n|  | 定时器文件描述符指南\n发布版本: 1.13\n本指南讨论了 Python 对 linux 定时器文件描述符的支持。\n例子\n下面的例子演示了如何使用定时器文件描述符每秒钟执行两次某个函数： |  |\n|  | # 真正实用的脚本应当使用非阻塞型定时器，\n# 这里我们使用阻塞型定时器是出于简单化考虑。\nimport os, time\n# 创建定时器文件描述符\nfd = os.timerfd_create(time.CLOCK_REALTIME)\n# 在 1 秒种时启动定时器，间隔时间为半秒\nos.timerfd_settime(fd, initial=1, interval=0.5)\ntry:\n# 处理定时器事件四次。\nfor _ in range(4):\n# read() 将会阻塞直到定时器过期\n_ = os.read(fd, 8)\nprint(\"Timer expired\")\nfinally:\n# 记住要关闭定时器文件描述符！\nos.close(fd) |  |\n|  | 为避免 float 类型导致的精度损失，定时器文件描述符允许使用这些函数的 _ns 变种形式以整数纳\n秒值指定初始到期时间和间隔。\n这个例子演示了如何使用 epoll() 配合定时器文件描述符来执行等待直到文件描述符准备好读取： |  |\n|  | import os, time, select, socket, sys\n# 创建一个轮询对象\nep = select.epoll()\n# 在本例中，使用回环地址向服务器发送 \"stop\" 命令。\n#\n# $ telnet 127.0.0.1 1234\n# Trying 127.0.0.1...\n# Connected to 127.0.0.1.\n# Escape character is '^]'.\n# stop\n# Connection closed by foreign host.\n#\nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nsock.bind((\"127.0.0.1\", 1234)) |  |\n|  |  |  |\n\nsock.setblocking(False)\nsock.listen(1)\nep.register(sock, select.EPOLLIN)\n# 以非阻塞模式创建定时器文件描述符。\nnum = 3\nfds = []\nfor _ in range(num):\nfd = os.timerfd_create(time.CLOCK_REALTIME, flags=os.TFD_NONBLOCK)\nfds.append(fd)\n# 注册定时器文件描述符用于读取事件\nep.register(fd, select.EPOLLIN)\n# 以纳秒精度的 os.timerfd_settime_ns() 启动定时器。\n# 定时器 1 间隔为 0.25 秒；定时器 2 间隔为 0.5 秒；依此类推\nfor i, fd in enumerate(fds, start=1):\none_sec_in_nsec = 10**9\ni = i * one_sec_in_nsec\nos.timerfd_settime_ns(fd, initial=i//4, interval=i//4)\ntimeout = 3\ntry:\nconn = None\nis_active = True\nwhile is_active:\n# 等待定时器 3 秒到期。\n# epoll.poll() 返回一个 (fd, event) 对的列表。\n# fd 是一个文件描述符。\n# sock 和 conn[=socket.accept() 的返回值] 是套接字对象，而不是文件描述符。\n# 因此使用 sock.fileno() 和 conn.fileno() 来获取文件描述符。\nevents = ep.poll(timeout)\n# 如果同时有多个定时器文件描述符准备读取，\n# epoll.poll() 将返回一个 (fd, event) 对的列表。\n#\n# 在本例的设置中，\n# 第 1 个定时器在 0.25 秒后间隔 0.25 秒启动。 (0.25, 0.5, 0.75, 1.0, ...)\n# 第 2 个定时器在 0.5 秒后间隔 0.5 秒启动。 (0.5, 1.0, 1.5, 2.0, ...)\n# 第 3 个定时器在 0.75 秒后间隔 0.75 秒启动。 (0.75, 1.5, 2.25, 3.0, ...)\n#\n# 在 0.25 秒时，只有第 1 个定时器启动。\n# 在 0.5 秒时，第 1 个定时器和第 2 个定时器同时启动。\n# 在 0.75 秒时，第 1 个定时器和第 3 个定时器同时启动。\n# 在 1.5 秒时，第 1 个定时器、第 2 个定时器和第 3 个定时器同时启动。\n#\n# 如果一个定时器文件描述符自上次 os.read() 调用后\n# 多次发出信号，os.read() 将以主机的类字节顺序\n# 返回发出信号的次数。\nprint(f\"Signaled events={events}\")\nfor fd, event in events:\nif event & select.EPOLLIN:\nif fd == sock.fileno():\n# 检查是否有连接请求。\nprint(f\"Accepting connection {fd}\")\nconn, addr = sock.accept()\nconn.setblocking(False)\nprint(f\"Accepted connection {conn} from {addr}\")\nep.register(conn, select.EPOLLIN)\nelif conn and fd == conn.fileno():\n# 检查是否有数据要读取。\n\n|  | sock.setblocking(False)\nsock.listen(1)\nep.register(sock, select.EPOLLIN)\n# 以非阻塞模式创建定时器文件描述符。\nnum = 3\nfds = []\nfor _ in range(num):\nfd = os.timerfd_create(time.CLOCK_REALTIME, flags=os.TFD_NONBLOCK)\nfds.append(fd)\n# 注册定时器文件描述符用于读取事件\nep.register(fd, select.EPOLLIN)\n# 以纳秒精度的 os.timerfd_settime_ns() 启动定时器。\n# 定时器 1 间隔为 0.25 秒；定时器 2 间隔为 0.5 秒；依此类推\nfor i, fd in enumerate(fds, start=1):\none_sec_in_nsec = 10**9\ni = i * one_sec_in_nsec\nos.timerfd_settime_ns(fd, initial=i//4, interval=i//4)\ntimeout = 3\ntry:\nconn = None\nis_active = True\nwhile is_active:\n# 等待定时器 3 秒到期。\n# epoll.poll() 返回一个 (fd, event) 对的列表。\n# fd 是一个文件描述符。\n# sock 和 conn[=socket.accept() 的返回值] 是套接字对象，而不是文件描述符。\n# 因此使用 sock.fileno() 和 conn.fileno() 来获取文件描述符。\nevents = ep.poll(timeout)\n# 如果同时有多个定时器文件描述符准备读取，\n# epoll.poll() 将返回一个 (fd, event) 对的列表。\n#\n# 在本例的设置中，\n# 第 1 个定时器在 0.25 秒后间隔 0.25 秒启动。 (0.25, 0.5, 0.75, 1.0, ...\n# 第 2 个定时器在 0.5 秒后间隔 0.5 秒启动。 (0.5, 1.0, 1.5, 2.0, ...)\n# 第 3 个定时器在 0.75 秒后间隔 0.75 秒启动。 (0.75, 1.5, 2.25, 3.0, ...\n#\n# 在 0.25 秒时，只有第 1 个定时器启动。\n# 在 0.5 秒时，第 1 个定时器和第 2 个定时器同时启动。\n# 在 0.75 秒时，第 1 个定时器和第 3 个定时器同时启动。\n# 在 1.5 秒时，第 1 个定时器、第 2 个定时器和第 3 个定时器同时启动。\n#\n# 如果一个定时器文件描述符自上次 os.read() 调用后\n# 多次发出信号，os.read() 将以主机的类字节顺序\n# 返回发出信号的次数。\nprint(f\"Signaled events={events}\")\nfor fd, event in events:\nif event & select.EPOLLIN:\nif fd == sock.fileno():\n# 检查是否有连接请求。\nprint(f\"Accepting connection {fd}\")\nconn, addr = sock.accept()\nconn.setblocking(False)\nprint(f\"Accepted connection {conn} from {addr}\")\nep.register(conn, select.EPOLLIN)\nelif conn and fd == conn.fileno():\n# 检查是否有数据要读取。 | )\n) |\n| --- | --- | --- |\n|  |  |  |\n\nprint(f\"Reading data {fd}\")\ndata = conn.recv(1024)\nif data:\n# 安全起见你应当捕获 UnicodeDecodeError 异常。\ncmd = data.decode()\nif cmd.startswith(\"stop\"):\nprint(f\"Stopping server\")\nis_active = False\nelse:\nprint(f\"Unknown command: {cmd}\")\nelse:\n# 已无数据，关闭连接\nprint(f\"Closing connection {fd}\")\nep.unregister(conn)\nconn.close()\nconn = None\nelif fd in fds:\nprint(f\"Reading timer {fd}\")\ncount = int.from_bytes(os.read(fd, 8), byteorder=sys.byteorder\nprint(f\"Timer {fds.index(fd) + 1} expired {count} times\")\nelse:\nprint(f\"Unknown file descriptor {fd}\")\nfinally:\nfor fd in fds:\nep.unregister(fd)\nos.close(fd)\nep.close()\n这个例子演示了如何使用 select() 配合定时器文件描述符来执行等待直接文件描述符准备好读\n取：\nimport os, time, select, socket, sys\n# 在本例中，使用回环地址向服务器发送 \"stop\" 命令。\n#\n# $ telnet 127.0.0.1 1234\n# Trying 127.0.0.1...\n# Connected to 127.0.0.1.\n# Escape character is '^]'.\n# stop\n# Connection closed by foreign host.\n#\nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nsock.bind((\"127.0.0.1\", 1234))\nsock.setblocking(False)\nsock.listen(1)\n# 以非阻塞模式创建定时器文件描述符。\nnum = 3\nfds = [os.timerfd_create(time.CLOCK_REALTIME, flags=os.TFD_NONBLOCK)\nfor _ in range(num)]\nselect_fds = fds + [sock]\n# 使用 os.timerfd_settime() 启动指定秒数的定时器。\n# 定时器 1 间隔为 0.25 秒；定时器 2 间隔为 0.5 秒；依此类推\nfor i, fd in enumerate(fds, start=1):\nos.timerfd_settime(fd, initial=i/4, interval=i/4)\n\n|  | print(f\"Reading data {fd}\")\ndata = conn.recv(1024)\nif data:\n# 安全起见你应当捕获 UnicodeDecodeError 异常。\ncmd = data.decode()\nif cmd.startswith(\"stop\"):\nprint(f\"Stopping server\")\nis_active = False\nelse:\nprint(f\"Unknown command: {cmd}\")\nelse:\n# 已无数据，关闭连接\nprint(f\"Closing connection {fd}\")\nep.unregister(conn)\nconn.close()\nconn = None\nelif fd in fds:\nprint(f\"Reading timer {fd}\")\ncount = int.from_bytes(os.read(fd, 8), byteorder=sys.byteorder\nprint(f\"Timer {fds.index(fd) + 1} expired {count} times\")\nelse:\nprint(f\"Unknown file descriptor {fd}\")\nfinally:\nfor fd in fds:\nep.unregister(fd)\nos.close(fd)\nep.close() |  |\n| --- | --- | --- |\n|  | 这个例子演示了如何使用 select() 配合定时器文件描述符来执行等待直接文件描述符准备好读\n取： |  |\n|  | import os, time, select, socket, sys\n# 在本例中，使用回环地址向服务器发送 \"stop\" 命令。\n#\n# $ telnet 127.0.0.1 1234\n# Trying 127.0.0.1...\n# Connected to 127.0.0.1.\n# Escape character is '^]'.\n# stop\n# Connection closed by foreign host.\n#\nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nsock.bind((\"127.0.0.1\", 1234))\nsock.setblocking(False)\nsock.listen(1)\n# 以非阻塞模式创建定时器文件描述符。\nnum = 3\nfds = [os.timerfd_create(time.CLOCK_REALTIME, flags=os.TFD_NONBLOCK)\nfor _ in range(num)]\nselect_fds = fds + [sock]\n# 使用 os.timerfd_settime() 启动指定秒数的定时器。\n# 定时器 1 间隔为 0.25 秒；定时器 2 间隔为 0.5 秒；依此类推\nfor i, fd in enumerate(fds, start=1):\nos.timerfd_settime(fd, initial=i/4, interval=i/4) |  |\n|  |  |  |\n\ntimeout = 3\ntry:\nconn = None\nis_active = True\nwhile is_active:\n# 等待定时器 3 秒到期。\n# select.select() 返回一个文件描述符或对象的列表。\nrfd, wfd, xfd = select.select(select_fds, select_fds, select_fds, timeout)\nfor fd in rfd:\nif fd == sock:\n# 检查是否有连接请求。\nprint(f\"Accepting connection {fd}\")\nconn, addr = sock.accept()\nconn.setblocking(False)\nprint(f\"Accepted connection {conn} from {addr}\")\nselect_fds.append(conn)\nelif conn and fd == conn:\n# 检查中否有数据要读取。\nprint(f\"Reading data {fd}\")\ndata = conn.recv(1024)\nif data:\n# 安全起见你应当捕获 UnicodeDecodeError 异常。\ncmd = data.decode()\nif cmd.startswith(\"stop\"):\nprint(f\"Stopping server\")\nis_active = False\nelse:\nprint(f\"Unknown command: {cmd}\")\nelse:\n# 已无数据，关闭连接\nprint(f\"Closing connection {fd}\")\nselect_fds.remove(conn)\nconn.close()\nconn = None\nelif fd in fds:\nprint(f\"Reading timer {fd}\")\ncount = int.from_bytes(os.read(fd, 8), byteorder=sys.byteorder)\nprint(f\"Timer {fds.index(fd) + 1} expired {count} times\")\nelse:\nprint(f\"Unknown file descriptor {fd}\")\nfinally:\nfor fd in fds:\nos.close(fd)\nsock.close()\nsock = None", "metadata": {"title": "20_定时器文件描述符指南", "source": "md_docs\\python_howto_md\\20_定时器文件描述符指南.md", "doc_type": "指南", "language": "中文", "doc_id": "b5306562"}}
{"doc_id": "79a0fe35", "content": "将扩展模块移植到 Python 3\n对于将扩展模块移植到 Python 3，我们推荐下列资源：\nSupporting Python 3: An in-depth guide 中的 Migrating C extensions 这一章，这本书介绍了如何\n从 Python 2 迁移到 Python 3，包括指导读者如何移植扩展模块。\npy3c 项目中的 Porting guide 提供了有关支持代码的指导性建议。\n推荐的第三方工具 提供了对于 Python 的 C API 的进一步抽象。 扩展通常需要被重写以使用它们\n中的某一个，而在此之后就可通过库来处理各种 Python 版本和实现之间的差异。", "metadata": {"title": "21_将扩展模块移植到_Python_3", "source": "md_docs\\python_howto_md\\21_将扩展模块移植到_Python_3.md", "doc_type": "指南", "language": "中文", "doc_id": "79a0fe35"}}
{"doc_id": "3b9e08db", "content": "使用 GDB 调试 C API 扩展和 CPython 内部代码\n本文档介绍了如何将 Python GDB 扩展 python-gdb.py 与 GDB 调试器一起使用以调试 CPython 扩\n展以及 CPython 解释器本身。\n当调试低层级问题如崩溃或死锁时，低层级的调试器如 GDB 适合被用来诊断和修正错误。 在默认情\n况下，GDB（或其任一种前端）并不支持 CPython 解释器专属的高层级信息。\npython-gdb.py 扩展可向 GDB 添加 CPython 解释器信息。 该扩展能协助对当前执行的 Python 函\n数栈进行内省。 当给定一个由 PyObject* 指针代表的 Python 对象时，该扩展将展示对象的类型和\n值。\n开发 CPython 扩展或处理 CPython 中用 C 语言编写的部分的开发人员可以通过本文档学习如何将\npython-gdb.py 扩展与 GDB 一起使用。\n备注: 本文档假定你已熟悉 GDB 和 CPython C API 的基础知识。 它对来自 devguide 和 Python\nwiki 的内容进行了整合。\n前提条件\n你需要有：\nGDB 7 或更高的版本。 （对于较低版本的 GDB，请参阅 Python 3.11 或更低版本源代码中的\nMisc/gdbinit。）\n针对 Python 和你正在调试的任何扩展的 GDB 兼容调试信息。\npython-gdb.py 扩展。\n此扩展与 Python 一起构建，但可能单独发布或根本不发布。 下面，我们将以几个常见系统为例进\n行说明。 请注意即使这些说明与你的系统相匹配，它们也可能已经过时。\n使用从源代码构建的 Python 进行设置\n当你从源代码构建 CPython 时，调试信息应当是可用的，并且构建应当在你的代码库根目录中添加\n一个 python-gdb.py 文件。\n要激活支持，你必须将包含 python-gdb.py 的目录添加到 GDB 的 \"auto-load-safe-path\" 中。如果\n你没有这样做，较新版本的 GDB 会打印一个警告来说明如何执行此操作。\n备注: 如果你没有看到针对你的 GDB 版本的说明，请将以下内容放到你的配置文件中\n(~/.gdbinit 或 ~/.config/gdb/gdbinit):\nadd-auto-load-safe-path /path/to/cpython\n\n| 使用 GDB 调试 C API 扩展和 CPython 内部代码\n本文档介绍了如何将 Python GDB 扩展 python-gdb.py 与 GDB 调试器一起使用以调试 CPython 扩\n展以及 CPython 解释器本身。\n当调试低层级问题如崩溃或死锁时，低层级的调试器如 GDB 适合被用来诊断和修正错误。 在默认情\n况下，GDB（或其任一种前端）并不支持 CPython 解释器专属的高层级信息。\npython-gdb.py 扩展可向 GDB 添加 CPython 解释器信息。 该扩展能协助对当前执行的 Python 函\n数栈进行内省。 当给定一个由 PyObject* 指针代表的 Python 对象时，该扩展将展示对象的类型和\n值。\n开发 CPython 扩展或处理 CPython 中用 C 语言编写的部分的开发人员可以通过本文档学习如何将\npython-gdb.py 扩展与 GDB 一起使用。 |\n| --- |\n| 备注: 本文档假定你已熟悉 GDB 和 CPython C API 的基础知识。 它对来自 devguide 和 Python\nwiki 的内容进行了整合。 |\n| 前提条件\n你需要有：\nGDB 7 或更高的版本。 （对于较低版本的 GDB，请参阅 Python 3.11 或更低版本源代码中的\nMisc/gdbinit。）\n针对 Python 和你正在调试的任何扩展的 GDB 兼容调试信息。\npython-gdb.py 扩展。\n此扩展与 Python 一起构建，但可能单独发布或根本不发布。 下面，我们将以几个常见系统为例进\n行说明。 请注意即使这些说明与你的系统相匹配，它们也可能已经过时。\n使用从源代码构建的 Python 进行设置\n当你从源代码构建 CPython 时，调试信息应当是可用的，并且构建应当在你的代码库根目录中添加\n一个 python-gdb.py 文件。\n要激活支持，你必须将包含 python-gdb.py 的目录添加到 GDB 的 \"auto-load-safe-path\" 中。如果\n你没有这样做，较新版本的 GDB 会打印一个警告来说明如何执行此操作。 |\n| 备注: 如果你没有看到针对你的 GDB 版本的说明，请将以下内容放到你的配置文件中\n(~/.gdbinit 或 ~/.config/gdb/gdbinit):\nadd-auto-load-safe-path /path/to/cpython |\n\n你还可以添加多个路径，以 : 分隔。\n针对 Linux 发行版的 Python 设置\n大多数 Linux 系统会在名为 python-debuginfo、python-dbg 或类似的包中提供系统 Python 的调\n试信息。 例如：\nFedora：\nsudo dnf install gdb\nsudo dnf debuginfo-install python3\nUbuntu：\nsudo apt install gdb python3-dbg\n在一些最新的 Linux 系统上，GDB 可以使用 debuginfod 自动下载调试符号。 不过，这并不会安装\npython-gdb.py 扩展；你通常需要单独安装调试信息包。\n使用调试构建和开发模式\n为了方便调试，你可能需要：\n使用 Python 的 调试构建版。 （当从源代码构建时，使用 configure --with-pydebug。 在\nLinux 发行版上，安装并运行 python-debug 或 python-dbg 之类的包，如果有的话。）\n使用运行时 开发模式 (-X dev)。\n两者都将启用额外的断言并禁用某些优化。 有时这会隐藏你想要查找的程序错误，但大多数情况下\n它们都能使调试过程更简单。\n使用 python-gdb 扩展\n当该扩展被加载时，它将提供两个主要特性：Python 值的美化打印，以及附加的命令。\n美化打印\n这是当此扩展被启用时 GDB 回溯信息的显示效果（截取部分）:\n#0 0x000000000041a6b1 in PyObject_Malloc (nbytes=Cannot access memory at address\n) at Objects/obmalloc.c:748\n#1 0x000000000041b7c0 in _PyObject_DebugMallocApi (id=111 'o', nbytes=24) at Obje\n#2 0x000000000041b717 in _PyObject_DebugMalloc (nbytes=24) at Objects/obmalloc.c:\n#3 0x000000000044060a in _PyUnicode_New (length=11) at Objects/unicodeobject.c:34\n#4 0x00000000004466aa in PyUnicodeUCS2_DecodeUTF8Stateful (s=0x5c2b8d \"__lltrace_\n0x0) at Objects/unicodeobject.c:2531\n#5 0x0000000000446647 in PyUnicodeUCS2_DecodeUTF8 (s=0x5c2b8d \"__lltrace__\", size\nat Objects/unicodeobject.c:2495\n#6 0x0000000000440d1b in PyUnicodeUCS2_FromStringAndSize (u=0x5c2b8d \"__lltrace__\nat Objects/unicodeobject.c:551\n#7 0x0000000000440d94 in PyUnicodeUCS2_FromString (u=0x5c2b8d \"__lltrace__\") at O\n#8 0x0000000000584abd in PyDict_GetItemString (v=\n\n|  | 你还可以添加多个路径，以 : 分隔。 |  |\n| --- | --- | --- |\n|  | 针对 Linux 发行版的 Python 设置\n大多数 Linux 系统会在名为 python-debuginfo、python-dbg 或类似的包中提供系统 Python 的调\n试信息。 例如：\nFedora：\nsudo dnf install gdb\nsudo dnf debuginfo-install python3\nUbuntu：\nsudo apt install gdb python3-dbg\n在一些最新的 Linux 系统上，GDB 可以使用 debuginfod 自动下载调试符号。 不过，这并不会安装\npython-gdb.py 扩展；你通常需要单独安装调试信息包。\n使用调试构建和开发模式\n为了方便调试，你可能需要：\n使用 Python 的 调试构建版。 （当从源代码构建时，使用 configure --with-pydebug。 在\nLinux 发行版上，安装并运行 python-debug 或 python-dbg 之类的包，如果有的话。）\n使用运行时 开发模式 (-X dev)。\n两者都将启用额外的断言并禁用某些优化。 有时这会隐藏你想要查找的程序错误，但大多数情况下\n它们都能使调试过程更简单。\n使用 python-gdb 扩展\n当该扩展被加载时，它将提供两个主要特性：Python 值的美化打印，以及附加的命令。\n美化打印\n这是当此扩展被启用时 GDB 回溯信息的显示效果（截取部分）: |  |\n|  | #0 0x000000000041a6b1 in PyObject_Malloc (nbytes=Cannot access memory at address\n) at Objects/obmalloc.c:748\n#1 0x000000000041b7c0 in _PyObject_DebugMallocApi (id=111 'o', nbytes=24) at Obje\n#2 0x000000000041b717 in _PyObject_DebugMalloc (nbytes=24) at Objects/obmalloc.c:\n#3 0x000000000044060a in _PyUnicode_New (length=11) at Objects/unicodeobject.c:34\n#4 0x00000000004466aa in PyUnicodeUCS2_DecodeUTF8Stateful (s=0x5c2b8d \"__lltrace_\n0x0) at Objects/unicodeobject.c:2531\n#5 0x0000000000446647 in PyUnicodeUCS2_DecodeUTF8 (s=0x5c2b8d \"__lltrace__\", size\nat Objects/unicodeobject.c:2495\n#6 0x0000000000440d1b in PyUnicodeUCS2_FromStringAndSize (u=0x5c2b8d \"__lltrace__\nat Objects/unicodeobject.c:551\n#7 0x0000000000440d94 in PyUnicodeUCS2_FromString (u=0x5c2b8d \"__lltrace__\") at O\n#8 0x0000000000584abd in PyDict_GetItemString (v= |  |\n\n{'Yuck': <type at remote 0xad4730>, '__builtins__': <module at remote 0x7ffff7\n0x5c2b8d \"__lltrace__\") at Objects/dictobject.c:2171\n请注意传给 PyDict_GetItemString 的字典参数被显示为其 repr()，而非不透明的 PyObject *\n指针。\n该扩展通过为类型 PyObject * 的值提供自定义的打印例程来发挥作用。 如果你需要访问一个对象\n的低层级细节，则要将原值投射为适当类型的指针。 例如:\n(gdb) p globals\n$1 = {'__builtins__': <module at remote 0x7ffff7fb1868>, '__name__':\n'__main__', 'ctypes': <module at remote 0x7ffff7f14360>, '__doc__': None,\n'__package__': None}\n(gdb) p *(PyDictObject*)globals\n$2 = {ob_refcnt = 3, ob_type = 0x3dbdf85820, ma_fill = 5, ma_used = 5,\nma_mask = 7, ma_table = 0x63d0f8, ma_lookup = 0x3dbdc7ea70\n<lookdict_string>, ma_smalltable = {{me_hash = 7065186196740147912,\nme_key = '__builtins__', me_value = <module at remote 0x7ffff7fb1868>},\n{me_hash = -368181376027291943, me_key = '__name__',\nme_value ='__main__'}, {me_hash = 0, me_key = 0x0, me_value = 0x0},\n{me_hash = 0, me_key = 0x0, me_value = 0x0},\n{me_hash = -9177857982131165996, me_key = 'ctypes',\nme_value = <module at remote 0x7ffff7f14360>},\n{me_hash = -8518757509529533123, me_key = '__doc__', me_value = None},\n{me_hash = 0, me_key = 0x0, me_value = 0x0}, {\nme_hash = 6614918939584953775, me_key = '__package__', me_value = None}}}\n请注意美化打印并不会实际调用 repr()。 对于基本类型，它将尝试尽量匹配其结果。\n一个可能令人困惑的地方是某些类型的自定义打印效果很像是 GDB 针对标准类型的内置打印形式。\n例如，针对 Python int (PyLongObject*) 的美化打印表示形式与机器层级上常规的整数并无区别:\n(gdb) p some_machine_integer\n$3 = 42\n(gdb) p some_python_integer\n$4 = 42\n内部结构可通过投射到 PyLongObject* 来揭示:\n(gdb) p *(PyLongObject*)some_python_integer\n$5 = {ob_base = {ob_base = {ob_refcnt = 8, ob_type = 0x3dad39f5e0}, ob_size = 1},\nob_digit = {42}}\n类似的困惑也可能发生于 str 类型，这里的输出看起来很像 gdb 针对 char * 的内置打印形式:\n(gdb) p ptr_to_python_str\n$6 = '__builtins__'\n针对 str 实例的美化打印默认使用单引号（就像 Python 字符串的 repr 一样）而针对 char * 值的\n标准打印形式使用双引号并且包含一个十六进制的地址:\n\n|  | {'Yuck': <type at remote 0xad4730>, '__builtins__': <module at remote 0x7ffff7\n0x5c2b8d \"__lltrace__\") at Objects/dictobject.c:2171 |  |  |\n| --- | --- | --- | --- |\n|  | 请注意传给 PyDict_GetItemString 的字典参数被显示为其 repr()，而非不透明的 PyObject *\n指针。\n该扩展通过为类型 PyObject * 的值提供自定义的打印例程来发挥作用。 如果你需要访问一个对象\n的低层级细节，则要将原值投射为适当类型的指针。 例如: |  |  |\n|  | (gdb) p globals\n$1 = {'__builtins__': <module at remote 0x7ffff7fb1868>, '__name__':\n'__main__', 'ctypes': <module at remote 0x7ffff7f14360>, '__doc__': None,\n'__package__': None} |  |  |\n|  | (gdb) p *(PyDictObject*)globals\n$2 = {ob_refcnt = 3, ob_type = 0x3dbdf85820, ma_fill = 5, ma_used = 5,\nma_mask = 7, ma_table = 0x63d0f8, ma_lookup = 0x3dbdc7ea70\n<lookdict_string>, ma_smalltable = {{me_hash = 7065186196740147912,\nme_key = '__builtins__', me_value = <module at remote 0x7ffff7fb1868>},\n{me_hash = -368181376027291943, me_key = '__name__',\nme_value ='__main__'}, {me_hash = 0, me_key = 0x0, me_value = 0x0},\n{me_hash = 0, me_key = 0x0, me_value = 0x0},\n{me_hash = -9177857982131165996, me_key = 'ctypes',\nme_value = <module at remote 0x7ffff7f14360>},\n{me_hash = -8518757509529533123, me_key = '__doc__', me_value = None},\n{me_hash = 0, me_key = 0x0, me_value = 0x0}, {\nme_hash = 6614918939584953775, me_key = '__package__', me_value = None}}} |  |  |\n|  | 请注意美化打印并不会实际调用 repr()。 对于基本类型，它将尝试尽量匹配其结果。\n一个可能令人困惑的地方是某些类型的自定义打印效果很像是 GDB 针对标准类型的内置打印形式。\n例如，针对 Python int (PyLongObject*) 的美化打印表示形式与机器层级上常规的整数并无区别: |  |  |\n|  | (gdb) p some_machine_integer\n$3 = 42\n(gdb) p some_python_integer\n$4 = 42 |  |  |\n|  | 内部结构可通过投射到 PyLongObject* 来揭示: |  |  |\n|  | (gdb) p *(PyLongObject*)some_python_integer\n$5 = {ob_base = {ob_base = {ob_refcnt = 8, ob_type = 0x3dad39f5e0}, ob_size = 1},\nob_digit = {42}} |  |  |\n|  | 类似的困惑也可能发生于 str 类型，这里的输出看起来很像 gdb 针对 char * 的内置打印形式: |  |  |\n|  | (gdb) p ptr_to_python_str\n$6 = '__builtins__' |  |  |\n|  | 针对 str 实例的美化打印默认使用单引号（就像 Python 字符串的 repr 一样）而针对 char * 值的\n标准打印形式使用双引号并且包含一个十六进制的地址: |  |  |\n\n(gdb) p ptr_to_char_star\n$7 = 0x6d72c0 \"hello world\"\n同样地，该实现细节可通过投射为 PyUnicodeObject* 来显示:\n(gdb) p *(PyUnicodeObject*)$6\n$8 = {ob_base = {ob_refcnt = 33, ob_type = 0x3dad3a95a0}, length = 12,\nstr = 0x7ffff2128500, hash = 7065186196740147912, state = 1, defenc = 0x0}\npy-list\n该扩展添加了一个 py-list 命令，它将列出选定的线程中当前帧的 Python 源代码（如果存\n在）。 当前行将以一个 \">\" 来标记:\n(gdb) py-list\n901 if options.profile:\n902 options.profile = False\n903 profile_me()\n904 return\n905\n>906 u = UI()\n907 if not u.quit:\n908 try:\n909 gtk.main()\n910 except KeyboardInterrupt:\n911 # properly quit on a keyboard interrupt...\n使用 py-list START 从不同的行号开始列出 Python 源代码，而 py-list START,END 则从列出\n指定行范围内的 Python 源代码。\npy-up 和 py-down\npy-up 和 py-down 命令类似于 GDB 的常规 up 和 down 命令，但会尝试在 CPython 帧而不是 C\n帧的层级上移动。\nGDB 并不总是能够读取相关的帧信息，这取决于编译 CPython 时的优化级别。 在内部，这些命\n令会查找正在执行默认帧求值函数（即 CPython 内的的核心字节码解释器循环）的 C 帧并查找相\n关 PyFrameObject * 的值。\n它们将发出线程内的帧编号（在 C 层级上）。\n例如:\n(gdb) py-up\n#37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/\ngnome_sudoku/main.py, line 906, in start_game ()\nu = UI()\n(gdb) py-up\n#40 Frame 0x948e82c, for file /usr/lib/python2.6/site-packages/\ngnome_sudoku/gnome_sudoku.py, line 22, in start_game(main=<module at remote 0xb7\nmain.start_game()\n(gdb) py-up\nUnable to find an older python frame\n\n|  | (gdb) p ptr_to_char_star\n$7 = 0x6d72c0 \"hello world\" |  |  |  |\n| --- | --- | --- | --- | --- |\n|  | 同样地，该实现细节可通过投射为 PyUnicodeObject* 来显示: |  |  |  |\n|  | (gdb) p *(PyUnicodeObject*)$6\n$8 = {ob_base = {ob_refcnt = 33, ob_type = 0x3dad3a95a0}, length = 12,\nstr = 0x7ffff2128500, hash = 7065186196740147912, state = 1, defenc = 0x0} |  |  |  |\n|  | py-list\n该扩展添加了一个 py-list 命令，它将列出选定的线程中当前帧的 Python 源代码（如果存\n在）。 当前行将以一个 \">\" 来标记:\n(gdb) py-list\n901 if options.profile:\n902 options.profile = False\n903 profile_me()\n904 return\n905\n>906 u = UI()\n907 if not u.quit:\n908 try:\n909 gtk.main()\n910 except KeyboardInterrupt:\n911 # properly quit on a keyboard interrupt...\n使用 py-list START 从不同的行号开始列出 Python 源代码，而 py-list START,END 则从列出\n指定行范围内的 Python 源代码。\npy-up 和 py-down\npy-up 和 py-down 命令类似于 GDB 的常规 up 和 down 命令，但会尝试在 CPython 帧而不是 C\n帧的层级上移动。\nGDB 并不总是能够读取相关的帧信息，这取决于编译 CPython 时的优化级别。 在内部，这些命\n令会查找正在执行默认帧求值函数（即 CPython 内的的核心字节码解释器循环）的 C 帧并查找相\n关 PyFrameObject * 的值。\n它们将发出线程内的帧编号（在 C 层级上）。\n例如:\n(gdb) py-up\n#37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/\ngnome_sudoku/main.py, line 906, in start_game ()\nu = UI()\n(gdb) py-up\n#40 Frame 0x948e82c, for file /usr/lib/python2.6/site-packages/\ngnome_sudoku/gnome_sudoku.py, line 22, in start_game(main=<module at remote 0xb7\nmain.start_game()\n(gdb) py-up\nUnable to find an older python frame |  |  |  |\n|  |  | (gdb) py-up\n#37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/\ngnome_sudoku/main.py, line 906, in start_game ()\nu = UI()\n(gdb) py-up\n#40 Frame 0x948e82c, for file /usr/lib/python2.6/site-packages/\ngnome_sudoku/gnome_sudoku.py, line 22, in start_game(main=<module at remote 0xb7\nmain.start_game()\n(gdb) py-up\nUnable to find an older python frame |  |  |\n\n这样我们位于 Python 栈的顶部。\n帧编号对应于 GDB 的 backtrace 命令所显示的内容。 该命令将跳过未在执行 Python 代码的 C\n帧。\n向下回退:\n(gdb) py-down\n#37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/gnome_sudoku/main\nu = UI()\n(gdb) py-down\n#34 (unable to read python frame information)\n(gdb) py-down\n#23 (unable to read python frame information)\n(gdb) py-down\n#19 (unable to read python frame information)\n(gdb) py-down\n#14 Frame 0x99262ac, for file /usr/lib/python2.6/site-packages/gnome_sudoku/game\nswallower.run_dialog(self.dialog)\n(gdb) py-down\n#11 Frame 0x9aead74, for file /usr/lib/python2.6/site-packages/gnome_sudoku/dial\ngtk.main()\n(gdb) py-down\n#8 (unable to read python frame information)\n(gdb) py-down\nUnable to find a newer python frame\n现在我们位于 Python 栈的底部。\n请注意在 Python 3.12 及更新的版本中，同一个 C 栈帧可被用于多个 Python 栈帧。 这意味着\npy-up 和 py-down 可以同时移动多个 Python 帧。 例如:\n(gdb) py-up\n#6 Frame 0x7ffff7fb62b0, for file /tmp/rec.py, line 5, in recursive_function (n=\ntime.sleep(5)\n#6 Frame 0x7ffff7fb6240, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb61d0, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb6160, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb60f0, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb6080, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb6020, for file /tmp/rec.py, line 9, in <module> ()\nrecursive_function(5)\n(gdb) py-up\nUnable to find an older python frame\npy-bt\npy-bt 命令会尝试显示当前线程的 Python 层级回溯。\n例如:\n\n|  | 这样我们位于 Python 栈的顶部。\n帧编号对应于 GDB 的 backtrace 命令所显示的内容。 该命令将跳过未在执行 Python 代码的 C\n帧。\n向下回退:\n(gdb) py-down\n#37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/gnome_sudoku/main\nu = UI()\n(gdb) py-down\n#34 (unable to read python frame information)\n(gdb) py-down\n#23 (unable to read python frame information)\n(gdb) py-down\n#19 (unable to read python frame information)\n(gdb) py-down\n#14 Frame 0x99262ac, for file /usr/lib/python2.6/site-packages/gnome_sudoku/game\nswallower.run_dialog(self.dialog)\n(gdb) py-down\n#11 Frame 0x9aead74, for file /usr/lib/python2.6/site-packages/gnome_sudoku/dial\ngtk.main()\n(gdb) py-down\n#8 (unable to read python frame information)\n(gdb) py-down\nUnable to find a newer python frame\n现在我们位于 Python 栈的底部。\n请注意在 Python 3.12 及更新的版本中，同一个 C 栈帧可被用于多个 Python 栈帧。 这意味着\npy-up 和 py-down 可以同时移动多个 Python 帧。 例如:\n(gdb) py-up\n#6 Frame 0x7ffff7fb62b0, for file /tmp/rec.py, line 5, in recursive_function (n=\ntime.sleep(5)\n#6 Frame 0x7ffff7fb6240, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb61d0, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb6160, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb60f0, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb6080, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb6020, for file /tmp/rec.py, line 9, in <module> ()\nrecursive_function(5)\n(gdb) py-up\nUnable to find an older python frame\npy-bt\npy-bt 命令会尝试显示当前线程的 Python 层级回溯。\n例如: |  |  |  |\n| --- | --- | --- | --- | --- |\n|  |  | (gdb) py-down\n#37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/gnome_sudoku/main\nu = UI()\n(gdb) py-down\n#34 (unable to read python frame information)\n(gdb) py-down\n#23 (unable to read python frame information)\n(gdb) py-down\n#19 (unable to read python frame information)\n(gdb) py-down\n#14 Frame 0x99262ac, for file /usr/lib/python2.6/site-packages/gnome_sudoku/game\nswallower.run_dialog(self.dialog)\n(gdb) py-down\n#11 Frame 0x9aead74, for file /usr/lib/python2.6/site-packages/gnome_sudoku/dial\ngtk.main()\n(gdb) py-down\n#8 (unable to read python frame information)\n(gdb) py-down\nUnable to find a newer python frame |  |  |\n|  |  |  |  |  |\n|  |  | (gdb) py-up\n#6 Frame 0x7ffff7fb62b0, for file /tmp/rec.py, line 5, in recursive_function (n=\ntime.sleep(5)\n#6 Frame 0x7ffff7fb6240, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb61d0, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb6160, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb60f0, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb6080, for file /tmp/rec.py, line 7, in recursive_function (n=\nrecursive_function(n-1)\n#6 Frame 0x7ffff7fb6020, for file /tmp/rec.py, line 9, in <module> ()\nrecursive_function(5)\n(gdb) py-up\nUnable to find an older python frame |  |  |\n|  |  |  |  |  |\n\n(gdb) py-bt\n#8 (unable to read python frame information)\n#11 Frame 0x9aead74, for file /usr/lib/python2.6/site-packages/gnome_sudoku/dial\ngtk.main()\n#14 Frame 0x99262ac, for file /usr/lib/python2.6/site-packages/gnome_sudoku/game\nswallower.run_dialog(self.dialog)\n#19 (unable to read python frame information)\n#23 (unable to read python frame information)\n#34 (unable to read python frame information)\n#37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/gnome_sudoku/main\nu = UI()\n#40 Frame 0x948e82c, for file /usr/lib/python2.6/site-packages/gnome_sudoku/gnom\nmain.start_game()\n帧编号对应于 GDB 的 backtrace 命令所显示的内容。\npy-print\npy-print 命令会查找一个 Python 名称并尝试打印它。 它将先在当前线程的 locals 中查找，然后\n是 globals，最后是 builtins:\n(gdb) py-print self\nlocal 'self' = <SwappableArea(running=<gtk.Dialog at remote 0x98faaa4>,\nmain_page=0) at remote 0x98fa6e4>\n(gdb) py-print __name__\nglobal '__name__' = 'gnome_sudoku.dialog_swallower'\n(gdb) py-print len\nbuiltin 'len' = <built-in function len>\n(gdb) py-print scarlet_pimpernel\n'scarlet_pimpernel' not found\n如果当前 C 帧对应多个 Python 帧，则 py-print 只会考虑其中第一个。\npy-locals\npy-locals 命令会在选定的线程中查找当前 Python 帧内的所有 Python 的 locals，并打印它们的\n表示形式:\n(gdb) py-locals\nself = <SwappableArea(running=<gtk.Dialog at remote 0x98faaa4>,\nmain_page=0) at remote 0x98fa6e4>\nd = <gtk.Dialog at remote 0x98faaa4>\n如果当前 C 帧对应多个 Python 帧，同它们的所有 locals 都会被显示:\n(gdb) py-locals\nLocals for recursive_function\nn = 0\nLocals for recursive_function\nn = 1\nLocals for recursive_function\nn = 2\nLocals for recursive_function\nn = 3\nLocals for recursive_function\n\n|  | (gdb) py-bt\n#8 (unable to read python frame information)\n#11 Frame 0x9aead74, for file /usr/lib/python2.6/site-packages/gnome_sudoku/dial\ngtk.main()\n#14 Frame 0x99262ac, for file /usr/lib/python2.6/site-packages/gnome_sudoku/game\nswallower.run_dialog(self.dialog)\n#19 (unable to read python frame information)\n#23 (unable to read python frame information)\n#34 (unable to read python frame information)\n#37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/gnome_sudoku/main\nu = UI()\n#40 Frame 0x948e82c, for file /usr/lib/python2.6/site-packages/gnome_sudoku/gnom\nmain.start_game()\n帧编号对应于 GDB 的 backtrace 命令所显示的内容。\npy-print\npy-print 命令会查找一个 Python 名称并尝试打印它。 它将先在当前线程的 locals 中查找，然后\n是 globals，最后是 builtins:\n(gdb) py-print self\nlocal 'self' = <SwappableArea(running=<gtk.Dialog at remote 0x98faaa4>,\nmain_page=0) at remote 0x98fa6e4>\n(gdb) py-print __name__\nglobal '__name__' = 'gnome_sudoku.dialog_swallower'\n(gdb) py-print len\nbuiltin 'len' = <built-in function len>\n(gdb) py-print scarlet_pimpernel\n'scarlet_pimpernel' not found\n如果当前 C 帧对应多个 Python 帧，则 py-print 只会考虑其中第一个。\npy-locals\npy-locals 命令会在选定的线程中查找当前 Python 帧内的所有 Python 的 locals，并打印它们的\n表示形式:\n(gdb) py-locals\nself = <SwappableArea(running=<gtk.Dialog at remote 0x98faaa4>,\nmain_page=0) at remote 0x98fa6e4>\nd = <gtk.Dialog at remote 0x98faaa4>\n如果当前 C 帧对应多个 Python 帧，同它们的所有 locals 都会被显示:\n(gdb) py-locals\nLocals for recursive_function\nn = 0\nLocals for recursive_function\nn = 1\nLocals for recursive_function\nn = 2\nLocals for recursive_function\nn = 3\nLocals for recursive_function | (gdb) py-bt\n#8 (unable to read python frame information)\n#11 Frame 0x9aead74, for file /usr/lib/python2.6/site-packages/gnome_sudoku/dial\ngtk.main()\n#14 Frame 0x99262ac, for file /usr/lib/python2.6/site-packages/gnome_sudoku/game\nswallower.run_dialog(self.dialog)\n#19 (unable to read python frame information)\n#23 (unable to read python frame information)\n#34 (unable to read python frame information)\n#37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/gnome_sudoku/main\nu = UI()\n#40 Frame 0x948e82c, for file /usr/lib/python2.6/site-packages/gnome_sudoku/gnom\nmain.start_game() |  |  |\n| --- | --- | --- | --- | --- |\n|  |  |  |  |  |\n|  |  | (gdb) py-locals\nLocals for recursive_function\nn = 0\nLocals for recursive_function\nn = 1\nLocals for recursive_function\nn = 2\nLocals for recursive_function\nn = 3\nLocals for recursive_function |  |  |\n\nn = 4\nLocals for recursive_function\nn = 5\nLocals for <module>\n与 GDB 命令一起使用\n这些扩展命令是对 GDB 的内置命令的补充。 例如，你可以使用 py-bt 显示的帧编号与 frame 命令\n一起使用以转到所选线程中的特定帧，如下所示:\n(gdb) py-bt\n(output snipped)\n#68 Frame 0xaa4560, for file Lib/test/regrtest.py, line 1548, in <module> ()\nmain()\n(gdb) frame 68\n#68 0x00000000004cd1e6 in PyEval_EvalFrameEx (f=Frame 0xaa4560, for file Lib/test/\n2665 x = call_function(&sp, oparg);\n(gdb) py-list\n1543 # Run the tests in a context manager that temporary changes the CWD to\n1544 # temporary and writable directory. If it's not possible to create or\n1545 # change the CWD, the original CWD will be used. The original CWD is\n1546 # available from test_support.SAVEDCWD.\n1547 with test_support.temp_cwd(TESTCWD, quiet=True):\n>1548 main()\ninfo threads 命令将向你提供进程内的线程列表，您还可以使用 thread 命令来选择不同的线程:\n(gdb) info threads\n105 Thread 0x7fffefa18710 (LWP 10260) sem_wait () at ../nptl/sysdeps/unix/sysv/\n104 Thread 0x7fffdf5fe710 (LWP 10259) sem_wait () at ../nptl/sysdeps/unix/sysv/\n* 1 Thread 0x7ffff7fe2700 (LWP 10145) 0x00000038e46d73e3 in select () at ../sysde\n你可以使用 thread apply all COMMAND 或 (简短写法 t a a COMMAND) 在所有线程上运行一个命\n令。 配合 py-bt，这将让你在 Python 层级上查看看到每个线程在做什么:\n(gdb) t a a py-bt\nThread 105 (Thread 0x7fffefa18710 (LWP 10260)):\n#5 Frame 0x7fffd00019d0, for file /home/david/coding/python-svn/Lib/threading.py,\nself.__block.acquire()\n#8 Frame 0x7fffac001640, for file /home/david/coding/python-svn/Lib/threading.py,\nself._acquire_restore(saved_state)\n#12 Frame 0x7fffb8001a10, for file /home/david/coding/python-svn/Lib/test/lock_tes\ncond.wait()\n#16 Frame 0x7fffb8001c40, for file /home/david/coding/python-svn/Lib/test/lock_tes\nf()\nThread 104 (Thread 0x7fffdf5fe710 (LWP 10259)):\n#5 Frame 0x7fffe4001580, for file /home/david/coding/python-svn/Lib/threading.py,\nself.__block.acquire()\n#8 Frame 0x7fffc8002090, for file /home/david/coding/python-svn/Lib/threading.py,\nself._acquire_restore(saved_state)\n#12 Frame 0x7fffac001c90, for file /home/david/coding/python-svn/Lib/test/lock_tes\ncond.wait()\n#16 Frame 0x7fffac0011c0, for file /home/david/coding/python-svn/Lib/test/lock_tes\nf()\n\n|  | n = 4\nLocals for recursive_function\nn = 5\nLocals for <module>\n与 GDB 命令一起使用\n这些扩展命令是对 GDB 的内置命令的补充。 例如，你可以使用 py-bt 显示的帧编号与 frame 命令\n一起使用以转到所选线程中的特定帧，如下所示: | n = 4\nLocals for recursive_function\nn = 5\nLocals for <module> |  |  |\n| --- | --- | --- | --- | --- |\n|  | (gdb) py-bt\n(output snipped)\n#68 Frame 0xaa4560, for file Lib/test/regrtest.py, line 1548, in <module> ()\nmain()\n(gdb) frame 68\n#68 0x00000000004cd1e6 in PyEval_EvalFrameEx (f=Frame 0xaa4560, for file Lib/test/\n2665 x = call_function(&sp, oparg);\n(gdb) py-list\n1543 # Run the tests in a context manager that temporary changes the CWD to\n1544 # temporary and writable directory. If it's not possible to create or\n1545 # change the CWD, the original CWD will be used. The original CWD is\n1546 # available from test_support.SAVEDCWD.\n1547 with test_support.temp_cwd(TESTCWD, quiet=True):\n>1548 main() |  |  |  |\n|  | info threads 命令将向你提供进程内的线程列表，您还可以使用 thread 命令来选择不同的线程: |  |  |  |\n|  | (gdb) info threads\n105 Thread 0x7fffefa18710 (LWP 10260) sem_wait () at ../nptl/sysdeps/unix/sysv/\n104 Thread 0x7fffdf5fe710 (LWP 10259) sem_wait () at ../nptl/sysdeps/unix/sysv/\n* 1 Thread 0x7ffff7fe2700 (LWP 10145) 0x00000038e46d73e3 in select () at ../sysde |  |  |  |\n|  | 你可以使用 thread apply all COMMAND 或 (简短写法 t a a COMMAND) 在所有线程上运行一个命\n令。 配合 py-bt，这将让你在 Python 层级上查看看到每个线程在做什么: |  |  |  |\n|  | (gdb) t a a py-bt\nThread 105 (Thread 0x7fffefa18710 (LWP 10260)):\n#5 Frame 0x7fffd00019d0, for file /home/david/coding/python-svn/Lib/threading.py,\nself.__block.acquire()\n#8 Frame 0x7fffac001640, for file /home/david/coding/python-svn/Lib/threading.py,\nself._acquire_restore(saved_state)\n#12 Frame 0x7fffb8001a10, for file /home/david/coding/python-svn/Lib/test/lock_tes\ncond.wait()\n#16 Frame 0x7fffb8001c40, for file /home/david/coding/python-svn/Lib/test/lock_tes\nf()\nThread 104 (Thread 0x7fffdf5fe710 (LWP 10259)):\n#5 Frame 0x7fffe4001580, for file /home/david/coding/python-svn/Lib/threading.py,\nself.__block.acquire()\n#8 Frame 0x7fffc8002090, for file /home/david/coding/python-svn/Lib/threading.py,\nself._acquire_restore(saved_state)\n#12 Frame 0x7fffac001c90, for file /home/david/coding/python-svn/Lib/test/lock_tes\ncond.wait()\n#16 Frame 0x7fffac0011c0, for file /home/david/coding/python-svn/Lib/test/lock_tes\nf() |  |  |  |\n\nThread 1 (Thread 0x7ffff7fe2700 (LWP 10145)):\n#5 Frame 0xcb5380, for file /home/david/coding/python-svn/Lib/test/lock_tests.py,\ntime.sleep(0.01)\n#8 Frame 0x7fffd00024a0, for file /home/david/coding/python-svn/Lib/test/lock_test\n_wait()\n\n| Thread 1 (Thread 0x7ffff7fe2700 (LWP 10145)):\n#5 Frame 0xcb5380, for file /home/david/coding/python-svn/Lib/test/lock_tests.py,\ntime.sleep(0.01)\n#8 Frame 0x7fffd00024a0, for file /home/david/coding/python-svn/Lib/test/lock_test\n_wait() |  |\n| --- | --- |\n\n| Thread 1 (Thread 0x7ffff7fe2700 (LWP 10145)):\n#5 Frame 0xcb5380, for file /home/david/coding/python-svn/Lib/test/lock_tests.py,\ntime.sleep(0.01)\n#8 Frame 0x7fffd00024a0, for file /home/david/coding/python-svn/Lib/test/lock_test\n_wait() |\n| --- |\n|  |", "metadata": {"title": "22_使用_GDB_调试_C_API_扩展和_CPython_内部代码", "source": "md_docs\\python_howto_md\\22_使用_GDB_调试_C_API_扩展和_CPython_内部代码.md", "doc_type": "指南", "language": "中文", "doc_id": "3b9e08db"}}
{"doc_id": "85e64d6d", "content": "使用 DTrace 和 SystemTap 检测CPython\n作者: David Malcolm\n作者: Łukasz Langa\nDTrace和SystemTap是监控工具，它们都提供了一种检查计算机系统上的进程的方法。 它们都使用特\n定领域的语言，允许用户编写脚本，其中：\n进程监视的过滤器\n从感兴趣的进程中收集数据\n生成有关数据的报告\n从Python 3.6开始，CPython可以使用嵌入式“标记”构建，也称为“探测器”，可以通过DTrace或\nSystemTap脚本观察，从而更容易监视系统上的CPython进程正在做什么。\nDTrace标记是CPython解释器的实现细节。 不保证CPython版本之间的探针兼容性。 更改CPython版\n本时，DTrace脚本可能会停止工作或无法正常工作而不会发出警告。\n启用静态标记\nmacOS内置了对DTrace的支持。 在Linux上，为了使用SystemTap的嵌入式标记构建CPython，必须\n安装SystemTap开发工具。\n在Linux机器上，这可以通过：\n$ yum install systemtap-sdt-devel\n或者：\n$ sudo apt-get install systemtap-sdt-dev\n之后 CPython 必须 配置 --with-dtrace 选项:\nchecking for --with-dtrace... yes\n在macOS上，您可以通过在后台运行Python进程列出可用的DTrace探测器，并列出Python程序提供\n的所有探测器：\n$ python3.6 -q &\n$ sudo dtrace -l -P python$! # or: dtrace -l -m python3.6\nID PROVIDER MODULE FUNCTION NAME\n29564 python18035 python3.6 _PyEval_EvalFrameDefault function-entr\n29565 python18035 python3.6 dtrace_function_entry function-entr\n29566 python18035 python3.6 _PyEval_EvalFrameDefault function-retu\n29567 python18035 python3.6 dtrace_function_return function-retu\n29568 python18035 python3.6 collect gc-done\n\n| 使用 DTrace 和 SystemTap 检测CPython\n作者: David Malcolm\n作者: Łukasz Langa\nDTrace和SystemTap是监控工具，它们都提供了一种检查计算机系统上的进程的方法。 它们都使用特\n定领域的语言，允许用户编写脚本，其中：\n进程监视的过滤器\n从感兴趣的进程中收集数据\n生成有关数据的报告\n从Python 3.6开始，CPython可以使用嵌入式“标记”构建，也称为“探测器”，可以通过DTrace或\nSystemTap脚本观察，从而更容易监视系统上的CPython进程正在做什么。\nDTrace标记是CPython解释器的实现细节。 不保证CPython版本之间的探针兼容性。 更改CPython版\n本时，DTrace脚本可能会停止工作或无法正常工作而不会发出警告。\n启用静态标记\nmacOS内置了对DTrace的支持。 在Linux上，为了使用SystemTap的嵌入式标记构建CPython，必须\n安装SystemTap开发工具。\n在Linux机器上，这可以通过：\n$ yum install systemtap-sdt-devel\n或者：\n$ sudo apt-get install systemtap-sdt-dev\n之后 CPython 必须 配置 --with-dtrace 选项:\nchecking for --with-dtrace... yes\n在macOS上，您可以通过在后台运行Python进程列出可用的DTrace探测器，并列出Python程序提供\n的所有探测器：\n$ python3.6 -q &\n$ sudo dtrace -l -P python$! # or: dtrace -l -m python3.6\nID PROVIDER MODULE FUNCTION NAME\n29564 python18035 python3.6 _PyEval_EvalFrameDefault function-entr\n29565 python18035 python3.6 dtrace_function_entry function-entr\n29566 python18035 python3.6 _PyEval_EvalFrameDefault function-retu\n29567 python18035 python3.6 dtrace_function_return function-retu\n29568 python18035 python3.6 collect gc-done |  |  |\n| --- | --- | --- |\n|  | 使用 DTrace 和 SystemTap 检测CPython\n作者: David Malcolm\n作者: Łukasz Langa\nDTrace和SystemTap是监控工具，它们都提供了一种检查计算机系统上的进程的方法。 它们都使用特\n定领域的语言，允许用户编写脚本，其中：\n进程监视的过滤器\n从感兴趣的进程中收集数据\n生成有关数据的报告\n从Python 3.6开始，CPython可以使用嵌入式“标记”构建，也称为“探测器”，可以通过DTrace或\nSystemTap脚本观察，从而更容易监视系统上的CPython进程正在做什么。\nDTrace标记是CPython解释器的实现细节。 不保证CPython版本之间的探针兼容性。 更改CPython版\n本时，DTrace脚本可能会停止工作或无法正常工作而不会发出警告。\n启用静态标记\nmacOS内置了对DTrace的支持。 在Linux上，为了使用SystemTap的嵌入式标记构建CPython，必须\n安装SystemTap开发工具。\n在Linux机器上，这可以通过： |  |\n|  | $ yum install systemtap-sdt-devel |  |\n|  | 或者： |  |\n|  | $ sudo apt-get install systemtap-sdt-dev |  |\n|  | 之后 CPython 必须 配置 --with-dtrace 选项: |  |\n|  | checking for --with-dtrace... yes |  |\n|  | 在macOS上，您可以通过在后台运行Python进程列出可用的DTrace探测器，并列出Python程序提供\n的所有探测器： |  |\n|  | $ python3.6 -q &\n$ sudo dtrace -l -P python$! # or: dtrace -l -m python3.6\nID PROVIDER MODULE FUNCTION NAME\n29564 python18035 python3.6 _PyEval_EvalFrameDefault function-entr\n29565 python18035 python3.6 dtrace_function_entry function-entr\n29566 python18035 python3.6 _PyEval_EvalFrameDefault function-retu\n29567 python18035 python3.6 dtrace_function_return function-retu\n29568 python18035 python3.6 collect gc-done |  |\n\n| 作者: |\n| --- |\n| 作者: |\n\n29569 python18035 python3.6 collect gc-start\n29570 python18035 python3.6 _PyEval_EvalFrameDefault line\n29571 python18035 python3.6 maybe_dtrace_line line\n在Linux上，您可以通过查看是否包含“.note.stapsdt”部分来验证构建的二进制文件中是否存在\nSystemTap静态标记。\n$ readelf -S ./python | grep .note.stapsdt\n[30] .note.stapsdt NOTE 0000000000000000 00308d78\n如果你将 Python 编译为共享库（使用 --enable-shared 配置选项），那么你需要改为在共享库内\n部查看。 例如:\n$ readelf -S libpython3.3dm.so.1.0 | grep .note.stapsdt\n[29] .note.stapsdt NOTE 0000000000000000 00365b68\n足够现代的readelf命令可以打印元数据：\n$ readelf -n ./python\nDisplaying notes found at file offset 0x00000254 with length 0x00000020:\nOwner Data size Description\nGNU 0x00000010 NT_GNU_ABI_TAG (ABI version tag)\nOS: Linux, ABI: 2.6.32\nDisplaying notes found at file offset 0x00000274 with length 0x00000024:\nOwner Data size Description\nGNU 0x00000014 NT_GNU_BUILD_ID (unique build ID bits\nBuild ID: df924a2b08a7e89f6e11251d4602022977af2670\nDisplaying notes found at file offset 0x002d6c30 with length 0x00000144:\nOwner Data size Description\nstapsdt 0x00000031 NT_STAPSDT (SystemTap probe descripto\nProvider: python\nName: gc__start\nLocation: 0x00000000004371c3, Base: 0x0000000000630ce2, Semaphore: 0x00000\nArguments: -4@%ebx\nstapsdt 0x00000030 NT_STAPSDT (SystemTap probe descripto\nProvider: python\nName: gc__done\nLocation: 0x00000000004374e1, Base: 0x0000000000630ce2, Semaphore: 0x00000\nArguments: -8@%rax\nstapsdt 0x00000045 NT_STAPSDT (SystemTap probe descripto\nProvider: python\nName: function__entry\nLocation: 0x000000000053db6c, Base: 0x0000000000630ce2, Semaphore: 0x00000\nArguments: 8@%rbp 8@%r12 -4@%eax\nstapsdt 0x00000046 NT_STAPSDT (SystemTap probe descripto\nProvider: python\nName: function__return\nLocation: 0x000000000053dba8, Base: 0x0000000000630ce2, Semaphore: 0x00000\nArguments: 8@%rbp 8@%r12 -4@%eax\n上述元数据包含 SystemTap 信息，它描述了如何修补策略性放置的机器码指令以启用 SystemTap 脚\n本所使用的跟踪钩子。\n\n|  | 29569 python18035 python3.6 collect gc-start\n29570 python18035 python3.6 _PyEval_EvalFrameDefault line\n29571 python18035 python3.6 maybe_dtrace_line line |  |  |\n| --- | --- | --- | --- |\n|  | 在Linux上，您可以通过查看是否包含“.note.stapsdt”部分来验证构建的二进制文件中是否存在\nSystemTap静态标记。 |  |  |\n|  | $ readelf -S ./python | grep .note.stapsdt\n[30] .note.stapsdt NOTE 0000000000000000 00308d78 |  |  |\n|  | 如果你将 Python 编译为共享库（使用 --enable-shared 配置选项），那么你需要改为在共享库内 |  |  |\n|  | 部查看。 例如: |  |  |\n|  | $ readelf -S libpython3.3dm.so.1.0 | grep .note.stapsdt\n[29] .note.stapsdt NOTE 0000000000000000 00365b68 |  |  |\n|  | 足够现代的readelf命令可以打印元数据： |  |  |\n|  | $ readelf -n ./python\nDisplaying notes found at file offset 0x00000254 with length 0x00000020:\nOwner Data size Description\nGNU 0x00000010 NT_GNU_ABI_TAG (ABI version tag)\nOS: Linux, ABI: 2.6.32\nDisplaying notes found at file offset 0x00000274 with length 0x00000024:\nOwner Data size Description\nGNU 0x00000014 NT_GNU_BUILD_ID (unique build ID bits\nBuild ID: df924a2b08a7e89f6e11251d4602022977af2670\nDisplaying notes found at file offset 0x002d6c30 with length 0x00000144:\nOwner Data size Description\nstapsdt 0x00000031 NT_STAPSDT (SystemTap probe descripto\nProvider: python\nName: gc__start\nLocation: 0x00000000004371c3, Base: 0x0000000000630ce2, Semaphore: 0x00000\nArguments: -4@%ebx\nstapsdt 0x00000030 NT_STAPSDT (SystemTap probe descripto\nProvider: python\nName: gc__done\nLocation: 0x00000000004374e1, Base: 0x0000000000630ce2, Semaphore: 0x00000\nArguments: -8@%rax\nstapsdt 0x00000045 NT_STAPSDT (SystemTap probe descripto\nProvider: python\nName: function__entry\nLocation: 0x000000000053db6c, Base: 0x0000000000630ce2, Semaphore: 0x00000\nArguments: 8@%rbp 8@%r12 -4@%eax\nstapsdt 0x00000046 NT_STAPSDT (SystemTap probe descripto\nProvider: python\nName: function__return\nLocation: 0x000000000053dba8, Base: 0x0000000000630ce2, Semaphore: 0x00000\nArguments: 8@%rbp 8@%r12 -4@%eax |  |  |\n|  | 上述元数据包含 SystemTap 信息，它描述了如何修补策略性放置的机器码指令以启用 SystemTap 脚\n本所使用的跟踪钩子。 |  |  |\n\n静态DTrace探针\n下面的 DTrace 脚本示例可以用来显示一个 Python 脚本的调用/返回层次结构，只在调用名为 \"start\"\n的函数内进行跟踪。换句话说，导入时的函数调用不会被列出。\nself int indent;\npython$target:::function-entry\n/copyinstr(arg1) == \"start\"/\n{\nself->trace = 1;\n}\npython$target:::function-entry\n/self->trace/\n{\nprintf(\"%d\\t%*s:\", timestamp, 15, probename);\nprintf(\"%*s\", self->indent, \"\");\nprintf(\"%s:%s:%d\\n\", basename(copyinstr(arg0)), copyinstr(arg1), arg2);\nself->indent++;\n}\npython$target:::function-return\n/self->trace/\n{\nself->indent--;\nprintf(\"%d\\t%*s:\", timestamp, 15, probename);\nprintf(\"%*s\", self->indent, \"\");\nprintf(\"%s:%s:%d\\n\", basename(copyinstr(arg0)), copyinstr(arg1), arg2);\n}\npython$target:::function-return\n/copyinstr(arg1) == \"start\"/\n{\nself->trace = 0;\n}\n它可以这样调用:\n$ sudo dtrace -q -s call_stack.d -c \"python3.6 script.py\"\n输出结果会像这样:\n156641360502280 function-entry:call_stack.py:start:23\n156641360518804 function-entry: call_stack.py:function_1:1\n156641360532797 function-entry: call_stack.py:function_3:9\n156641360546807 function-return: call_stack.py:function_3:10\n156641360563367 function-return: call_stack.py:function_1:2\n156641360578365 function-entry: call_stack.py:function_2:5\n156641360591757 function-entry: call_stack.py:function_1:1\n156641360605556 function-entry: call_stack.py:function_3:9\n156641360617482 function-return: call_stack.py:function_3:10\n156641360629814 function-return: call_stack.py:function_1:2\n156641360642285 function-return: call_stack.py:function_2:6\n156641360656770 function-entry: call_stack.py:function_3:9\n156641360669707 function-return: call_stack.py:function_3:10\n\n|  | 静态DTrace探针\n下面的 DTrace 脚本示例可以用来显示一个 Python 脚本的调用/返回层次结构，只在调用名为 \"start\"\n的函数内进行跟踪。换句话说，导入时的函数调用不会被列出。 |  |\n| --- | --- | --- |\n|  | self int indent;\npython$target:::function-entry\n/copyinstr(arg1) == \"start\"/\n{\nself->trace = 1;\n}\npython$target:::function-entry\n/self->trace/\n{\nprintf(\"%d\\t%*s:\", timestamp, 15, probename);\nprintf(\"%*s\", self->indent, \"\");\nprintf(\"%s:%s:%d\\n\", basename(copyinstr(arg0)), copyinstr(arg1), arg2);\nself->indent++;\n}\npython$target:::function-return\n/self->trace/\n{\nself->indent--;\nprintf(\"%d\\t%*s:\", timestamp, 15, probename);\nprintf(\"%*s\", self->indent, \"\");\nprintf(\"%s:%s:%d\\n\", basename(copyinstr(arg0)), copyinstr(arg1), arg2);\n}\npython$target:::function-return\n/copyinstr(arg1) == \"start\"/\n{\nself->trace = 0;\n} |  |\n|  | 它可以这样调用: |  |\n|  | $ sudo dtrace -q -s call_stack.d -c \"python3.6 script.py\" |  |\n|  | 输出结果会像这样: |  |\n|  | 156641360502280 function-entry:call_stack.py:start:23\n156641360518804 function-entry: call_stack.py:function_1:1\n156641360532797 function-entry: call_stack.py:function_3:9\n156641360546807 function-return: call_stack.py:function_3:10\n156641360563367 function-return: call_stack.py:function_1:2\n156641360578365 function-entry: call_stack.py:function_2:5\n156641360591757 function-entry: call_stack.py:function_1:1\n156641360605556 function-entry: call_stack.py:function_3:9\n156641360617482 function-return: call_stack.py:function_3:10\n156641360629814 function-return: call_stack.py:function_1:2\n156641360642285 function-return: call_stack.py:function_2:6\n156641360656770 function-entry: call_stack.py:function_3:9\n156641360669707 function-return: call_stack.py:function_3:10 |  |\n\n156641360687853 function-entry: call_stack.py:function_4:13\n156641360700719 function-return: call_stack.py:function_4:14\n156641360719640 function-entry: call_stack.py:function_5:18\n156641360732567 function-return: call_stack.py:function_5:21\n156641360747370 function-return:call_stack.py:start:28\n静态SystemTap标记\n使用 SystemTap 集成的底层方法是直接使用静态标记。 这需要你显式地说明包含它们的二进制文\n件。\n例如，这个SystemTap脚本可以用来显示Python脚本的调用/返回层次结构：\nprobe process(\"python\").mark(\"function__entry\") {\nfilename = user_string($arg1);\nfuncname = user_string($arg2);\nlineno = $arg3;\nprintf(\"%s => %s in %s:%d\\\\n\",\nthread_indent(1), funcname, filename, lineno);\n}\nprobe process(\"python\").mark(\"function__return\") {\nfilename = user_string($arg1);\nfuncname = user_string($arg2);\nlineno = $arg3;\nprintf(\"%s <= %s in %s:%d\\\\n\",\nthread_indent(-1), funcname, filename, lineno);\n}\n它可以这样调用:\n$ stap \\\nshow-call-hierarchy.stp \\\n-c \"./python test.py\"\n输出结果会像这样:\n11408 python(8274): => __contains__ in Lib/_abcoll.py:362\n11414 python(8274): => __getitem__ in Lib/os.py:425\n11418 python(8274): => encode in Lib/os.py:490\n11424 python(8274): <= encode in Lib/os.py:493\n11428 python(8274): <= __getitem__ in Lib/os.py:426\n11433 python(8274): <= __contains__ in Lib/_abcoll.py:366\n其中的列是：\n脚本开始后经过的微秒数\n可执行文件的名字\n进程的PID\n其余部分则表示脚本执行时的调用/返回层次结构。\n\n|  | 156641360687853 function-entry: call_stack.py:function_4:13\n156641360700719 function-return: call_stack.py:function_4:14\n156641360719640 function-entry: call_stack.py:function_5:18\n156641360732567 function-return: call_stack.py:function_5:21\n156641360747370 function-return:call_stack.py:start:28 |  |\n| --- | --- | --- |\n|  | 静态SystemTap标记\n使用 SystemTap 集成的底层方法是直接使用静态标记。 这需要你显式地说明包含它们的二进制文\n件。\n例如，这个SystemTap脚本可以用来显示Python脚本的调用/返回层次结构： |  |\n|  | probe process(\"python\").mark(\"function__entry\") {\nfilename = user_string($arg1);\nfuncname = user_string($arg2);\nlineno = $arg3;\nprintf(\"%s => %s in %s:%d\\\\n\",\nthread_indent(1), funcname, filename, lineno);\n}\nprobe process(\"python\").mark(\"function__return\") {\nfilename = user_string($arg1);\nfuncname = user_string($arg2);\nlineno = $arg3;\nprintf(\"%s <= %s in %s:%d\\\\n\",\nthread_indent(-1), funcname, filename, lineno);\n} |  |\n|  | 它可以这样调用: |  |\n|  | $ stap \\\nshow-call-hierarchy.stp \\\n-c \"./python test.py\" |  |\n|  | 输出结果会像这样: |  |\n|  | 11408 python(8274): => __contains__ in Lib/_abcoll.py:362\n11414 python(8274): => __getitem__ in Lib/os.py:425\n11418 python(8274): => encode in Lib/os.py:490\n11424 python(8274): <= encode in Lib/os.py:493\n11428 python(8274): <= __getitem__ in Lib/os.py:426\n11433 python(8274): <= __contains__ in Lib/_abcoll.py:366 |  |\n|  | 其中的列是：\n脚本开始后经过的微秒数\n可执行文件的名字\n进程的PID\n其余部分则表示脚本执行时的调用/返回层次结构。 |  |\n\n对于 CPython 的 --enable-shared 编译版，这些标记包含在 libpython 共享库内部，并且 probe 的\n加点路径需要反映这个。 例如，上述示例的这一行:\nprobe process(\"python\").mark(\"function__entry\") {\n应改为：\nprobe process(\"python\").library(\"libpython3.6dm.so.1.0\").mark(\"function__entry\") {\n(假定为 CPython 3.6 的 调试编译版)\n可用的静态标记\nfunction__entry(str filename, str funcname, int lineno)\n这个标记表示一个Python函数的执行已经开始。它只对纯 Python （字节码）函数触发。\n文件名、函数名和行号作为位置参数提供给跟踪脚本，必须使用 $arg1, $arg2, $arg3 访问：\n$arg1 : (const char *) 文件名，使用 user_string($arg1) 访问\n$arg2 : (const char *) 函数名，使用 user_string($arg2) 访问\n$arg3 : int 行号\nfunction__return(str filename, str funcname, int lineno)\n这个标记与 function__entry() 相反，表示 Python 函数的执行已经结束（通过 return，或\n者通过异常）。 它只会为纯 Python（字节码）函数触发。\n参数与 function__entry() 的相同\nline(str filename, str funcname, int lineno)\n这个标记表示一个 Python 行即将被执行。它相当于用 Python 分析器逐行追踪。它不会在C函\n数中触发。\n参数与 function__entry() 的相同。\ngc__start(int generation)\n当 Python 解释器启动一个垃圾回收循环时触发。 arg0 是要扫描的代，与 gc.collect() 一\n样。\ngc__done(long collected)\n当Python解释器完成一个垃圾回收循环时被触发。arg0 是收集到的对象的数量。\nimport__find__load__start(str modulename)\n在 importlib 试图查找并加载模块之前被触发。arg0 是模块名称。\nAdded in version 3.7.\nimport__find__load__done(str modulename, int found)\n在 importlib 的 find_and_load 函数被调用后被触发 。arg0 是模块名称， arg1 表示模块是\n否成功加载。\n\n|  | 对于 CPython 的 --enable-shared 编译版，这些标记包含在 libpython 共享库内部，并且 probe 的\n加点路径需要反映这个。 例如，上述示例的这一行: |  |\n| --- | --- | --- |\n|  | probe process(\"python\").mark(\"function__entry\") { |  |\n|  | 应改为： |  |\n|  | probe process(\"python\").library(\"libpython3.6dm.so.1.0\").mark(\"function__entry\") { |  |\n|  | (假定为 CPython 3.6 的 调试编译版)\n可用的静态标记\nfunction__entry(str filename, str funcname, int lineno)\n这个标记表示一个Python函数的执行已经开始。它只对纯 Python （字节码）函数触发。\n文件名、函数名和行号作为位置参数提供给跟踪脚本，必须使用 $arg1, $arg2, $arg3 访问：\n$arg1 : (const char *) 文件名，使用 user_string($arg1) 访问\n$arg2 : (const char *) 函数名，使用 user_string($arg2) 访问\n$arg3 : int 行号\nfunction__return(str filename, str funcname, int lineno)\n这个标记与 function__entry() 相反，表示 Python 函数的执行已经结束（通过 return，或\n者通过异常）。 它只会为纯 Python（字节码）函数触发。\n参数与 function__entry() 的相同\nline(str filename, str funcname, int lineno)\n这个标记表示一个 Python 行即将被执行。它相当于用 Python 分析器逐行追踪。它不会在C函\n数中触发。\n参数与 function__entry() 的相同。\ngc__start(int generation)\n当 Python 解释器启动一个垃圾回收循环时触发。 arg0 是要扫描的代，与 gc.collect() 一\n样。\ngc__done(long collected)\n当Python解释器完成一个垃圾回收循环时被触发。arg0 是收集到的对象的数量。\nimport__find__load__start(str modulename)\n在 importlib 试图查找并加载模块之前被触发。arg0 是模块名称。\nAdded in version 3.7.\nimport__find__load__done(str modulename, int found)\n在 importlib 的 find_and_load 函数被调用后被触发 。arg0 是模块名称， arg1 表示模块是\n否成功加载。 |  |\n\nAdded in version 3.7.\naudit(str event, void *tuple)\n当 sys.audit() 或 PySys_Audit() 被调用时启动。 arg0 是事件名称的 C 字符串，arg1 是一\n个指向元组对象的 PyObject 指针。\nAdded in version 3.8.\nSystemTap Tapsets\n使用SystemTap集成的更高层次的方法是使用 \"tapset\" 。SystemTap 的等效库，它隐藏了静态标记的\n一些底层细节。\n这里是一个基于 CPython 的非共享构建的 tapset 文件。\n/*\n提供对 function__entry 和 function__return 标记的高级封装\n\\*/\nprobe python.function.entry = process(\"python\").mark(\"function__entry\")\n{\nfilename = user_string($arg1);\nfuncname = user_string($arg2);\nlineno = $arg3;\nframeptr = $arg4\n}\nprobe python.function.return = process(\"python\").mark(\"function__return\")\n{\nfilename = user_string($arg1);\nfuncname = user_string($arg2);\nlineno = $arg3;\nframeptr = $arg4\n}\n如果这个文件安装在 SystemTap 的 tapset 目录下（例如 /usr/share/systemtap/tapset ），那么\n这些额外的探测点就会变得可用。\npython.function.entry(str filename, str funcname, int lineno, frameptr)\n这个探针点表示一个Python函数的执行已经开始。它只对纯Python （字节码）函数触发。\npython.function.return(str filename, str funcname, int lineno, frameptr)\n这个探针点是 python.function.return 的反义操作，表示一个 Python 函数的执行已经结束\n（或是通过 return，或是通过异常）。 它只会针对纯 Python（字节码）函数触发。\n例子\n这个SystemTap脚本使用上面的tapset来更清晰地实现上面给出的跟踪Python函数调用层次结构的例\n子，而不需要直接命名静态标记。\nprobe python.function.entry\n{\nprintf(\"%s => %s in %s:%d\\n\",\nthread_indent(1), funcname, filename, lineno);\n\n|  | Added in version 3.7.\naudit(str event, void *tuple)\n当 sys.audit() 或 PySys_Audit() 被调用时启动。 arg0 是事件名称的 C 字符串，arg1 是一\n个指向元组对象的 PyObject 指针。\nAdded in version 3.8.\nSystemTap Tapsets\n使用SystemTap集成的更高层次的方法是使用 \"tapset\" 。SystemTap 的等效库，它隐藏了静态标记的\n一些底层细节。\n这里是一个基于 CPython 的非共享构建的 tapset 文件。 |  |\n| --- | --- | --- |\n|  | /*\n提供对 function__entry 和 function__return 标记的高级封装\n\\*/\nprobe python.function.entry = process(\"python\").mark(\"function__entry\")\n{\nfilename = user_string($arg1);\nfuncname = user_string($arg2);\nlineno = $arg3;\nframeptr = $arg4\n}\nprobe python.function.return = process(\"python\").mark(\"function__return\")\n{\nfilename = user_string($arg1);\nfuncname = user_string($arg2);\nlineno = $arg3;\nframeptr = $arg4\n} |  |\n|  | 如果这个文件安装在 SystemTap 的 tapset 目录下（例如 /usr/share/systemtap/tapset ），那么\n这些额外的探测点就会变得可用。\npython.function.entry(str filename, str funcname, int lineno, frameptr)\n这个探针点表示一个Python函数的执行已经开始。它只对纯Python （字节码）函数触发。\npython.function.return(str filename, str funcname, int lineno, frameptr)\n这个探针点是 python.function.return 的反义操作，表示一个 Python 函数的执行已经结束\n（或是通过 return，或是通过异常）。 它只会针对纯 Python（字节码）函数触发。\n例子\n这个SystemTap脚本使用上面的tapset来更清晰地实现上面给出的跟踪Python函数调用层次结构的例\n子，而不需要直接命名静态标记。 |  |\n|  | probe python.function.entry\n{\nprintf(\"%s => %s in %s:%d\\n\",\nthread_indent(1), funcname, filename, lineno); |  |\n\n}\nprobe python.function.return\n{\nprintf(\"%s <= %s in %s:%d\\n\",\nthread_indent(-1), funcname, filename, lineno);\n}\n下面的脚本使用上面的 tapset 来提供所有运行中的 CPython 代码的类似 top 的视图，显示了整个系\n统中每一秒内前 20 个最频繁进入的字节码帧:\nglobal fn_calls;\nprobe python.function.entry\n{\nfn_calls[pid(), filename, funcname, lineno] += 1;\n}\nprobe timer.ms(1000) {\nprintf(\"\\033[2J\\033[1;1H\") /* clear screen \\*/\nprintf(\"%6s %80s %6s %30s %6s\\n\",\n\"PID\", \"FILENAME\", \"LINE\", \"FUNCTION\", \"CALLS\")\nforeach ([pid, filename, funcname, lineno] in fn_calls- limit 20) {\nprintf(\"%6d %80s %6d %30s %6d\\n\",\npid, filename, lineno, funcname,\nfn_calls[pid, filename, funcname, lineno]);\n}\ndelete fn_calls;\n}\n\n| }\nprobe python.function.return\n{\nprintf(\"%s <= %s in %s:%d\\n\",\nthread_indent(-1), funcname, filename, lineno);\n} |\n| --- |\n| 下面的脚本使用上面的 tapset 来提供所有运行中的 CPython 代码的类似 top 的视图，显示了整个系\n统中每一秒内前 20 个最频繁进入的字节码帧: |\n| global fn_calls;\nprobe python.function.entry\n{\nfn_calls[pid(), filename, funcname, lineno] += 1;\n}\nprobe timer.ms(1000) {\nprintf(\"\\033[2J\\033[1;1H\") /* clear screen \\*/\nprintf(\"%6s %80s %6s %30s %6s\\n\",\n\"PID\", \"FILENAME\", \"LINE\", \"FUNCTION\", \"CALLS\")\nforeach ([pid, filename, funcname, lineno] in fn_calls- limit 20) {\nprintf(\"%6d %80s %6d %30s %6d\\n\",\npid, filename, lineno, funcname,\nfn_calls[pid, filename, funcname, lineno]);\n}\ndelete fn_calls;\n} |\n|  |", "metadata": {"title": "23_使用_DTrace_和_SystemTap_检测CPython", "source": "md_docs\\python_howto_md\\23_使用_DTrace_和_SystemTap_检测CPython.md", "doc_type": "指南", "language": "中文", "doc_id": "85e64d6d"}}
{"doc_id": "a1e15b66", "content": "Python 对 Linux perf 性能分析器的支持\n作者: Pablo Galindo\nLinux perf 性能分析器 是一个非常强大的工具，它允许你分析并获取有关你的应用程序运行性能的\n信息。 perf 还拥有一个非常活跃的工具生态系统可以帮助分析它所产生的数据。\n将 perf 性能分析器与 Python 应用程序配合使用的主要问题在于 perf 只能获取原生符号的信息，\n即以 C 编写的函数和过程的名称。 这意味着在你的代码中的 Python 函数名称和文件名称将不会出\n现在 perf 输出中。\n从 Python 3.12 开始，解释器可以运行于一个允许 perf 性能分析器的输出中显示 Python 函数的特\n殊模式下。 当启用此模式时，解释器将在每个 Python 函数执行之前插入一小段即时编译的代码，\n它将使用 perf 映射文件 来告知 perf 这段代码与相关联的 Python 函数之间的关系。\n备注: 对 perf 性能分析器的支持目前仅在特定架构的 Linux 上可用。 请检查 configure 构建步\n骤的输出或检查 python -m sysconfig | grep HAVE_PERF_TRAMPOLINE 的输出来确定你的系统\n是否受到支持。\n例如，考虑以下脚本:\ndef foo(n):\nresult = 0\nfor _ in range(n):\nresult += 1\nreturn result\ndef bar(n):\nfoo(n)\ndef baz(n):\nbar(n)\nif __name__ == \"__main__\":\nbaz(1000000)\n我们可以运行 perf 以 9999 赫兹的频率来对 CPU 栈追踪信息进行采样:\n$ perf record -F 9999 -g -o perf.data python my_script.py\n然后我们可以使用 perf report 来分析数据:\n$ perf report --stdio -n -g\n# Children Self Samples Command Shared Object Symbol\n# ........ ........ ............ .......... .................. ..............\n#\n91.08% 0.00% 0 python.exe python.exe [.] _start\n\n| Python 对 Linux perf 性能分析器的支持\n作者: Pablo Galindo\nLinux perf 性能分析器 是一个非常强大的工具，它允许你分析并获取有关你的应用程序运行性能的\n信息。 perf 还拥有一个非常活跃的工具生态系统可以帮助分析它所产生的数据。\n将 perf 性能分析器与 Python 应用程序配合使用的主要问题在于 perf 只能获取原生符号的信息，\n即以 C 编写的函数和过程的名称。 这意味着在你的代码中的 Python 函数名称和文件名称将不会出\n现在 perf 输出中。\n从 Python 3.12 开始，解释器可以运行于一个允许 perf 性能分析器的输出中显示 Python 函数的特\n殊模式下。 当启用此模式时，解释器将在每个 Python 函数执行之前插入一小段即时编译的代码，\n它将使用 perf 映射文件 来告知 perf 这段代码与相关联的 Python 函数之间的关系。\n备注: 对 perf 性能分析器的支持目前仅在特定架构的 Linux 上可用。 请检查 configure 构建步\n骤的输出或检查 python -m sysconfig | grep HAVE_PERF_TRAMPOLINE 的输出来确定你的系统\n是否受到支持。\n例如，考虑以下脚本:\ndef foo(n):\nresult = 0\nfor _ in range(n):\nresult += 1\nreturn result\ndef bar(n):\nfoo(n)\ndef baz(n):\nbar(n)\nif __name__ == \"__main__\":\nbaz(1000000)\n我们可以运行 perf 以 9999 赫兹的频率来对 CPU 栈追踪信息进行采样:\n$ perf record -F 9999 -g -o perf.data python my_script.py\n然后我们可以使用 perf report 来分析数据:\n$ perf report --stdio -n -g\n# Children Self Samples Command Shared Object Symbol\n# ........ ........ ............ .......... .................. ..............\n#\n91.08% 0.00% 0 python.exe python.exe [.] _start |  |  |\n| --- | --- | --- |\n|  | Python 对 Linux perf 性能分析器的支持\n作者: Pablo Galindo\nLinux perf 性能分析器 是一个非常强大的工具，它允许你分析并获取有关你的应用程序运行性能的\n信息。 perf 还拥有一个非常活跃的工具生态系统可以帮助分析它所产生的数据。\n将 perf 性能分析器与 Python 应用程序配合使用的主要问题在于 perf 只能获取原生符号的信息，\n即以 C 编写的函数和过程的名称。 这意味着在你的代码中的 Python 函数名称和文件名称将不会出\n现在 perf 输出中。\n从 Python 3.12 开始，解释器可以运行于一个允许 perf 性能分析器的输出中显示 Python 函数的特\n殊模式下。 当启用此模式时，解释器将在每个 Python 函数执行之前插入一小段即时编译的代码，\n它将使用 perf 映射文件 来告知 perf 这段代码与相关联的 Python 函数之间的关系。 |  |\n|  | 备注: 对 perf 性能分析器的支持目前仅在特定架构的 Linux 上可用。 请检查 configure 构建步\n骤的输出或检查 python -m sysconfig | grep HAVE_PERF_TRAMPOLINE 的输出来确定你的系统\n是否受到支持。 |  |\n|  | 例如，考虑以下脚本: |  |\n|  | def foo(n):\nresult = 0\nfor _ in range(n):\nresult += 1\nreturn result\ndef bar(n):\nfoo(n)\ndef baz(n):\nbar(n)\nif __name__ == \"__main__\":\nbaz(1000000) |  |\n|  | 我们可以运行 perf 以 9999 赫兹的频率来对 CPU 栈追踪信息进行采样: |  |\n|  | $ perf record -F 9999 -g -o perf.data python my_script.py |  |\n|  | 然后我们可以使用 perf report 来分析数据: |  |\n|  | $ perf report --stdio -n -g\n# Children Self Samples Command Shared Object Symbol\n# ........ ........ ............ .......... .................. ..............\n#\n91.08% 0.00% 0 python.exe python.exe [.] _start |  |\n\n|\n---_start\n|\n--90.71%--__libc_start_main\nPy_BytesMain\n|\n|--56.88%--pymain_run_python.constprop.0\n| |\n| |--56.13%--_PyRun_AnyFileObject\n| | _PyRun_SimpleFileObject\n| | |\n| | |--55.02%--run_mod\n| | | |\n| | | --54.65%--PyEval_EvalCod\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | |\n| | | |--51.67%--_Py\n| | | | |\n| | | | |--\n| | | | |\n| | | | |\n...\n如你所见，Python 函数不会显示在输出中，只有 _PyEval_EvalFrameDefault (评估 Python 字节码\n的函数) 会显示出来。 不幸的是那没有什么用处因为所有 Python 函数都使用相同的 C 函数来评估字\n节码所以我们无法知道哪个 Python 函数与哪个字节码评估函数相对应。\n相反，如果我们在启用 perf 支持的情况下运行相同的实验代码我们将获得:\n$ perf report --stdio -n -g\n# Children Self Samples Command Shared Object Symbol\n# ........ ........ ............ .......... .................. ..............\n#\n90.58% 0.36% 1 python.exe python.exe [.] _start\n|\n---_start\n|\n--89.86%--__libc_start_main\nPy_BytesMain\n|\n|--55.43%--pymain_run_python.constprop.0\n| |\n| |--54.71%--_PyRun_AnyFileObject\n| | _PyRun_SimpleFileObject\n| | |\n| | |--53.62%--run_mod\n| | | |\n| | | --53.26%--PyEval_EvalCod\n| | | py::<module>:/\n\n|  | |\n---_start\n|\n--90.71%--__libc_start_main\nPy_BytesMain\n|\n|--56.88%--pymain_run_python.constprop.0\n| |\n| |--56.13%--_PyRun_AnyFileObject\n| | _PyRun_SimpleFileObject\n| | |\n| | |--55.02%--run_mod\n| | | |\n| | | --54.65%--PyEval_EvalCod\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | |\n| | | |--51.67%--_Py\n| | | | |\n| | | | |--\n| | | | |\n| | | | |\n... |  |  |\n| --- | --- | --- | --- |\n|  | 如你所见，Python 函数不会显示在输出中，只有 _PyEval_EvalFrameDefault (评估 Python 字节码\n的函数) 会显示出来。 不幸的是那没有什么用处因为所有 Python 函数都使用相同的 C 函数来评估字\n节码所以我们无法知道哪个 Python 函数与哪个字节码评估函数相对应。\n相反，如果我们在启用 perf 支持的情况下运行相同的实验代码我们将获得: |  |  |\n|  |  |  |  |\n|  | $ perf report --stdio -n -g\n# Children Self Samples Command Shared Object Symbol\n# ........ ........ ............ .......... .................. ..............\n#\n90.58% 0.36% 1 python.exe python.exe [.] _start\n|\n---_start\n|\n--89.86%--__libc_start_main\nPy_BytesMain\n|\n|--55.43%--pymain_run_python.constprop.0\n| |\n| |--54.71%--_PyRun_AnyFileObject\n| | _PyRun_SimpleFileObject\n| | |\n| | |--53.62%--run_mod\n| | | |\n| | | --53.26%--PyEval_EvalCod\n| | | py::<module>:/ |  |  |\n\n| perf |\n| --- |\n|  |\n\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | py::baz:/src/s\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | py::bar:/src/s\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | py::foo:/src/s\n| | | |\n| | | |--51.81%--_Py\n| | | | |\n| | | | |--\n| | | | |\n| | | | |\n如何启用 perf 性能分析支持\n要启动 perf 性能分析支持可以通过使用环境变量 PYTHONPERFSUPPORT 或 -X perf 选项，或者动\n态地使用 sys.activate_stack_trampoline() 和 sys.deactivate_stack_trampoline() 来运\n行。\nsys 函数的优先级高于 -X 选项，-X 选项的优先级高于环境变量。\n示例，使用环境变量:\n$ PYTHONPERFSUPPORT=1 perf record -F 9999 -g -o perf.data python my_script.py\n$ perf report -g -i perf.data\n示例，使用 -X 选项:\n$ perf record -F 9999 -g -o perf.data python -X perf my_script.py\n$ perf report -g -i perf.data\n示例，在文件 example.py 中使用 sys API:\nimport sys\nsys.activate_stack_trampoline(\"perf\")\ndo_profiled_stuff()\nsys.deactivate_stack_trampoline()\nnon_profiled_stuff()\n...然后:\n$ perf record -F 9999 -g -o perf.data python ./example.py\n$ perf report -g -i perf.data\n\n|  | | | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | py::baz:/src/s\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | py::bar:/src/s\n| | | _PyEval_EvalFr\n| | | PyObject_Vecto\n| | | _PyEval_Vector\n| | | py::foo:/src/s\n| | | |\n| | | |--51.81%--_Py\n| | | | |\n| | | | |--\n| | | | |\n| | | | | |  |  |\n| --- | --- | --- | --- |\n|  | 如何启用 perf 性能分析支持\n要启动 perf 性能分析支持可以通过使用环境变量 PYTHONPERFSUPPORT 或 -X perf 选项，或者动\n态地使用 sys.activate_stack_trampoline() 和 sys.deactivate_stack_trampoline() 来运\n行。\nsys 函数的优先级高于 -X 选项，-X 选项的优先级高于环境变量。\n示例，使用环境变量: |  |  |\n|  | $ PYTHONPERFSUPPORT=1 perf record -F 9999 -g -o perf.data python my_script.py\n$ perf report -g -i perf.data |  |  |\n|  | 示例，使用 -X 选项: |  |  |\n|  | $ perf record -F 9999 -g -o perf.data python -X perf my_script.py\n$ perf report -g -i perf.data |  |  |\n|  |  |  |  |\n|  | 示例，在文件 example.py 中使用 sys API: |  |  |\n|  | import sys\nsys.activate_stack_trampoline(\"perf\")\ndo_profiled_stuff()\nsys.deactivate_stack_trampoline()\nnon_profiled_stuff() |  |  |\n|  | ...然后: |  |  |\n|  | $ perf record -F 9999 -g -o perf.data python ./example.py\n$ perf report -g -i perf.data |  |  |\n|  |  |  |  |\n\n如何获取最佳结果\n要获取最佳结果，Python 应当使用 CFLAGS=\"-fno-omit-frame-pointer -mno-omit-leaf-frame-\npointer\" 来编译因为这将允许性能分析器仅使用帧指针而不是基于 DWARF 调试信息进行展开。 这\n是因为被插入以允许 perf 支持的代码是动态生成的所以它没有任何 DWARF 调试信息可用。\n你可以通过运行以下代码来检查你的系统是否为附带此旗标来编译的:\n$ python -m sysconfig | grep 'no-omit-frame-pointer'\n如果你没有看到任何输出则意味着你的解释器没有附带帧指针来编译因而它将无法在 perf 的输出中\n显示 Python 函数。\n如何在不带帧指针的情况下使用\n如果你使用在不带帧指针的情况下编译的 Python 解释器，你仍然可以使用 perf 性能分析器，但会\n有较高的资源开销因为 Python 需要为每个 Python 函数即时生成回撤信息。 此外，perf 将花费更\n多时间来处理数据因为它需要使用 DWARF 调试信息来回撤栈而这是一个缓慢的过程。\n要启用此模式，你可以使用环境变量 PYTHON_PERF_JIT_SUPPORT 或 -X perf_jit 选项，它将为\nperf 性能分析器启用 JIT 模式。\n备注: 由于 perf 工具的一个程序错误，只有 perf 版本号高于 v6.8 才能使用 JIT 模式。 修复也\n向下移植到了此工具的 v6.7.2 版。\n请注意在检测 perf 工具的版本时（这可通过运行 perf version 来完成）你必须将某些发行版\n添加包括了 - 字符的自定义版本号纳入考虑。 这意味着 perf 6.7-3 不一定等于 perf 6.7.3。\n当使用 perf JIT 模式时，在你运行 perf report 之前你还需要一个额外的步骤。 你需要调用 perf\ninject 命令来将 JIT 信息注入 perf.data 文件。:\n$ perf record -F 9999 -g -k 1 --call-graph dwarf -o perf.data python -Xperf_jit my\n$ perf inject -i perf.data --jit --output perf.jit.data\n$ perf report -g -i perf.jit.data\n或者使用环境变量:\n$ PYTHON_PERF_JIT_SUPPORT=1 perf record -F 9999 -g --call-graph dwarf -o perf.data\n$ perf inject -i perf.data --jit --output perf.jit.data\n$ perf report -g -i perf.jit.data\nperf inject --jit 命令将读取 perf.data，自动获取 Python 创建的 perf 转储文件（在\n/tmp/perf-$PID.dump 中），然后创建将所有 JIT 信息合并到一起的 perf.jit.data 文件。 它还\n会在当前目录下创建大量 jitted-XXXX-N.so 文件，它们是 Python 所创建的所有 JIT 中间数据的\nELF 映像。\n\n|  |  |  | 如何获取最佳结果\n要获取最佳结果，Python 应当使用 CFLAGS=\"-fno-omit-frame-pointer -mno-omit-leaf-frame-\npointer\" 来编译因为这将允许性能分析器仅使用帧指针而不是基于 DWARF 调试信息进行展开。 这\n是因为被插入以允许 perf 支持的代码是动态生成的所以它没有任何 DWARF 调试信息可用。\n你可以通过运行以下代码来检查你的系统是否为附带此旗标来编译的: |  |  |  |  |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  |  |  |  | CFLAGS=\"-fno-omit-frame-pointer -mno-omit-leaf-frame- |  |  |  |\n|  |  |  |  |  |  |  |  |\n|  |  |  | pointer\" |  |  |  |  |\n|  |  |  |  |  |  |  |  |\n|  |  |  | $ python -m sysconfig | grep 'no-omit-frame-pointer' |  |  |  |  |\n|  |  |  | 如果你没有看到任何输出则意味着你的解释器没有附带帧指针来编译因而它将无法在 perf 的输出中\n显示 Python 函数。\n如何在不带帧指针的情况下使用\n如果你使用在不带帧指针的情况下编译的 Python 解释器，你仍然可以使用 perf 性能分析器，但会\n有较高的资源开销因为 Python 需要为每个 Python 函数即时生成回撤信息。 此外，perf 将花费更\n多时间来处理数据因为它需要使用 DWARF 调试信息来回撤栈而这是一个缓慢的过程。\n要启用此模式，你可以使用环境变量 PYTHON_PERF_JIT_SUPPORT 或 -X perf_jit 选项，它将为\nperf 性能分析器启用 JIT 模式。 |  |  |  |  |\n|  |  |  | 备注: 由于 perf 工具的一个程序错误，只有 perf 版本号高于 v6.8 才能使用 JIT 模式。 修复也\n向下移植到了此工具的 v6.7.2 版。\n请注意在检测 perf 工具的版本时（这可通过运行 perf version 来完成）你必须将某些发行版\n添加包括了 - 字符的自定义版本号纳入考虑。 这意味着 perf 6.7-3 不一定等于 perf 6.7.3。 |  |  |  |  |\n|  |  |  | 当使用 perf JIT 模式时，在你运行 perf report 之前你还需要一个额外的步骤。 你需要调用 perf\ninject 命令来将 JIT 信息注入 perf.data 文件。: |  |  |  |  |\n|  |  |  |  |  | perf |  |  |\n|  |  |  |  |  |  |  |  |\n|  |  |  | inject |  |  |  |  |\n|  |  |  |  |  |  |  |  |\n|  |  |  | $ perf record -F 9999 -g -k 1 --call-graph dwarf -o perf.data python -Xperf_jit my\n$ perf inject -i perf.data --jit --output perf.jit.data\n$ perf report -g -i perf.jit.data |  |  |  |  |\n|  |  |  | 或者使用环境变量: |  |  |  |  |\n|  |  |  | $ PYTHON_PERF_JIT_SUPPORT=1 perf record -F 9999 -g --call-graph dwarf -o perf.data\n$ perf inject -i perf.data --jit --output perf.jit.data\n$ perf report -g -i perf.jit.data |  |  |  |  |\n|  |  |  | perf inject --jit 命令将读取 perf.data，自动获取 Python 创建的 perf 转储文件（在\n/tmp/perf-$PID.dump 中），然后创建将所有 JIT 信息合并到一起的 perf.jit.data 文件。 它还\n会在当前目录下创建大量 jitted-XXXX-N.so 文件，它们是 Python 所创建的所有 JIT 中间数据的\nELF 映像。 |  |  |  |  |\n\n警告: 当使用 --call-graph dwarf 时，perf 工具将对被分析进程的栈打快照并将信息保存在\nperf.data 文件中。 在默认情况下，栈转储的大小为 8192 字节，但你可以通过额外传入一个逗\n号加数值如 --call-graph dwarf,16384 来改变这个大小。\n栈转储的大小很重要因为如果这个值太小 perf 将无法展开栈信息而输出将不完整。 另一方面，\n如果这个值太大，那么 perf 将无法按需以足够的频率对进程执行采样因为那样资源开销会过\n高。\n栈大小在对使用较低优化级别 (如 -O0) 编译的 Python 代码进行性能分析时更为重要，因为这类\n构建版往往有更大的栈帧。 如果你是使用 -O0 来编译 Python 并且没有在你的性能分析输出中看\n到 Python 函数，请尝试将栈转储大小增加到 65528 字节 (最大值):\n$ perf record -F 9999 -g -k 1 --call-graph dwarf,65528 -o perf.data python -Xper\n不同的编译旗标可能显著地影响栈大小：\n使用 -O0 构建通常会比使用 -O1 或更高的值具有大得多的栈帧数。\n添加优化 (-O1, -O2 等) 通常会减小栈大小\n帧指针 (-fno-omit-frame-pointer) 通常会提供更可靠的栈展开\n\n| 警告: 当使用 --call-graph dwarf 时，perf 工具将对被分析进程的栈打快照并将信息保存在\nperf.data 文件中。 在默认情况下，栈转储的大小为 8192 字节，但你可以通过额外传入一个逗\n号加数值如 --call-graph dwarf,16384 来改变这个大小。\n栈转储的大小很重要因为如果这个值太小 perf 将无法展开栈信息而输出将不完整。 另一方面，\n如果这个值太大，那么 perf 将无法按需以足够的频率对进程执行采样因为那样资源开销会过\n高。\n栈大小在对使用较低优化级别 (如 -O0) 编译的 Python 代码进行性能分析时更为重要，因为这类\n构建版往往有更大的栈帧。 如果你是使用 -O0 来编译 Python 并且没有在你的性能分析输出中看\n到 Python 函数，请尝试将栈转储大小增加到 65528 字节 (最大值):\n$ perf record -F 9999 -g -k 1 --call-graph dwarf,65528 -o perf.data python -Xper\n不同的编译旗标可能显著地影响栈大小：\n使用 -O0 构建通常会比使用 -O1 或更高的值具有大得多的栈帧数。\n添加优化 (-O1, -O2 等) 通常会减小栈大小\n帧指针 (-fno-omit-frame-pointer) 通常会提供更可靠的栈展开 | 警告: 当使用 --call-graph dwarf 时，perf 工具将对被分析进程的栈打快照并将信息保存在\nperf.data 文件中。 在默认情况下，栈转储的大小为 8192 字节，但你可以通过额外传入一个逗\n号加数值如 --call-graph dwarf,16384 来改变这个大小。\n栈转储的大小很重要因为如果这个值太小 perf 将无法展开栈信息而输出将不完整。 另一方面，\n如果这个值太大，那么 perf 将无法按需以足够的频率对进程执行采样因为那样资源开销会过\n高。\n栈大小在对使用较低优化级别 (如 -O0) 编译的 Python 代码进行性能分析时更为重要，因为这类\n构建版往往有更大的栈帧。 如果你是使用 -O0 来编译 Python 并且没有在你的性能分析输出中看\n到 Python 函数，请尝试将栈转储大小增加到 65528 字节 (最大值):\n$ perf record -F 9999 -g -k 1 --call-graph dwarf,65528 -o perf.data python -Xper\n不同的编译旗标可能显著地影响栈大小：\n使用 -O0 构建通常会比使用 -O1 或更高的值具有大得多的栈帧数。\n添加优化 (-O1, -O2 等) 通常会减小栈大小\n帧指针 (-fno-omit-frame-pointer) 通常会提供更可靠的栈展开 |  |  |  |  |\n| --- | --- | --- | --- | --- | --- |\n|  |  | $ perf record -F 9999 -g -k 1 --call-graph dwarf,65528 -o perf.data python -Xper |  |  |  |", "metadata": {"title": "24_Python_对_Linux_perf_性能分析器的支持", "source": "md_docs\\python_howto_md\\24_Python_对_Linux_perf_性能分析器的支持.md", "doc_type": "指南", "language": "中文", "doc_id": "a1e15b66"}}
{"doc_id": "403cbd9d", "content": "远程调试附加协议\n此协议使得外部工具能够附加到正在运行的 CPython 进程并远程执行 Python 代码。\n大多数平台上需要提升的权限才能附加到另一个 Python 进程。\n权限需求\n在大多数平台上，需要提升的权限才能附加到一个正在运行的 Python 进程以远程调试。具体的需求\n和故障排除方法取决于您的操作系统：\nLinux\n追踪进程必须拥有 CAP_SYS_PTRACE 能力或等价的权限。你只能追踪你拥有且可发送信号的进程。\n如果该进程正被追踪或者在 set-user-ID 或 set-group-ID 下运行，追踪可能失败。Yama 等安全模块\n可能会进一步限制追踪。\n若要暂时放松 ptrace 限制（直到重启），可以运行：\necho 0 | sudo tee /proc/sys/kernel/yama/ptrace_scope\n备注: 禁用 ptrace_scope 会降低系统安全强度，因而只应在受信任的环境中进行。\n若在容器中运行，使用 --cap-add=SYS_PTRACE 或者 --privileged，并按需以 root 身份运行。\n尝试用提升的权限重新运行命令：\nsudo -E !!\nmacOS\n要附加到另一个进程，您通常需要通过使用 sudo 或以 root 身份运行，从而以提升的权限运行调试\n工具。\n即使您拥有要附加到的进程，在 macOS 上调试仍可能因系统安全限制被阻止，除非使用 root 权限\n运行调试器。\nWindows\n要附加到另一个进程，您通常需要以管理员权限运行调试工具：以管理员身份运行命令提示符或者\n终端。\n使用管理员权限时，除非启用 SeDebugPrivilege 权限，否则有的进程仍可能无法被访问。\n\n| 远程调试附加协议\n此协议使得外部工具能够附加到正在运行的 CPython 进程并远程执行 Python 代码。\n大多数平台上需要提升的权限才能附加到另一个 Python 进程。\n权限需求\n在大多数平台上，需要提升的权限才能附加到一个正在运行的 Python 进程以远程调试。具体的需求\n和故障排除方法取决于您的操作系统：\nLinux\n追踪进程必须拥有 CAP_SYS_PTRACE 能力或等价的权限。你只能追踪你拥有且可发送信号的进程。\n如果该进程正被追踪或者在 set-user-ID 或 set-group-ID 下运行，追踪可能失败。Yama 等安全模块\n可能会进一步限制追踪。\n若要暂时放松 ptrace 限制（直到重启），可以运行：\necho 0 | sudo tee /proc/sys/kernel/yama/ptrace_scope |\n| --- |\n| 备注: 禁用 ptrace_scope 会降低系统安全强度，因而只应在受信任的环境中进行。 |\n| 若在容器中运行，使用 --cap-add=SYS_PTRACE 或者 --privileged，并按需以 root 身份运行。\n尝试用提升的权限重新运行命令：\nsudo -E !!\nmacOS\n要附加到另一个进程，您通常需要通过使用 sudo 或以 root 身份运行，从而以提升的权限运行调试\n工具。\n即使您拥有要附加到的进程，在 macOS 上调试仍可能因系统安全限制被阻止，除非使用 root 权限\n运行调试器。\nWindows\n要附加到另一个进程，您通常需要以管理员权限运行调试工具：以管理员身份运行命令提示符或者\n终端。\n使用管理员权限时，除非启用 SeDebugPrivilege 权限，否则有的进程仍可能无法被访问。 |\n\n要解决文件或文件夹访问的问题，请调整安全权限：\n1. 右键文件或文件夹并选择 属性。\n2. 在 安全 选项卡中查看有访问权限的用户和用户组。\n3. 点击 编辑 以调整权限。\n4. 选择您的用户账户。\n5. 在 权限 中，按需勾选 读取 或者 完全控制。\n6. 在点击 应用 后点击 确定。\n备注: 在继续前，请确保您已满足所有 权限需求。\n本节描述了低级协议，该协议使外部工具能够在运行的CPython进程中注入和执行Python脚本。\n该机制构成了 sys.remote_exec() 函数的基础，该函数用于指示远程Python进程执行指定的 .py\n文件。但本节并不记录该函数的具体用法，而是详细阐述其底层协议的工作原理——该协议以目标\nPython进程的 pid 和待执行的Python源文件路径作为输入。这些信息支持协议的独立重新实现，且\n不受编程语言限制。\n警告: 注入脚本的执行依赖于解释器到达安全的求值点。因此，实际执行时机可能会因目标进程\n的运行时状态而产生延迟。\n一旦注入，脚本将在解释器下一次达到安全求值点时在目标进程中执行。这种方法能够在不修改运\n行中Python应用的行为或结构的情况下实现远程执行功能。\n后续各节提供了该协议的逐步描述，包括定位内存中解释器结构的技术、安全访问内部字段以及触\n发代码执行的方法。适用的情况下会注明平台特定的变体，并包含示例实现以澄清每个操作。\n定位PyRuntime结构\nCPython将 PyRuntime 结构放置在一个专用的二进制节中，以帮助外部工具在运行时找到它。该节\n的名称和格式因平台而异。例如，在ELF系统上使用 .PyRuntime，在macOS上使用\n__DATA,__PyRuntime。工具可以通过检查磁盘上的二进制文件来找到该结构的偏移量。\nPyRuntime 结构包含 CPython 的全局解释器状态，并提供对其他内部数据的访问，包括解释器列\n表、线程状态和调试器支持字段。\n要处理远程Python进程，调试器首先必须在目标进程中找到 PyRuntime 结构的内存地址。这个地址\n不能硬编码或通过符号名计算，因为它取决于操作系统加载二进制文件的位置。\n查找 PyRuntime 的方法取决于平台，但一般步骤是相同的：\n1. 找到Python二进制文件或共享库在目标进程中加载的基址。\n2. 使用磁盘上的二进制文件定位 .PyRuntime 段的偏移。\n3. 将段偏移加到基址上，计算出内存中的地址。\n以下部分将说明在每个受支持平台上如何进行此操作，并包括示例代码。\n\n|  | 要解决文件或文件夹访问的问题，请调整安全权限：\n1. 右键文件或文件夹并选择 属性。\n2. 在 安全 选项卡中查看有访问权限的用户和用户组。\n3. 点击 编辑 以调整权限。\n4. 选择您的用户账户。\n5. 在 权限 中，按需勾选 读取 或者 完全控制。\n6. 在点击 应用 后点击 确定。 |  |\n| --- | --- | --- |\n|  | 备注: 在继续前，请确保您已满足所有 权限需求。 |  |\n|  | 本节描述了低级协议，该协议使外部工具能够在运行的CPython进程中注入和执行Python脚本。\n该机制构成了 sys.remote_exec() 函数的基础，该函数用于指示远程Python进程执行指定的 .py\n文件。但本节并不记录该函数的具体用法，而是详细阐述其底层协议的工作原理——该协议以目标\nPython进程的 pid 和待执行的Python源文件路径作为输入。这些信息支持协议的独立重新实现，且\n不受编程语言限制。 |  |\n|  | 警告: 注入脚本的执行依赖于解释器到达安全的求值点。因此，实际执行时机可能会因目标进程\n的运行时状态而产生延迟。 |  |\n|  | 一旦注入，脚本将在解释器下一次达到安全求值点时在目标进程中执行。这种方法能够在不修改运\n行中Python应用的行为或结构的情况下实现远程执行功能。\n后续各节提供了该协议的逐步描述，包括定位内存中解释器结构的技术、安全访问内部字段以及触\n发代码执行的方法。适用的情况下会注明平台特定的变体，并包含示例实现以澄清每个操作。\n定位PyRuntime结构\nCPython将 PyRuntime 结构放置在一个专用的二进制节中，以帮助外部工具在运行时找到它。该节\n的名称和格式因平台而异。例如，在ELF系统上使用 .PyRuntime，在macOS上使用\n__DATA,__PyRuntime。工具可以通过检查磁盘上的二进制文件来找到该结构的偏移量。\nPyRuntime 结构包含 CPython 的全局解释器状态，并提供对其他内部数据的访问，包括解释器列\n表、线程状态和调试器支持字段。\n要处理远程Python进程，调试器首先必须在目标进程中找到 PyRuntime 结构的内存地址。这个地址\n不能硬编码或通过符号名计算，因为它取决于操作系统加载二进制文件的位置。\n查找 PyRuntime 的方法取决于平台，但一般步骤是相同的：\n1. 找到Python二进制文件或共享库在目标进程中加载的基址。\n2. 使用磁盘上的二进制文件定位 .PyRuntime 段的偏移。\n3. 将段偏移加到基址上，计算出内存中的地址。\n以下部分将说明在每个受支持平台上如何进行此操作，并包括示例代码。 |  |\n\nLinux (ELF)\n在Linux上查找 PyRuntime 结构：\n1. 读取进程的内存映射（例如，/proc/<pid>/maps）以找到Python可执行文件或 libpython\n加载的地址。\n2. 解析二进制文件中的ELF段头，获取 .PyRuntime 段的偏移。\n3. 将此偏移加到步骤1中的基址上，得到 PyRuntime 的内存地址。\n以下是一个示例实现：\ndef find_py_runtime_linux(pid: int) -> int:\n# 步骤 1：尝试在内存中找到 Python 可执行文件\nbinary_path, base_address = find_mapped_binary(\npid, name_contains=\"python\"\n)\n# 步骤2：如果找不到可执行文件，则回退到共享库\nif binary_path is None:\nbinary_path, base_address = find_mapped_binary(\npid, name_contains=\"libpython\"\n)\n# 步骤3：解析ELF头以获取.PyRuntime节的偏移量\nsection_offset = parse_elf_section_offset(\nbinary_path, \".PyRuntime\"\n)\n# 步骤4：计算内存中的PyRuntime地址\nreturn base_address + section_offset\n在Linux系统上，有两种主要方法读取另一个进程的内存。第一种是通过 /proc 文件系统，具体来说\n是通过读取 /proc/[pid]/mem ，它提供了对进程内存的直接访问。这需要适当的权限——要么是与\n目标进程相同的用户，要么拥有root权限。第二种方法是使用 process_vm_readv() 系统调用，它\n提供了在进程间复制内存的更高效方式。虽然ptrace的 PTRACE_PEEKTEXT 操作也可以用来读取内\n存，但它显著较慢，因为它一次只读取一个字，并且需要在跟踪器和被跟踪进程之间进行多次上下\n文切换。\n为了解析ELF节，过程包括从磁盘上的二进制文件中读取和解释ELF文件格式结构。ELF头部包含一个\n指向节头表的指针。每个节头包含有关节的元数据，包括其名称（存储在单独的字符串表中）、偏\n移量和大小。要查找特定节（如.PyRuntime），需要遍历这些头部并匹配节名称。节头然后提供该\n节在文件中存在的偏移量，这可以用来计算二进制文件加载到内存时的运行时地址。\n你可以在`ELF规范 <https://en.wikipedia.org/wiki/Executable_and_Linkable_Format>`_中了解更多关\n于ELF文件格式的信息。\nmacOS (Mach-O)\n在macOS上查找 PyRuntime 结构：\n\n|  | Linux (ELF)\n在Linux上查找 PyRuntime 结构：\n1. 读取进程的内存映射（例如，/proc/<pid>/maps）以找到Python可执行文件或 libpython\n加载的地址。\n2. 解析二进制文件中的ELF段头，获取 .PyRuntime 段的偏移。\n3. 将此偏移加到步骤1中的基址上，得到 PyRuntime 的内存地址。\n以下是一个示例实现： |  |\n| --- | --- | --- |\n|  | def find_py_runtime_linux(pid: int) -> int:\n# 步骤 1：尝试在内存中找到 Python 可执行文件\nbinary_path, base_address = find_mapped_binary(\npid, name_contains=\"python\"\n)\n# 步骤2：如果找不到可执行文件，则回退到共享库\nif binary_path is None:\nbinary_path, base_address = find_mapped_binary(\npid, name_contains=\"libpython\"\n)\n# 步骤3：解析ELF头以获取.PyRuntime节的偏移量\nsection_offset = parse_elf_section_offset(\nbinary_path, \".PyRuntime\"\n)\n# 步骤4：计算内存中的PyRuntime地址\nreturn base_address + section_offset |  |\n|  | 在Linux系统上，有两种主要方法读取另一个进程的内存。第一种是通过 /proc 文件系统，具体来说\n是通过读取 /proc/[pid]/mem ，它提供了对进程内存的直接访问。这需要适当的权限——要么是与\n目标进程相同的用户，要么拥有root权限。第二种方法是使用 process_vm_readv() 系统调用，它\n提供了在进程间复制内存的更高效方式。虽然ptrace的 PTRACE_PEEKTEXT 操作也可以用来读取内\n存，但它显著较慢，因为它一次只读取一个字，并且需要在跟踪器和被跟踪进程之间进行多次上下\n文切换。\n为了解析ELF节，过程包括从磁盘上的二进制文件中读取和解释ELF文件格式结构。ELF头部包含一个\n指向节头表的指针。每个节头包含有关节的元数据，包括其名称（存储在单独的字符串表中）、偏\n移量和大小。要查找特定节（如.PyRuntime），需要遍历这些头部并匹配节名称。节头然后提供该\n节在文件中存在的偏移量，这可以用来计算二进制文件加载到内存时的运行时地址。\n你可以在`ELF规范 <https://en.wikipedia.org/wiki/Executable_and_Linkable_Format>`_中了解更多关\n于ELF文件格式的信息。\nmacOS (Mach-O)\n在macOS上查找 PyRuntime 结构： |  |\n\n1. 调用 task_for_pid() 以获取目标进程的 mach_port_t 任务端口。此句柄用于通过\nmach_vm_read_overwrite 和 mach_vm_region 等API读取内存。\n2. 扫描内存区域，找到包含Python可执行文件或 libpython 的区域。\n3. 从磁盘加载二进制文件并解析Mach-O头部，以在 __DATA 段中找到名为 PyRuntime 的节。在\nmacOS上，符号名称自动以一个下划线为前缀，因此 PyRuntime 符号在符号表中显示为\n``_PyRuntime``，但节名称不受影响。\n以下是一个示例实现：\ndef find_py_runtime_macos(pid: int) -> int:\n# 步骤 1：访问进程的内存\nhandle = get_memory_access_handle(pid)\n# 步骤 2：尝试在内存中找到 Python 可执行文件\nbinary_path, base_address = find_mapped_binary(\nhandle, name_contains=\"python\"\n)\n# 步骤3：如果找不到可执行文件，则回退到libpython\nif binary_path is None:\nbinary_path, base_address = find_mapped_binary(\nhandle, name_contains=\"libpython\"\n)\n# 步骤4：解析Mach-O头以获取__DATA,__PyRuntime段的偏移量\nsection_offset = parse_macho_section_offset(\nbinary_path, \"__DATA\", \"__PyRuntime\"\n)\n# 步骤5：计算内存中的PyRuntime地址\nreturn base_address + section_offset\n在macOS上，访问另一个进程的内存需要使用Mach-O特定的API和文件格式。第一步是通过\ntask_for_pid() 获取 task_port 句柄，这提供了对目标进程内存空间的访问。此句柄通过\nmach_vm_read_overwrite() 等API启用内存操作。\n可以使用 mach_vm_region() 检查进程内存，以扫描虚拟内存空间，而 proc_regionfilename()\n帮助识别每个内存区域加载了哪些二进制文件。当找到 Python 二进制文件或库时，需要解析其\nMach-O 头部以定位 PyRuntime 结构。\nMach-O 格式将代码和数据组织到段和节中。PyRuntime 结构位于 __DATA 段中的名为\n__PyRuntime 的节内。实际的运行时地址计算涉及找到作为二进制文件基址的 __TEXT 段，然后定\n位包含目标节的 __DATA 段。最终地址是通过将基址与 Mach-O 头部中的适当节偏移量组合来计算\n的。\n请注意，在 macOS 上访问另一个进程的内存通常需要提升权限——要么是 root 访问权限，要么是\n授予调试进程的特殊安全权限。\nWindows (PE)\n在 Windows 上查找 PyRuntime 结构：\n\n|  | 1. 调用 task_for_pid() 以获取目标进程的 mach_port_t 任务端口。此句柄用于通过\nmach_vm_read_overwrite 和 mach_vm_region 等API读取内存。\n2. 扫描内存区域，找到包含Python可执行文件或 libpython 的区域。\n3. 从磁盘加载二进制文件并解析Mach-O头部，以在 __DATA 段中找到名为 PyRuntime 的节。在\nmacOS上，符号名称自动以一个下划线为前缀，因此 PyRuntime 符号在符号表中显示为\n``_PyRuntime``，但节名称不受影响。\n以下是一个示例实现： |  |\n| --- | --- | --- |\n|  | def find_py_runtime_macos(pid: int) -> int:\n# 步骤 1：访问进程的内存\nhandle = get_memory_access_handle(pid)\n# 步骤 2：尝试在内存中找到 Python 可执行文件\nbinary_path, base_address = find_mapped_binary(\nhandle, name_contains=\"python\"\n)\n# 步骤3：如果找不到可执行文件，则回退到libpython\nif binary_path is None:\nbinary_path, base_address = find_mapped_binary(\nhandle, name_contains=\"libpython\"\n)\n# 步骤4：解析Mach-O头以获取__DATA,__PyRuntime段的偏移量\nsection_offset = parse_macho_section_offset(\nbinary_path, \"__DATA\", \"__PyRuntime\"\n)\n# 步骤5：计算内存中的PyRuntime地址\nreturn base_address + section_offset |  |\n|  | 在macOS上，访问另一个进程的内存需要使用Mach-O特定的API和文件格式。第一步是通过\ntask_for_pid() 获取 task_port 句柄，这提供了对目标进程内存空间的访问。此句柄通过\nmach_vm_read_overwrite() 等API启用内存操作。\n可以使用 mach_vm_region() 检查进程内存，以扫描虚拟内存空间，而 proc_regionfilename()\n帮助识别每个内存区域加载了哪些二进制文件。当找到 Python 二进制文件或库时，需要解析其\nMach-O 头部以定位 PyRuntime 结构。\nMach-O 格式将代码和数据组织到段和节中。PyRuntime 结构位于 __DATA 段中的名为\n__PyRuntime 的节内。实际的运行时地址计算涉及找到作为二进制文件基址的 __TEXT 段，然后定\n位包含目标节的 __DATA 段。最终地址是通过将基址与 Mach-O 头部中的适当节偏移量组合来计算\n的。\n请注意，在 macOS 上访问另一个进程的内存通常需要提升权限——要么是 root 访问权限，要么是\n授予调试进程的特殊安全权限。\nWindows (PE)\n在 Windows 上查找 PyRuntime 结构： |  |\n\n1. 使用 ToolHelp API 枚举目标进程中加载的所有模块。这通过使用如\nCreateToolhelp32Snapshot, Module32First, 和 Module32Next 等函数来完成。\n2. 识别对应于 python.exe 或 pythonXY.dll 的模块，其中 X 和 Y 是 Python 版本的主次版本\n号，并记录其基址。\n3. 定位 PyRuntim 节。由于 PE 格式对节名称有 8 个字符的限制（定义为\nIMAGE_SIZEOF_SHORT_NAME），原始名称 PyRuntime 被截断。此节包含 PyRuntime 结构。\n4. 检索节的相对虚拟地址（RVA），并将其添加到模块的基址。\n以下是一个示例实现：\ndef find_py_runtime_windows(pid: int) -> int:\n# 步骤 1：尝试在内存中找到 Python 可执行文件\nbinary_path, base_address = find_loaded_module(\npid, name_contains=\"python\"\n)\n# 步骤2：如果可执行文件未找到，则回退到共享的pythonXY.dll\n#\nif binary_path is None:\nbinary_path, base_address = find_loaded_module(\npid, name_contains=\"python3\"\n)\n# 步骤 3：解析 PE 节头以获取 PyRuntime 节的相对虚拟地址（RVA）。\n# 由于 PE 格式（IMAGE_SIZEOF_SHORT_NAME）规定的 8 字符限制，\n# 该节的名称显示为“PyRuntim”。.\nsection_rva = parse_pe_section_offset(binary_path, \"PyRuntim\")\n# 步骤4：计算内存中的PyRuntime地址\nreturn base_address + section_rva\n在Windows上，访问另一个进程的内存需要使用Windows API函数，如\nCreateToolhelp32Snapshot() 和 Module32First()/Module32Next() 来枚举已加载的模块。\nOpenProcess() 函数提供了一个句柄，用于访问目标进程的内存空间，通过 ReadProcessMemory()\n实现内存操作。\n可以通过枚举已加载的模块来检查进程内存，以找到Python二进制文件或DLL。找到后，需要解析其\nPE头以定位 PyRuntime 结构。\nPE 格式将代码和数据组织到节中。 PyRuntime 结构位于名为 \"PyRuntim\" 的节中（由于 PE 的 8 字\n符名称限制，从 \"PyRuntime\" 截断）。 实际的运行时地址计算涉及从模块入口找到模块的基址，然\n后在 PE 头中定位目标节。最终地址是通过将基址与PE节头中的节的虚拟地址组合来计算的。\n请注意，在Windows上访问另一个进程的内存通常需要适当的权限——要么是管理员访问权限，要\n么是授予调试进程的 SeDebugPrivilege 权限。\n读取_Py_DebugOffsets\n一旦确定了 PyRuntime 结构的地址，下一步就是读取位于 PyRuntime 块开头的 _Py_DebugOffsets\n结构。\n\n|  | 1. 使用 ToolHelp API 枚举目标进程中加载的所有模块。这通过使用如\nCreateToolhelp32Snapshot, Module32First, 和 Module32Next 等函数来完成。\n2. 识别对应于 python.exe 或 pythonXY.dll 的模块，其中 X 和 Y 是 Python 版本的主次版本\n号，并记录其基址。\n3. 定位 PyRuntim 节。由于 PE 格式对节名称有 8 个字符的限制（定义为\nIMAGE_SIZEOF_SHORT_NAME），原始名称 PyRuntime 被截断。此节包含 PyRuntime 结构。\n4. 检索节的相对虚拟地址（RVA），并将其添加到模块的基址。\n以下是一个示例实现： |  |\n| --- | --- | --- |\n|  | def find_py_runtime_windows(pid: int) -> int:\n# 步骤 1：尝试在内存中找到 Python 可执行文件\nbinary_path, base_address = find_loaded_module(\npid, name_contains=\"python\"\n)\n# 步骤2：如果可执行文件未找到，则回退到共享的pythonXY.dll\n#\nif binary_path is None:\nbinary_path, base_address = find_loaded_module(\npid, name_contains=\"python3\"\n)\n# 步骤 3：解析 PE 节头以获取 PyRuntime 节的相对虚拟地址（RVA）。\n# 由于 PE 格式（IMAGE_SIZEOF_SHORT_NAME）规定的 8 字符限制，\n# 该节的名称显示为“PyRuntim”。.\nsection_rva = parse_pe_section_offset(binary_path, \"PyRuntim\")\n# 步骤4：计算内存中的PyRuntime地址\nreturn base_address + section_rva |  |\n|  | 在Windows上，访问另一个进程的内存需要使用Windows API函数，如\nCreateToolhelp32Snapshot() 和 Module32First()/Module32Next() 来枚举已加载的模块。\nOpenProcess() 函数提供了一个句柄，用于访问目标进程的内存空间，通过 ReadProcessMemory()\n实现内存操作。\n可以通过枚举已加载的模块来检查进程内存，以找到Python二进制文件或DLL。找到后，需要解析其\nPE头以定位 PyRuntime 结构。\nPE 格式将代码和数据组织到节中。 PyRuntime 结构位于名为 \"PyRuntim\" 的节中（由于 PE 的 8 字\n符名称限制，从 \"PyRuntime\" 截断）。 实际的运行时地址计算涉及从模块入口找到模块的基址，然\n后在 PE 头中定位目标节。最终地址是通过将基址与PE节头中的节的虚拟地址组合来计算的。\n请注意，在Windows上访问另一个进程的内存通常需要适当的权限——要么是管理员访问权限，要\n么是授予调试进程的 SeDebugPrivilege 权限。\n读取_Py_DebugOffsets\n一旦确定了 PyRuntime 结构的地址，下一步就是读取位于 PyRuntime 块开头的 _Py_DebugOffsets\n结构。 |  |\n\n该结构提供了特定版本的字段偏移量，这些偏移量用于安全地读取解释器和线程状态内存。这些偏\n移量在CPython版本之间有所变化，必须在使用前进行检查以确保它们是兼容的。\n要读取和检查调试偏移量，请按照以下步骤操作：\n1. 从目标进程的 PyRuntime 地址开始读取内存，覆盖的字节数与 _Py_DebugOffsets 结构相\n同。该结构位于 PyRuntime 内存块的起始位置。其布局在CPython的内部头文件中定义，并\n在给定的小版本中保持不变，但在大版本中可能会发生变化。\n2. 检查该结构是否包含有效数据：\ncookie 字段必须与预期的调试标记匹配。\nversion 字段必须与调试器使用的Python解释器版本匹配。\n如果调试器或目标进程使用的是预发布版本（例如，alpha、beta或发布候选版本），则版\n本必须完全匹配。\nfree_threaded 字段在调试器和目标进程中必须具有相同的值。\n3. 如果结构体有效，其中包含的偏移量可以用于定位内存中的字段。如果任何检查失败，调试器\n应停止操作，以避免以错误格式读取内存。\n以下是一个读取和检查 _Py_DebugOffsets 的示例实现：\ndef read_debug_offsets(pid: int, py_runtime_addr: int) -> DebugOffsets:\n# 步骤1：从目标进程中读取PyRuntime地址处的内存\ndata = read_process_memory(\npid, address=py_runtime_addr, size=DEBUG_OFFSETS_SIZE\n)\n# 第2步：将原始字节反序列化为_Py_DebugOffsets结构体\ndebug_offsets = parse_debug_offsets(data)\n# 步骤3：验证结构体的内容\nif debug_offsets.cookie != EXPECTED_COOKIE:\nraise RuntimeError(\"Invalid or missing debug cookie\")\nif debug_offsets.version != LOCAL_PYTHON_VERSION:\nraise RuntimeError(\n\"Mismatch between caller and target Python versions\"\n)\nif debug_offsets.free_threaded != LOCAL_FREE_THREADED:\nraise RuntimeError(\"Mismatch in free-threaded configuration\")\nreturn debug_offsets\n警告: 建议挂起进程\n为避免竞态条件并确保内存一致性，在执行任何读取或写入解释器内部状态的操作前，强烈建议\n先挂起目标进程。Python运行时可能在正常执行期间并发修改解释器数据结构（例如创建或销毁\n线程），这可能导致无效的内存读写操作。\n调试器可以通过使用 ptrace 附加到进程或发送 SIGSTOP 信号来挂起执行。只有在调试器端的内\n存操作完成后，才应恢复执行。\n\n|  | 该结构提供了特定版本的字段偏移量，这些偏移量用于安全地读取解释器和线程状态内存。这些偏\n移量在CPython版本之间有所变化，必须在使用前进行检查以确保它们是兼容的。\n要读取和检查调试偏移量，请按照以下步骤操作：\n1. 从目标进程的 PyRuntime 地址开始读取内存，覆盖的字节数与 _Py_DebugOffsets 结构相\n同。该结构位于 PyRuntime 内存块的起始位置。其布局在CPython的内部头文件中定义，并\n在给定的小版本中保持不变，但在大版本中可能会发生变化。\n2. 检查该结构是否包含有效数据：\ncookie 字段必须与预期的调试标记匹配。\nversion 字段必须与调试器使用的Python解释器版本匹配。\n如果调试器或目标进程使用的是预发布版本（例如，alpha、beta或发布候选版本），则版\n本必须完全匹配。\nfree_threaded 字段在调试器和目标进程中必须具有相同的值。\n3. 如果结构体有效，其中包含的偏移量可以用于定位内存中的字段。如果任何检查失败，调试器\n应停止操作，以避免以错误格式读取内存。\n以下是一个读取和检查 _Py_DebugOffsets 的示例实现： |  |\n| --- | --- | --- |\n|  | def read_debug_offsets(pid: int, py_runtime_addr: int) -> DebugOffsets:\n# 步骤1：从目标进程中读取PyRuntime地址处的内存\ndata = read_process_memory(\npid, address=py_runtime_addr, size=DEBUG_OFFSETS_SIZE\n)\n# 第2步：将原始字节反序列化为_Py_DebugOffsets结构体\ndebug_offsets = parse_debug_offsets(data)\n# 步骤3：验证结构体的内容\nif debug_offsets.cookie != EXPECTED_COOKIE:\nraise RuntimeError(\"Invalid or missing debug cookie\")\nif debug_offsets.version != LOCAL_PYTHON_VERSION:\nraise RuntimeError(\n\"Mismatch between caller and target Python versions\"\n)\nif debug_offsets.free_threaded != LOCAL_FREE_THREADED:\nraise RuntimeError(\"Mismatch in free-threaded configuration\")\nreturn debug_offsets |  |\n|  |  |  |\n|  | 警告: 建议挂起进程\n为避免竞态条件并确保内存一致性，在执行任何读取或写入解释器内部状态的操作前，强烈建议\n先挂起目标进程。Python运行时可能在正常执行期间并发修改解释器数据结构（例如创建或销毁\n线程），这可能导致无效的内存读写操作。\n调试器可以通过使用 ptrace 附加到进程或发送 SIGSTOP 信号来挂起执行。只有在调试器端的内\n存操作完成后，才应恢复执行。 |  |\n\n备注: 一些工具，如性能分析器或基于采样的调试器，可以在不挂起运行进程的情况下操作。\n在这种情况下，工具必须明确设计以处理部分更新或不一致的内存。对于大多数调试器实现来\n说，挂起进程仍然是最安全、最稳健的方法。\n定位解释器和线程状态\n在远程Python进程中注入并执行代码前，调试器必须选定一个目标线程来调度执行。这是因为用于\n远程代码注入的控制字段位于 _PyRemoteDebuggerSupport 结构体中，而该结构体又嵌入在\nPyThreadState 对象内。调试器通过修改这些字段来请求执行已注入的脚本。\nPyThreadState 结构体表示在Python解释器内运行的线程。它维护线程的求值上下文，并包含调试\n器协调所需的字段。因此，定位一个有效的 PyThreadState 是触发远程执行的关键前提。\n通常基于线程的角色或ID来选择线程。在大多数情况下，使用主线程，但一些工具可能通过其本地\n线程ID定位特定线程。一旦选择了目标线程，调试器必须在内存中定位解释器和相关的线程状态结\n构。\n相关内部结构体定义如下：\nPyInterpreterState 表示一个隔离的Python解释器实例。每个解释器维护其自己的导入模块\n集、内置状态和线程状态列表。尽管大多数Python应用程序使用单个解释器，但CPython支持在\n同一进程中使用多个解释器。\nPyThreadState 表示在解释器内运行的线程。它包含执行状态和调试器使用的控制字段。\n要定位一个线程：\n1. 使用偏移量 runtime_state.interpreters_head 获取 PyRuntime 结构体中第一个解释器的\n地址。这是活动解释器链表的入口点。\n2. 使用偏移量 interpreter_state.threads_main 访问与选定解释器相关联的主线程状态。这\n通常是目标的最可靠线程。\n3. 可选地，使用偏移量 interpreter_state.threads_head 遍历所有线程状态的链表。每个\nPyThreadState 结构体包含一个 native_thread_id 字段，可以将其与目标线程 ID 进行比\n较以找到特定线程。\n4. 一旦找到有效的 PyThreadState，其地址可以在协议的后续步骤中使用，例如写入调试器控\n制字段和调度执行。\n以下是一个定位主线程状态的示例实现:\ndef find_main_thread_state(\npid: int, py_runtime_addr: int, debug_offsets: DebugOffsets,\n) -> int:\n# 步骤 1：从 PyRuntime 中读取 interpreters_head\ninterp_head_ptr = (\npy_runtime_addr + debug_offsets.runtime_state.interpreters_head\n)\ninterp_addr = read_pointer(pid, interp_head_ptr)\nif interp_addr == 0:\n\n|  | 备注: 一些工具，如性能分析器或基于采样的调试器，可以在不挂起运行进程的情况下操作。\n在这种情况下，工具必须明确设计以处理部分更新或不一致的内存。对于大多数调试器实现来\n说，挂起进程仍然是最安全、最稳健的方法。 |  |\n| --- | --- | --- |\n|  | 定位解释器和线程状态\n在远程Python进程中注入并执行代码前，调试器必须选定一个目标线程来调度执行。这是因为用于\n远程代码注入的控制字段位于 _PyRemoteDebuggerSupport 结构体中，而该结构体又嵌入在\nPyThreadState 对象内。调试器通过修改这些字段来请求执行已注入的脚本。\nPyThreadState 结构体表示在Python解释器内运行的线程。它维护线程的求值上下文，并包含调试\n器协调所需的字段。因此，定位一个有效的 PyThreadState 是触发远程执行的关键前提。\n通常基于线程的角色或ID来选择线程。在大多数情况下，使用主线程，但一些工具可能通过其本地\n线程ID定位特定线程。一旦选择了目标线程，调试器必须在内存中定位解释器和相关的线程状态结\n构。\n相关内部结构体定义如下：\nPyInterpreterState 表示一个隔离的Python解释器实例。每个解释器维护其自己的导入模块\n集、内置状态和线程状态列表。尽管大多数Python应用程序使用单个解释器，但CPython支持在\n同一进程中使用多个解释器。\nPyThreadState 表示在解释器内运行的线程。它包含执行状态和调试器使用的控制字段。\n要定位一个线程：\n1. 使用偏移量 runtime_state.interpreters_head 获取 PyRuntime 结构体中第一个解释器的\n地址。这是活动解释器链表的入口点。\n2. 使用偏移量 interpreter_state.threads_main 访问与选定解释器相关联的主线程状态。这\n通常是目标的最可靠线程。\n3. 可选地，使用偏移量 interpreter_state.threads_head 遍历所有线程状态的链表。每个\nPyThreadState 结构体包含一个 native_thread_id 字段，可以将其与目标线程 ID 进行比\n较以找到特定线程。\n4. 一旦找到有效的 PyThreadState，其地址可以在协议的后续步骤中使用，例如写入调试器控\n制字段和调度执行。\n以下是一个定位主线程状态的示例实现: |  |\n|  | def find_main_thread_state(\npid: int, py_runtime_addr: int, debug_offsets: DebugOffsets,\n) -> int:\n# 步骤 1：从 PyRuntime 中读取 interpreters_head\ninterp_head_ptr = (\npy_runtime_addr + debug_offsets.runtime_state.interpreters_head\n)\ninterp_addr = read_pointer(pid, interp_head_ptr)\nif interp_addr == 0: |  |\n\nraise RuntimeError(\"在目标进程中没有找到解释器\")\n# 步骤2：从解释器中读取threads_main指针\nthreads_main_ptr = (\ninterp_addr + debug_offsets.interpreter_state.threads_main\n)\nthread_state_addr = read_pointer(pid, threads_main_ptr)\nif thread_state_addr == 0:\nraise RuntimeError(\"主线程状态不可用\")\nreturn thread_state_addr\n以下示例演示了如何通过其本地线程 ID 定位线程:\ndef find_thread_by_id(\npid: int,\ninterp_addr: int,\ndebug_offsets: DebugOffsets,\ntarget_tid: int,\n) -> int:\n# 从 threads_head 开始遍历链表\nthread_ptr = read_pointer(\npid,\ninterp_addr + debug_offsets.interpreter_state.threads_head\n)\nwhile thread_ptr:\nnative_tid_ptr = (\nthread_ptr + debug_offsets.thread_state.native_thread_id\n)\nnative_tid = read_int(pid, native_tid_ptr)\nif native_tid == target_tid:\nreturn thread_ptr\nthread_ptr = read_pointer(\npid,\nthread_ptr + debug_offsets.thread_state.next\n)\nraise RuntimeError(\"没有找到给定ID的线程\")\n一旦定位到有效的线程状态，调试器可以继续修改其控制字段并调度执行，如下一节所述。\n写入控制信息\n一旦识别出有效的 PyThreadState 结构体，调试器可以修改其中的控制字段以调度指定 Python 脚\n本的执行。这些控制字段由解释器定期检查，当正确设置时，它们会在求值循环的安全点触发远程\n代码的执行。\n每个 PyThreadState 包含一个 _PyRemoteDebuggerSupport 结构体，用于调试器和解释器之间的\n通信。其字段的位置由 _Py_DebugOffsets 结构体定义，包括以下内容：\ndebugger_script_path：一个固定大小的缓冲区，用于存储 Python 源文件（.py）的完整路\n径。当触发执行时，目标进程必须能够访问并读取该文件。\n\n|  | raise RuntimeError(\"在目标进程中没有找到解释器\")\n# 步骤2：从解释器中读取threads_main指针\nthreads_main_ptr = (\ninterp_addr + debug_offsets.interpreter_state.threads_main\n)\nthread_state_addr = read_pointer(pid, threads_main_ptr)\nif thread_state_addr == 0:\nraise RuntimeError(\"主线程状态不可用\")\nreturn thread_state_addr |  |\n| --- | --- | --- |\n|  | 以下示例演示了如何通过其本地线程 ID 定位线程: |  |\n|  | def find_thread_by_id(\npid: int,\ninterp_addr: int,\ndebug_offsets: DebugOffsets,\ntarget_tid: int,\n) -> int:\n# 从 threads_head 开始遍历链表\nthread_ptr = read_pointer(\npid,\ninterp_addr + debug_offsets.interpreter_state.threads_head\n)\nwhile thread_ptr:\nnative_tid_ptr = (\nthread_ptr + debug_offsets.thread_state.native_thread_id\n)\nnative_tid = read_int(pid, native_tid_ptr)\nif native_tid == target_tid:\nreturn thread_ptr\nthread_ptr = read_pointer(\npid,\nthread_ptr + debug_offsets.thread_state.next\n)\nraise RuntimeError(\"没有找到给定ID的线程\") |  |\n|  | 一旦定位到有效的线程状态，调试器可以继续修改其控制字段并调度执行，如下一节所述。\n写入控制信息\n一旦识别出有效的 PyThreadState 结构体，调试器可以修改其中的控制字段以调度指定 Python 脚\n本的执行。这些控制字段由解释器定期检查，当正确设置时，它们会在求值循环的安全点触发远程\n代码的执行。\n每个 PyThreadState 包含一个 _PyRemoteDebuggerSupport 结构体，用于调试器和解释器之间的\n通信。其字段的位置由 _Py_DebugOffsets 结构体定义，包括以下内容：\ndebugger_script_path：一个固定大小的缓冲区，用于存储 Python 源文件（.py）的完整路\n径。当触发执行时，目标进程必须能够访问并读取该文件。 |  |\n\ndebugger_pending_call：一个整数型旗标。将其设为 1 表示告知解释器已有脚本准备就绪等待\n执行。\neval_breaker：解释器在执行过程中会检查的字段。设置该字段的第5位\n（_PY_EVAL_PLEASE_STOP_BIT，值为 1U << 5）将使解释器暂停并检查调试器活动。\n要完成注入，调试器必须执行以下步骤：\n1. 将完整脚本路径写入 debugger_script_path 缓冲区。\n2. 将 debugger_pending_call 设置为 1。\n3. 读取 eval_breaker 的当前值，设置位 5 (_PY_EVAL_PLEASE_STOP_BIT)，并将更新后的值写\n回。这会指示解释器检查调试器活动。\n以下是一个示例实现：\ndef inject_script(\npid: int,\nthread_state_addr: int,\ndebug_offsets: DebugOffsets,\nscript_path: str\n) -> None:\n# 计算 _PyRemoteDebuggerSupport 的基准偏移量\nsupport_base = (\nthread_state_addr +\ndebug_offsets.debugger_support.remote_debugger_support\n)\n# 步骤 1：将脚本路径写入 debugger_script_path\nscript_path_ptr = (\nsupport_base +\ndebug_offsets.debugger_support.debugger_script_path\n)\nwrite_string(pid, script_path_ptr, script_path)\n# 步骤 2：将 debugger_pending_call 设置为 1\npending_ptr = (\nsupport_base +\ndebug_offsets.debugger_support.debugger_pending_call\n)\nwrite_int(pid, pending_ptr, 1)\n# 步骤 3：在 eval_breaker 中设置 _PY_EVAL_PLEASE_STOP_BIT\n# （第 5 位，值为 1 << 5）\neval_breaker_ptr = (\nthread_state_addr +\ndebug_offsets.debugger_support.eval_breaker\n)\nbreaker = read_int(pid, eval_breaker_ptr)\nbreaker |= (1 << 5)\nwrite_int(pid, eval_breaker_ptr, breaker)\n设置这些字段后，调试器可以恢复进程（如果它被挂起）。解释器将在下一个安全求值点处理请\n求，从磁盘加载脚本并执行它。\n调试器有责任确保脚本文件在执行期间对目标进程保持存在和可访问。\n\n|  | debugger_pending_call：一个整数型旗标。将其设为 1 表示告知解释器已有脚本准备就绪等待\n执行。\neval_breaker：解释器在执行过程中会检查的字段。设置该字段的第5位\n（_PY_EVAL_PLEASE_STOP_BIT，值为 1U << 5）将使解释器暂停并检查调试器活动。\n要完成注入，调试器必须执行以下步骤：\n1. 将完整脚本路径写入 debugger_script_path 缓冲区。\n2. 将 debugger_pending_call 设置为 1。\n3. 读取 eval_breaker 的当前值，设置位 5 (_PY_EVAL_PLEASE_STOP_BIT)，并将更新后的值写\n回。这会指示解释器检查调试器活动。\n以下是一个示例实现： |  |\n| --- | --- | --- |\n|  | def inject_script(\npid: int,\nthread_state_addr: int,\ndebug_offsets: DebugOffsets,\nscript_path: str\n) -> None:\n# 计算 _PyRemoteDebuggerSupport 的基准偏移量\nsupport_base = (\nthread_state_addr +\ndebug_offsets.debugger_support.remote_debugger_support\n)\n# 步骤 1：将脚本路径写入 debugger_script_path\nscript_path_ptr = (\nsupport_base +\ndebug_offsets.debugger_support.debugger_script_path\n)\nwrite_string(pid, script_path_ptr, script_path)\n# 步骤 2：将 debugger_pending_call 设置为 1\npending_ptr = (\nsupport_base +\ndebug_offsets.debugger_support.debugger_pending_call\n)\nwrite_int(pid, pending_ptr, 1)\n# 步骤 3：在 eval_breaker 中设置 _PY_EVAL_PLEASE_STOP_BIT\n# （第 5 位，值为 1 << 5）\neval_breaker_ptr = (\nthread_state_addr +\ndebug_offsets.debugger_support.eval_breaker\n)\nbreaker = read_int(pid, eval_breaker_ptr)\nbreaker |= (1 << 5)\nwrite_int(pid, eval_breaker_ptr, breaker) |  |\n|  | 设置这些字段后，调试器可以恢复进程（如果它被挂起）。解释器将在下一个安全求值点处理请\n求，从磁盘加载脚本并执行它。\n调试器有责任确保脚本文件在执行期间对目标进程保持存在和可访问。 |  |\n\n备注: 脚本执行是异步的。注入脚本后不能立即删除脚本文件。调试器应等待注入脚本产生可观\n察的效果后再删除文件。这个效果取决于脚本的设计目的。例如，调试器可能会等待远程进程连\n接回套接字后再删除脚本。一旦观察到此类效果，可以安全地假设文件不再需要。\n总结\n要在远程进程中注入并执行 Python 脚本：\n1. 在目标进程的内存中定位 PyRuntime 结构体。\n2. 读取并验证 PyRuntime 开头的 _Py_DebugOffsets 结构体。\n3. 使用该偏移量来定位一个有效的 PyThreadState。\n4. 将一个 Python 脚本的路径写入到 debugger_script_path。\n5. 将 debugger_pending_call 旗标设为 1。\n6. 设置 eval_breaker 字段中的 _PY_EVAL_PLEASE_STOP_BIT。\n7. 恢复进程（如已挂起）。 脚本将在下一个安全求值点开始执行。\n\n| 备注: 脚本执行是异步的。注入脚本后不能立即删除脚本文件。调试器应等待注入脚本产生可观\n察的效果后再删除文件。这个效果取决于脚本的设计目的。例如，调试器可能会等待远程进程连\n接回套接字后再删除脚本。一旦观察到此类效果，可以安全地假设文件不再需要。 |\n| --- |\n| 总结\n要在远程进程中注入并执行 Python 脚本：\n1. 在目标进程的内存中定位 PyRuntime 结构体。\n2. 读取并验证 PyRuntime 开头的 _Py_DebugOffsets 结构体。\n3. 使用该偏移量来定位一个有效的 PyThreadState。\n4. 将一个 Python 脚本的路径写入到 debugger_script_path。\n5. 将 debugger_pending_call 旗标设为 1。\n6. 设置 eval_breaker 字段中的 _PY_EVAL_PLEASE_STOP_BIT。\n7. 恢复进程（如已挂起）。 脚本将在下一个安全求值点开始执行。 |", "metadata": {"title": "25_远程调试附加协议", "source": "md_docs\\python_howto_md\\25_远程调试附加协议.md", "doc_type": "指南", "language": "中文", "doc_id": "403cbd9d"}}
